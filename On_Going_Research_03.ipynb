{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RafsanJany-44/ARC/blob/master/On_Going_Research_03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTfbltWs4jaf"
      },
      "source": [
        "# ReneWind\n",
        "\n",
        "Renewable energy sources play an increasingly important role in the global energy mix, as the effort to reduce the environmental impact of energy production increases.\n",
        "\n",
        "Out of all the renewable energy alternatives, wind energy is one of the most developed technologies worldwide. The U.S Department of Energy has put together a guide to achieving operational efficiency using predictive maintenance practices.\n",
        "\n",
        "Predictive maintenance uses sensor information and analysis methods to measure and predict degradation and future component capability. The idea behind predictive maintenance is that failure patterns are predictable and if component failure can be predicted accurately and the component is replaced before it fails, the costs of operation and maintenance will be much lower.\n",
        "\n",
        "The sensors fitted across different machines involved in the process of energy generation collect data related to various environmental factors (temperature, humidity, wind speed, etc.) and additional features related to various parts of the wind turbine (gearbox, tower, blades, break, etc.). \n",
        "\n",
        "\n",
        "\n",
        "## Objective\n",
        "“ReneWind” is a company working on improving the machinery/processes involved in the production of wind energy using machine learning and has collected data of generator failure of wind turbines using sensors. They have shared a ciphered version of the data, as the data collected through sensors is confidential (the type of data collected varies with companies). Data has 40 predictors, 40000 observations in the training set and 10000 in the test set.\n",
        "\n",
        "The objective is to build various classification models, tune them and find the best one that will help identify failures so that the generator could be repaired before failing/breaking and the overall maintenance cost of the generators can be brought down. \n",
        "\n",
        "“1” in the target variables should be considered as “failure” and “0” will represent “No failure”.\n",
        "\n",
        "The nature of predictions made by the classification model will translate as follows:\n",
        "\n",
        "- True positives (TP) are failures correctly predicted by the model.\n",
        "- False negatives (FN) are real failures in a wind turbine where there is no detection by model. \n",
        "- False positives (FP) are detections in a wind turbine where there is no failure. \n",
        "\n",
        "So, the maintenance cost associated with the model would be:\n",
        "\n",
        "**Maintenance cost** = `TP*(Repair cost) + FN*(Replacement cost) + FP*(Inspection cost)`\n",
        "where,\n",
        "\n",
        "- `Replacement cost = $40,000`\n",
        "- `Repair cost = $15,000`\n",
        "- `Inspection cost = $5,000`\n",
        "\n",
        "Here the objective is to reduce the maintenance cost so, we want a metric that could reduce the maintenance cost.\n",
        "\n",
        "- The minimum possible maintenance cost  =  `Actual failures*(Repair cost) = (TP + FN)*(Repair cost)`\n",
        "- The maintenance cost associated with model = `TP*(Repair cost) + FN*(Replacement cost) + FP*(Inspection cost)`\n",
        "\n",
        "So, we will try to maximize the ratio of minimum possible maintenance cost and the maintenance cost associated with the model.\n",
        "\n",
        "The value of this ratio will lie between 0 and 1, the ratio will be 1 only when the maintenance cost associated with the model will be equal to the minimum possible maintenance cost.\n",
        "\n",
        "## Data Description\n",
        "- The data provided is a transformed version of original data which was collected using sensors.\n",
        "- Train.csv - To be used for training and tuning of models. \n",
        "- Test.csv - To be used only for testing the performance of the final best model.\n",
        "- Both the datasets consist of 40 predictor variables and 1 target variable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjFpJBnb4jak"
      },
      "source": [
        "## Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ujP6RVWWCYyl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9af4ceb6-5bbd-4930-8b7d-1c3537ee79f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting nb-black\n",
            "  Downloading nb_black-1.0.7.tar.gz (4.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.8/dist-packages (from nb-black) (7.9.0)\n",
            "Collecting black>='19.3'\n",
            "  Downloading black-23.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/lib/python3.8/dist-packages (from black>='19.3'->nb-black) (4.5.0)\n",
            "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.8/dist-packages (from black>='19.3'->nb-black) (23.0)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.8/dist-packages (from black>='19.3'->nb-black) (3.0.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from black>='19.3'->nb-black) (2.0.1)\n",
            "Collecting pathspec>=0.9.0\n",
            "  Downloading pathspec-0.11.0-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.8/dist-packages (from black>='19.3'->nb-black) (8.1.3)\n",
            "Collecting mypy-extensions>=0.4.3\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipython->nb-black) (5.7.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython->nb-black) (0.7.5)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython->nb-black) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython->nb-black) (2.0.10)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython->nb-black) (0.2.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython->nb-black) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython->nb-black) (2.6.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.8/dist-packages (from ipython->nb-black) (57.4.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython->nb-black) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->nb-black) (0.2.6)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->nb-black) (1.15.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->ipython->nb-black) (0.7.0)\n",
            "Building wheels for collected packages: nb-black\n",
            "  Building wheel for nb-black (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nb-black: filename=nb_black-1.0.7-py3-none-any.whl size=5298 sha256=5768059a8b293d5ab2bcb72d3dee60bd94f9bb24694a1d99e893b37453aaeaaf\n",
            "  Stored in directory: /root/.cache/pip/wheels/a6/5e/1e/a15614d6ea220d070043db3b650d73a8b4938aefd520496c11\n",
            "Successfully built nb-black\n",
            "Installing collected packages: pathspec, mypy-extensions, jedi, black, nb-black\n",
            "Successfully installed black-23.1.0 jedi-0.18.2 mypy-extensions-1.0.0 nb-black-1.0.7 pathspec-0.11.0\n"
          ]
        }
      ],
      "source": [
        "!pip install nb-black"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "LhLaJgVPCYym",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26a84367-8268-4235-857c-9ca7a84f58ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imblearn in /usr/local/lib/python3.8/dist-packages (0.0)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.8/dist-packages (from imblearn) (0.8.1)\n",
            "Requirement already satisfied: scikit-learn>=0.24 in /usr/local/lib/python3.8/dist-packages (from imbalanced-learn->imblearn) (1.2.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.8/dist-packages (from imbalanced-learn->imblearn) (1.22.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from imbalanced-learn->imblearn) (1.2.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.8/dist-packages (from imbalanced-learn->imblearn) (1.10.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.24->imbalanced-learn->imblearn) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install imblearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "83D17_Wl4jal",
        "outputId": "41755aa9-2a09-4525-d748-cfc538f54a1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 4;\n",
              "                var nbb_unformatted_code = \"# To help with reading and manipulating data\\nimport pandas as pd\\nimport numpy as np\\n\\n# To help with data visualization\\n%matplotlib inline\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\n\\n# To be used for missing value imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# To help with model building\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.tree import DecisionTreeClassifier\\nfrom sklearn.ensemble import (\\n    AdaBoostClassifier,\\n    GradientBoostingClassifier,\\n    RandomForestClassifier,\\n    BaggingClassifier,\\n)\\nfrom xgboost import XGBClassifier\\n\\n# To get different metric scores, and split data\\nfrom sklearn import metrics\\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\\nfrom sklearn.metrics import (\\n    f1_score,\\n    accuracy_score,\\n    recall_score,\\n    precision_score,\\n    confusion_matrix,\\n    roc_auc_score,\\n    ConfusionMatrixDisplay\\n)\\n\\n# To oversample and undersample data\\nfrom imblearn.over_sampling import SMOTE\\nfrom imblearn.under_sampling import RandomUnderSampler\\n\\n# To be used for data scaling and one hot encoding\\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\\n\\n# To be used for tuning the model\\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\\n\\n# To use statistical functions\\nimport scipy.stats as stats\\n\\n# To be used for creating pipelines and personalizing them\\nfrom sklearn.pipeline import Pipeline\\nfrom sklearn.compose import ColumnTransformer\\n\\n# To define maximum number of columns to be displayed in a dataframe\\npd.set_option(\\\"display.max_columns\\\", None)\\n\\n# To supress scientific notations for a dataframe\\npd.set_option(\\\"display.float_format\\\", lambda x: \\\"%.3f\\\" % x)\\n\\n# To supress warnings\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\n# This will help in making the Python code more structured automatically (good coding practice)\\n%load_ext nb_black\";\n",
              "                var nbb_formatted_code = \"# To help with reading and manipulating data\\nimport pandas as pd\\nimport numpy as np\\n\\n# To help with data visualization\\n%matplotlib inline\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\n\\n# To be used for missing value imputation\\nfrom sklearn.impute import SimpleImputer\\n\\n# To help with model building\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.tree import DecisionTreeClassifier\\nfrom sklearn.ensemble import (\\n    AdaBoostClassifier,\\n    GradientBoostingClassifier,\\n    RandomForestClassifier,\\n    BaggingClassifier,\\n)\\nfrom xgboost import XGBClassifier\\n\\n# To get different metric scores, and split data\\nfrom sklearn import metrics\\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\\nfrom sklearn.metrics import (\\n    f1_score,\\n    accuracy_score,\\n    recall_score,\\n    precision_score,\\n    confusion_matrix,\\n    roc_auc_score,\\n    ConfusionMatrixDisplay,\\n)\\n\\n# To oversample and undersample data\\nfrom imblearn.over_sampling import SMOTE\\nfrom imblearn.under_sampling import RandomUnderSampler\\n\\n# To be used for data scaling and one hot encoding\\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\\n\\n# To be used for tuning the model\\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\\n\\n# To use statistical functions\\nimport scipy.stats as stats\\n\\n# To be used for creating pipelines and personalizing them\\nfrom sklearn.pipeline import Pipeline\\nfrom sklearn.compose import ColumnTransformer\\n\\n# To define maximum number of columns to be displayed in a dataframe\\npd.set_option(\\\"display.max_columns\\\", None)\\n\\n# To supress scientific notations for a dataframe\\npd.set_option(\\\"display.float_format\\\", lambda x: \\\"%.3f\\\" % x)\\n\\n# To supress warnings\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\n# This will help in making the Python code more structured automatically (good coding practice)\\n%load_ext nb_black\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# To help with reading and manipulating data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# To help with data visualization\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# To be used for missing value imputation\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# To help with model building\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import (\n",
        "    AdaBoostClassifier,\n",
        "    GradientBoostingClassifier,\n",
        "    RandomForestClassifier,\n",
        "    BaggingClassifier,\n",
        ")\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# To get different metric scores, and split data\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
        "from sklearn.metrics import (\n",
        "    f1_score,\n",
        "    accuracy_score,\n",
        "    recall_score,\n",
        "    precision_score,\n",
        "    confusion_matrix,\n",
        "    roc_auc_score,\n",
        "    ConfusionMatrixDisplay\n",
        ")\n",
        "\n",
        "# To oversample and undersample data\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "# To be used for data scaling and one hot encoding\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
        "\n",
        "# To be used for tuning the model\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "\n",
        "# To use statistical functions\n",
        "import scipy.stats as stats\n",
        "\n",
        "# To be used for creating pipelines and personalizing them\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# To define maximum number of columns to be displayed in a dataframe\n",
        "pd.set_option(\"display.max_columns\", None)\n",
        "\n",
        "# To supress scientific notations for a dataframe\n",
        "pd.set_option(\"display.float_format\", lambda x: \"%.3f\" % x)\n",
        "\n",
        "# To supress warnings\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# This will help in making the Python code more structured automatically (good coding practice)\n",
        "%load_ext nb_black"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqF4q7G94jam"
      },
      "source": [
        "## Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "oJnKoHy14jam",
        "outputId": "52208e53-c666-4eec-8da8-fbc1b85937cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 16;\n",
              "                var nbb_unformatted_code = \"# Loading the dataset\\ntrain = pd.read_csv('https://raw.githubusercontent.com/RafsanJany-44/Machine-School/main/datasets/FiveStageSleep_Small_dataset.csv')\\n\\ntrain = train.loc[:,train.columns != \\\"Unnamed: 0\\\"]\\ntrain = train.loc[:,train.columns != \\\"Epoch\\\"]\\ntrain = train.loc[:,train.columns != \\\"Subject\\\"]\";\n",
              "                var nbb_formatted_code = \"# Loading the dataset\\ntrain = pd.read_csv(\\n    \\\"https://raw.githubusercontent.com/RafsanJany-44/Machine-School/main/datasets/FiveStageSleep_Small_dataset.csv\\\"\\n)\\n\\ntrain = train.loc[:, train.columns != \\\"Unnamed: 0\\\"]\\ntrain = train.loc[:, train.columns != \\\"Epoch\\\"]\\ntrain = train.loc[:, train.columns != \\\"Subject\\\"]\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Loading the dataset\n",
        "train = pd.read_csv('https://raw.githubusercontent.com/RafsanJany-44/Machine-School/main/datasets/FiveStageSleep_Small_dataset.csv')\n",
        "\n",
        "train = train.loc[:,train.columns != \"Unnamed: 0\"]\n",
        "train = train.loc[:,train.columns != \"Epoch\"]\n",
        "train = train.loc[:,train.columns != \"Subject\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "GIz4a-p4CYyq",
        "outputId": "f558ca05-141a-4522-9c9b-b97fb283baca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 76)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 17;\n",
              "                var nbb_unformatted_code = \"# Checking the number of rows and columns in the data\\ntrain.shape\";\n",
              "                var nbb_formatted_code = \"# Checking the number of rows and columns in the data\\ntrain.shape\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Checking the number of rows and columns in the data\n",
        "train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MKfv5T9CYyr"
      },
      "source": [
        "- There are 40,000 rows and 41 attributes (including the predictor) in the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwkVpNBpCYyt"
      },
      "source": [
        "## Data Overview"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "6sCFnOmeCYyu",
        "outputId": "d12b315d-56fa-4b10-ec14-4db0b62df355",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 18;\n",
              "                var nbb_unformatted_code = \"data = train.copy()\";\n",
              "                var nbb_formatted_code = \"data = train.copy()\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "data = train.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "a8Q_ew4iCYyv",
        "outputId": "a2562a8f-28b8-410c-8e1b-ec11de7ddc44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Sleep Stage  MeanP_Alpha_F4  MedianF_Alpha_F4  MeanF_Alpha_F4  \\\n",
              "0           W           0.001             8.741          18.482   \n",
              "1           W           0.000            10.240          17.483   \n",
              "2           W           0.000             9.740          17.982   \n",
              "3           W           0.000            10.115          17.608   \n",
              "4           W           0.000             9.740          17.608   \n",
              "\n",
              "   Spectral Edge_Alpha_F4  PeakF_Alpha_F4  MeanP_Beta_F4  MedianF_Beta_F4  \\\n",
              "0                  17.483           8.242          0.001           19.731   \n",
              "1                  16.859          10.615          0.001           17.233   \n",
              "2                  17.483           8.741          0.000           17.608   \n",
              "3                  17.108           9.616          0.000           17.358   \n",
              "4                  17.233           8.117          0.000           17.233   \n",
              "\n",
              "   MeanF_Beta_F4  Spectral Edge_Beta_F4  PeakF_Beta_F4  MeanP_Theta_F4  \\\n",
              "0         29.846                 33.842         15.984           0.001   \n",
              "1         26.349                 29.346         19.606           0.001   \n",
              "2         25.475                 28.222         18.732           0.001   \n",
              "3         26.474                 28.722         16.359           0.000   \n",
              "4         25.850                 28.098         17.608           0.001   \n",
              "\n",
              "   MedianF_Theta_F4  MeanF_Theta_F4  Spectral Edge_Theta_F4  PeakF_Theta_F4  \\\n",
              "0             4.246          10.490                   7.992           2.622   \n",
              "1             4.371          12.363                   9.990           2.872   \n",
              "2             4.995          12.113                   9.366           2.997   \n",
              "3             5.744          12.613                  10.365           2.123   \n",
              "4             4.745          12.238                   9.491           2.997   \n",
              "\n",
              "   MeanP_Delta_F4  MedianF_Delta_F4  MeanF_Delta_F4  Spectral Edge_Delta_F4  \\\n",
              "0           0.011             1.124           4.745                   2.622   \n",
              "1           0.005             0.874           4.496                   2.622   \n",
              "2           0.010             0.624           4.371                   1.748   \n",
              "3           0.002             0.999           5.869                   2.622   \n",
              "4           0.004             0.749           4.995                   2.622   \n",
              "\n",
              "   PeakF_Delta_F4  MeanP_Gamma_F4  MedianF_Gamma_F4  MeanF_Gamma_F4  \\\n",
              "0           1.124           0.000            36.215          43.083   \n",
              "1           0.749           0.000            34.966          46.580   \n",
              "2           0.624           0.000            34.341          49.202   \n",
              "3           0.624           0.000            32.968          46.455   \n",
              "4           0.500           0.000            34.217          49.577   \n",
              "\n",
              "   Spectral Edge_Gamma_F4  PeakF_Gamma_F4  MeanP_Alpha_C4  MedianF_Alpha_C4  \\\n",
              "0                  50.076          49.951           0.000            10.115   \n",
              "1                  49.951          49.951           0.000            10.365   \n",
              "2                  49.951          49.951           0.000            10.365   \n",
              "3                  49.951          49.951           0.000            10.115   \n",
              "4                  49.951          49.951           0.000            10.240   \n",
              "\n",
              "   MeanF_Alpha_C4  Spectral Edge_Alpha_C4  PeakF_Alpha_C4  MeanP_Beta_C4  \\\n",
              "0          19.356                  18.482          10.490          0.001   \n",
              "1          17.733                  17.358          10.115          0.001   \n",
              "2          18.107                  17.733           9.116          0.000   \n",
              "3          18.357                  17.858          10.240          0.001   \n",
              "4          17.733                  17.483          10.365          0.000   \n",
              "\n",
              "   MedianF_Beta_C4  MeanF_Beta_C4  Spectral Edge_Beta_C4  PeakF_Beta_C4  \\\n",
              "0           19.980         28.972                 33.218         16.859   \n",
              "1           17.358         26.349                 28.472         17.358   \n",
              "2           17.608         24.851                 26.849         14.236   \n",
              "3           18.857         26.349                 28.098         16.359   \n",
              "4           17.358         26.100                 28.098         17.608   \n",
              "\n",
              "   MeanP_Theta_C4  MedianF_Theta_C4  MeanF_Theta_C4  Spectral Edge_Theta_C4  \\\n",
              "0           0.001             5.245          12.238                   9.865   \n",
              "1           0.000             5.744          12.738                  10.740   \n",
              "2           0.000             5.620          12.987                  10.490   \n",
              "3           0.000             5.994          12.738                  10.490   \n",
              "4           0.000             5.744          13.112                  10.365   \n",
              "\n",
              "   PeakF_Theta_C4  MeanP_Delta_C4  MedianF_Delta_C4  MeanF_Delta_C4  \\\n",
              "0           3.871           0.004             1.124           5.495   \n",
              "1           3.621           0.002             0.999           5.869   \n",
              "2           2.997           0.003             0.749           5.744   \n",
              "3           5.869           0.001             1.124           6.494   \n",
              "4           5.744           0.001             0.874           6.119   \n",
              "\n",
              "   Spectral Edge_Delta_C4  PeakF_Delta_C4  MeanP_Gamma_C4  MedianF_Gamma_C4  \\\n",
              "0                   2.747           0.624           0.000            34.716   \n",
              "1                   2.872           0.749           0.000            31.344   \n",
              "2                   2.622           0.375           0.000            29.596   \n",
              "3                   3.122           0.749           0.000            28.472   \n",
              "4                   3.122           0.624           0.000            29.971   \n",
              "\n",
              "   MeanF_Gamma_C4  Spectral Edge_Gamma_C4  PeakF_Gamma_C4  MeanP_Alpha_O2  \\\n",
              "0          41.584                  49.951          49.951           0.000   \n",
              "1          40.835                  49.951          49.951           0.000   \n",
              "2          40.835                  49.951          49.951           0.000   \n",
              "3          39.212                  49.826          49.951           0.000   \n",
              "4          39.711                  49.826          49.951           0.000   \n",
              "\n",
              "   MedianF_Alpha_O2  MeanF_Alpha_O2  Spectral Edge_Alpha_O2  PeakF_Alpha_O2  \\\n",
              "0            10.989          20.730                  20.480          10.490   \n",
              "1            10.615          18.232                  17.858          10.615   \n",
              "2            10.740          18.107                  17.858          10.864   \n",
              "3            10.365          18.357                  18.107          10.240   \n",
              "4            10.490          18.357                  17.982          10.365   \n",
              "\n",
              "   MeanP_Beta_O2  MedianF_Beta_O2  MeanF_Beta_O2  Spectral Edge_Beta_O2  \\\n",
              "0          0.001           21.104         29.721                 34.217   \n",
              "1          0.000           17.982         27.223                 30.970   \n",
              "2          0.000           17.733         25.475                 28.472   \n",
              "3          0.000           18.232         26.724                 28.597   \n",
              "4          0.000           18.232         25.975                 28.722   \n",
              "\n",
              "   PeakF_Beta_O2  MeanP_Theta_O2  MedianF_Theta_O2  MeanF_Theta_O2  \\\n",
              "0         21.229           0.000             4.496          13.487   \n",
              "1         19.481           0.000             5.869          13.612   \n",
              "2         20.730           0.000             5.744          13.362   \n",
              "3         16.359           0.000             6.119          13.237   \n",
              "4         20.480           0.000             5.869          13.237   \n",
              "\n",
              "   Spectral Edge_Theta_O2  PeakF_Theta_O2  MeanP_Delta_O2  MedianF_Delta_O2  \\\n",
              "0                  10.740           2.248           0.007             0.749   \n",
              "1                  11.239           2.997           0.007             0.500   \n",
              "2                  11.114           5.120           0.002             0.624   \n",
              "3                  10.989           3.621           0.001             0.874   \n",
              "4                  10.989           2.997           0.002             0.500   \n",
              "\n",
              "   MeanF_Delta_O2  Spectral Edge_Delta_O2  PeakF_Delta_O2  MeanP_Gamma_O2  \\\n",
              "0           3.871                   1.998           0.874           0.000   \n",
              "1           3.746                   1.249           0.500           0.000   \n",
              "2           5.245                   2.123           0.624           0.000   \n",
              "3           6.619                   3.122           0.624           0.000   \n",
              "4           5.744                   2.248           0.500           0.000   \n",
              "\n",
              "   MedianF_Gamma_O2  MeanF_Gamma_O2  Spectral Edge_Gamma_O2  PeakF_Gamma_O2  \n",
              "0            35.216          42.209                  49.951          49.951  \n",
              "1            34.341          43.333                  49.951          49.951  \n",
              "2            34.591          45.955                  49.951          49.951  \n",
              "3            32.468          43.957                  49.951          49.951  \n",
              "4            33.592          44.831                  49.951          49.951  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-513f793c-5120-4a71-94d9-3bc1d4e9eff7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sleep Stage</th>\n",
              "      <th>MeanP_Alpha_F4</th>\n",
              "      <th>MedianF_Alpha_F4</th>\n",
              "      <th>MeanF_Alpha_F4</th>\n",
              "      <th>Spectral Edge_Alpha_F4</th>\n",
              "      <th>PeakF_Alpha_F4</th>\n",
              "      <th>MeanP_Beta_F4</th>\n",
              "      <th>MedianF_Beta_F4</th>\n",
              "      <th>MeanF_Beta_F4</th>\n",
              "      <th>Spectral Edge_Beta_F4</th>\n",
              "      <th>PeakF_Beta_F4</th>\n",
              "      <th>MeanP_Theta_F4</th>\n",
              "      <th>MedianF_Theta_F4</th>\n",
              "      <th>MeanF_Theta_F4</th>\n",
              "      <th>Spectral Edge_Theta_F4</th>\n",
              "      <th>PeakF_Theta_F4</th>\n",
              "      <th>MeanP_Delta_F4</th>\n",
              "      <th>MedianF_Delta_F4</th>\n",
              "      <th>MeanF_Delta_F4</th>\n",
              "      <th>Spectral Edge_Delta_F4</th>\n",
              "      <th>PeakF_Delta_F4</th>\n",
              "      <th>MeanP_Gamma_F4</th>\n",
              "      <th>MedianF_Gamma_F4</th>\n",
              "      <th>MeanF_Gamma_F4</th>\n",
              "      <th>Spectral Edge_Gamma_F4</th>\n",
              "      <th>PeakF_Gamma_F4</th>\n",
              "      <th>MeanP_Alpha_C4</th>\n",
              "      <th>MedianF_Alpha_C4</th>\n",
              "      <th>MeanF_Alpha_C4</th>\n",
              "      <th>Spectral Edge_Alpha_C4</th>\n",
              "      <th>PeakF_Alpha_C4</th>\n",
              "      <th>MeanP_Beta_C4</th>\n",
              "      <th>MedianF_Beta_C4</th>\n",
              "      <th>MeanF_Beta_C4</th>\n",
              "      <th>Spectral Edge_Beta_C4</th>\n",
              "      <th>PeakF_Beta_C4</th>\n",
              "      <th>MeanP_Theta_C4</th>\n",
              "      <th>MedianF_Theta_C4</th>\n",
              "      <th>MeanF_Theta_C4</th>\n",
              "      <th>Spectral Edge_Theta_C4</th>\n",
              "      <th>PeakF_Theta_C4</th>\n",
              "      <th>MeanP_Delta_C4</th>\n",
              "      <th>MedianF_Delta_C4</th>\n",
              "      <th>MeanF_Delta_C4</th>\n",
              "      <th>Spectral Edge_Delta_C4</th>\n",
              "      <th>PeakF_Delta_C4</th>\n",
              "      <th>MeanP_Gamma_C4</th>\n",
              "      <th>MedianF_Gamma_C4</th>\n",
              "      <th>MeanF_Gamma_C4</th>\n",
              "      <th>Spectral Edge_Gamma_C4</th>\n",
              "      <th>PeakF_Gamma_C4</th>\n",
              "      <th>MeanP_Alpha_O2</th>\n",
              "      <th>MedianF_Alpha_O2</th>\n",
              "      <th>MeanF_Alpha_O2</th>\n",
              "      <th>Spectral Edge_Alpha_O2</th>\n",
              "      <th>PeakF_Alpha_O2</th>\n",
              "      <th>MeanP_Beta_O2</th>\n",
              "      <th>MedianF_Beta_O2</th>\n",
              "      <th>MeanF_Beta_O2</th>\n",
              "      <th>Spectral Edge_Beta_O2</th>\n",
              "      <th>PeakF_Beta_O2</th>\n",
              "      <th>MeanP_Theta_O2</th>\n",
              "      <th>MedianF_Theta_O2</th>\n",
              "      <th>MeanF_Theta_O2</th>\n",
              "      <th>Spectral Edge_Theta_O2</th>\n",
              "      <th>PeakF_Theta_O2</th>\n",
              "      <th>MeanP_Delta_O2</th>\n",
              "      <th>MedianF_Delta_O2</th>\n",
              "      <th>MeanF_Delta_O2</th>\n",
              "      <th>Spectral Edge_Delta_O2</th>\n",
              "      <th>PeakF_Delta_O2</th>\n",
              "      <th>MeanP_Gamma_O2</th>\n",
              "      <th>MedianF_Gamma_O2</th>\n",
              "      <th>MeanF_Gamma_O2</th>\n",
              "      <th>Spectral Edge_Gamma_O2</th>\n",
              "      <th>PeakF_Gamma_O2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>W</td>\n",
              "      <td>0.001</td>\n",
              "      <td>8.741</td>\n",
              "      <td>18.482</td>\n",
              "      <td>17.483</td>\n",
              "      <td>8.242</td>\n",
              "      <td>0.001</td>\n",
              "      <td>19.731</td>\n",
              "      <td>29.846</td>\n",
              "      <td>33.842</td>\n",
              "      <td>15.984</td>\n",
              "      <td>0.001</td>\n",
              "      <td>4.246</td>\n",
              "      <td>10.490</td>\n",
              "      <td>7.992</td>\n",
              "      <td>2.622</td>\n",
              "      <td>0.011</td>\n",
              "      <td>1.124</td>\n",
              "      <td>4.745</td>\n",
              "      <td>2.622</td>\n",
              "      <td>1.124</td>\n",
              "      <td>0.000</td>\n",
              "      <td>36.215</td>\n",
              "      <td>43.083</td>\n",
              "      <td>50.076</td>\n",
              "      <td>49.951</td>\n",
              "      <td>0.000</td>\n",
              "      <td>10.115</td>\n",
              "      <td>19.356</td>\n",
              "      <td>18.482</td>\n",
              "      <td>10.490</td>\n",
              "      <td>0.001</td>\n",
              "      <td>19.980</td>\n",
              "      <td>28.972</td>\n",
              "      <td>33.218</td>\n",
              "      <td>16.859</td>\n",
              "      <td>0.001</td>\n",
              "      <td>5.245</td>\n",
              "      <td>12.238</td>\n",
              "      <td>9.865</td>\n",
              "      <td>3.871</td>\n",
              "      <td>0.004</td>\n",
              "      <td>1.124</td>\n",
              "      <td>5.495</td>\n",
              "      <td>2.747</td>\n",
              "      <td>0.624</td>\n",
              "      <td>0.000</td>\n",
              "      <td>34.716</td>\n",
              "      <td>41.584</td>\n",
              "      <td>49.951</td>\n",
              "      <td>49.951</td>\n",
              "      <td>0.000</td>\n",
              "      <td>10.989</td>\n",
              "      <td>20.730</td>\n",
              "      <td>20.480</td>\n",
              "      <td>10.490</td>\n",
              "      <td>0.001</td>\n",
              "      <td>21.104</td>\n",
              "      <td>29.721</td>\n",
              "      <td>34.217</td>\n",
              "      <td>21.229</td>\n",
              "      <td>0.000</td>\n",
              "      <td>4.496</td>\n",
              "      <td>13.487</td>\n",
              "      <td>10.740</td>\n",
              "      <td>2.248</td>\n",
              "      <td>0.007</td>\n",
              "      <td>0.749</td>\n",
              "      <td>3.871</td>\n",
              "      <td>1.998</td>\n",
              "      <td>0.874</td>\n",
              "      <td>0.000</td>\n",
              "      <td>35.216</td>\n",
              "      <td>42.209</td>\n",
              "      <td>49.951</td>\n",
              "      <td>49.951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>W</td>\n",
              "      <td>0.000</td>\n",
              "      <td>10.240</td>\n",
              "      <td>17.483</td>\n",
              "      <td>16.859</td>\n",
              "      <td>10.615</td>\n",
              "      <td>0.001</td>\n",
              "      <td>17.233</td>\n",
              "      <td>26.349</td>\n",
              "      <td>29.346</td>\n",
              "      <td>19.606</td>\n",
              "      <td>0.001</td>\n",
              "      <td>4.371</td>\n",
              "      <td>12.363</td>\n",
              "      <td>9.990</td>\n",
              "      <td>2.872</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.874</td>\n",
              "      <td>4.496</td>\n",
              "      <td>2.622</td>\n",
              "      <td>0.749</td>\n",
              "      <td>0.000</td>\n",
              "      <td>34.966</td>\n",
              "      <td>46.580</td>\n",
              "      <td>49.951</td>\n",
              "      <td>49.951</td>\n",
              "      <td>0.000</td>\n",
              "      <td>10.365</td>\n",
              "      <td>17.733</td>\n",
              "      <td>17.358</td>\n",
              "      <td>10.115</td>\n",
              "      <td>0.001</td>\n",
              "      <td>17.358</td>\n",
              "      <td>26.349</td>\n",
              "      <td>28.472</td>\n",
              "      <td>17.358</td>\n",
              "      <td>0.000</td>\n",
              "      <td>5.744</td>\n",
              "      <td>12.738</td>\n",
              "      <td>10.740</td>\n",
              "      <td>3.621</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.999</td>\n",
              "      <td>5.869</td>\n",
              "      <td>2.872</td>\n",
              "      <td>0.749</td>\n",
              "      <td>0.000</td>\n",
              "      <td>31.344</td>\n",
              "      <td>40.835</td>\n",
              "      <td>49.951</td>\n",
              "      <td>49.951</td>\n",
              "      <td>0.000</td>\n",
              "      <td>10.615</td>\n",
              "      <td>18.232</td>\n",
              "      <td>17.858</td>\n",
              "      <td>10.615</td>\n",
              "      <td>0.000</td>\n",
              "      <td>17.982</td>\n",
              "      <td>27.223</td>\n",
              "      <td>30.970</td>\n",
              "      <td>19.481</td>\n",
              "      <td>0.000</td>\n",
              "      <td>5.869</td>\n",
              "      <td>13.612</td>\n",
              "      <td>11.239</td>\n",
              "      <td>2.997</td>\n",
              "      <td>0.007</td>\n",
              "      <td>0.500</td>\n",
              "      <td>3.746</td>\n",
              "      <td>1.249</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.000</td>\n",
              "      <td>34.341</td>\n",
              "      <td>43.333</td>\n",
              "      <td>49.951</td>\n",
              "      <td>49.951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>W</td>\n",
              "      <td>0.000</td>\n",
              "      <td>9.740</td>\n",
              "      <td>17.982</td>\n",
              "      <td>17.483</td>\n",
              "      <td>8.741</td>\n",
              "      <td>0.000</td>\n",
              "      <td>17.608</td>\n",
              "      <td>25.475</td>\n",
              "      <td>28.222</td>\n",
              "      <td>18.732</td>\n",
              "      <td>0.001</td>\n",
              "      <td>4.995</td>\n",
              "      <td>12.113</td>\n",
              "      <td>9.366</td>\n",
              "      <td>2.997</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.624</td>\n",
              "      <td>4.371</td>\n",
              "      <td>1.748</td>\n",
              "      <td>0.624</td>\n",
              "      <td>0.000</td>\n",
              "      <td>34.341</td>\n",
              "      <td>49.202</td>\n",
              "      <td>49.951</td>\n",
              "      <td>49.951</td>\n",
              "      <td>0.000</td>\n",
              "      <td>10.365</td>\n",
              "      <td>18.107</td>\n",
              "      <td>17.733</td>\n",
              "      <td>9.116</td>\n",
              "      <td>0.000</td>\n",
              "      <td>17.608</td>\n",
              "      <td>24.851</td>\n",
              "      <td>26.849</td>\n",
              "      <td>14.236</td>\n",
              "      <td>0.000</td>\n",
              "      <td>5.620</td>\n",
              "      <td>12.987</td>\n",
              "      <td>10.490</td>\n",
              "      <td>2.997</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.749</td>\n",
              "      <td>5.744</td>\n",
              "      <td>2.622</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.000</td>\n",
              "      <td>29.596</td>\n",
              "      <td>40.835</td>\n",
              "      <td>49.951</td>\n",
              "      <td>49.951</td>\n",
              "      <td>0.000</td>\n",
              "      <td>10.740</td>\n",
              "      <td>18.107</td>\n",
              "      <td>17.858</td>\n",
              "      <td>10.864</td>\n",
              "      <td>0.000</td>\n",
              "      <td>17.733</td>\n",
              "      <td>25.475</td>\n",
              "      <td>28.472</td>\n",
              "      <td>20.730</td>\n",
              "      <td>0.000</td>\n",
              "      <td>5.744</td>\n",
              "      <td>13.362</td>\n",
              "      <td>11.114</td>\n",
              "      <td>5.120</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.624</td>\n",
              "      <td>5.245</td>\n",
              "      <td>2.123</td>\n",
              "      <td>0.624</td>\n",
              "      <td>0.000</td>\n",
              "      <td>34.591</td>\n",
              "      <td>45.955</td>\n",
              "      <td>49.951</td>\n",
              "      <td>49.951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>W</td>\n",
              "      <td>0.000</td>\n",
              "      <td>10.115</td>\n",
              "      <td>17.608</td>\n",
              "      <td>17.108</td>\n",
              "      <td>9.616</td>\n",
              "      <td>0.000</td>\n",
              "      <td>17.358</td>\n",
              "      <td>26.474</td>\n",
              "      <td>28.722</td>\n",
              "      <td>16.359</td>\n",
              "      <td>0.000</td>\n",
              "      <td>5.744</td>\n",
              "      <td>12.613</td>\n",
              "      <td>10.365</td>\n",
              "      <td>2.123</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.999</td>\n",
              "      <td>5.869</td>\n",
              "      <td>2.622</td>\n",
              "      <td>0.624</td>\n",
              "      <td>0.000</td>\n",
              "      <td>32.968</td>\n",
              "      <td>46.455</td>\n",
              "      <td>49.951</td>\n",
              "      <td>49.951</td>\n",
              "      <td>0.000</td>\n",
              "      <td>10.115</td>\n",
              "      <td>18.357</td>\n",
              "      <td>17.858</td>\n",
              "      <td>10.240</td>\n",
              "      <td>0.001</td>\n",
              "      <td>18.857</td>\n",
              "      <td>26.349</td>\n",
              "      <td>28.098</td>\n",
              "      <td>16.359</td>\n",
              "      <td>0.000</td>\n",
              "      <td>5.994</td>\n",
              "      <td>12.738</td>\n",
              "      <td>10.490</td>\n",
              "      <td>5.869</td>\n",
              "      <td>0.001</td>\n",
              "      <td>1.124</td>\n",
              "      <td>6.494</td>\n",
              "      <td>3.122</td>\n",
              "      <td>0.749</td>\n",
              "      <td>0.000</td>\n",
              "      <td>28.472</td>\n",
              "      <td>39.212</td>\n",
              "      <td>49.826</td>\n",
              "      <td>49.951</td>\n",
              "      <td>0.000</td>\n",
              "      <td>10.365</td>\n",
              "      <td>18.357</td>\n",
              "      <td>18.107</td>\n",
              "      <td>10.240</td>\n",
              "      <td>0.000</td>\n",
              "      <td>18.232</td>\n",
              "      <td>26.724</td>\n",
              "      <td>28.597</td>\n",
              "      <td>16.359</td>\n",
              "      <td>0.000</td>\n",
              "      <td>6.119</td>\n",
              "      <td>13.237</td>\n",
              "      <td>10.989</td>\n",
              "      <td>3.621</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.874</td>\n",
              "      <td>6.619</td>\n",
              "      <td>3.122</td>\n",
              "      <td>0.624</td>\n",
              "      <td>0.000</td>\n",
              "      <td>32.468</td>\n",
              "      <td>43.957</td>\n",
              "      <td>49.951</td>\n",
              "      <td>49.951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>W</td>\n",
              "      <td>0.000</td>\n",
              "      <td>9.740</td>\n",
              "      <td>17.608</td>\n",
              "      <td>17.233</td>\n",
              "      <td>8.117</td>\n",
              "      <td>0.000</td>\n",
              "      <td>17.233</td>\n",
              "      <td>25.850</td>\n",
              "      <td>28.098</td>\n",
              "      <td>17.608</td>\n",
              "      <td>0.001</td>\n",
              "      <td>4.745</td>\n",
              "      <td>12.238</td>\n",
              "      <td>9.491</td>\n",
              "      <td>2.997</td>\n",
              "      <td>0.004</td>\n",
              "      <td>0.749</td>\n",
              "      <td>4.995</td>\n",
              "      <td>2.622</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.000</td>\n",
              "      <td>34.217</td>\n",
              "      <td>49.577</td>\n",
              "      <td>49.951</td>\n",
              "      <td>49.951</td>\n",
              "      <td>0.000</td>\n",
              "      <td>10.240</td>\n",
              "      <td>17.733</td>\n",
              "      <td>17.483</td>\n",
              "      <td>10.365</td>\n",
              "      <td>0.000</td>\n",
              "      <td>17.358</td>\n",
              "      <td>26.100</td>\n",
              "      <td>28.098</td>\n",
              "      <td>17.608</td>\n",
              "      <td>0.000</td>\n",
              "      <td>5.744</td>\n",
              "      <td>13.112</td>\n",
              "      <td>10.365</td>\n",
              "      <td>5.744</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.874</td>\n",
              "      <td>6.119</td>\n",
              "      <td>3.122</td>\n",
              "      <td>0.624</td>\n",
              "      <td>0.000</td>\n",
              "      <td>29.971</td>\n",
              "      <td>39.711</td>\n",
              "      <td>49.826</td>\n",
              "      <td>49.951</td>\n",
              "      <td>0.000</td>\n",
              "      <td>10.490</td>\n",
              "      <td>18.357</td>\n",
              "      <td>17.982</td>\n",
              "      <td>10.365</td>\n",
              "      <td>0.000</td>\n",
              "      <td>18.232</td>\n",
              "      <td>25.975</td>\n",
              "      <td>28.722</td>\n",
              "      <td>20.480</td>\n",
              "      <td>0.000</td>\n",
              "      <td>5.869</td>\n",
              "      <td>13.237</td>\n",
              "      <td>10.989</td>\n",
              "      <td>2.997</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.500</td>\n",
              "      <td>5.744</td>\n",
              "      <td>2.248</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.000</td>\n",
              "      <td>33.592</td>\n",
              "      <td>44.831</td>\n",
              "      <td>49.951</td>\n",
              "      <td>49.951</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-513f793c-5120-4a71-94d9-3bc1d4e9eff7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-513f793c-5120-4a71-94d9-3bc1d4e9eff7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-513f793c-5120-4a71-94d9-3bc1d4e9eff7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 19;\n",
              "                var nbb_unformatted_code = \"# let's view the first 5 rows of the data\\ndata.head()\";\n",
              "                var nbb_formatted_code = \"# let's view the first 5 rows of the data\\ndata.head()\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# let's view the first 5 rows of the data\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "_uZvUQcwCYyv",
        "outputId": "3b8cf763-71f6-4775-cc3a-2382315cf730",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Sleep Stage  MeanP_Alpha_F4  MedianF_Alpha_F4  MeanF_Alpha_F4  \\\n",
              "4995          N2           0.001             9.616          13.737   \n",
              "4996          N2           0.001             8.617          13.612   \n",
              "4997          N3           0.001             9.740          13.487   \n",
              "4998          N3           0.001             8.242          13.737   \n",
              "4999          N3           0.001             8.741          13.737   \n",
              "\n",
              "      Spectral Edge_Alpha_F4  PeakF_Alpha_F4  MeanP_Beta_F4  MedianF_Beta_F4  \\\n",
              "4995                  13.487          11.114          0.000           12.363   \n",
              "4996                  13.237           7.493          0.001           12.488   \n",
              "4997                  12.987          12.113          0.001           12.113   \n",
              "4998                  12.987           9.990          0.000           12.363   \n",
              "4999                  13.112          11.114          0.000           12.238   \n",
              "\n",
              "      MeanF_Beta_F4  Spectral Edge_Beta_F4  PeakF_Beta_F4  MeanP_Theta_F4  \\\n",
              "4995         21.229                 21.604         11.114           0.001   \n",
              "4996         20.230                 20.480         13.362           0.001   \n",
              "4997         19.980                 20.230         12.113           0.001   \n",
              "4998         21.854                 22.103          9.990           0.001   \n",
              "4999         20.730                 20.980         11.114           0.001   \n",
              "\n",
              "      MedianF_Theta_F4  MeanF_Theta_F4  Spectral Edge_Theta_F4  \\\n",
              "4995             5.495          11.364                   9.990   \n",
              "4996             5.744          11.364                   9.366   \n",
              "4997             5.370          11.988                  10.490   \n",
              "4998             5.120          10.240                   8.617   \n",
              "4999             5.120          11.114                   8.866   \n",
              "\n",
              "      PeakF_Theta_F4  MeanP_Delta_F4  MedianF_Delta_F4  MeanF_Delta_F4  \\\n",
              "4995           4.246           0.004             1.249           6.119   \n",
              "4996           4.371           0.006             1.249           5.994   \n",
              "4997           3.122           0.017             0.624           4.620   \n",
              "4998           5.869           0.010             0.999           5.120   \n",
              "4999           4.745           0.006             1.374           5.744   \n",
              "\n",
              "      Spectral Edge_Delta_F4  PeakF_Delta_F4  MeanP_Gamma_F4  \\\n",
              "4995                   2.997           0.874           0.000   \n",
              "4996                   2.747           0.874           0.000   \n",
              "4997                   1.748           0.624           0.000   \n",
              "4998                   2.373           0.874           0.000   \n",
              "4999                   3.122           1.623           0.000   \n",
              "\n",
              "      MedianF_Gamma_F4  MeanF_Gamma_F4  Spectral Edge_Gamma_F4  \\\n",
              "4995            24.226          34.966                  43.333   \n",
              "4996            23.102          34.217                  42.084   \n",
              "4997            22.103          33.592                  41.709   \n",
              "4998            25.350          36.090                  45.580   \n",
              "4999            23.602          34.716                  42.958   \n",
              "\n",
              "      PeakF_Gamma_F4  MeanP_Alpha_C4  MedianF_Alpha_C4  MeanF_Alpha_C4  \\\n",
              "4995          49.951           0.001             8.991          13.986   \n",
              "4996          49.951           0.001             9.116          13.986   \n",
              "4997          49.951           0.001             8.991          14.236   \n",
              "4998          49.951           0.001             8.242          14.236   \n",
              "4999          49.951           0.001             8.617          14.236   \n",
              "\n",
              "      Spectral Edge_Alpha_C4  PeakF_Alpha_C4  MeanP_Beta_C4  MedianF_Beta_C4  \\\n",
              "4995                  13.487           6.494          0.000           13.112   \n",
              "4996                  13.737          13.362          0.001           13.237   \n",
              "4997                  13.612           8.741          0.000           12.987   \n",
              "4998                  13.487           8.242          0.000           13.237   \n",
              "4999                  13.737           7.992          0.000           13.237   \n",
              "\n",
              "      MeanF_Beta_C4  Spectral Edge_Beta_C4  PeakF_Beta_C4  MeanP_Theta_C4  \\\n",
              "4995         21.354                 21.979         13.487           0.001   \n",
              "4996         19.606                 20.230         13.362           0.001   \n",
              "4997         21.229                 21.729         13.237           0.001   \n",
              "4998         21.354                 21.729         13.362           0.001   \n",
              "4999         20.230                 20.730         13.362           0.001   \n",
              "\n",
              "      MedianF_Theta_C4  MeanF_Theta_C4  Spectral Edge_Theta_C4  \\\n",
              "4995             5.120          11.114                   9.116   \n",
              "4996             4.745          11.739                   8.991   \n",
              "4997             4.496          11.489                   8.991   \n",
              "4998             4.246          10.240                   8.117   \n",
              "4999             4.870          10.989                   8.741   \n",
              "\n",
              "      PeakF_Theta_C4  MeanP_Delta_C4  MedianF_Delta_C4  MeanF_Delta_C4  \\\n",
              "4995           4.371           0.004             1.124           5.869   \n",
              "4996           4.371           0.009             0.999           5.245   \n",
              "4997           3.871           0.007             0.749           5.370   \n",
              "4998           3.746           0.011             0.999           4.995   \n",
              "4999           4.745           0.007             1.374           5.495   \n",
              "\n",
              "      Spectral Edge_Delta_C4  PeakF_Delta_C4  MeanP_Gamma_C4  \\\n",
              "4995                   2.997           0.874           0.000   \n",
              "4996                   2.622           0.749           0.000   \n",
              "4997                   3.122           0.624           0.000   \n",
              "4998                   2.622           0.874           0.000   \n",
              "4999                   2.872           1.623           0.000   \n",
              "\n",
              "      MedianF_Gamma_C4  MeanF_Gamma_C4  Spectral Edge_Gamma_C4  \\\n",
              "4995            29.596          49.826                  49.951   \n",
              "4996            27.348          49.826                  49.951   \n",
              "4997            27.598          49.826                  49.951   \n",
              "4998            31.469          49.826                  49.951   \n",
              "4999            28.847          49.826                  49.951   \n",
              "\n",
              "      PeakF_Gamma_C4  MeanP_Alpha_O2  MedianF_Alpha_O2  MeanF_Alpha_O2  \\\n",
              "4995          49.951           0.000             7.867          13.737   \n",
              "4996          49.951           0.000             8.242          13.986   \n",
              "4997          49.951           0.001             8.242          14.236   \n",
              "4998          49.951           0.000             8.492          14.111   \n",
              "4999          49.951           0.000             8.242          14.611   \n",
              "\n",
              "      Spectral Edge_Alpha_O2  PeakF_Alpha_O2  MeanP_Beta_O2  MedianF_Beta_O2  \\\n",
              "4995                  12.987           6.868          0.000           12.738   \n",
              "4996                  13.487           6.619          0.000           12.987   \n",
              "4997                  13.362           6.868          0.000           12.738   \n",
              "4998                  13.237           7.243          0.000           12.613   \n",
              "4999                  13.986           8.117          0.000           13.362   \n",
              "\n",
              "      MeanF_Beta_O2  Spectral Edge_Beta_O2  PeakF_Beta_O2  MeanP_Theta_O2  \\\n",
              "4995         21.604                 21.979         12.987           0.001   \n",
              "4996         21.104                 21.479         13.612           0.001   \n",
              "4997         21.229                 21.604         12.363           0.001   \n",
              "4998         21.229                 21.729         10.365           0.001   \n",
              "4999         21.229                 21.729         13.362           0.001   \n",
              "\n",
              "      MedianF_Theta_O2  MeanF_Theta_O2  Spectral Edge_Theta_O2  \\\n",
              "4995             5.994          10.240                   8.741   \n",
              "4996             5.495          10.615                   8.617   \n",
              "4997             5.744          10.864                   8.866   \n",
              "4998             5.495          10.490                   8.991   \n",
              "4999             5.245          10.740                   8.617   \n",
              "\n",
              "      PeakF_Theta_O2  MeanP_Delta_O2  MedianF_Delta_O2  MeanF_Delta_O2  \\\n",
              "4995           5.994           0.002             1.374           6.868   \n",
              "4996           4.496           0.003             1.249           6.494   \n",
              "4997           6.369           0.003             0.999           6.494   \n",
              "4998           6.244           0.003             0.874           6.244   \n",
              "4999           4.121           0.002             1.374           6.619   \n",
              "\n",
              "      Spectral Edge_Delta_O2  PeakF_Delta_O2  MeanP_Gamma_O2  \\\n",
              "4995                   4.121           0.500           0.000   \n",
              "4996                   3.871           0.500           0.000   \n",
              "4997                   3.122           0.375           0.000   \n",
              "4998                   3.247           0.749           0.000   \n",
              "4999                   3.996           0.624           0.000   \n",
              "\n",
              "      MedianF_Gamma_O2  MeanF_Gamma_O2  Spectral Edge_Gamma_O2  PeakF_Gamma_O2  \n",
              "4995            26.724          37.089                  45.331          49.951  \n",
              "4996            25.350          37.214                  45.331          49.951  \n",
              "4997            24.726          36.964                  44.956          49.951  \n",
              "4998            25.975          37.588                  45.955          49.951  \n",
              "4999            24.726          37.463                  45.955          49.951  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1ffa0152-6484-463c-8f81-90634b95a4c9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sleep Stage</th>\n",
              "      <th>MeanP_Alpha_F4</th>\n",
              "      <th>MedianF_Alpha_F4</th>\n",
              "      <th>MeanF_Alpha_F4</th>\n",
              "      <th>Spectral Edge_Alpha_F4</th>\n",
              "      <th>PeakF_Alpha_F4</th>\n",
              "      <th>MeanP_Beta_F4</th>\n",
              "      <th>MedianF_Beta_F4</th>\n",
              "      <th>MeanF_Beta_F4</th>\n",
              "      <th>Spectral Edge_Beta_F4</th>\n",
              "      <th>PeakF_Beta_F4</th>\n",
              "      <th>MeanP_Theta_F4</th>\n",
              "      <th>MedianF_Theta_F4</th>\n",
              "      <th>MeanF_Theta_F4</th>\n",
              "      <th>Spectral Edge_Theta_F4</th>\n",
              "      <th>PeakF_Theta_F4</th>\n",
              "      <th>MeanP_Delta_F4</th>\n",
              "      <th>MedianF_Delta_F4</th>\n",
              "      <th>MeanF_Delta_F4</th>\n",
              "      <th>Spectral Edge_Delta_F4</th>\n",
              "      <th>PeakF_Delta_F4</th>\n",
              "      <th>MeanP_Gamma_F4</th>\n",
              "      <th>MedianF_Gamma_F4</th>\n",
              "      <th>MeanF_Gamma_F4</th>\n",
              "      <th>Spectral Edge_Gamma_F4</th>\n",
              "      <th>PeakF_Gamma_F4</th>\n",
              "      <th>MeanP_Alpha_C4</th>\n",
              "      <th>MedianF_Alpha_C4</th>\n",
              "      <th>MeanF_Alpha_C4</th>\n",
              "      <th>Spectral Edge_Alpha_C4</th>\n",
              "      <th>PeakF_Alpha_C4</th>\n",
              "      <th>MeanP_Beta_C4</th>\n",
              "      <th>MedianF_Beta_C4</th>\n",
              "      <th>MeanF_Beta_C4</th>\n",
              "      <th>Spectral Edge_Beta_C4</th>\n",
              "      <th>PeakF_Beta_C4</th>\n",
              "      <th>MeanP_Theta_C4</th>\n",
              "      <th>MedianF_Theta_C4</th>\n",
              "      <th>MeanF_Theta_C4</th>\n",
              "      <th>Spectral Edge_Theta_C4</th>\n",
              "      <th>PeakF_Theta_C4</th>\n",
              "      <th>MeanP_Delta_C4</th>\n",
              "      <th>MedianF_Delta_C4</th>\n",
              "      <th>MeanF_Delta_C4</th>\n",
              "      <th>Spectral Edge_Delta_C4</th>\n",
              "      <th>PeakF_Delta_C4</th>\n",
              "      <th>MeanP_Gamma_C4</th>\n",
              "      <th>MedianF_Gamma_C4</th>\n",
              "      <th>MeanF_Gamma_C4</th>\n",
              "      <th>Spectral Edge_Gamma_C4</th>\n",
              "      <th>PeakF_Gamma_C4</th>\n",
              "      <th>MeanP_Alpha_O2</th>\n",
              "      <th>MedianF_Alpha_O2</th>\n",
              "      <th>MeanF_Alpha_O2</th>\n",
              "      <th>Spectral Edge_Alpha_O2</th>\n",
              "      <th>PeakF_Alpha_O2</th>\n",
              "      <th>MeanP_Beta_O2</th>\n",
              "      <th>MedianF_Beta_O2</th>\n",
              "      <th>MeanF_Beta_O2</th>\n",
              "      <th>Spectral Edge_Beta_O2</th>\n",
              "      <th>PeakF_Beta_O2</th>\n",
              "      <th>MeanP_Theta_O2</th>\n",
              "      <th>MedianF_Theta_O2</th>\n",
              "      <th>MeanF_Theta_O2</th>\n",
              "      <th>Spectral Edge_Theta_O2</th>\n",
              "      <th>PeakF_Theta_O2</th>\n",
              "      <th>MeanP_Delta_O2</th>\n",
              "      <th>MedianF_Delta_O2</th>\n",
              "      <th>MeanF_Delta_O2</th>\n",
              "      <th>Spectral Edge_Delta_O2</th>\n",
              "      <th>PeakF_Delta_O2</th>\n",
              "      <th>MeanP_Gamma_O2</th>\n",
              "      <th>MedianF_Gamma_O2</th>\n",
              "      <th>MeanF_Gamma_O2</th>\n",
              "      <th>Spectral Edge_Gamma_O2</th>\n",
              "      <th>PeakF_Gamma_O2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>N2</td>\n",
              "      <td>0.001</td>\n",
              "      <td>9.616</td>\n",
              "      <td>13.737</td>\n",
              "      <td>13.487</td>\n",
              "      <td>11.114</td>\n",
              "      <td>0.000</td>\n",
              "      <td>12.363</td>\n",
              "      <td>21.229</td>\n",
              "      <td>21.604</td>\n",
              "      <td>11.114</td>\n",
              "      <td>0.001</td>\n",
              "      <td>5.495</td>\n",
              "      <td>11.364</td>\n",
              "      <td>9.990</td>\n",
              "      <td>4.246</td>\n",
              "      <td>0.004</td>\n",
              "      <td>1.249</td>\n",
              "      <td>6.119</td>\n",
              "      <td>2.997</td>\n",
              "      <td>0.874</td>\n",
              "      <td>0.000</td>\n",
              "      <td>24.226</td>\n",
              "      <td>34.966</td>\n",
              "      <td>43.333</td>\n",
              "      <td>49.951</td>\n",
              "      <td>0.001</td>\n",
              "      <td>8.991</td>\n",
              "      <td>13.986</td>\n",
              "      <td>13.487</td>\n",
              "      <td>6.494</td>\n",
              "      <td>0.000</td>\n",
              "      <td>13.112</td>\n",
              "      <td>21.354</td>\n",
              "      <td>21.979</td>\n",
              "      <td>13.487</td>\n",
              "      <td>0.001</td>\n",
              "      <td>5.120</td>\n",
              "      <td>11.114</td>\n",
              "      <td>9.116</td>\n",
              "      <td>4.371</td>\n",
              "      <td>0.004</td>\n",
              "      <td>1.124</td>\n",
              "      <td>5.869</td>\n",
              "      <td>2.997</td>\n",
              "      <td>0.874</td>\n",
              "      <td>0.000</td>\n",
              "      <td>29.596</td>\n",
              "      <td>49.826</td>\n",
              "      <td>49.951</td>\n",
              "      <td>49.951</td>\n",
              "      <td>0.000</td>\n",
              "      <td>7.867</td>\n",
              "      <td>13.737</td>\n",
              "      <td>12.987</td>\n",
              "      <td>6.868</td>\n",
              "      <td>0.000</td>\n",
              "      <td>12.738</td>\n",
              "      <td>21.604</td>\n",
              "      <td>21.979</td>\n",
              "      <td>12.987</td>\n",
              "      <td>0.001</td>\n",
              "      <td>5.994</td>\n",
              "      <td>10.240</td>\n",
              "      <td>8.741</td>\n",
              "      <td>5.994</td>\n",
              "      <td>0.002</td>\n",
              "      <td>1.374</td>\n",
              "      <td>6.868</td>\n",
              "      <td>4.121</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.000</td>\n",
              "      <td>26.724</td>\n",
              "      <td>37.089</td>\n",
              "      <td>45.331</td>\n",
              "      <td>49.951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>N2</td>\n",
              "      <td>0.001</td>\n",
              "      <td>8.617</td>\n",
              "      <td>13.612</td>\n",
              "      <td>13.237</td>\n",
              "      <td>7.493</td>\n",
              "      <td>0.001</td>\n",
              "      <td>12.488</td>\n",
              "      <td>20.230</td>\n",
              "      <td>20.480</td>\n",
              "      <td>13.362</td>\n",
              "      <td>0.001</td>\n",
              "      <td>5.744</td>\n",
              "      <td>11.364</td>\n",
              "      <td>9.366</td>\n",
              "      <td>4.371</td>\n",
              "      <td>0.006</td>\n",
              "      <td>1.249</td>\n",
              "      <td>5.994</td>\n",
              "      <td>2.747</td>\n",
              "      <td>0.874</td>\n",
              "      <td>0.000</td>\n",
              "      <td>23.102</td>\n",
              "      <td>34.217</td>\n",
              "      <td>42.084</td>\n",
              "      <td>49.951</td>\n",
              "      <td>0.001</td>\n",
              "      <td>9.116</td>\n",
              "      <td>13.986</td>\n",
              "      <td>13.737</td>\n",
              "      <td>13.362</td>\n",
              "      <td>0.001</td>\n",
              "      <td>13.237</td>\n",
              "      <td>19.606</td>\n",
              "      <td>20.230</td>\n",
              "      <td>13.362</td>\n",
              "      <td>0.001</td>\n",
              "      <td>4.745</td>\n",
              "      <td>11.739</td>\n",
              "      <td>8.991</td>\n",
              "      <td>4.371</td>\n",
              "      <td>0.009</td>\n",
              "      <td>0.999</td>\n",
              "      <td>5.245</td>\n",
              "      <td>2.622</td>\n",
              "      <td>0.749</td>\n",
              "      <td>0.000</td>\n",
              "      <td>27.348</td>\n",
              "      <td>49.826</td>\n",
              "      <td>49.951</td>\n",
              "      <td>49.951</td>\n",
              "      <td>0.000</td>\n",
              "      <td>8.242</td>\n",
              "      <td>13.986</td>\n",
              "      <td>13.487</td>\n",
              "      <td>6.619</td>\n",
              "      <td>0.000</td>\n",
              "      <td>12.987</td>\n",
              "      <td>21.104</td>\n",
              "      <td>21.479</td>\n",
              "      <td>13.612</td>\n",
              "      <td>0.001</td>\n",
              "      <td>5.495</td>\n",
              "      <td>10.615</td>\n",
              "      <td>8.617</td>\n",
              "      <td>4.496</td>\n",
              "      <td>0.003</td>\n",
              "      <td>1.249</td>\n",
              "      <td>6.494</td>\n",
              "      <td>3.871</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.000</td>\n",
              "      <td>25.350</td>\n",
              "      <td>37.214</td>\n",
              "      <td>45.331</td>\n",
              "      <td>49.951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>N3</td>\n",
              "      <td>0.001</td>\n",
              "      <td>9.740</td>\n",
              "      <td>13.487</td>\n",
              "      <td>12.987</td>\n",
              "      <td>12.113</td>\n",
              "      <td>0.001</td>\n",
              "      <td>12.113</td>\n",
              "      <td>19.980</td>\n",
              "      <td>20.230</td>\n",
              "      <td>12.113</td>\n",
              "      <td>0.001</td>\n",
              "      <td>5.370</td>\n",
              "      <td>11.988</td>\n",
              "      <td>10.490</td>\n",
              "      <td>3.122</td>\n",
              "      <td>0.017</td>\n",
              "      <td>0.624</td>\n",
              "      <td>4.620</td>\n",
              "      <td>1.748</td>\n",
              "      <td>0.624</td>\n",
              "      <td>0.000</td>\n",
              "      <td>22.103</td>\n",
              "      <td>33.592</td>\n",
              "      <td>41.709</td>\n",
              "      <td>49.951</td>\n",
              "      <td>0.001</td>\n",
              "      <td>8.991</td>\n",
              "      <td>14.236</td>\n",
              "      <td>13.612</td>\n",
              "      <td>8.741</td>\n",
              "      <td>0.000</td>\n",
              "      <td>12.987</td>\n",
              "      <td>21.229</td>\n",
              "      <td>21.729</td>\n",
              "      <td>13.237</td>\n",
              "      <td>0.001</td>\n",
              "      <td>4.496</td>\n",
              "      <td>11.489</td>\n",
              "      <td>8.991</td>\n",
              "      <td>3.871</td>\n",
              "      <td>0.007</td>\n",
              "      <td>0.749</td>\n",
              "      <td>5.370</td>\n",
              "      <td>3.122</td>\n",
              "      <td>0.624</td>\n",
              "      <td>0.000</td>\n",
              "      <td>27.598</td>\n",
              "      <td>49.826</td>\n",
              "      <td>49.951</td>\n",
              "      <td>49.951</td>\n",
              "      <td>0.001</td>\n",
              "      <td>8.242</td>\n",
              "      <td>14.236</td>\n",
              "      <td>13.362</td>\n",
              "      <td>6.868</td>\n",
              "      <td>0.000</td>\n",
              "      <td>12.738</td>\n",
              "      <td>21.229</td>\n",
              "      <td>21.604</td>\n",
              "      <td>12.363</td>\n",
              "      <td>0.001</td>\n",
              "      <td>5.744</td>\n",
              "      <td>10.864</td>\n",
              "      <td>8.866</td>\n",
              "      <td>6.369</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.999</td>\n",
              "      <td>6.494</td>\n",
              "      <td>3.122</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.000</td>\n",
              "      <td>24.726</td>\n",
              "      <td>36.964</td>\n",
              "      <td>44.956</td>\n",
              "      <td>49.951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>N3</td>\n",
              "      <td>0.001</td>\n",
              "      <td>8.242</td>\n",
              "      <td>13.737</td>\n",
              "      <td>12.987</td>\n",
              "      <td>9.990</td>\n",
              "      <td>0.000</td>\n",
              "      <td>12.363</td>\n",
              "      <td>21.854</td>\n",
              "      <td>22.103</td>\n",
              "      <td>9.990</td>\n",
              "      <td>0.001</td>\n",
              "      <td>5.120</td>\n",
              "      <td>10.240</td>\n",
              "      <td>8.617</td>\n",
              "      <td>5.869</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.999</td>\n",
              "      <td>5.120</td>\n",
              "      <td>2.373</td>\n",
              "      <td>0.874</td>\n",
              "      <td>0.000</td>\n",
              "      <td>25.350</td>\n",
              "      <td>36.090</td>\n",
              "      <td>45.580</td>\n",
              "      <td>49.951</td>\n",
              "      <td>0.001</td>\n",
              "      <td>8.242</td>\n",
              "      <td>14.236</td>\n",
              "      <td>13.487</td>\n",
              "      <td>8.242</td>\n",
              "      <td>0.000</td>\n",
              "      <td>13.237</td>\n",
              "      <td>21.354</td>\n",
              "      <td>21.729</td>\n",
              "      <td>13.362</td>\n",
              "      <td>0.001</td>\n",
              "      <td>4.246</td>\n",
              "      <td>10.240</td>\n",
              "      <td>8.117</td>\n",
              "      <td>3.746</td>\n",
              "      <td>0.011</td>\n",
              "      <td>0.999</td>\n",
              "      <td>4.995</td>\n",
              "      <td>2.622</td>\n",
              "      <td>0.874</td>\n",
              "      <td>0.000</td>\n",
              "      <td>31.469</td>\n",
              "      <td>49.826</td>\n",
              "      <td>49.951</td>\n",
              "      <td>49.951</td>\n",
              "      <td>0.000</td>\n",
              "      <td>8.492</td>\n",
              "      <td>14.111</td>\n",
              "      <td>13.237</td>\n",
              "      <td>7.243</td>\n",
              "      <td>0.000</td>\n",
              "      <td>12.613</td>\n",
              "      <td>21.229</td>\n",
              "      <td>21.729</td>\n",
              "      <td>10.365</td>\n",
              "      <td>0.001</td>\n",
              "      <td>5.495</td>\n",
              "      <td>10.490</td>\n",
              "      <td>8.991</td>\n",
              "      <td>6.244</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.874</td>\n",
              "      <td>6.244</td>\n",
              "      <td>3.247</td>\n",
              "      <td>0.749</td>\n",
              "      <td>0.000</td>\n",
              "      <td>25.975</td>\n",
              "      <td>37.588</td>\n",
              "      <td>45.955</td>\n",
              "      <td>49.951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>N3</td>\n",
              "      <td>0.001</td>\n",
              "      <td>8.741</td>\n",
              "      <td>13.737</td>\n",
              "      <td>13.112</td>\n",
              "      <td>11.114</td>\n",
              "      <td>0.000</td>\n",
              "      <td>12.238</td>\n",
              "      <td>20.730</td>\n",
              "      <td>20.980</td>\n",
              "      <td>11.114</td>\n",
              "      <td>0.001</td>\n",
              "      <td>5.120</td>\n",
              "      <td>11.114</td>\n",
              "      <td>8.866</td>\n",
              "      <td>4.745</td>\n",
              "      <td>0.006</td>\n",
              "      <td>1.374</td>\n",
              "      <td>5.744</td>\n",
              "      <td>3.122</td>\n",
              "      <td>1.623</td>\n",
              "      <td>0.000</td>\n",
              "      <td>23.602</td>\n",
              "      <td>34.716</td>\n",
              "      <td>42.958</td>\n",
              "      <td>49.951</td>\n",
              "      <td>0.001</td>\n",
              "      <td>8.617</td>\n",
              "      <td>14.236</td>\n",
              "      <td>13.737</td>\n",
              "      <td>7.992</td>\n",
              "      <td>0.000</td>\n",
              "      <td>13.237</td>\n",
              "      <td>20.230</td>\n",
              "      <td>20.730</td>\n",
              "      <td>13.362</td>\n",
              "      <td>0.001</td>\n",
              "      <td>4.870</td>\n",
              "      <td>10.989</td>\n",
              "      <td>8.741</td>\n",
              "      <td>4.745</td>\n",
              "      <td>0.007</td>\n",
              "      <td>1.374</td>\n",
              "      <td>5.495</td>\n",
              "      <td>2.872</td>\n",
              "      <td>1.623</td>\n",
              "      <td>0.000</td>\n",
              "      <td>28.847</td>\n",
              "      <td>49.826</td>\n",
              "      <td>49.951</td>\n",
              "      <td>49.951</td>\n",
              "      <td>0.000</td>\n",
              "      <td>8.242</td>\n",
              "      <td>14.611</td>\n",
              "      <td>13.986</td>\n",
              "      <td>8.117</td>\n",
              "      <td>0.000</td>\n",
              "      <td>13.362</td>\n",
              "      <td>21.229</td>\n",
              "      <td>21.729</td>\n",
              "      <td>13.362</td>\n",
              "      <td>0.001</td>\n",
              "      <td>5.245</td>\n",
              "      <td>10.740</td>\n",
              "      <td>8.617</td>\n",
              "      <td>4.121</td>\n",
              "      <td>0.002</td>\n",
              "      <td>1.374</td>\n",
              "      <td>6.619</td>\n",
              "      <td>3.996</td>\n",
              "      <td>0.624</td>\n",
              "      <td>0.000</td>\n",
              "      <td>24.726</td>\n",
              "      <td>37.463</td>\n",
              "      <td>45.955</td>\n",
              "      <td>49.951</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1ffa0152-6484-463c-8f81-90634b95a4c9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1ffa0152-6484-463c-8f81-90634b95a4c9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1ffa0152-6484-463c-8f81-90634b95a4c9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 20;\n",
              "                var nbb_unformatted_code = \"# let's view the last 5 rows of the data\\ndata.tail()\";\n",
              "                var nbb_formatted_code = \"# let's view the last 5 rows of the data\\ndata.tail()\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# let's view the last 5 rows of the data\n",
        "data.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IF9KvzqOCYyw"
      },
      "source": [
        "- The attributes are ciphered"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "cLqYc4T2CYyx",
        "outputId": "84805c27-8fc8-4160-c603-510c8b1aec93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5000 entries, 0 to 4999\n",
            "Data columns (total 76 columns):\n",
            " #   Column                  Non-Null Count  Dtype  \n",
            "---  ------                  --------------  -----  \n",
            " 0   Sleep Stage             5000 non-null   object \n",
            " 1   MeanP_Alpha_F4          5000 non-null   float64\n",
            " 2   MedianF_Alpha_F4        5000 non-null   float64\n",
            " 3   MeanF_Alpha_F4          5000 non-null   float64\n",
            " 4   Spectral Edge_Alpha_F4  5000 non-null   float64\n",
            " 5   PeakF_Alpha_F4          5000 non-null   float64\n",
            " 6   MeanP_Beta_F4           5000 non-null   float64\n",
            " 7   MedianF_Beta_F4         5000 non-null   float64\n",
            " 8   MeanF_Beta_F4           5000 non-null   float64\n",
            " 9   Spectral Edge_Beta_F4   5000 non-null   float64\n",
            " 10  PeakF_Beta_F4           5000 non-null   float64\n",
            " 11  MeanP_Theta_F4          5000 non-null   float64\n",
            " 12  MedianF_Theta_F4        5000 non-null   float64\n",
            " 13  MeanF_Theta_F4          5000 non-null   float64\n",
            " 14  Spectral Edge_Theta_F4  5000 non-null   float64\n",
            " 15  PeakF_Theta_F4          5000 non-null   float64\n",
            " 16  MeanP_Delta_F4          5000 non-null   float64\n",
            " 17  MedianF_Delta_F4        5000 non-null   float64\n",
            " 18  MeanF_Delta_F4          5000 non-null   float64\n",
            " 19  Spectral Edge_Delta_F4  5000 non-null   float64\n",
            " 20  PeakF_Delta_F4          5000 non-null   float64\n",
            " 21  MeanP_Gamma_F4          5000 non-null   float64\n",
            " 22  MedianF_Gamma_F4        5000 non-null   float64\n",
            " 23  MeanF_Gamma_F4          5000 non-null   float64\n",
            " 24  Spectral Edge_Gamma_F4  5000 non-null   float64\n",
            " 25  PeakF_Gamma_F4          5000 non-null   float64\n",
            " 26  MeanP_Alpha_C4          5000 non-null   float64\n",
            " 27  MedianF_Alpha_C4        5000 non-null   float64\n",
            " 28  MeanF_Alpha_C4          5000 non-null   float64\n",
            " 29  Spectral Edge_Alpha_C4  5000 non-null   float64\n",
            " 30  PeakF_Alpha_C4          5000 non-null   float64\n",
            " 31  MeanP_Beta_C4           5000 non-null   float64\n",
            " 32  MedianF_Beta_C4         5000 non-null   float64\n",
            " 33  MeanF_Beta_C4           5000 non-null   float64\n",
            " 34  Spectral Edge_Beta_C4   5000 non-null   float64\n",
            " 35  PeakF_Beta_C4           5000 non-null   float64\n",
            " 36  MeanP_Theta_C4          5000 non-null   float64\n",
            " 37  MedianF_Theta_C4        5000 non-null   float64\n",
            " 38  MeanF_Theta_C4          5000 non-null   float64\n",
            " 39  Spectral Edge_Theta_C4  5000 non-null   float64\n",
            " 40  PeakF_Theta_C4          5000 non-null   float64\n",
            " 41  MeanP_Delta_C4          5000 non-null   float64\n",
            " 42  MedianF_Delta_C4        5000 non-null   float64\n",
            " 43  MeanF_Delta_C4          5000 non-null   float64\n",
            " 44  Spectral Edge_Delta_C4  5000 non-null   float64\n",
            " 45  PeakF_Delta_C4          5000 non-null   float64\n",
            " 46  MeanP_Gamma_C4          5000 non-null   float64\n",
            " 47  MedianF_Gamma_C4        5000 non-null   float64\n",
            " 48  MeanF_Gamma_C4          5000 non-null   float64\n",
            " 49  Spectral Edge_Gamma_C4  5000 non-null   float64\n",
            " 50  PeakF_Gamma_C4          5000 non-null   float64\n",
            " 51  MeanP_Alpha_O2          5000 non-null   float64\n",
            " 52  MedianF_Alpha_O2        5000 non-null   float64\n",
            " 53  MeanF_Alpha_O2          5000 non-null   float64\n",
            " 54  Spectral Edge_Alpha_O2  5000 non-null   float64\n",
            " 55  PeakF_Alpha_O2          5000 non-null   float64\n",
            " 56  MeanP_Beta_O2           5000 non-null   float64\n",
            " 57  MedianF_Beta_O2         5000 non-null   float64\n",
            " 58  MeanF_Beta_O2           5000 non-null   float64\n",
            " 59  Spectral Edge_Beta_O2   5000 non-null   float64\n",
            " 60  PeakF_Beta_O2           5000 non-null   float64\n",
            " 61  MeanP_Theta_O2          5000 non-null   float64\n",
            " 62  MedianF_Theta_O2        5000 non-null   float64\n",
            " 63  MeanF_Theta_O2          5000 non-null   float64\n",
            " 64  Spectral Edge_Theta_O2  5000 non-null   float64\n",
            " 65  PeakF_Theta_O2          5000 non-null   float64\n",
            " 66  MeanP_Delta_O2          5000 non-null   float64\n",
            " 67  MedianF_Delta_O2        5000 non-null   float64\n",
            " 68  MeanF_Delta_O2          5000 non-null   float64\n",
            " 69  Spectral Edge_Delta_O2  5000 non-null   float64\n",
            " 70  PeakF_Delta_O2          5000 non-null   float64\n",
            " 71  MeanP_Gamma_O2          5000 non-null   float64\n",
            " 72  MedianF_Gamma_O2        5000 non-null   float64\n",
            " 73  MeanF_Gamma_O2          5000 non-null   float64\n",
            " 74  Spectral Edge_Gamma_O2  5000 non-null   float64\n",
            " 75  PeakF_Gamma_O2          5000 non-null   float64\n",
            "dtypes: float64(75), object(1)\n",
            "memory usage: 2.9+ MB\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 21;\n",
              "                var nbb_unformatted_code = \"# let's check the data types of the columns in the dataset\\ndata.info()\";\n",
              "                var nbb_formatted_code = \"# let's check the data types of the columns in the dataset\\ndata.info()\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# let's check the data types of the columns in the dataset\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0ofEE1BCYyz"
      },
      "source": [
        "- All attributes except for the predictor \"Target\" are of float type\n",
        "- There are 46 missing values for attribute \"V1\" and 39 missing values for attribute \"V2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "9c4pLdosCYyz",
        "outputId": "29ed9f20-3629-4e71-ab57-cab477617a91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 22;\n",
              "                var nbb_unformatted_code = \"# let's check for duplicate values in the data\\ndata.duplicated().sum()\";\n",
              "                var nbb_formatted_code = \"# let's check for duplicate values in the data\\ndata.duplicated().sum()\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# let's check for duplicate values in the data\n",
        "data.duplicated().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMLMV6uQCYy0"
      },
      "source": [
        "- There are no duplicate values in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "U5avIXyLCYy1",
        "outputId": "97bad805-112d-489c-f0c6-4196341f0385",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sleep Stage                 5\n",
              "MeanP_Alpha_F4            282\n",
              "MedianF_Alpha_F4           69\n",
              "MeanF_Alpha_F4            117\n",
              "Spectral Edge_Alpha_F4    130\n",
              "                         ... \n",
              "MeanP_Gamma_O2            994\n",
              "MedianF_Gamma_O2          259\n",
              "MeanF_Gamma_O2            135\n",
              "Spectral Edge_Gamma_O2    109\n",
              "PeakF_Gamma_O2            267\n",
              "Length: 76, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 23;\n",
              "                var nbb_unformatted_code = \"# let's check for number of unique values in each column\\ndata.nunique()\";\n",
              "                var nbb_formatted_code = \"# let's check for number of unique values in each column\\ndata.nunique()\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# let's check for number of unique values in each column\n",
        "data.nunique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wLqAxjzCYy1"
      },
      "source": [
        "- All attributes except \"Target\" have all unique values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "rImqQLJ4CYy1",
        "outputId": "711898eb-bc40-49ab-b480-131f5d56fa33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       MeanP_Alpha_F4  MedianF_Alpha_F4  MeanF_Alpha_F4  \\\n",
              "count        5000.000          5000.000        5000.000   \n",
              "mean            0.001             9.161          15.649   \n",
              "std             0.001             1.016           2.328   \n",
              "min             0.000             5.120          11.114   \n",
              "25%             0.000             8.617          14.111   \n",
              "50%             0.000             9.116          15.360   \n",
              "75%             0.001             9.616          16.484   \n",
              "max             0.032            15.235          26.349   \n",
              "\n",
              "       Spectral Edge_Alpha_F4  PeakF_Alpha_F4  MeanP_Beta_F4  MedianF_Beta_F4  \\\n",
              "count                5000.000        5000.000       5000.000         5000.000   \n",
              "mean                   14.838           8.291          0.001           14.956   \n",
              "std                     2.501           1.822          0.001            3.284   \n",
              "min                    10.115           2.872          0.000            8.991   \n",
              "25%                    13.237           6.993          0.000           12.488   \n",
              "50%                    14.486           7.742          0.000           14.486   \n",
              "75%                    15.735           9.616          0.001           16.359   \n",
              "max                    27.598          21.604          0.037           27.348   \n",
              "\n",
              "       MeanF_Beta_F4  Spectral Edge_Beta_F4  PeakF_Beta_F4  MeanP_Theta_F4  \\\n",
              "count       5000.000               5000.000       5000.000        5000.000   \n",
              "mean          25.202                 27.876         21.577           0.001   \n",
              "std            6.005                  8.435         15.881           0.001   \n",
              "min           17.108                 16.234          6.244           0.000   \n",
              "25%           21.229                 21.729         10.615           0.000   \n",
              "50%           23.602                 25.225         13.237           0.001   \n",
              "75%           27.223                 31.719         24.351           0.001   \n",
              "max           49.826                 49.951         50.076           0.026   \n",
              "\n",
              "       MedianF_Theta_F4  MeanF_Theta_F4  Spectral Edge_Theta_F4  \\\n",
              "count          5000.000        5000.000                5000.000   \n",
              "mean              5.149          11.194                   9.296   \n",
              "std               0.865           1.196                   1.143   \n",
              "min               2.373           6.743                   4.745   \n",
              "25%               4.620          10.490                   8.617   \n",
              "50%               5.120          10.989                   9.241   \n",
              "75%               5.620          11.739                   9.865   \n",
              "max               9.491          18.482                  16.234   \n",
              "\n",
              "       PeakF_Theta_F4  MeanP_Delta_F4  MedianF_Delta_F4  MeanF_Delta_F4  \\\n",
              "count        5000.000        5000.000          5000.000        5000.000   \n",
              "mean            4.614           0.015             1.037           5.492   \n",
              "std             1.523           0.046             0.300           1.084   \n",
              "min             0.749           0.000             0.125           1.748   \n",
              "25%             3.621           0.002             0.874           4.745   \n",
              "50%             4.121           0.005             0.999           5.495   \n",
              "75%             5.620           0.011             1.249           6.244   \n",
              "max            12.613           0.787             1.998           9.865   \n",
              "\n",
              "       Spectral Edge_Delta_F4  PeakF_Delta_F4  MeanP_Gamma_F4  \\\n",
              "count                5000.000        5000.000        5000.000   \n",
              "mean                    2.714           0.831           0.000   \n",
              "std                     0.712           0.365           0.000   \n",
              "min                     0.624           0.125           0.000   \n",
              "25%                     2.248           0.624           0.000   \n",
              "50%                     2.747           0.749           0.000   \n",
              "75%                     3.247           0.999           0.000   \n",
              "max                     6.244           3.247           0.015   \n",
              "\n",
              "       MedianF_Gamma_F4  MeanF_Gamma_F4  Spectral Edge_Gamma_F4  \\\n",
              "count          5000.000        5000.000                5000.000   \n",
              "mean             34.432          42.488                  48.249   \n",
              "std              10.007           5.938                   3.088   \n",
              "min              17.358          30.970                  35.840   \n",
              "25%              25.475          37.463                  46.455   \n",
              "50%              32.219          40.710                  49.826   \n",
              "75%              43.083          49.826                  49.951   \n",
              "max              49.951          49.951                  58.568   \n",
              "\n",
              "       PeakF_Gamma_F4  MeanP_Alpha_C4  MedianF_Alpha_C4  MeanF_Alpha_C4  \\\n",
              "count        5000.000        5000.000          5000.000        5000.000   \n",
              "mean           42.535           0.001             9.141          15.760   \n",
              "std            12.494           0.001             1.073           2.349   \n",
              "min             7.493           0.000             5.620          11.239   \n",
              "25%            35.216           0.000             8.492          14.236   \n",
              "50%            49.951           0.001             9.116          15.360   \n",
              "75%            49.951           0.001             9.616          16.640   \n",
              "max            50.076           0.012            15.860          49.826   \n",
              "\n",
              "       Spectral Edge_Alpha_C4  PeakF_Alpha_C4  MeanP_Beta_C4  MedianF_Beta_C4  \\\n",
              "count                5000.000        5000.000       5000.000         5000.000   \n",
              "mean                   15.085          10.402          0.001           19.612   \n",
              "std                     2.888           9.051          0.001           12.264   \n",
              "min                     9.990           1.249          0.000            8.617   \n",
              "25%                    13.487           6.993          0.000           12.987   \n",
              "50%                    14.486           8.117          0.000           14.611   \n",
              "75%                    15.735           9.740          0.001           18.607   \n",
              "max                    49.826          50.076          0.023           49.951   \n",
              "\n",
              "       MeanF_Beta_C4  Spectral Edge_Beta_C4  PeakF_Beta_C4  MeanP_Theta_C4  \\\n",
              "count       5000.000               5000.000       5000.000        5000.000   \n",
              "mean          27.749                 29.060         22.435           0.001   \n",
              "std           10.561                 10.693         16.537           0.001   \n",
              "min           16.109                 15.110          6.369           0.000   \n",
              "25%           21.104                 21.604         10.864           0.000   \n",
              "50%           23.602                 25.100         13.737           0.001   \n",
              "75%           28.472                 32.219         49.951           0.002   \n",
              "max           49.951                 50.076         50.076           0.030   \n",
              "\n",
              "       MedianF_Theta_C4  MeanF_Theta_C4  Spectral Edge_Theta_C4  \\\n",
              "count          5000.000        5000.000                5000.000   \n",
              "mean              5.212          11.246                   9.275   \n",
              "std               0.916           1.270                   1.205   \n",
              "min               1.873           8.117                   5.120   \n",
              "25%               4.620          10.365                   8.492   \n",
              "50%               5.120          11.114                   9.116   \n",
              "75%               5.620          11.863                   9.865   \n",
              "max               9.491          19.481                  18.107   \n",
              "\n",
              "       PeakF_Theta_C4  MeanP_Delta_C4  MedianF_Delta_C4  MeanF_Delta_C4  \\\n",
              "count        5000.000        5000.000          5000.000        5000.000   \n",
              "mean            4.659           0.013             1.159           5.745   \n",
              "std             1.536           0.045             0.359           1.105   \n",
              "min             0.749           0.000             0.125           1.748   \n",
              "25%             3.621           0.001             0.874           5.120   \n",
              "50%             4.121           0.004             1.124           5.744   \n",
              "75%             5.495           0.009             1.374           6.369   \n",
              "max            12.613           1.009             2.498          10.864   \n",
              "\n",
              "       Spectral Edge_Delta_C4  PeakF_Delta_C4  MeanP_Gamma_C4  \\\n",
              "count                5000.000        5000.000        5000.000   \n",
              "mean                    3.011           0.888           0.000   \n",
              "std                     0.756           0.416           0.001   \n",
              "min                     0.500           0.125           0.000   \n",
              "25%                     2.622           0.624           0.000   \n",
              "50%                     3.122           0.749           0.000   \n",
              "75%                     3.497           0.999           0.000   \n",
              "max                     6.993           3.497           0.009   \n",
              "\n",
              "       MedianF_Gamma_C4  MeanF_Gamma_C4  Spectral Edge_Gamma_C4  \\\n",
              "count          5000.000        5000.000                5000.000   \n",
              "mean             34.227          42.743                  47.548   \n",
              "std              10.859           6.682                   3.643   \n",
              "min              14.736          29.221                  34.841   \n",
              "25%              24.476          36.464                  45.331   \n",
              "50%              32.219          41.335                  49.826   \n",
              "75%              49.701          49.826                  49.951   \n",
              "max              49.951          49.951                  55.196   \n",
              "\n",
              "       PeakF_Gamma_C4  MeanP_Alpha_O2  MedianF_Alpha_O2  MeanF_Alpha_O2  \\\n",
              "count        5000.000        5000.000          5000.000        5000.000   \n",
              "mean           41.031           0.000             9.040          15.877   \n",
              "std            13.635           0.001             1.159           2.088   \n",
              "min             7.118           0.000             6.119          10.864   \n",
              "25%            31.313           0.000             8.242          14.611   \n",
              "50%            49.951           0.000             8.991          15.735   \n",
              "75%            49.951           0.001             9.616          16.734   \n",
              "max            50.076           0.031            16.109          27.348   \n",
              "\n",
              "       Spectral Edge_Alpha_O2  PeakF_Alpha_O2  MeanP_Beta_O2  MedianF_Beta_O2  \\\n",
              "count                5000.000        5000.000       5000.000         5000.000   \n",
              "mean                   15.059           8.275          0.001           15.571   \n",
              "std                     2.346           2.573          0.001            3.935   \n",
              "min                    10.365           1.249          0.000            9.116   \n",
              "25%                    13.737           6.868          0.000           13.487   \n",
              "50%                    14.736           7.867          0.000           15.360   \n",
              "75%                    15.984           9.366          0.000           16.734   \n",
              "max                    27.973          49.951          0.028           49.826   \n",
              "\n",
              "       MeanF_Beta_O2  Spectral Edge_Beta_O2  PeakF_Beta_O2  MeanP_Theta_O2  \\\n",
              "count       5000.000               5000.000       5000.000        5000.000   \n",
              "mean          25.591                 28.001         21.601           0.001   \n",
              "std            5.503                  6.922         15.694           0.002   \n",
              "min           15.984                 15.735          5.744           0.000   \n",
              "25%           22.478                 23.227         11.364           0.000   \n",
              "50%           24.851                 27.223         13.986           0.000   \n",
              "75%           27.723                 31.344         22.978           0.001   \n",
              "max           49.951                 50.076         50.076           0.070   \n",
              "\n",
              "       MedianF_Theta_O2  MeanF_Theta_O2  Spectral Edge_Theta_O2  \\\n",
              "count          5000.000        5000.000                5000.000   \n",
              "mean              5.582          11.214                   9.377   \n",
              "std               0.992           1.389                   1.305   \n",
              "min               1.623           8.117                   5.120   \n",
              "25%               5.120          10.365                   8.617   \n",
              "50%               5.495          10.989                   9.241   \n",
              "75%               5.994          11.863                   9.990   \n",
              "max              11.364          20.730                  20.105   \n",
              "\n",
              "       PeakF_Theta_O2  MeanP_Delta_O2  MedianF_Delta_O2  MeanF_Delta_O2  \\\n",
              "count        5000.000        5000.000          5000.000        5000.000   \n",
              "mean            5.095           0.016             0.982           6.097   \n",
              "std             1.634           0.068             0.289           1.315   \n",
              "min             0.500           0.000             0.125           1.499   \n",
              "25%             3.871           0.001             0.874           5.620   \n",
              "50%             4.995           0.002             0.999           6.244   \n",
              "75%             6.119           0.004             1.124           6.743   \n",
              "max            14.486           1.293             2.373          13.112   \n",
              "\n",
              "       Spectral Edge_Delta_O2  PeakF_Delta_O2  MeanP_Gamma_O2  \\\n",
              "count                5000.000        5000.000        5000.000   \n",
              "mean                    3.046           0.748           0.000   \n",
              "std                     0.942           0.277           0.001   \n",
              "min                     0.500           0.125           0.000   \n",
              "25%                     2.622           0.500           0.000   \n",
              "50%                     3.247           0.749           0.000   \n",
              "75%                     3.621           0.874           0.000   \n",
              "max                     9.616           2.747           0.010   \n",
              "\n",
              "       MedianF_Gamma_O2  MeanF_Gamma_O2  Spectral Edge_Gamma_O2  \\\n",
              "count          5000.000        5000.000                5000.000   \n",
              "mean             35.310          43.450                  48.536   \n",
              "std               9.151           5.609                   2.297   \n",
              "min              15.984          32.343                  37.713   \n",
              "25%              27.598          38.587                  47.579   \n",
              "50%              33.717          41.335                  49.826   \n",
              "75%              41.709          49.826                  49.951   \n",
              "max              49.951          49.951                  55.196   \n",
              "\n",
              "       PeakF_Gamma_O2  \n",
              "count        5000.000  \n",
              "mean           42.726  \n",
              "std            11.970  \n",
              "min             6.244  \n",
              "25%            35.091  \n",
              "50%            49.951  \n",
              "75%            49.951  \n",
              "max            50.076  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b862127a-5ebf-4e8b-aaa2-8e9f9bcfd48e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MeanP_Alpha_F4</th>\n",
              "      <th>MedianF_Alpha_F4</th>\n",
              "      <th>MeanF_Alpha_F4</th>\n",
              "      <th>Spectral Edge_Alpha_F4</th>\n",
              "      <th>PeakF_Alpha_F4</th>\n",
              "      <th>MeanP_Beta_F4</th>\n",
              "      <th>MedianF_Beta_F4</th>\n",
              "      <th>MeanF_Beta_F4</th>\n",
              "      <th>Spectral Edge_Beta_F4</th>\n",
              "      <th>PeakF_Beta_F4</th>\n",
              "      <th>MeanP_Theta_F4</th>\n",
              "      <th>MedianF_Theta_F4</th>\n",
              "      <th>MeanF_Theta_F4</th>\n",
              "      <th>Spectral Edge_Theta_F4</th>\n",
              "      <th>PeakF_Theta_F4</th>\n",
              "      <th>MeanP_Delta_F4</th>\n",
              "      <th>MedianF_Delta_F4</th>\n",
              "      <th>MeanF_Delta_F4</th>\n",
              "      <th>Spectral Edge_Delta_F4</th>\n",
              "      <th>PeakF_Delta_F4</th>\n",
              "      <th>MeanP_Gamma_F4</th>\n",
              "      <th>MedianF_Gamma_F4</th>\n",
              "      <th>MeanF_Gamma_F4</th>\n",
              "      <th>Spectral Edge_Gamma_F4</th>\n",
              "      <th>PeakF_Gamma_F4</th>\n",
              "      <th>MeanP_Alpha_C4</th>\n",
              "      <th>MedianF_Alpha_C4</th>\n",
              "      <th>MeanF_Alpha_C4</th>\n",
              "      <th>Spectral Edge_Alpha_C4</th>\n",
              "      <th>PeakF_Alpha_C4</th>\n",
              "      <th>MeanP_Beta_C4</th>\n",
              "      <th>MedianF_Beta_C4</th>\n",
              "      <th>MeanF_Beta_C4</th>\n",
              "      <th>Spectral Edge_Beta_C4</th>\n",
              "      <th>PeakF_Beta_C4</th>\n",
              "      <th>MeanP_Theta_C4</th>\n",
              "      <th>MedianF_Theta_C4</th>\n",
              "      <th>MeanF_Theta_C4</th>\n",
              "      <th>Spectral Edge_Theta_C4</th>\n",
              "      <th>PeakF_Theta_C4</th>\n",
              "      <th>MeanP_Delta_C4</th>\n",
              "      <th>MedianF_Delta_C4</th>\n",
              "      <th>MeanF_Delta_C4</th>\n",
              "      <th>Spectral Edge_Delta_C4</th>\n",
              "      <th>PeakF_Delta_C4</th>\n",
              "      <th>MeanP_Gamma_C4</th>\n",
              "      <th>MedianF_Gamma_C4</th>\n",
              "      <th>MeanF_Gamma_C4</th>\n",
              "      <th>Spectral Edge_Gamma_C4</th>\n",
              "      <th>PeakF_Gamma_C4</th>\n",
              "      <th>MeanP_Alpha_O2</th>\n",
              "      <th>MedianF_Alpha_O2</th>\n",
              "      <th>MeanF_Alpha_O2</th>\n",
              "      <th>Spectral Edge_Alpha_O2</th>\n",
              "      <th>PeakF_Alpha_O2</th>\n",
              "      <th>MeanP_Beta_O2</th>\n",
              "      <th>MedianF_Beta_O2</th>\n",
              "      <th>MeanF_Beta_O2</th>\n",
              "      <th>Spectral Edge_Beta_O2</th>\n",
              "      <th>PeakF_Beta_O2</th>\n",
              "      <th>MeanP_Theta_O2</th>\n",
              "      <th>MedianF_Theta_O2</th>\n",
              "      <th>MeanF_Theta_O2</th>\n",
              "      <th>Spectral Edge_Theta_O2</th>\n",
              "      <th>PeakF_Theta_O2</th>\n",
              "      <th>MeanP_Delta_O2</th>\n",
              "      <th>MedianF_Delta_O2</th>\n",
              "      <th>MeanF_Delta_O2</th>\n",
              "      <th>Spectral Edge_Delta_O2</th>\n",
              "      <th>PeakF_Delta_O2</th>\n",
              "      <th>MeanP_Gamma_O2</th>\n",
              "      <th>MedianF_Gamma_O2</th>\n",
              "      <th>MeanF_Gamma_O2</th>\n",
              "      <th>Spectral Edge_Gamma_O2</th>\n",
              "      <th>PeakF_Gamma_O2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "      <td>5000.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.001</td>\n",
              "      <td>9.161</td>\n",
              "      <td>15.649</td>\n",
              "      <td>14.838</td>\n",
              "      <td>8.291</td>\n",
              "      <td>0.001</td>\n",
              "      <td>14.956</td>\n",
              "      <td>25.202</td>\n",
              "      <td>27.876</td>\n",
              "      <td>21.577</td>\n",
              "      <td>0.001</td>\n",
              "      <td>5.149</td>\n",
              "      <td>11.194</td>\n",
              "      <td>9.296</td>\n",
              "      <td>4.614</td>\n",
              "      <td>0.015</td>\n",
              "      <td>1.037</td>\n",
              "      <td>5.492</td>\n",
              "      <td>2.714</td>\n",
              "      <td>0.831</td>\n",
              "      <td>0.000</td>\n",
              "      <td>34.432</td>\n",
              "      <td>42.488</td>\n",
              "      <td>48.249</td>\n",
              "      <td>42.535</td>\n",
              "      <td>0.001</td>\n",
              "      <td>9.141</td>\n",
              "      <td>15.760</td>\n",
              "      <td>15.085</td>\n",
              "      <td>10.402</td>\n",
              "      <td>0.001</td>\n",
              "      <td>19.612</td>\n",
              "      <td>27.749</td>\n",
              "      <td>29.060</td>\n",
              "      <td>22.435</td>\n",
              "      <td>0.001</td>\n",
              "      <td>5.212</td>\n",
              "      <td>11.246</td>\n",
              "      <td>9.275</td>\n",
              "      <td>4.659</td>\n",
              "      <td>0.013</td>\n",
              "      <td>1.159</td>\n",
              "      <td>5.745</td>\n",
              "      <td>3.011</td>\n",
              "      <td>0.888</td>\n",
              "      <td>0.000</td>\n",
              "      <td>34.227</td>\n",
              "      <td>42.743</td>\n",
              "      <td>47.548</td>\n",
              "      <td>41.031</td>\n",
              "      <td>0.000</td>\n",
              "      <td>9.040</td>\n",
              "      <td>15.877</td>\n",
              "      <td>15.059</td>\n",
              "      <td>8.275</td>\n",
              "      <td>0.001</td>\n",
              "      <td>15.571</td>\n",
              "      <td>25.591</td>\n",
              "      <td>28.001</td>\n",
              "      <td>21.601</td>\n",
              "      <td>0.001</td>\n",
              "      <td>5.582</td>\n",
              "      <td>11.214</td>\n",
              "      <td>9.377</td>\n",
              "      <td>5.095</td>\n",
              "      <td>0.016</td>\n",
              "      <td>0.982</td>\n",
              "      <td>6.097</td>\n",
              "      <td>3.046</td>\n",
              "      <td>0.748</td>\n",
              "      <td>0.000</td>\n",
              "      <td>35.310</td>\n",
              "      <td>43.450</td>\n",
              "      <td>48.536</td>\n",
              "      <td>42.726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.001</td>\n",
              "      <td>1.016</td>\n",
              "      <td>2.328</td>\n",
              "      <td>2.501</td>\n",
              "      <td>1.822</td>\n",
              "      <td>0.001</td>\n",
              "      <td>3.284</td>\n",
              "      <td>6.005</td>\n",
              "      <td>8.435</td>\n",
              "      <td>15.881</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.865</td>\n",
              "      <td>1.196</td>\n",
              "      <td>1.143</td>\n",
              "      <td>1.523</td>\n",
              "      <td>0.046</td>\n",
              "      <td>0.300</td>\n",
              "      <td>1.084</td>\n",
              "      <td>0.712</td>\n",
              "      <td>0.365</td>\n",
              "      <td>0.000</td>\n",
              "      <td>10.007</td>\n",
              "      <td>5.938</td>\n",
              "      <td>3.088</td>\n",
              "      <td>12.494</td>\n",
              "      <td>0.001</td>\n",
              "      <td>1.073</td>\n",
              "      <td>2.349</td>\n",
              "      <td>2.888</td>\n",
              "      <td>9.051</td>\n",
              "      <td>0.001</td>\n",
              "      <td>12.264</td>\n",
              "      <td>10.561</td>\n",
              "      <td>10.693</td>\n",
              "      <td>16.537</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.916</td>\n",
              "      <td>1.270</td>\n",
              "      <td>1.205</td>\n",
              "      <td>1.536</td>\n",
              "      <td>0.045</td>\n",
              "      <td>0.359</td>\n",
              "      <td>1.105</td>\n",
              "      <td>0.756</td>\n",
              "      <td>0.416</td>\n",
              "      <td>0.001</td>\n",
              "      <td>10.859</td>\n",
              "      <td>6.682</td>\n",
              "      <td>3.643</td>\n",
              "      <td>13.635</td>\n",
              "      <td>0.001</td>\n",
              "      <td>1.159</td>\n",
              "      <td>2.088</td>\n",
              "      <td>2.346</td>\n",
              "      <td>2.573</td>\n",
              "      <td>0.001</td>\n",
              "      <td>3.935</td>\n",
              "      <td>5.503</td>\n",
              "      <td>6.922</td>\n",
              "      <td>15.694</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.992</td>\n",
              "      <td>1.389</td>\n",
              "      <td>1.305</td>\n",
              "      <td>1.634</td>\n",
              "      <td>0.068</td>\n",
              "      <td>0.289</td>\n",
              "      <td>1.315</td>\n",
              "      <td>0.942</td>\n",
              "      <td>0.277</td>\n",
              "      <td>0.001</td>\n",
              "      <td>9.151</td>\n",
              "      <td>5.609</td>\n",
              "      <td>2.297</td>\n",
              "      <td>11.970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000</td>\n",
              "      <td>5.120</td>\n",
              "      <td>11.114</td>\n",
              "      <td>10.115</td>\n",
              "      <td>2.872</td>\n",
              "      <td>0.000</td>\n",
              "      <td>8.991</td>\n",
              "      <td>17.108</td>\n",
              "      <td>16.234</td>\n",
              "      <td>6.244</td>\n",
              "      <td>0.000</td>\n",
              "      <td>2.373</td>\n",
              "      <td>6.743</td>\n",
              "      <td>4.745</td>\n",
              "      <td>0.749</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.125</td>\n",
              "      <td>1.748</td>\n",
              "      <td>0.624</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.000</td>\n",
              "      <td>17.358</td>\n",
              "      <td>30.970</td>\n",
              "      <td>35.840</td>\n",
              "      <td>7.493</td>\n",
              "      <td>0.000</td>\n",
              "      <td>5.620</td>\n",
              "      <td>11.239</td>\n",
              "      <td>9.990</td>\n",
              "      <td>1.249</td>\n",
              "      <td>0.000</td>\n",
              "      <td>8.617</td>\n",
              "      <td>16.109</td>\n",
              "      <td>15.110</td>\n",
              "      <td>6.369</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.873</td>\n",
              "      <td>8.117</td>\n",
              "      <td>5.120</td>\n",
              "      <td>0.749</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.125</td>\n",
              "      <td>1.748</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.000</td>\n",
              "      <td>14.736</td>\n",
              "      <td>29.221</td>\n",
              "      <td>34.841</td>\n",
              "      <td>7.118</td>\n",
              "      <td>0.000</td>\n",
              "      <td>6.119</td>\n",
              "      <td>10.864</td>\n",
              "      <td>10.365</td>\n",
              "      <td>1.249</td>\n",
              "      <td>0.000</td>\n",
              "      <td>9.116</td>\n",
              "      <td>15.984</td>\n",
              "      <td>15.735</td>\n",
              "      <td>5.744</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.623</td>\n",
              "      <td>8.117</td>\n",
              "      <td>5.120</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.125</td>\n",
              "      <td>1.499</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.000</td>\n",
              "      <td>15.984</td>\n",
              "      <td>32.343</td>\n",
              "      <td>37.713</td>\n",
              "      <td>6.244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000</td>\n",
              "      <td>8.617</td>\n",
              "      <td>14.111</td>\n",
              "      <td>13.237</td>\n",
              "      <td>6.993</td>\n",
              "      <td>0.000</td>\n",
              "      <td>12.488</td>\n",
              "      <td>21.229</td>\n",
              "      <td>21.729</td>\n",
              "      <td>10.615</td>\n",
              "      <td>0.000</td>\n",
              "      <td>4.620</td>\n",
              "      <td>10.490</td>\n",
              "      <td>8.617</td>\n",
              "      <td>3.621</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.874</td>\n",
              "      <td>4.745</td>\n",
              "      <td>2.248</td>\n",
              "      <td>0.624</td>\n",
              "      <td>0.000</td>\n",
              "      <td>25.475</td>\n",
              "      <td>37.463</td>\n",
              "      <td>46.455</td>\n",
              "      <td>35.216</td>\n",
              "      <td>0.000</td>\n",
              "      <td>8.492</td>\n",
              "      <td>14.236</td>\n",
              "      <td>13.487</td>\n",
              "      <td>6.993</td>\n",
              "      <td>0.000</td>\n",
              "      <td>12.987</td>\n",
              "      <td>21.104</td>\n",
              "      <td>21.604</td>\n",
              "      <td>10.864</td>\n",
              "      <td>0.000</td>\n",
              "      <td>4.620</td>\n",
              "      <td>10.365</td>\n",
              "      <td>8.492</td>\n",
              "      <td>3.621</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.874</td>\n",
              "      <td>5.120</td>\n",
              "      <td>2.622</td>\n",
              "      <td>0.624</td>\n",
              "      <td>0.000</td>\n",
              "      <td>24.476</td>\n",
              "      <td>36.464</td>\n",
              "      <td>45.331</td>\n",
              "      <td>31.313</td>\n",
              "      <td>0.000</td>\n",
              "      <td>8.242</td>\n",
              "      <td>14.611</td>\n",
              "      <td>13.737</td>\n",
              "      <td>6.868</td>\n",
              "      <td>0.000</td>\n",
              "      <td>13.487</td>\n",
              "      <td>22.478</td>\n",
              "      <td>23.227</td>\n",
              "      <td>11.364</td>\n",
              "      <td>0.000</td>\n",
              "      <td>5.120</td>\n",
              "      <td>10.365</td>\n",
              "      <td>8.617</td>\n",
              "      <td>3.871</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.874</td>\n",
              "      <td>5.620</td>\n",
              "      <td>2.622</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.000</td>\n",
              "      <td>27.598</td>\n",
              "      <td>38.587</td>\n",
              "      <td>47.579</td>\n",
              "      <td>35.091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000</td>\n",
              "      <td>9.116</td>\n",
              "      <td>15.360</td>\n",
              "      <td>14.486</td>\n",
              "      <td>7.742</td>\n",
              "      <td>0.000</td>\n",
              "      <td>14.486</td>\n",
              "      <td>23.602</td>\n",
              "      <td>25.225</td>\n",
              "      <td>13.237</td>\n",
              "      <td>0.001</td>\n",
              "      <td>5.120</td>\n",
              "      <td>10.989</td>\n",
              "      <td>9.241</td>\n",
              "      <td>4.121</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.999</td>\n",
              "      <td>5.495</td>\n",
              "      <td>2.747</td>\n",
              "      <td>0.749</td>\n",
              "      <td>0.000</td>\n",
              "      <td>32.219</td>\n",
              "      <td>40.710</td>\n",
              "      <td>49.826</td>\n",
              "      <td>49.951</td>\n",
              "      <td>0.001</td>\n",
              "      <td>9.116</td>\n",
              "      <td>15.360</td>\n",
              "      <td>14.486</td>\n",
              "      <td>8.117</td>\n",
              "      <td>0.000</td>\n",
              "      <td>14.611</td>\n",
              "      <td>23.602</td>\n",
              "      <td>25.100</td>\n",
              "      <td>13.737</td>\n",
              "      <td>0.001</td>\n",
              "      <td>5.120</td>\n",
              "      <td>11.114</td>\n",
              "      <td>9.116</td>\n",
              "      <td>4.121</td>\n",
              "      <td>0.004</td>\n",
              "      <td>1.124</td>\n",
              "      <td>5.744</td>\n",
              "      <td>3.122</td>\n",
              "      <td>0.749</td>\n",
              "      <td>0.000</td>\n",
              "      <td>32.219</td>\n",
              "      <td>41.335</td>\n",
              "      <td>49.826</td>\n",
              "      <td>49.951</td>\n",
              "      <td>0.000</td>\n",
              "      <td>8.991</td>\n",
              "      <td>15.735</td>\n",
              "      <td>14.736</td>\n",
              "      <td>7.867</td>\n",
              "      <td>0.000</td>\n",
              "      <td>15.360</td>\n",
              "      <td>24.851</td>\n",
              "      <td>27.223</td>\n",
              "      <td>13.986</td>\n",
              "      <td>0.000</td>\n",
              "      <td>5.495</td>\n",
              "      <td>10.989</td>\n",
              "      <td>9.241</td>\n",
              "      <td>4.995</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.999</td>\n",
              "      <td>6.244</td>\n",
              "      <td>3.247</td>\n",
              "      <td>0.749</td>\n",
              "      <td>0.000</td>\n",
              "      <td>33.717</td>\n",
              "      <td>41.335</td>\n",
              "      <td>49.826</td>\n",
              "      <td>49.951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.001</td>\n",
              "      <td>9.616</td>\n",
              "      <td>16.484</td>\n",
              "      <td>15.735</td>\n",
              "      <td>9.616</td>\n",
              "      <td>0.001</td>\n",
              "      <td>16.359</td>\n",
              "      <td>27.223</td>\n",
              "      <td>31.719</td>\n",
              "      <td>24.351</td>\n",
              "      <td>0.001</td>\n",
              "      <td>5.620</td>\n",
              "      <td>11.739</td>\n",
              "      <td>9.865</td>\n",
              "      <td>5.620</td>\n",
              "      <td>0.011</td>\n",
              "      <td>1.249</td>\n",
              "      <td>6.244</td>\n",
              "      <td>3.247</td>\n",
              "      <td>0.999</td>\n",
              "      <td>0.000</td>\n",
              "      <td>43.083</td>\n",
              "      <td>49.826</td>\n",
              "      <td>49.951</td>\n",
              "      <td>49.951</td>\n",
              "      <td>0.001</td>\n",
              "      <td>9.616</td>\n",
              "      <td>16.640</td>\n",
              "      <td>15.735</td>\n",
              "      <td>9.740</td>\n",
              "      <td>0.001</td>\n",
              "      <td>18.607</td>\n",
              "      <td>28.472</td>\n",
              "      <td>32.219</td>\n",
              "      <td>49.951</td>\n",
              "      <td>0.002</td>\n",
              "      <td>5.620</td>\n",
              "      <td>11.863</td>\n",
              "      <td>9.865</td>\n",
              "      <td>5.495</td>\n",
              "      <td>0.009</td>\n",
              "      <td>1.374</td>\n",
              "      <td>6.369</td>\n",
              "      <td>3.497</td>\n",
              "      <td>0.999</td>\n",
              "      <td>0.000</td>\n",
              "      <td>49.701</td>\n",
              "      <td>49.826</td>\n",
              "      <td>49.951</td>\n",
              "      <td>49.951</td>\n",
              "      <td>0.001</td>\n",
              "      <td>9.616</td>\n",
              "      <td>16.734</td>\n",
              "      <td>15.984</td>\n",
              "      <td>9.366</td>\n",
              "      <td>0.000</td>\n",
              "      <td>16.734</td>\n",
              "      <td>27.723</td>\n",
              "      <td>31.344</td>\n",
              "      <td>22.978</td>\n",
              "      <td>0.001</td>\n",
              "      <td>5.994</td>\n",
              "      <td>11.863</td>\n",
              "      <td>9.990</td>\n",
              "      <td>6.119</td>\n",
              "      <td>0.004</td>\n",
              "      <td>1.124</td>\n",
              "      <td>6.743</td>\n",
              "      <td>3.621</td>\n",
              "      <td>0.874</td>\n",
              "      <td>0.000</td>\n",
              "      <td>41.709</td>\n",
              "      <td>49.826</td>\n",
              "      <td>49.951</td>\n",
              "      <td>49.951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.032</td>\n",
              "      <td>15.235</td>\n",
              "      <td>26.349</td>\n",
              "      <td>27.598</td>\n",
              "      <td>21.604</td>\n",
              "      <td>0.037</td>\n",
              "      <td>27.348</td>\n",
              "      <td>49.826</td>\n",
              "      <td>49.951</td>\n",
              "      <td>50.076</td>\n",
              "      <td>0.026</td>\n",
              "      <td>9.491</td>\n",
              "      <td>18.482</td>\n",
              "      <td>16.234</td>\n",
              "      <td>12.613</td>\n",
              "      <td>0.787</td>\n",
              "      <td>1.998</td>\n",
              "      <td>9.865</td>\n",
              "      <td>6.244</td>\n",
              "      <td>3.247</td>\n",
              "      <td>0.015</td>\n",
              "      <td>49.951</td>\n",
              "      <td>49.951</td>\n",
              "      <td>58.568</td>\n",
              "      <td>50.076</td>\n",
              "      <td>0.012</td>\n",
              "      <td>15.860</td>\n",
              "      <td>49.826</td>\n",
              "      <td>49.826</td>\n",
              "      <td>50.076</td>\n",
              "      <td>0.023</td>\n",
              "      <td>49.951</td>\n",
              "      <td>49.951</td>\n",
              "      <td>50.076</td>\n",
              "      <td>50.076</td>\n",
              "      <td>0.030</td>\n",
              "      <td>9.491</td>\n",
              "      <td>19.481</td>\n",
              "      <td>18.107</td>\n",
              "      <td>12.613</td>\n",
              "      <td>1.009</td>\n",
              "      <td>2.498</td>\n",
              "      <td>10.864</td>\n",
              "      <td>6.993</td>\n",
              "      <td>3.497</td>\n",
              "      <td>0.009</td>\n",
              "      <td>49.951</td>\n",
              "      <td>49.951</td>\n",
              "      <td>55.196</td>\n",
              "      <td>50.076</td>\n",
              "      <td>0.031</td>\n",
              "      <td>16.109</td>\n",
              "      <td>27.348</td>\n",
              "      <td>27.973</td>\n",
              "      <td>49.951</td>\n",
              "      <td>0.028</td>\n",
              "      <td>49.826</td>\n",
              "      <td>49.951</td>\n",
              "      <td>50.076</td>\n",
              "      <td>50.076</td>\n",
              "      <td>0.070</td>\n",
              "      <td>11.364</td>\n",
              "      <td>20.730</td>\n",
              "      <td>20.105</td>\n",
              "      <td>14.486</td>\n",
              "      <td>1.293</td>\n",
              "      <td>2.373</td>\n",
              "      <td>13.112</td>\n",
              "      <td>9.616</td>\n",
              "      <td>2.747</td>\n",
              "      <td>0.010</td>\n",
              "      <td>49.951</td>\n",
              "      <td>49.951</td>\n",
              "      <td>55.196</td>\n",
              "      <td>50.076</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b862127a-5ebf-4e8b-aaa2-8e9f9bcfd48e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b862127a-5ebf-4e8b-aaa2-8e9f9bcfd48e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b862127a-5ebf-4e8b-aaa2-8e9f9bcfd48e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 24;\n",
              "                var nbb_unformatted_code = \"# let's view the statistical summary of the numerical columns in the data\\ndata.describe()\";\n",
              "                var nbb_formatted_code = \"# let's view the statistical summary of the numerical columns in the data\\ndata.describe()\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# let's view the statistical summary of the numerical columns in the data\n",
        "data.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCW1kGcdCYy2"
      },
      "source": [
        "- The spread of attributes will be explored further (univariate analysis)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVCj6_DD4jan"
      },
      "source": [
        "## Univariate Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "vrJ16QJBCYy2"
      },
      "outputs": [],
      "source": [
        "cols = data.columns.tolist()\n",
        "\n",
        "plt.figure(figsize=(20, 50))\n",
        "for i, variable in enumerate(cols):\n",
        "    plt.subplot(14, 3, i + 1)\n",
        "    sns.boxplot(data[variable])\n",
        "    plt.tight_layout()\n",
        "    plt.title(variable)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfHRSY0TCYy3"
      },
      "source": [
        "- There are positive and negative outliers for all attributes \"V1\" to \"V40\". The scale of attributes are more or less the same (somewhere between -20 to +20). Since not much is known about the attributes, the outliers will not be treated and are assumed to be real data trends"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "xZ0QGqmHCYy3",
        "outputId": "3d333712-4648-44af-af2d-687aa22f7f0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "N2    1884\n",
              "W      926\n",
              "N3     827\n",
              "R      793\n",
              "N1     570\n",
              "Name: Sleep Stage, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 26;\n",
              "                var nbb_unformatted_code = \"plt.figure(figsize=(6, 4))\\nsns.countplot(data[\\\"Sleep Stage\\\"])\\nplt.show()\\ndata[\\\"Sleep Stage\\\"].value_counts()\";\n",
              "                var nbb_formatted_code = \"plt.figure(figsize=(6, 4))\\nsns.countplot(data[\\\"Sleep Stage\\\"])\\nplt.show()\\ndata[\\\"Sleep Stage\\\"].value_counts()\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.figure(figsize=(6, 4))\n",
        "sns.countplot(data[\"Sleep Stage\"])\n",
        "plt.show()\n",
        "data[\"Sleep Stage\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENsghNY9CYy3"
      },
      "source": [
        "- \"Target\" class is imbalanced with 37813 or 94.53% \"No failures (i.e., 0)\" and 2187 or 5.47% \"Failures (i.e., 1)\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knk0w9XH4jao"
      },
      "source": [
        "## Data Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "2JbJc1bX4jao",
        "outputId": "fdbe248e-dde6-40c0-9439-df917076fa65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 27;\n",
              "                var nbb_unformatted_code = \"# Split data\\ndf = data.copy()\\n\\nX = df.drop([\\\"Sleep Stage\\\"], axis=1)\\ny = df[\\\"Sleep Stage\\\"]\";\n",
              "                var nbb_formatted_code = \"# Split data\\ndf = data.copy()\\n\\nX = df.drop([\\\"Sleep Stage\\\"], axis=1)\\ny = df[\\\"Sleep Stage\\\"]\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Split data\n",
        "df = data.copy()\n",
        "\n",
        "X = df.drop([\"Sleep Stage\"], axis=1)\n",
        "y = df[\"Sleep Stage\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "zpm3kr8UCYy4",
        "outputId": "f3ed3117-551b-4f9f-ec14-930dd06b1b1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3500, 75) (1500, 75)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 28;\n",
              "                var nbb_unformatted_code = \"# Splitting data into training and validation sets:\\n\\nX_train, X_val, y_train, y_val = train_test_split(\\n    X, y, test_size=0.30, random_state=1, stratify=y\\n)\\nprint(X_train.shape, X_val.shape)\";\n",
              "                var nbb_formatted_code = \"# Splitting data into training and validation sets:\\n\\nX_train, X_val, y_train, y_val = train_test_split(\\n    X, y, test_size=0.30, random_state=1, stratify=y\\n)\\nprint(X_train.shape, X_val.shape)\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Splitting data into training and validation sets:\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.30, random_state=1, stratify=y\n",
        ")\n",
        "print(X_train.shape, X_val.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Dw_A3ygCYy4"
      },
      "source": [
        "- There are 28000 rows in the training and 12000 rows in the validation sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "7HOHVMI-CYy5",
        "outputId": "e4c23a14-fb86-40c0-c1df-09b83bbb524a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "N2    1319\n",
              "W      648\n",
              "N3     579\n",
              "R      555\n",
              "N1     399\n",
              "Name: Sleep Stage, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 29;\n",
              "                var nbb_unformatted_code = \"y_train.value_counts()\";\n",
              "                var nbb_formatted_code = \"y_train.value_counts()\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "y_train.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "r62wSQvsCYy5",
        "outputId": "ebf82c40-57ca-4c98-9d6b-c8c3602be97a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "N2    565\n",
              "W     278\n",
              "N3    248\n",
              "R     238\n",
              "N1    171\n",
              "Name: Sleep Stage, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 30;\n",
              "                var nbb_unformatted_code = \"y_val.value_counts()\";\n",
              "                var nbb_formatted_code = \"y_val.value_counts()\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "y_val.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxAyqae2CYy6"
      },
      "source": [
        "- Stratify has maintained a distribution of 94.53% \"No failures\" or \"0\" and 5.47% \"Failures\" or \"1\" in both the test and validation splits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_MoRFurCYy6"
      },
      "source": [
        "### Missing-Value Treatment\n",
        "\n",
        "* We will use median to impute missing values in \"V1\" and \"V2\" columns. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "AoHCoHHaCYy7",
        "outputId": "cc9becd9-6f73-4009-d572-adc1a738ac94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 31;\n",
              "                var nbb_unformatted_code = \"imputer = SimpleImputer(strategy=\\\"median\\\")\\nimpute = imputer.fit(X_train)\\n\\nX_train = impute.transform(X_train)\\nX_val = imputer.transform(X_val)\";\n",
              "                var nbb_formatted_code = \"imputer = SimpleImputer(strategy=\\\"median\\\")\\nimpute = imputer.fit(X_train)\\n\\nX_train = impute.transform(X_train)\\nX_val = imputer.transform(X_val)\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "imputer = SimpleImputer(strategy=\"median\")\n",
        "impute = imputer.fit(X_train)\n",
        "\n",
        "X_train = impute.transform(X_train)\n",
        "X_val = imputer.transform(X_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONL1sM1n4jap"
      },
      "source": [
        "## Model evaluation criterion\n",
        "\n",
        "### 3 types of cost are associated with the provided problem\n",
        "1. Replacement cost - False Negatives - Predicting no failure, while there will be a failure\n",
        "2. Inspection cost - False Positives - Predicting failure, while there is no failure \n",
        "3. Repair cost - True Positives - Predicting failure correctly\n",
        "\n",
        "### How to reduce the overall cost?\n",
        "* We need to create a customized metric, that can help to bring down the overall cost\n",
        "* The cost associated with any model = (TPX15000) + (FPX5000) + (FNX40000)\n",
        "* And the minimum possible cost will be when, the model will be able to identify all failures, in that case, the cost will be (TP + FN)X15000\n",
        "* So, we will try to maximize `Minimum cost/Cost associated with model`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djQTqGKU4jap"
      },
      "source": [
        "### Let's create two functions to calculate different metrics and confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "bIekBxwp4jaq",
        "outputId": "5b96d6b2-3d23-419b-ee61-7981826051be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 32;\n",
              "                var nbb_unformatted_code = \"# defining a function to compute different metrics to check performance of a classification model built using sklearn\\ndef model_performance_classification_sklearn(model, predictors, target):\\n    \\\"\\\"\\\"\\n    Function to compute different metrics to check classification model performance\\n\\n    model: classifier\\n    predictors: independent variables\\n    target: dependent variable\\n    \\\"\\\"\\\"\\n\\n    TP = confusion_matrix(target, model.predict(predictors))[1, 1]\\n    FP = confusion_matrix(target, model.predict(predictors))[0, 1]\\n    FN = confusion_matrix(target, model.predict(predictors))[1, 0]\\n    Cost = TP * 15 + FP * 5 + FN * 40  # maintenance cost by using model\\n    Min_Cost = (\\n        TP + FN\\n    ) * 15  # minimum possible maintenance cost = number of actual positives\\n    Percent = (\\n        Min_Cost / Cost\\n    )  # ratio of minimum possible maintenance cost and maintenance cost by model\\n\\n    # predicting using the independent variables\\n    pred = model.predict(predictors)\\n\\n    acc = accuracy_score(target, pred)  # to compute Accuracy\\n    recall = recall_score(target, pred)  # to compute Recall\\n    precision = precision_score(target, pred)  # to compute Precision\\n    f1 = f1_score(target, pred)  # to compute F1-score\\n\\n    # creating a dataframe of metrics\\n    df_perf = pd.DataFrame(\\n        {\\n            \\\"Accuracy\\\": acc,\\n            \\\"Recall\\\": recall,\\n            \\\"Precision\\\": precision,\\n            \\\"F1\\\": f1,\\n            \\\"Minimum_Vs_Model_cost\\\": Percent,\\n        },\\n        index=[0],\\n    )\\n\\n    return df_perf\";\n",
              "                var nbb_formatted_code = \"# defining a function to compute different metrics to check performance of a classification model built using sklearn\\ndef model_performance_classification_sklearn(model, predictors, target):\\n    \\\"\\\"\\\"\\n    Function to compute different metrics to check classification model performance\\n\\n    model: classifier\\n    predictors: independent variables\\n    target: dependent variable\\n    \\\"\\\"\\\"\\n\\n    TP = confusion_matrix(target, model.predict(predictors))[1, 1]\\n    FP = confusion_matrix(target, model.predict(predictors))[0, 1]\\n    FN = confusion_matrix(target, model.predict(predictors))[1, 0]\\n    Cost = TP * 15 + FP * 5 + FN * 40  # maintenance cost by using model\\n    Min_Cost = (\\n        TP + FN\\n    ) * 15  # minimum possible maintenance cost = number of actual positives\\n    Percent = (\\n        Min_Cost / Cost\\n    )  # ratio of minimum possible maintenance cost and maintenance cost by model\\n\\n    # predicting using the independent variables\\n    pred = model.predict(predictors)\\n\\n    acc = accuracy_score(target, pred)  # to compute Accuracy\\n    recall = recall_score(target, pred)  # to compute Recall\\n    precision = precision_score(target, pred)  # to compute Precision\\n    f1 = f1_score(target, pred)  # to compute F1-score\\n\\n    # creating a dataframe of metrics\\n    df_perf = pd.DataFrame(\\n        {\\n            \\\"Accuracy\\\": acc,\\n            \\\"Recall\\\": recall,\\n            \\\"Precision\\\": precision,\\n            \\\"F1\\\": f1,\\n            \\\"Minimum_Vs_Model_cost\\\": Percent,\\n        },\\n        index=[0],\\n    )\\n\\n    return df_perf\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# defining a function to compute different metrics to check performance of a classification model built using sklearn\n",
        "def model_performance_classification_sklearn(model, predictors, target):\n",
        "    \"\"\"\n",
        "    Function to compute different metrics to check classification model performance\n",
        "\n",
        "    model: classifier\n",
        "    predictors: independent variables\n",
        "    target: dependent variable\n",
        "    \"\"\"\n",
        "\n",
        "    TP = confusion_matrix(target, model.predict(predictors))[1, 1]\n",
        "    FP = confusion_matrix(target, model.predict(predictors))[0, 1]\n",
        "    FN = confusion_matrix(target, model.predict(predictors))[1, 0]\n",
        "    Cost = TP * 15 + FP * 5 + FN * 40  # maintenance cost by using model\n",
        "    Min_Cost = (\n",
        "        TP + FN\n",
        "    ) * 15  # minimum possible maintenance cost = number of actual positives\n",
        "    Percent = (\n",
        "        Min_Cost / Cost\n",
        "    )  # ratio of minimum possible maintenance cost and maintenance cost by model\n",
        "\n",
        "    # predicting using the independent variables\n",
        "    pred = model.predict(predictors)\n",
        "\n",
        "    acc = accuracy_score(target, pred)  # to compute Accuracy\n",
        "    recall = recall_score(target, pred)  # to compute Recall\n",
        "    precision = precision_score(target, pred)  # to compute Precision\n",
        "    f1 = f1_score(target, pred)  # to compute F1-score\n",
        "\n",
        "    # creating a dataframe of metrics\n",
        "    df_perf = pd.DataFrame(\n",
        "        {\n",
        "            \"Accuracy\": acc,\n",
        "            \"Recall\": recall,\n",
        "            \"Precision\": precision,\n",
        "            \"F1\": f1,\n",
        "            \"Minimum_Vs_Model_cost\": Percent,\n",
        "        },\n",
        "        index=[0],\n",
        "    )\n",
        "\n",
        "    return df_perf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "8LXyI50s4jar",
        "outputId": "65af9f45-02e0-4711-b152-ec2e6cc7656a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 33;\n",
              "                var nbb_unformatted_code = \"def confusion_matrix_sklearn(model, predictors, target):\\n    \\\"\\\"\\\"\\n    To plot the confusion_matrix with percentages\\n\\n    model: classifier\\n    predictors: independent variables\\n    target: dependent variable\\n    \\\"\\\"\\\"\\n    y_pred = model.predict(predictors)\\n    cm = confusion_matrix(target, y_pred)\\n    labels = np.asarray(\\n        [\\n            [\\\"{0:0.0f}\\\".format(item) + \\\"\\\\n{0:.2%}\\\".format(item / cm.flatten().sum())]\\n            for item in cm.flatten()\\n        ]\\n    ).reshape(2, 2)\\n\\n    plt.figure(figsize=(6, 4))\\n    sns.heatmap(cm, annot=labels, fmt=\\\"\\\")\\n    plt.ylabel(\\\"True label\\\")\\n    plt.xlabel(\\\"Predicted label\\\")\";\n",
              "                var nbb_formatted_code = \"def confusion_matrix_sklearn(model, predictors, target):\\n    \\\"\\\"\\\"\\n    To plot the confusion_matrix with percentages\\n\\n    model: classifier\\n    predictors: independent variables\\n    target: dependent variable\\n    \\\"\\\"\\\"\\n    y_pred = model.predict(predictors)\\n    cm = confusion_matrix(target, y_pred)\\n    labels = np.asarray(\\n        [\\n            [\\\"{0:0.0f}\\\".format(item) + \\\"\\\\n{0:.2%}\\\".format(item / cm.flatten().sum())]\\n            for item in cm.flatten()\\n        ]\\n    ).reshape(2, 2)\\n\\n    plt.figure(figsize=(6, 4))\\n    sns.heatmap(cm, annot=labels, fmt=\\\"\\\")\\n    plt.ylabel(\\\"True label\\\")\\n    plt.xlabel(\\\"Predicted label\\\")\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def confusion_matrix_sklearn(model, predictors, target):\n",
        "    \"\"\"\n",
        "    To plot the confusion_matrix with percentages\n",
        "\n",
        "    model: classifier\n",
        "    predictors: independent variables\n",
        "    target: dependent variable\n",
        "    \"\"\"\n",
        "    y_pred = model.predict(predictors)\n",
        "    cm = confusion_matrix(target, y_pred)\n",
        "    labels = np.asarray(\n",
        "        [\n",
        "            [\"{0:0.0f}\".format(item) + \"\\n{0:.2%}\".format(item / cm.flatten().sum())]\n",
        "            for item in cm.flatten()\n",
        "        ]\n",
        "    ).reshape(2, 2)\n",
        "\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.heatmap(cm, annot=labels, fmt=\"\")\n",
        "    plt.ylabel(\"True label\")\n",
        "    plt.xlabel(\"Predicted label\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rxw_gopM4jar"
      },
      "source": [
        "###  Defining scorer to be used for hyperparameter tuning\n",
        "\n",
        "- Every prediction of a classification model will be either a TP, FP, FN or TN\n",
        "- For this classification problem, we need to reduce the maintenance cost, which can be reiterated as:\n",
        "  - Maximize (minimum possible maintenance cost/maintenance cost)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "X09SzkBA4jas",
        "outputId": "ce379174-c7e2-4cd0-f53a-2e4e3016364b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 34;\n",
              "                var nbb_unformatted_code = \"# defining metric to be used for optimization and with cross-validation\\ndef Minimum_Vs_Model_cost(y_train, y_pred):\\n    \\\"\\\"\\\"\\n    We want the model to optimize the maintenance cost and reduce it to the lowest possible value.\\n    The lowest possible maintenance cost will be achieved when each sample is predicted correctly.\\n\\n    In such a scenario, the maintenance cost will be the total number of failures times the maintenance cost of replacing one generator,\\n    which is given by (TP + FN) * 40 (i.e., the actual positives*40).\\n    For any other scenario,\\n    the maintenance cost associated with the model will be given by (TP * 15 + FP * 5 + FN * 40).\\n\\n    We will use the ratio of these two maintenance costs as the cost function for our model.\\n    The greater the ratio, the lower the associated maintenance cost and the better the model.\\n    \\\"\\\"\\\"\\n    TP = confusion_matrix(y_train, y_pred)[1, 1]\\n    FP = confusion_matrix(y_train, y_pred)[0, 1]\\n    FN = confusion_matrix(y_train, y_pred)[1, 0]\\n    return ((TP + FN) * 15) / (TP * 15 + FP * 5 + FN * 40)\\n\\n\\n# A value of .80 here, will represent that the minimum maintenance cost is 80% of the maintenance cost associated with the model.\\n# Since minimum maintenance cost is constant for any data, when minimum cost will become 100% of maintenance cost associated with the model\\n# Model will have give the least possible maintenance cost.\\n\\n\\n# Type of scoring used to compare parameter combinations\\nscorer = metrics.make_scorer(Minimum_Vs_Model_cost, greater_is_better=True)\\n\\n# Higher the values, the lower the maintenance cost\";\n",
              "                var nbb_formatted_code = \"# defining metric to be used for optimization and with cross-validation\\ndef Minimum_Vs_Model_cost(y_train, y_pred):\\n    \\\"\\\"\\\"\\n    We want the model to optimize the maintenance cost and reduce it to the lowest possible value.\\n    The lowest possible maintenance cost will be achieved when each sample is predicted correctly.\\n\\n    In such a scenario, the maintenance cost will be the total number of failures times the maintenance cost of replacing one generator,\\n    which is given by (TP + FN) * 40 (i.e., the actual positives*40).\\n    For any other scenario,\\n    the maintenance cost associated with the model will be given by (TP * 15 + FP * 5 + FN * 40).\\n\\n    We will use the ratio of these two maintenance costs as the cost function for our model.\\n    The greater the ratio, the lower the associated maintenance cost and the better the model.\\n    \\\"\\\"\\\"\\n    TP = confusion_matrix(y_train, y_pred)[1, 1]\\n    FP = confusion_matrix(y_train, y_pred)[0, 1]\\n    FN = confusion_matrix(y_train, y_pred)[1, 0]\\n    return ((TP + FN) * 15) / (TP * 15 + FP * 5 + FN * 40)\\n\\n\\n# A value of .80 here, will represent that the minimum maintenance cost is 80% of the maintenance cost associated with the model.\\n# Since minimum maintenance cost is constant for any data, when minimum cost will become 100% of maintenance cost associated with the model\\n# Model will have give the least possible maintenance cost.\\n\\n\\n# Type of scoring used to compare parameter combinations\\nscorer = metrics.make_scorer(Minimum_Vs_Model_cost, greater_is_better=True)\\n\\n# Higher the values, the lower the maintenance cost\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# defining metric to be used for optimization and with cross-validation\n",
        "def Minimum_Vs_Model_cost(y_train, y_pred):\n",
        "    \"\"\"\n",
        "    We want the model to optimize the maintenance cost and reduce it to the lowest possible value.\n",
        "    The lowest possible maintenance cost will be achieved when each sample is predicted correctly.\n",
        "\n",
        "    In such a scenario, the maintenance cost will be the total number of failures times the maintenance cost of replacing one generator,\n",
        "    which is given by (TP + FN) * 40 (i.e., the actual positives*40).\n",
        "    For any other scenario,\n",
        "    the maintenance cost associated with the model will be given by (TP * 15 + FP * 5 + FN * 40).\n",
        "\n",
        "    We will use the ratio of these two maintenance costs as the cost function for our model.\n",
        "    The greater the ratio, the lower the associated maintenance cost and the better the model.\n",
        "    \"\"\"\n",
        "    TP = confusion_matrix(y_train, y_pred)[1, 1]\n",
        "    FP = confusion_matrix(y_train, y_pred)[0, 1]\n",
        "    FN = confusion_matrix(y_train, y_pred)[1, 0]\n",
        "    return ((TP + FN) * 15) / (TP * 15 + FP * 5 + FN * 40)\n",
        "\n",
        "\n",
        "# A value of .80 here, will represent that the minimum maintenance cost is 80% of the maintenance cost associated with the model.\n",
        "# Since minimum maintenance cost is constant for any data, when minimum cost will become 100% of maintenance cost associated with the model\n",
        "# Model will have give the least possible maintenance cost.\n",
        "\n",
        "\n",
        "# Type of scoring used to compare parameter combinations\n",
        "scorer = metrics.make_scorer(Minimum_Vs_Model_cost, greater_is_better=True)\n",
        "\n",
        "# Higher the values, the lower the maintenance cost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqCDCbcw4jas"
      },
      "source": [
        "## Model Building with Original Training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "V-tpzI7g4jas",
        "outputId": "2a392481-0e4d-4d09-94bc-704846196be1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 798
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cross-Validation Performance:\n",
            "\n",
            "Logistic Regression: 0.9208724629397074\n",
            "dtree: 0.8554851527741485\n",
            "Random forest: 0.9275196273213014\n",
            "Bagging: 0.8991681099203452\n",
            "Adaboost: 0.9016395232205436\n",
            "GBM: 0.9245363126028796\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-aa1b103c094a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     )  # Setting number of splits equal to 5\n\u001b[0;32m---> 27\u001b[0;31m     cv_result = cross_val_score(\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m     cv_results = cross_validate(\n\u001b[0m\u001b[1;32m    516\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    283\u001b[0m     )\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m     \u001b[0m_warn_or_raise_about_fit_failures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;31m# For callabe scoring, the return type is only know after calling. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    365\u001b[0m                 \u001b[0;34mf\"Below are more details about the failures:\\n{fit_errors_summary}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m             )\n\u001b[0;32m--> 367\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_fits_failed_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.8/dist-packages/xgboost/core.py\", line 620, in inner_f\n    return func(**kwargs)\n  File \"/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py\", line 1440, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3 4], got ['N1' 'N2' 'N3' 'R' 'W']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 35;\n",
              "                var nbb_unformatted_code = \"models = []  # Empty list to store all the models\\n\\n# Appending models into the list\\n\\nmodels.append(\\n    (\\\"Logistic Regression\\\", LogisticRegression(solver=\\\"newton-cg\\\", random_state=1))\\n)\\nmodels.append((\\\"dtree\\\", DecisionTreeClassifier(random_state=1)))\\nmodels.append((\\\"Random forest\\\", RandomForestClassifier(random_state=1)))\\nmodels.append((\\\"Bagging\\\", BaggingClassifier(random_state=1)))\\nmodels.append((\\\"Adaboost\\\", AdaBoostClassifier(random_state=1)))\\nmodels.append((\\\"GBM\\\", GradientBoostingClassifier(random_state=1)))\\nmodels.append((\\\"Xgboost\\\", XGBClassifier(random_state=1, eval_metric=\\\"logloss\\\")))\\n\\nresults = []  # Empty list to store all model's CV scores\\nnames = []  # Empty list to store name of the models\\nscore = []\\n\\n# loop through all models to get the mean cross validated score\\n\\nprint(\\\"\\\\n\\\" \\\"Cross-Validation Performance:\\\" \\\"\\\\n\\\")\\n\\nfor name, model in models:\\n    kfold = StratifiedKFold(\\n        n_splits=5, shuffle=True, random_state=1\\n    )  # Setting number of splits equal to 5\\n    cv_result = cross_val_score(\\n        estimator=model, X=X_train, y=y_train, scoring=scorer, cv=kfold\\n    )\\n    results.append(cv_result)\\n    names.append(name)\\n    print(\\\"{}: {}\\\".format(name, cv_result.mean()))\";\n",
              "                var nbb_formatted_code = \"models = []  # Empty list to store all the models\\n\\n# Appending models into the list\\n\\nmodels.append(\\n    (\\\"Logistic Regression\\\", LogisticRegression(solver=\\\"newton-cg\\\", random_state=1))\\n)\\nmodels.append((\\\"dtree\\\", DecisionTreeClassifier(random_state=1)))\\nmodels.append((\\\"Random forest\\\", RandomForestClassifier(random_state=1)))\\nmodels.append((\\\"Bagging\\\", BaggingClassifier(random_state=1)))\\nmodels.append((\\\"Adaboost\\\", AdaBoostClassifier(random_state=1)))\\nmodels.append((\\\"GBM\\\", GradientBoostingClassifier(random_state=1)))\\nmodels.append((\\\"Xgboost\\\", XGBClassifier(random_state=1, eval_metric=\\\"logloss\\\")))\\n\\nresults = []  # Empty list to store all model's CV scores\\nnames = []  # Empty list to store name of the models\\nscore = []\\n\\n# loop through all models to get the mean cross validated score\\n\\nprint(\\\"\\\\n\\\" \\\"Cross-Validation Performance:\\\" \\\"\\\\n\\\")\\n\\nfor name, model in models:\\n    kfold = StratifiedKFold(\\n        n_splits=5, shuffle=True, random_state=1\\n    )  # Setting number of splits equal to 5\\n    cv_result = cross_val_score(\\n        estimator=model, X=X_train, y=y_train, scoring=scorer, cv=kfold\\n    )\\n    results.append(cv_result)\\n    names.append(name)\\n    print(\\\"{}: {}\\\".format(name, cv_result.mean()))\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "models = []  # Empty list to store all the models\n",
        "\n",
        "# Appending models into the list\n",
        "\n",
        "models.append(\n",
        "    (\"Logistic Regression\", LogisticRegression(solver=\"newton-cg\", random_state=1))\n",
        ")\n",
        "models.append((\"dtree\", DecisionTreeClassifier(random_state=1)))\n",
        "models.append((\"Random forest\", RandomForestClassifier(random_state=1)))\n",
        "models.append((\"Bagging\", BaggingClassifier(random_state=1)))\n",
        "models.append((\"Adaboost\", AdaBoostClassifier(random_state=1)))\n",
        "models.append((\"GBM\", GradientBoostingClassifier(random_state=1)))\n",
        "models.append((\"Xgboost\", XGBClassifier(random_state=1, eval_metric=\"logloss\")))\n",
        "\n",
        "results = []  # Empty list to store all model's CV scores\n",
        "names = []  # Empty list to store name of the models\n",
        "score = []\n",
        "\n",
        "# loop through all models to get the mean cross validated score\n",
        "\n",
        "print(\"\\n\" \"Cross-Validation Performance:\" \"\\n\")\n",
        "\n",
        "for name, model in models:\n",
        "    kfold = StratifiedKFold(\n",
        "        n_splits=5, shuffle=True, random_state=1\n",
        "    )  # Setting number of splits equal to 5\n",
        "    cv_result = cross_val_score(\n",
        "        estimator=model, X=X_train, y=y_train, scoring=scorer, cv=kfold\n",
        "    )\n",
        "    results.append(cv_result)\n",
        "    names.append(name)\n",
        "    print(\"{}: {}\".format(name, cv_result.mean()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "6EkWBCWcCYzB",
        "outputId": "ba9ac7c6-0ddd-46f2-cc74-9c48e74dc89e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Performance:\n",
            "\n",
            "Logistic Regression: 0.9429718875502008\n",
            "dtree: 1.0\n",
            "Random forest: 1.0\n",
            "Bagging: 0.9949443882709808\n",
            "Adaboost: 0.9087099670757258\n",
            "GBM: 0.9671396564600448\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-63156229d360>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMinimum_Vs_Model_cost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{}: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1438\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mexpected_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1439\u001b[0m             ):\n\u001b[0;32m-> 1440\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   1441\u001b[0m                     \u001b[0;34mf\"Invalid classes inferred from unique values of `y`.  \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1442\u001b[0m                     \u001b[0;34mf\"Expected: {expected_classes}, got {self.classes_}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3 4], got ['N1' 'N2' 'N3' 'R' 'W']"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 36;\n",
              "                var nbb_unformatted_code = \"print(\\\"\\\\n\\\" \\\"Training Performance:\\\" \\\"\\\\n\\\")\\n\\nfor name, model in models:\\n    model.fit(X_train, y_train)\\n    scores = Minimum_Vs_Model_cost(y_train, model.predict(X_train))\\n    print(\\\"{}: {}\\\".format(name, scores))\";\n",
              "                var nbb_formatted_code = \"print(\\\"\\\\n\\\" \\\"Training Performance:\\\" \\\"\\\\n\\\")\\n\\nfor name, model in models:\\n    model.fit(X_train, y_train)\\n    scores = Minimum_Vs_Model_cost(y_train, model.predict(X_train))\\n    print(\\\"{}: {}\\\".format(name, scores))\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "print(\"\\n\" \"Training Performance:\" \"\\n\")\n",
        "\n",
        "for name, model in models:\n",
        "    model.fit(X_train, y_train)\n",
        "    scores = Minimum_Vs_Model_cost(y_train, model.predict(X_train))\n",
        "    print(\"{}: {}\".format(name, scores))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "SodOURqHCYzE",
        "outputId": "a64db589-3085-4504-8468-dd12ca9efeda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation Performance:\n",
            "\n",
            "Logistic Regression: 0.9084888621312462\n",
            "dtree: 0.8459250446162998\n",
            "Random forest: 0.9114369501466275\n",
            "Bagging: 0.8700854700854701\n",
            "Adaboost: 0.897489539748954\n",
            "GBM: 0.9043988269794722\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-77edad1be4c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMinimum_Vs_Model_cost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{}: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1438\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mexpected_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1439\u001b[0m             ):\n\u001b[0;32m-> 1440\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   1441\u001b[0m                     \u001b[0;34mf\"Invalid classes inferred from unique values of `y`.  \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1442\u001b[0m                     \u001b[0;34mf\"Expected: {expected_classes}, got {self.classes_}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3 4], got ['N1' 'N2' 'N3' 'R' 'W']"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 37;\n",
              "                var nbb_unformatted_code = \"print(\\\"\\\\n\\\" \\\"Validation Performance:\\\" \\\"\\\\n\\\")\\n\\nfor name, model in models:\\n    model.fit(X_train, y_train)\\n    scores = Minimum_Vs_Model_cost(y_val, model.predict(X_val))\\n    print(\\\"{}: {}\\\".format(name, scores))\";\n",
              "                var nbb_formatted_code = \"print(\\\"\\\\n\\\" \\\"Validation Performance:\\\" \\\"\\\\n\\\")\\n\\nfor name, model in models:\\n    model.fit(X_train, y_train)\\n    scores = Minimum_Vs_Model_cost(y_val, model.predict(X_val))\\n    print(\\\"{}: {}\\\".format(name, scores))\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "print(\"\\n\" \"Validation Performance:\" \"\\n\")\n",
        "\n",
        "for name, model in models:\n",
        "    model.fit(X_train, y_train)\n",
        "    scores = Minimum_Vs_Model_cost(y_val, model.predict(X_val))\n",
        "    print(\"{}: {}\".format(name, scores))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5abj1xhcCYzF"
      },
      "source": [
        "- The cross validation training performance scores (customized metric) are similar to the validation perfromance score. This indicates that the default algorithms on original dataset are able to generalize well\n",
        "- There is a tendency for some models (decision tree, random forest, bagging and XGBoost) to overfit the training set; as the training performance score (customized metric) approaches 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVFUd8dFCYzG",
        "outputId": "170b7c97-14c4-4a94-e9bf-a7c152f7e60e"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 25;\n",
              "                var nbb_unformatted_code = \"# Plotting boxplots for CV scores of all models defined above\\n\\nfig = plt.figure(figsize=(10, 4))\\n\\nfig.suptitle(\\\"Algorithm Comparison\\\")\\nax = fig.add_subplot(111)\\n\\nplt.boxplot(results)\\nax.set_xticklabels(names)\\n\\nplt.show()\";\n",
              "                var nbb_formatted_code = \"# Plotting boxplots for CV scores of all models defined above\\n\\nfig = plt.figure(figsize=(10, 4))\\n\\nfig.suptitle(\\\"Algorithm Comparison\\\")\\nax = fig.add_subplot(111)\\n\\nplt.boxplot(results)\\nax.set_xticklabels(names)\\n\\nplt.show()\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plotting boxplots for CV scores of all models defined above\n",
        "\n",
        "fig = plt.figure(figsize=(10, 4))\n",
        "\n",
        "fig.suptitle(\"Algorithm Comparison\")\n",
        "ax = fig.add_subplot(111)\n",
        "\n",
        "plt.boxplot(results)\n",
        "ax.set_xticklabels(names)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49jhAxSACYzG"
      },
      "source": [
        "- XGBoost (~ 0.77) and Random Forest (~ 0.71) have the best average (& median) training cross validation scores (on the customized metric). This is closely followed by Bagging Classifier (~ 0.68)\n",
        "- XGBoost and AdaBoost each have one outlier as can be observed from the boxplot\n",
        "- The boxplot widths (spread of CV scores) is small for XGBoost, Random Forest and Bagging Classifier as well, indicating these are reliable models to choose for further optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBKJaFU24jas"
      },
      "source": [
        "## Model Building with Oversampled Training data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9dYl2YwCYzH",
        "outputId": "8ac358e9-e420-434a-ef36-7065391a1a4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before Oversampling, counts of label '1 (Failures)': 1531\n",
            "Before Oversampling, counts of label '0 (No failures)': 26469 \n",
            "\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 26;\n",
              "                var nbb_unformatted_code = \"print(\\n    \\\"Before Oversampling, counts of label '1 (Failures)': {}\\\".format(sum(y_train == 1))\\n)\\nprint(\\n    \\\"Before Oversampling, counts of label '0 (No failures)': {} \\\\n\\\".format(\\n        sum(y_train == 0)\\n    )\\n)\";\n",
              "                var nbb_formatted_code = \"print(\\n    \\\"Before Oversampling, counts of label '1 (Failures)': {}\\\".format(sum(y_train == 1))\\n)\\nprint(\\n    \\\"Before Oversampling, counts of label '0 (No failures)': {} \\\\n\\\".format(\\n        sum(y_train == 0)\\n    )\\n)\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(\n",
        "    \"Before Oversampling, counts of label '1 (Failures)': {}\".format(sum(y_train == 1))\n",
        ")\n",
        "print(\n",
        "    \"Before Oversampling, counts of label '0 (No failures)': {} \\n\".format(\n",
        "        sum(y_train == 0)\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKxnygkE4jat",
        "outputId": "5d0f5462-b0c6-4736-d726-4691d18c93a1"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 27;\n",
              "                var nbb_unformatted_code = \"# Synthetic Minority Over Sampling Technique\\nsm = SMOTE(sampling_strategy=1, k_neighbors=5, random_state=1)\\nX_train_over, y_train_over = sm.fit_resample(X_train, y_train)\";\n",
              "                var nbb_formatted_code = \"# Synthetic Minority Over Sampling Technique\\nsm = SMOTE(sampling_strategy=1, k_neighbors=5, random_state=1)\\nX_train_over, y_train_over = sm.fit_resample(X_train, y_train)\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Synthetic Minority Over Sampling Technique\n",
        "sm = SMOTE(sampling_strategy=1, k_neighbors=5, random_state=1)\n",
        "X_train_over, y_train_over = sm.fit_resample(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYDlbnUO4jat",
        "outputId": "cbd70e19-80aa-4b1e-c35b-4c0876725253"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "After Oversampling, counts of label '1 (Failures)': 26469\n",
            "After Oversampling, counts of label '0 (No failures)': 26469 \n",
            "\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 28;\n",
              "                var nbb_unformatted_code = \"print(\\n    \\\"After Oversampling, counts of label '1 (Failures)': {}\\\".format(\\n        sum(y_train_over == 1)\\n    )\\n)\\nprint(\\n    \\\"After Oversampling, counts of label '0 (No failures)': {} \\\\n\\\".format(\\n        sum(y_train_over == 0)\\n    )\\n)\";\n",
              "                var nbb_formatted_code = \"print(\\n    \\\"After Oversampling, counts of label '1 (Failures)': {}\\\".format(\\n        sum(y_train_over == 1)\\n    )\\n)\\nprint(\\n    \\\"After Oversampling, counts of label '0 (No failures)': {} \\\\n\\\".format(\\n        sum(y_train_over == 0)\\n    )\\n)\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(\n",
        "    \"After Oversampling, counts of label '1 (Failures)': {}\".format(\n",
        "        sum(y_train_over == 1)\n",
        "    )\n",
        ")\n",
        "print(\n",
        "    \"After Oversampling, counts of label '0 (No failures)': {} \\n\".format(\n",
        "        sum(y_train_over == 0)\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fm5tcU-7CYzI"
      },
      "source": [
        "- To handle class imbalance in \"Target\" attribute, synthetic minority oversampling technique was employed to generate synthetic data points for minority class of importance (i.e, class \"1\" or No failures)\n",
        "- After applying SMOTE, we have equal number of class \"1\" and calss \"0\" target outcomes "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QnNvD9cCYzM",
        "outputId": "585ceacb-299d-4bce-afcd-f3d596041575"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Cross-Validation Performance:\n",
            "\n",
            "Logistic Regression: 0.7991885856657728\n",
            "dtree: 0.935799411923789\n",
            "Random forest: 0.9684099076356956\n",
            "Bagging: 0.9567710595379042\n",
            "Adaboost: 0.8302735716914681\n",
            "GBM: 0.8698213334032019\n",
            "Xgboost: 0.9735494688964318\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 29;\n",
              "                var nbb_unformatted_code = \"models_over = []  # Empty list to store all the models\\n\\n# Appending models into the list\\n\\nmodels_over.append(\\n    (\\\"Logistic Regression\\\", LogisticRegression(solver=\\\"newton-cg\\\", random_state=1))\\n)\\nmodels_over.append((\\\"dtree\\\", DecisionTreeClassifier(random_state=1)))\\nmodels_over.append((\\\"Random forest\\\", RandomForestClassifier(random_state=1)))\\nmodels_over.append((\\\"Bagging\\\", BaggingClassifier(random_state=1)))\\nmodels_over.append((\\\"Adaboost\\\", AdaBoostClassifier(random_state=1)))\\nmodels_over.append((\\\"GBM\\\", GradientBoostingClassifier(random_state=1)))\\nmodels_over.append((\\\"Xgboost\\\", XGBClassifier(random_state=1, eval_metric=\\\"logloss\\\")))\\n\\nresults_over = []  # Empty list to store all model's CV scores\\nnames_over = []  # Empty list to store name of the models\\nscore_over = []\\n\\n# loop through all models to get the mean cross validated score\\n\\nprint(\\\"\\\\n\\\" \\\"Cross-Validation Performance:\\\" \\\"\\\\n\\\")\\n\\nfor name, model in models_over:\\n    kfold = StratifiedKFold(\\n        n_splits=5, shuffle=True, random_state=1\\n    )  # Setting number of splits equal to 5\\n    cv_result = cross_val_score(\\n        estimator=model, X=X_train_over, y=y_train_over, scoring=scorer, cv=kfold\\n    )\\n    results_over.append(cv_result)\\n    names_over.append(name)\\n    print(\\\"{}: {}\\\".format(name, cv_result.mean()))\";\n",
              "                var nbb_formatted_code = \"models_over = []  # Empty list to store all the models\\n\\n# Appending models into the list\\n\\nmodels_over.append(\\n    (\\\"Logistic Regression\\\", LogisticRegression(solver=\\\"newton-cg\\\", random_state=1))\\n)\\nmodels_over.append((\\\"dtree\\\", DecisionTreeClassifier(random_state=1)))\\nmodels_over.append((\\\"Random forest\\\", RandomForestClassifier(random_state=1)))\\nmodels_over.append((\\\"Bagging\\\", BaggingClassifier(random_state=1)))\\nmodels_over.append((\\\"Adaboost\\\", AdaBoostClassifier(random_state=1)))\\nmodels_over.append((\\\"GBM\\\", GradientBoostingClassifier(random_state=1)))\\nmodels_over.append((\\\"Xgboost\\\", XGBClassifier(random_state=1, eval_metric=\\\"logloss\\\")))\\n\\nresults_over = []  # Empty list to store all model's CV scores\\nnames_over = []  # Empty list to store name of the models\\nscore_over = []\\n\\n# loop through all models to get the mean cross validated score\\n\\nprint(\\\"\\\\n\\\" \\\"Cross-Validation Performance:\\\" \\\"\\\\n\\\")\\n\\nfor name, model in models_over:\\n    kfold = StratifiedKFold(\\n        n_splits=5, shuffle=True, random_state=1\\n    )  # Setting number of splits equal to 5\\n    cv_result = cross_val_score(\\n        estimator=model, X=X_train_over, y=y_train_over, scoring=scorer, cv=kfold\\n    )\\n    results_over.append(cv_result)\\n    names_over.append(name)\\n    print(\\\"{}: {}\\\".format(name, cv_result.mean()))\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "models_over = []  # Empty list to store all the models\n",
        "\n",
        "# Appending models into the list\n",
        "\n",
        "models_over.append(\n",
        "    (\"Logistic Regression\", LogisticRegression(solver=\"newton-cg\", random_state=1))\n",
        ")\n",
        "models_over.append((\"dtree\", DecisionTreeClassifier(random_state=1)))\n",
        "models_over.append((\"Random forest\", RandomForestClassifier(random_state=1)))\n",
        "models_over.append((\"Bagging\", BaggingClassifier(random_state=1)))\n",
        "models_over.append((\"Adaboost\", AdaBoostClassifier(random_state=1)))\n",
        "models_over.append((\"GBM\", GradientBoostingClassifier(random_state=1)))\n",
        "models_over.append((\"Xgboost\", XGBClassifier(random_state=1, eval_metric=\"logloss\")))\n",
        "\n",
        "results_over = []  # Empty list to store all model's CV scores\n",
        "names_over = []  # Empty list to store name of the models\n",
        "score_over = []\n",
        "\n",
        "# loop through all models to get the mean cross validated score\n",
        "\n",
        "print(\"\\n\" \"Cross-Validation Performance:\" \"\\n\")\n",
        "\n",
        "for name, model in models_over:\n",
        "    kfold = StratifiedKFold(\n",
        "        n_splits=5, shuffle=True, random_state=1\n",
        "    )  # Setting number of splits equal to 5\n",
        "    cv_result = cross_val_score(\n",
        "        estimator=model, X=X_train_over, y=y_train_over, scoring=scorer, cv=kfold\n",
        "    )\n",
        "    results_over.append(cv_result)\n",
        "    names_over.append(name)\n",
        "    print(\"{}: {}\".format(name, cv_result.mean()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8QquFJACYzN",
        "outputId": "86de6c2d-6dca-4b36-d023-7a6383095981"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training Performance:\n",
            "\n",
            "Logistic Regression: 0.7997723770483548\n",
            "dtree: 1.0\n",
            "Random forest: 1.0\n",
            "Bagging: 0.9976255088195387\n",
            "Adaboost: 0.8345542254779346\n",
            "GBM: 0.8726427535276275\n",
            "Xgboost: 0.9979264062735635\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 30;\n",
              "                var nbb_unformatted_code = \"print(\\\"\\\\n\\\" \\\"Training Performance:\\\" \\\"\\\\n\\\")\\n\\nfor name, model in models_over:\\n    model.fit(X_train_over, y_train_over)\\n    scores = Minimum_Vs_Model_cost(y_train_over, model.predict(X_train_over))\\n    print(\\\"{}: {}\\\".format(name, scores))\";\n",
              "                var nbb_formatted_code = \"print(\\\"\\\\n\\\" \\\"Training Performance:\\\" \\\"\\\\n\\\")\\n\\nfor name, model in models_over:\\n    model.fit(X_train_over, y_train_over)\\n    scores = Minimum_Vs_Model_cost(y_train_over, model.predict(X_train_over))\\n    print(\\\"{}: {}\\\".format(name, scores))\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(\"\\n\" \"Training Performance:\" \"\\n\")\n",
        "\n",
        "for name, model in models_over:\n",
        "    model.fit(X_train_over, y_train_over)\n",
        "    scores = Minimum_Vs_Model_cost(y_train_over, model.predict(X_train_over))\n",
        "    print(\"{}: {}\".format(name, scores))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nf5cBgTCCYzQ",
        "outputId": "6f87b344-5820-4749-df02-0cc59d9fbe95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Validation Performance:\n",
            "\n",
            "Logistic Regression: 0.5025536261491318\n",
            "dtree: 0.6377187297472456\n",
            "Random forest: 0.802937576499388\n",
            "Bagging: 0.7633824670287044\n",
            "Adaboost: 0.5696092619392186\n",
            "GBM: 0.7294292068198666\n",
            "Xgboost: 0.8065573770491803\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 66;\n",
              "                var nbb_unformatted_code = \"print(\\\"\\\\n\\\" \\\"Validation Performance:\\\" \\\"\\\\n\\\")\\n\\nfor name, model in models_over:\\n    model.fit(X_train_over, y_train_over)\\n    scores = Minimum_Vs_Model_cost(y_val, model.predict(X_val))\\n    print(\\\"{}: {}\\\".format(name, scores))\";\n",
              "                var nbb_formatted_code = \"print(\\\"\\\\n\\\" \\\"Validation Performance:\\\" \\\"\\\\n\\\")\\n\\nfor name, model in models_over:\\n    model.fit(X_train_over, y_train_over)\\n    scores = Minimum_Vs_Model_cost(y_val, model.predict(X_val))\\n    print(\\\"{}: {}\\\".format(name, scores))\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(\"\\n\" \"Validation Performance:\" \"\\n\")\n",
        "\n",
        "for name, model in models_over:\n",
        "    model.fit(X_train_over, y_train_over)\n",
        "    scores = Minimum_Vs_Model_cost(y_val, model.predict(X_val))\n",
        "    print(\"{}: {}\".format(name, scores))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4AGHnnUCYzR"
      },
      "source": [
        "- The cross validation training performance scores (customized metric) are much higher than validation perfromance score. This indicates that the default algorithms on oversampled dataset are not able to generalize well\n",
        "- It is likely that the algorithms are overfitting the noise in the training sets which explains the trends in the observed performance scores (cross validation training scores ~ training score >> validation score). This will be a concern taking these models to production"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJd2ivhuCYzS",
        "outputId": "79938041-9cc7-439b-88a5-9f53448697a2"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 31;\n",
              "                var nbb_unformatted_code = \"# Plotting boxplots for CV scores of all models defined above\\n\\nfig = plt.figure(figsize=(10, 4))\\n\\nfig.suptitle(\\\"Algorithm Comparison\\\")\\nax = fig.add_subplot(111)\\n\\nplt.boxplot(results_over)\\nax.set_xticklabels(names)\\n\\nplt.show()\";\n",
              "                var nbb_formatted_code = \"# Plotting boxplots for CV scores of all models defined above\\n\\nfig = plt.figure(figsize=(10, 4))\\n\\nfig.suptitle(\\\"Algorithm Comparison\\\")\\nax = fig.add_subplot(111)\\n\\nplt.boxplot(results_over)\\nax.set_xticklabels(names)\\n\\nplt.show()\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plotting boxplots for CV scores of all models defined above\n",
        "\n",
        "fig = plt.figure(figsize=(10, 4))\n",
        "\n",
        "fig.suptitle(\"Algorithm Comparison\")\n",
        "ax = fig.add_subplot(111)\n",
        "\n",
        "plt.boxplot(results_over)\n",
        "ax.set_xticklabels(names)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f25jeqD7CYzT"
      },
      "source": [
        "- The average (& median) training cross validation scores on oversampled dataset has increased to match training performance scores across algorithms. This indicates potential overfitting of noise in the training datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aimb6bn4jat"
      },
      "source": [
        "## Model Building with Undersampled data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhxfTkvu4jat",
        "outputId": "f97a53e6-bdff-4746-c042-b234de1a26f5"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 32;\n",
              "                var nbb_unformatted_code = \"# Random undersampler for under sampling the data\\nrus = RandomUnderSampler(random_state=1, sampling_strategy=1)\\nX_train_un, y_train_un = rus.fit_resample(X_train, y_train)\";\n",
              "                var nbb_formatted_code = \"# Random undersampler for under sampling the data\\nrus = RandomUnderSampler(random_state=1, sampling_strategy=1)\\nX_train_un, y_train_un = rus.fit_resample(X_train, y_train)\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Random undersampler for under sampling the data\n",
        "rus = RandomUnderSampler(random_state=1, sampling_strategy=1)\n",
        "X_train_un, y_train_un = rus.fit_resample(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jROP_DVF4jau",
        "outputId": "58d59efe-035a-4b03-f01a-7c990405f828"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "After Undersampling, counts of label '1 (Failures)': 1531\n",
            "After Undersampling, counts of label '0 (No failures)': 1531 \n",
            "\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 33;\n",
              "                var nbb_unformatted_code = \"print(\\n    \\\"After Undersampling, counts of label '1 (Failures)': {}\\\".format(\\n        sum(y_train_un == 1)\\n    )\\n)\\nprint(\\n    \\\"After Undersampling, counts of label '0 (No failures)': {} \\\\n\\\".format(\\n        sum(y_train_un == 0)\\n    )\\n)\";\n",
              "                var nbb_formatted_code = \"print(\\n    \\\"After Undersampling, counts of label '1 (Failures)': {}\\\".format(\\n        sum(y_train_un == 1)\\n    )\\n)\\nprint(\\n    \\\"After Undersampling, counts of label '0 (No failures)': {} \\\\n\\\".format(\\n        sum(y_train_un == 0)\\n    )\\n)\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(\n",
        "    \"After Undersampling, counts of label '1 (Failures)': {}\".format(\n",
        "        sum(y_train_un == 1)\n",
        "    )\n",
        ")\n",
        "print(\n",
        "    \"After Undersampling, counts of label '0 (No failures)': {} \\n\".format(\n",
        "        sum(y_train_un == 0)\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxEQ-eY7CYzU"
      },
      "source": [
        "- Another technique to handle class imbalance in \"Target\" attribute is random undersampling, wherein only random samples from the majority class are chosen for model building. While this helps in dealing with models potentially overfitting, it can often lead to poor performing models due to \"loss of information\" from not considering all datapoints available \n",
        "- After random undersampling, we again have equal number of class \"1\" and class \"0\" (and overall less number of datapoints for model building)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2GEl2_KCYzV",
        "outputId": "069cfe4d-badf-486e-843d-5e3aecb7f44c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Cross-Validation Performance:\n",
            "\n",
            "Logistic Regression: 0.7724863000214184\n",
            "dtree: 0.7623582706765808\n",
            "Random forest: 0.842602547619812\n",
            "Bagging: 0.810537034879969\n",
            "Adaboost: 0.7875970384722428\n",
            "GBM: 0.8260845219126203\n",
            "Xgboost: 0.8405650028470488\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 34;\n",
              "                var nbb_unformatted_code = \"models_un = []  # Empty list to store all the models\\n\\n# Appending models into the list\\n\\nmodels_un.append(\\n    (\\\"Logistic Regression\\\", LogisticRegression(solver=\\\"newton-cg\\\", random_state=1))\\n)\\nmodels_un.append((\\\"dtree\\\", DecisionTreeClassifier(random_state=1)))\\nmodels_un.append((\\\"Random forest\\\", RandomForestClassifier(random_state=1)))\\nmodels_un.append((\\\"Bagging\\\", BaggingClassifier(random_state=1)))\\nmodels_un.append((\\\"Adaboost\\\", AdaBoostClassifier(random_state=1)))\\nmodels_un.append((\\\"GBM\\\", GradientBoostingClassifier(random_state=1)))\\nmodels_un.append((\\\"Xgboost\\\", XGBClassifier(random_state=1, eval_metric=\\\"logloss\\\")))\\n\\nresults_un = []  # Empty list to store all model's CV scores\\nnames_un = []  # Empty list to store name of the models\\nscore_un = []\\n\\n# loop through all models to get the mean cross validated score\\n\\nprint(\\\"\\\\n\\\" \\\"Cross-Validation Performance:\\\" \\\"\\\\n\\\")\\n\\nfor name, model in models_un:\\n    kfold = StratifiedKFold(\\n        n_splits=5, shuffle=True, random_state=1\\n    )  # Setting number of splits equal to 5\\n    cv_result = cross_val_score(\\n        estimator=model, X=X_train_un, y=y_train_un, scoring=scorer, cv=kfold\\n    )\\n    results_un.append(cv_result)\\n    names_un.append(name)\\n    print(\\\"{}: {}\\\".format(name, cv_result.mean()))\";\n",
              "                var nbb_formatted_code = \"models_un = []  # Empty list to store all the models\\n\\n# Appending models into the list\\n\\nmodels_un.append(\\n    (\\\"Logistic Regression\\\", LogisticRegression(solver=\\\"newton-cg\\\", random_state=1))\\n)\\nmodels_un.append((\\\"dtree\\\", DecisionTreeClassifier(random_state=1)))\\nmodels_un.append((\\\"Random forest\\\", RandomForestClassifier(random_state=1)))\\nmodels_un.append((\\\"Bagging\\\", BaggingClassifier(random_state=1)))\\nmodels_un.append((\\\"Adaboost\\\", AdaBoostClassifier(random_state=1)))\\nmodels_un.append((\\\"GBM\\\", GradientBoostingClassifier(random_state=1)))\\nmodels_un.append((\\\"Xgboost\\\", XGBClassifier(random_state=1, eval_metric=\\\"logloss\\\")))\\n\\nresults_un = []  # Empty list to store all model's CV scores\\nnames_un = []  # Empty list to store name of the models\\nscore_un = []\\n\\n# loop through all models to get the mean cross validated score\\n\\nprint(\\\"\\\\n\\\" \\\"Cross-Validation Performance:\\\" \\\"\\\\n\\\")\\n\\nfor name, model in models_un:\\n    kfold = StratifiedKFold(\\n        n_splits=5, shuffle=True, random_state=1\\n    )  # Setting number of splits equal to 5\\n    cv_result = cross_val_score(\\n        estimator=model, X=X_train_un, y=y_train_un, scoring=scorer, cv=kfold\\n    )\\n    results_un.append(cv_result)\\n    names_un.append(name)\\n    print(\\\"{}: {}\\\".format(name, cv_result.mean()))\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "models_un = []  # Empty list to store all the models\n",
        "\n",
        "# Appending models into the list\n",
        "\n",
        "models_un.append(\n",
        "    (\"Logistic Regression\", LogisticRegression(solver=\"newton-cg\", random_state=1))\n",
        ")\n",
        "models_un.append((\"dtree\", DecisionTreeClassifier(random_state=1)))\n",
        "models_un.append((\"Random forest\", RandomForestClassifier(random_state=1)))\n",
        "models_un.append((\"Bagging\", BaggingClassifier(random_state=1)))\n",
        "models_un.append((\"Adaboost\", AdaBoostClassifier(random_state=1)))\n",
        "models_un.append((\"GBM\", GradientBoostingClassifier(random_state=1)))\n",
        "models_un.append((\"Xgboost\", XGBClassifier(random_state=1, eval_metric=\"logloss\")))\n",
        "\n",
        "results_un = []  # Empty list to store all model's CV scores\n",
        "names_un = []  # Empty list to store name of the models\n",
        "score_un = []\n",
        "\n",
        "# loop through all models to get the mean cross validated score\n",
        "\n",
        "print(\"\\n\" \"Cross-Validation Performance:\" \"\\n\")\n",
        "\n",
        "for name, model in models_un:\n",
        "    kfold = StratifiedKFold(\n",
        "        n_splits=5, shuffle=True, random_state=1\n",
        "    )  # Setting number of splits equal to 5\n",
        "    cv_result = cross_val_score(\n",
        "        estimator=model, X=X_train_un, y=y_train_un, scoring=scorer, cv=kfold\n",
        "    )\n",
        "    results_un.append(cv_result)\n",
        "    names_un.append(name)\n",
        "    print(\"{}: {}\".format(name, cv_result.mean()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OSHHSLt8CYzW",
        "outputId": "72c4a9e9-38db-4f7f-e89e-0aff9e46ed0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training Performance:\n",
            "\n",
            "Logistic Regression: 0.772322179250042\n",
            "dtree: 1.0\n",
            "Random forest: 1.0\n",
            "Bagging: 0.9624895222129086\n",
            "Adaboost: 0.8197394253078708\n",
            "GBM: 0.8726961808854266\n",
            "Xgboost: 1.0\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 35;\n",
              "                var nbb_unformatted_code = \"print(\\\"\\\\n\\\" \\\"Training Performance:\\\" \\\"\\\\n\\\")\\n\\nfor name, model in models_un:\\n    model.fit(X_train_un, y_train_un)\\n    scores = Minimum_Vs_Model_cost(y_train_un, model.predict(X_train_un))\\n    print(\\\"{}: {}\\\".format(name, scores))\";\n",
              "                var nbb_formatted_code = \"print(\\\"\\\\n\\\" \\\"Training Performance:\\\" \\\"\\\\n\\\")\\n\\nfor name, model in models_un:\\n    model.fit(X_train_un, y_train_un)\\n    scores = Minimum_Vs_Model_cost(y_train_un, model.predict(X_train_un))\\n    print(\\\"{}: {}\\\".format(name, scores))\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(\"\\n\" \"Training Performance:\" \"\\n\")\n",
        "\n",
        "for name, model in models_un:\n",
        "    model.fit(X_train_un, y_train_un)\n",
        "    scores = Minimum_Vs_Model_cost(y_train_un, model.predict(X_train_un))\n",
        "    print(\"{}: {}\".format(name, scores))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqRLSrWhCYzW",
        "outputId": "97607c32-0637-45b3-b37a-1bb4580d98f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Validation Performance:\n",
            "\n",
            "Logistic Regression: 0.4932330827067669\n",
            "dtree: 0.4738743077293523\n",
            "Random forest: 0.7348767737117252\n",
            "Bagging: 0.6691601496089765\n",
            "Adaboost: 0.5512605042016807\n",
            "GBM: 0.6762886597938145\n",
            "Xgboost: 0.7440453686200378\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 67;\n",
              "                var nbb_unformatted_code = \"print(\\\"\\\\n\\\" \\\"Validation Performance:\\\" \\\"\\\\n\\\")\\n\\nfor name, model in models_un:\\n    model.fit(X_train_un, y_train_un)\\n    scores = Minimum_Vs_Model_cost(y_val, model.predict(X_val))\\n    print(\\\"{}: {}\\\".format(name, scores))\";\n",
              "                var nbb_formatted_code = \"print(\\\"\\\\n\\\" \\\"Validation Performance:\\\" \\\"\\\\n\\\")\\n\\nfor name, model in models_un:\\n    model.fit(X_train_un, y_train_un)\\n    scores = Minimum_Vs_Model_cost(y_val, model.predict(X_val))\\n    print(\\\"{}: {}\\\".format(name, scores))\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(\"\\n\" \"Validation Performance:\" \"\\n\")\n",
        "\n",
        "for name, model in models_un:\n",
        "    model.fit(X_train_un, y_train_un)\n",
        "    scores = Minimum_Vs_Model_cost(y_val, model.predict(X_val))\n",
        "    print(\"{}: {}\".format(name, scores))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzGCR7VTCYzY"
      },
      "source": [
        "- The performance score (customized metric) have dropped on the validation undersampled dataset than original dataset. This could be likely that the algorithms are overfitting the noise & underfitting the information in the undersampled datasets. This will again be a concern taking these models to production"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkU2GWsTCYzZ",
        "outputId": "b78071cb-b012-49af-e64b-3659dda345f4"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 68;\n",
              "                var nbb_unformatted_code = \"# Plotting boxplots for CV scores of all models defined above\\n\\nfig = plt.figure(figsize=(10, 4))\\n\\nfig.suptitle(\\\"Algorithm Comparison\\\")\\nax = fig.add_subplot(111)\\n\\nplt.boxplot(results_un)\\nax.set_xticklabels(names)\\n\\nplt.show()\";\n",
              "                var nbb_formatted_code = \"# Plotting boxplots for CV scores of all models defined above\\n\\nfig = plt.figure(figsize=(10, 4))\\n\\nfig.suptitle(\\\"Algorithm Comparison\\\")\\nax = fig.add_subplot(111)\\n\\nplt.boxplot(results_un)\\nax.set_xticklabels(names)\\n\\nplt.show()\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plotting boxplots for CV scores of all models defined above\n",
        "\n",
        "fig = plt.figure(figsize=(10, 4))\n",
        "\n",
        "fig.suptitle(\"Algorithm Comparison\")\n",
        "ax = fig.add_subplot(111)\n",
        "\n",
        "plt.boxplot(results_un)\n",
        "ax.set_xticklabels(names)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IC_g60XkCYzZ"
      },
      "source": [
        "- The algorithms are able to give better performance on the cross validation training scores on undersampled dataset in comparison to original dataset as can be seen from the boxplots. However, the issue is the lack of generalizatbility in carrying forth the performance to the validation set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50N658sB4jau"
      },
      "source": [
        "## Model Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFFwX4CG4jau"
      },
      "source": [
        "- Models built on original dataset have given generalized performance on cross validation training and validation sets unlike models built on oversampled or undersampled sets\n",
        "- Mean cross validation scores on training sets are highest with XGBoost, Random Forest & Bagging Classifiers (~77, ~71 and ~68% respectively). These models will be tuned further to try to increase performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZGY1eL84jau"
      },
      "source": [
        "## HyperparameterTuning "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AdpO9CX_CYzZ",
        "outputId": "2a2eb576-7084-4e70-c1c8-88e59ce01b92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters are {'subsample': 0.9, 'scale_pos_weight': 10, 'n_estimators': 250, 'learning_rate': 0.1, 'gamma': 3} with CV score=0.7997478671216852:\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 36;\n",
              "                var nbb_unformatted_code = \"# defining model - XGBoost Hyperparameter Tuning\\nmodel = XGBClassifier(random_state=1, eval_metric=\\\"logloss\\\")\\n\\n# Parameter grid to pass in RandomizedSearchCV\\nparam_grid = {\\n    \\\"n_estimators\\\": np.arange(150, 300, 50),\\n    \\\"scale_pos_weight\\\": [5, 10],\\n    \\\"learning_rate\\\": [0.1, 0.2],\\n    \\\"gamma\\\": [0, 3, 5],\\n    \\\"subsample\\\": [0.8, 0.9],\\n}\\n\\n# Type of scoring used to compare parameter combinations\\nscorer = metrics.make_scorer(Minimum_Vs_Model_cost, greater_is_better=True)\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(\\n    estimator=model,\\n    param_distributions=param_grid,\\n    n_iter=20,\\n    scoring=scorer,\\n    cv=3,\\n    random_state=1,\\n    n_jobs=-1,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train, y_train)\\n\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv.best_params_, randomized_cv.best_score_\\n    )\\n)\";\n",
              "                var nbb_formatted_code = \"# defining model - XGBoost Hyperparameter Tuning\\nmodel = XGBClassifier(random_state=1, eval_metric=\\\"logloss\\\")\\n\\n# Parameter grid to pass in RandomizedSearchCV\\nparam_grid = {\\n    \\\"n_estimators\\\": np.arange(150, 300, 50),\\n    \\\"scale_pos_weight\\\": [5, 10],\\n    \\\"learning_rate\\\": [0.1, 0.2],\\n    \\\"gamma\\\": [0, 3, 5],\\n    \\\"subsample\\\": [0.8, 0.9],\\n}\\n\\n# Type of scoring used to compare parameter combinations\\nscorer = metrics.make_scorer(Minimum_Vs_Model_cost, greater_is_better=True)\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(\\n    estimator=model,\\n    param_distributions=param_grid,\\n    n_iter=20,\\n    scoring=scorer,\\n    cv=3,\\n    random_state=1,\\n    n_jobs=-1,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train, y_train)\\n\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv.best_params_, randomized_cv.best_score_\\n    )\\n)\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# defining model - XGBoost Hyperparameter Tuning\n",
        "model = XGBClassifier(random_state=1, eval_metric=\"logloss\")\n",
        "\n",
        "# Parameter grid to pass in RandomizedSearchCV\n",
        "param_grid = {\n",
        "    \"n_estimators\": np.arange(150, 300, 50),\n",
        "    \"scale_pos_weight\": [5, 10],\n",
        "    \"learning_rate\": [0.1, 0.2],\n",
        "    \"gamma\": [0, 3, 5],\n",
        "    \"subsample\": [0.8, 0.9],\n",
        "}\n",
        "\n",
        "# Type of scoring used to compare parameter combinations\n",
        "scorer = metrics.make_scorer(Minimum_Vs_Model_cost, greater_is_better=True)\n",
        "\n",
        "# Calling RandomizedSearchCV\n",
        "randomized_cv = RandomizedSearchCV(\n",
        "    estimator=model,\n",
        "    param_distributions=param_grid,\n",
        "    n_iter=20,\n",
        "    scoring=scorer,\n",
        "    cv=3,\n",
        "    random_state=1,\n",
        "    n_jobs=-1,\n",
        ")\n",
        "\n",
        "# Fitting parameters in RandomizedSearchCV\n",
        "randomized_cv.fit(X_train, y_train)\n",
        "\n",
        "print(\n",
        "    \"Best parameters are {} with CV score={}:\".format(\n",
        "        randomized_cv.best_params_, randomized_cv.best_score_\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TY-HIIZJCYza",
        "outputId": "2e359b68-5415-438b-b798-e006817997bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, eval_metric='logloss',\n",
              "              gamma=3, gpu_id=-1, importance_type='gain',\n",
              "              interaction_constraints='', learning_rate=0.1, max_delta_step=0,\n",
              "              max_depth=6, min_child_weight=1, missing=nan,\n",
              "              monotone_constraints='()', n_estimators=250, n_jobs=4,\n",
              "              num_parallel_tree=1, random_state=1, reg_alpha=0, reg_lambda=1,\n",
              "              scale_pos_weight=10, subsample=0.9, tree_method='exact',\n",
              "              validate_parameters=1, verbosity=None)"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 37;\n",
              "                var nbb_unformatted_code = \"# building model with best parameters\\nxgb_tuned = XGBClassifier(\\n    subsample=0.9,\\n    scale_pos_weight=10,\\n    n_estimators=250,\\n    learning_rate=0.1,\\n    gamma=3,\\n    random_state=1,\\n    eval_metric=\\\"logloss\\\")\\n\\n# Fit the model on training data\\nxgb_tuned.fit(X_train, y_train)\";\n",
              "                var nbb_formatted_code = \"# building model with best parameters\\nxgb_tuned = XGBClassifier(\\n    subsample=0.9,\\n    scale_pos_weight=10,\\n    n_estimators=250,\\n    learning_rate=0.1,\\n    gamma=3,\\n    random_state=1,\\n    eval_metric=\\\"logloss\\\",\\n)\\n\\n# Fit the model on training data\\nxgb_tuned.fit(X_train, y_train)\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# building model with best parameters\n",
        "xgb_tuned = XGBClassifier(\n",
        "    subsample=0.9,\n",
        "    scale_pos_weight=10,\n",
        "    n_estimators=250,\n",
        "    learning_rate=0.1,\n",
        "    gamma=3,\n",
        "    random_state=1,\n",
        "    eval_metric=\"logloss\",\n",
        ")\n",
        "\n",
        "# Fit the model on training data\n",
        "xgb_tuned.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFh82GaHCYza",
        "outputId": "7fbfe184-d980-4557-e50a-b3421fc1b84a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training performance:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Precision</th>\n",
              "      <th>F1</th>\n",
              "      <th>Minimum_Vs_Model_cost</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.995</td>\n",
              "      <td>0.997</td>\n",
              "      <td>0.998</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Accuracy  Recall  Precision    F1  Minimum_Vs_Model_cost\n",
              "0     1.000   1.000      0.995 0.997                  0.998"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 69;\n",
              "                var nbb_unformatted_code = \"# Calculating different metrics on training set\\nxgboost_random_train = model_performance_classification_sklearn(\\n    xgb_tuned, X_train, y_train\\n)\\nprint(\\\"Training performance:\\\")\\nxgboost_random_train\";\n",
              "                var nbb_formatted_code = \"# Calculating different metrics on training set\\nxgboost_random_train = model_performance_classification_sklearn(\\n    xgb_tuned, X_train, y_train\\n)\\nprint(\\\"Training performance:\\\")\\nxgboost_random_train\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Calculating different metrics on training set\n",
        "xgboost_random_train = model_performance_classification_sklearn(\n",
        "    xgb_tuned, X_train, y_train\n",
        ")\n",
        "print(\"Training performance:\")\n",
        "xgboost_random_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2ctxhjgCYza",
        "outputId": "f8bed6de-6c32-4b82-d1d7-1f36ce78513b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation performance:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Precision</th>\n",
              "      <th>F1</th>\n",
              "      <th>Minimum_Vs_Model_cost</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.991</td>\n",
              "      <td>0.877</td>\n",
              "      <td>0.962</td>\n",
              "      <td>0.917</td>\n",
              "      <td>0.821</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Accuracy  Recall  Precision    F1  Minimum_Vs_Model_cost\n",
              "0     0.991   0.877      0.962 0.917                  0.821"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 39;\n",
              "                var nbb_unformatted_code = \"# Calculating different metrics on validation set\\nxgboost_random_val = model_performance_classification_sklearn(xgb_tuned, X_val, y_val)\\nprint(\\\"Validation performance:\\\")\\nxgboost_random_val\";\n",
              "                var nbb_formatted_code = \"# Calculating different metrics on validation set\\nxgboost_random_val = model_performance_classification_sklearn(xgb_tuned, X_val, y_val)\\nprint(\\\"Validation performance:\\\")\\nxgboost_random_val\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Calculating different metrics on validation set\n",
        "xgboost_random_val = model_performance_classification_sklearn(xgb_tuned, X_val, y_val)\n",
        "print(\"Validation performance:\")\n",
        "xgboost_random_val"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CPineBwCYzb"
      },
      "source": [
        "- The best hyperparameters using RandomizedSearch CV for XGBoost model were found to be: subsample 0.9, scale_pos_weight 10, n_estimators 250, learning_rate 0.1 and gamma 3\n",
        "- The average cross validation training performance score (customized metric) using the best parameter XGBoost model is 0.80. This is similar to the performance score (customized metric) on the validation set i.e., 0.82. This indicates the model may generalize with a performance score of ~0.80-0.82\n",
        "- The model does however have a tendency to overfit the training set as can be observed from training performance (customized metric score of 0.998)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVZcJ0hv4jau",
        "outputId": "ce319537-2daa-4f0a-b263-ad5d044fe6c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters are {'n_estimators': 250, 'min_samples_leaf': 1, 'max_samples': 0.5000000000000001, 'max_features': 'sqrt'} with CV score=0.6920650879825658:\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 40;\n",
              "                var nbb_unformatted_code = \"# defining model - Random Forest Hyperparameter Tuning\\nmodel2 = RandomForestClassifier(random_state=1, oob_score=True, bootstrap=True)\\n\\nparam_grid2 = {\\n    \\\"n_estimators\\\": [150, 250],\\n    \\\"min_samples_leaf\\\": np.arange(1, 3),\\n    \\\"max_features\\\": [\\\"sqrt\\\", \\\"log2\\\"],\\n    \\\"max_samples\\\": np.arange(0.2, 0.6, 0.1),\\n}\\n\\n# Type of scoring used to compare parameter combinations\\nscorer = metrics.make_scorer(Minimum_Vs_Model_cost, greater_is_better=True)\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv2 = RandomizedSearchCV(\\n    estimator=model2,\\n    param_distributions=param_grid2,\\n    n_iter=50,\\n    scoring=scorer,\\n    cv=5,\\n    random_state=1,\\n    n_jobs=-1,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv2.fit(X_train, y_train)\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv2.best_params_, randomized_cv2.best_score_\\n    )\\n)\";\n",
              "                var nbb_formatted_code = \"# defining model - Random Forest Hyperparameter Tuning\\nmodel2 = RandomForestClassifier(random_state=1, oob_score=True, bootstrap=True)\\n\\nparam_grid2 = {\\n    \\\"n_estimators\\\": [150, 250],\\n    \\\"min_samples_leaf\\\": np.arange(1, 3),\\n    \\\"max_features\\\": [\\\"sqrt\\\", \\\"log2\\\"],\\n    \\\"max_samples\\\": np.arange(0.2, 0.6, 0.1),\\n}\\n\\n# Type of scoring used to compare parameter combinations\\nscorer = metrics.make_scorer(Minimum_Vs_Model_cost, greater_is_better=True)\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv2 = RandomizedSearchCV(\\n    estimator=model2,\\n    param_distributions=param_grid2,\\n    n_iter=50,\\n    scoring=scorer,\\n    cv=5,\\n    random_state=1,\\n    n_jobs=-1,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv2.fit(X_train, y_train)\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv2.best_params_, randomized_cv2.best_score_\\n    )\\n)\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# defining model - Random Forest Hyperparameter Tuning\n",
        "model2 = RandomForestClassifier(random_state=1, oob_score=True, bootstrap=True)\n",
        "\n",
        "param_grid2 = {\n",
        "    \"n_estimators\": [150, 250],\n",
        "    \"min_samples_leaf\": np.arange(1, 3),\n",
        "    \"max_features\": [\"sqrt\", \"log2\"],\n",
        "    \"max_samples\": np.arange(0.2, 0.6, 0.1),\n",
        "}\n",
        "\n",
        "# Type of scoring used to compare parameter combinations\n",
        "scorer = metrics.make_scorer(Minimum_Vs_Model_cost, greater_is_better=True)\n",
        "\n",
        "# Calling RandomizedSearchCV\n",
        "randomized_cv2 = RandomizedSearchCV(\n",
        "    estimator=model2,\n",
        "    param_distributions=param_grid2,\n",
        "    n_iter=50,\n",
        "    scoring=scorer,\n",
        "    cv=5,\n",
        "    random_state=1,\n",
        "    n_jobs=-1,\n",
        ")\n",
        "\n",
        "# Fitting parameters in RandomizedSearchCV\n",
        "randomized_cv2.fit(X_train, y_train)\n",
        "print(\n",
        "    \"Best parameters are {} with CV score={}:\".format(\n",
        "        randomized_cv2.best_params_, randomized_cv2.best_score_\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZFXxP_ByCYzb",
        "outputId": "6fae1be7-1947-4199-8309-b171f790d228"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RandomForestClassifier(max_features='sqrt', max_samples=0.5000000000000001,\n",
              "                       n_estimators=250, random_state=1)"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 41;\n",
              "                var nbb_unformatted_code = \"# building model with best parameters\\nrf_tuned = RandomForestClassifier(\\n    n_estimators=250,\\n    min_samples_leaf=1,\\n    max_samples=0.5000000000000001,\\n    max_features=\\\"sqrt\\\",\\n    random_state=1,\\n)\\n\\n# Fit the model on training data\\nrf_tuned.fit(X_train, y_train)\";\n",
              "                var nbb_formatted_code = \"# building model with best parameters\\nrf_tuned = RandomForestClassifier(\\n    n_estimators=250,\\n    min_samples_leaf=1,\\n    max_samples=0.5000000000000001,\\n    max_features=\\\"sqrt\\\",\\n    random_state=1,\\n)\\n\\n# Fit the model on training data\\nrf_tuned.fit(X_train, y_train)\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# building model with best parameters\n",
        "rf_tuned = RandomForestClassifier(\n",
        "    n_estimators=250,\n",
        "    min_samples_leaf=1,\n",
        "    max_samples=0.5000000000000001,\n",
        "    max_features=\"sqrt\",\n",
        "    random_state=1,\n",
        ")\n",
        "\n",
        "# Fit the model on training data\n",
        "rf_tuned.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9dXA6VgCYzc",
        "outputId": "cf532d2a-a1ca-4066-c182-4f7924e30eb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training performance:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Precision</th>\n",
              "      <th>F1</th>\n",
              "      <th>Minimum_Vs_Model_cost</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.993</td>\n",
              "      <td>0.882</td>\n",
              "      <td>0.998</td>\n",
              "      <td>0.937</td>\n",
              "      <td>0.836</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Accuracy  Recall  Precision    F1  Minimum_Vs_Model_cost\n",
              "0     0.993   0.882      0.998 0.937                  0.836"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 70;\n",
              "                var nbb_unformatted_code = \"# Calculating different metrics on training set\\nrf_random_train = model_performance_classification_sklearn(rf_tuned, X_train, y_train)\\nprint(\\\"Training performance:\\\")\\nrf_random_train\";\n",
              "                var nbb_formatted_code = \"# Calculating different metrics on training set\\nrf_random_train = model_performance_classification_sklearn(rf_tuned, X_train, y_train)\\nprint(\\\"Training performance:\\\")\\nrf_random_train\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Calculating different metrics on training set\n",
        "rf_random_train = model_performance_classification_sklearn(rf_tuned, X_train, y_train)\n",
        "print(\"Training performance:\")\n",
        "rf_random_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_YAxp-XCYzc",
        "outputId": "0c3fa9dc-0123-4bd7-c582-b69366a5f981"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation performance:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Precision</th>\n",
              "      <th>F1</th>\n",
              "      <th>Minimum_Vs_Model_cost</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.985</td>\n",
              "      <td>0.741</td>\n",
              "      <td>0.988</td>\n",
              "      <td>0.847</td>\n",
              "      <td>0.697</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Accuracy  Recall  Precision    F1  Minimum_Vs_Model_cost\n",
              "0     0.985   0.741      0.988 0.847                  0.697"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 44;\n",
              "                var nbb_unformatted_code = \"# Calculating different metrics on validation set\\nrf_random_val = model_performance_classification_sklearn(rf_tuned, X_val, y_val)\\nprint(\\\"Validation performance:\\\")\\nrf_random_val\";\n",
              "                var nbb_formatted_code = \"# Calculating different metrics on validation set\\nrf_random_val = model_performance_classification_sklearn(rf_tuned, X_val, y_val)\\nprint(\\\"Validation performance:\\\")\\nrf_random_val\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Calculating different metrics on validation set\n",
        "rf_random_val = model_performance_classification_sklearn(rf_tuned, X_val, y_val)\n",
        "print(\"Validation performance:\")\n",
        "rf_random_val"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1fpaTdmCYzc"
      },
      "source": [
        "- The best hyperparameters using RandomizedSearch CV for Random forest model were found to be: n_estimators 250, min_sample_leaf 1, max_features 'sqrt', max_samples 0.5\n",
        "- The average 5 fold cross validation training performance score (customized metric) using the best parameter Random forest model is 0.692. This is similar to the performance score (customized metric) on the validation set i.e., 0.697. This indicates the model may generalize with a performance score of ~0.69\n",
        "- The model has a slight tendency (although not as much as XGBoost tuned) to overfit the training set as can be observed from training performance (customized metric score of 0.8336)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nwbstGtXCYzd",
        "outputId": "ccc2dd5d-5b6f-4fa6-d3fc-3eb4ee6f13fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters are {'n_estimators': 50, 'max_samples': 0.9, 'max_features': 0.8} with CV score=0.7092140237024578:\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 45;\n",
              "                var nbb_unformatted_code = \"# defining model - Bagging Classifier Hyperparameter Tuning\\nmodel3 = BaggingClassifier(random_state=1)\\n\\nparam_grid3 = {\\n    \\\"max_samples\\\": [0.8, 0.9],\\n    \\\"max_features\\\": [0.8, 0.9],\\n    \\\"n_estimators\\\": [40, 50],\\n}\\n\\n# Type of scoring used to compare parameter combinations\\nscorer = metrics.make_scorer(Minimum_Vs_Model_cost, greater_is_better=True)\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv3 = RandomizedSearchCV(\\n    estimator=model3,\\n    param_distributions=param_grid3,\\n    n_iter=50,\\n    scoring=scorer,\\n    cv=5,\\n    random_state=1,\\n    n_jobs=-1,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv3.fit(X_train, y_train)\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv3.best_params_, randomized_cv3.best_score_\\n    )\\n)\";\n",
              "                var nbb_formatted_code = \"# defining model - Bagging Classifier Hyperparameter Tuning\\nmodel3 = BaggingClassifier(random_state=1)\\n\\nparam_grid3 = {\\n    \\\"max_samples\\\": [0.8, 0.9],\\n    \\\"max_features\\\": [0.8, 0.9],\\n    \\\"n_estimators\\\": [40, 50],\\n}\\n\\n# Type of scoring used to compare parameter combinations\\nscorer = metrics.make_scorer(Minimum_Vs_Model_cost, greater_is_better=True)\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv3 = RandomizedSearchCV(\\n    estimator=model3,\\n    param_distributions=param_grid3,\\n    n_iter=50,\\n    scoring=scorer,\\n    cv=5,\\n    random_state=1,\\n    n_jobs=-1,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv3.fit(X_train, y_train)\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv3.best_params_, randomized_cv3.best_score_\\n    )\\n)\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# defining model - Bagging Classifier Hyperparameter Tuning\n",
        "model3 = BaggingClassifier(random_state=1)\n",
        "\n",
        "param_grid3 = {\n",
        "    \"max_samples\": [0.8, 0.9],\n",
        "    \"max_features\": [0.8, 0.9],\n",
        "    \"n_estimators\": [40, 50],\n",
        "}\n",
        "\n",
        "# Type of scoring used to compare parameter combinations\n",
        "scorer = metrics.make_scorer(Minimum_Vs_Model_cost, greater_is_better=True)\n",
        "\n",
        "# Calling RandomizedSearchCV\n",
        "randomized_cv3 = RandomizedSearchCV(\n",
        "    estimator=model3,\n",
        "    param_distributions=param_grid3,\n",
        "    n_iter=50,\n",
        "    scoring=scorer,\n",
        "    cv=5,\n",
        "    random_state=1,\n",
        "    n_jobs=-1,\n",
        ")\n",
        "\n",
        "# Fitting parameters in RandomizedSearchCV\n",
        "randomized_cv3.fit(X_train, y_train)\n",
        "print(\n",
        "    \"Best parameters are {} with CV score={}:\".format(\n",
        "        randomized_cv3.best_params_, randomized_cv3.best_score_\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKoiCkadCYzd",
        "outputId": "9ae43364-f296-46f0-b033-6b32a07bc7f6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BaggingClassifier(max_features=0.8, max_samples=0.9, n_estimators=50,\n",
              "                  random_state=1)"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 48;\n",
              "                var nbb_unformatted_code = \"# building model with best parameters\\nbagging_tuned = BaggingClassifier(\\n    n_estimators=50, max_samples=0.9, max_features=0.8, random_state=1,\\n)\\n\\n# Fit the model on training data\\nbagging_tuned.fit(X_train, y_train)\";\n",
              "                var nbb_formatted_code = \"# building model with best parameters\\nbagging_tuned = BaggingClassifier(\\n    n_estimators=50, max_samples=0.9, max_features=0.8, random_state=1,\\n)\\n\\n# Fit the model on training data\\nbagging_tuned.fit(X_train, y_train)\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# building model with best parameters\n",
        "bagging_tuned = BaggingClassifier(\n",
        "    n_estimators=50, max_samples=0.9, max_features=0.8, random_state=1,\n",
        ")\n",
        "\n",
        "# Fit the model on training data\n",
        "bagging_tuned.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tU5a6H47CYzd",
        "outputId": "c76c4039-149e-4d62-d13d-0198e6ba72c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training performance:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Precision</th>\n",
              "      <th>F1</th>\n",
              "      <th>Minimum_Vs_Model_cost</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.999</td>\n",
              "      <td>0.989</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.994</td>\n",
              "      <td>0.982</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Accuracy  Recall  Precision    F1  Minimum_Vs_Model_cost\n",
              "0     0.999   0.989      1.000 0.994                  0.982"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 49;\n",
              "                var nbb_unformatted_code = \"# Calculating different metrics on train set\\nbagging_random_train = model_performance_classification_sklearn(\\n    bagging_tuned, X_train, y_train\\n)\\nprint(\\\"Training performance:\\\")\\nbagging_random_train\";\n",
              "                var nbb_formatted_code = \"# Calculating different metrics on train set\\nbagging_random_train = model_performance_classification_sklearn(\\n    bagging_tuned, X_train, y_train\\n)\\nprint(\\\"Training performance:\\\")\\nbagging_random_train\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Calculating different metrics on train set\n",
        "bagging_random_train = model_performance_classification_sklearn(\n",
        "    bagging_tuned, X_train, y_train\n",
        ")\n",
        "print(\"Training performance:\")\n",
        "bagging_random_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QOFCKYiFCYze",
        "outputId": "cf73ccde-8c64-4e9a-a20a-4fee773969ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation performance:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Precision</th>\n",
              "      <th>F1</th>\n",
              "      <th>Minimum_Vs_Model_cost</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.985</td>\n",
              "      <td>0.745</td>\n",
              "      <td>0.978</td>\n",
              "      <td>0.846</td>\n",
              "      <td>0.699</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Accuracy  Recall  Precision    F1  Minimum_Vs_Model_cost\n",
              "0     0.985   0.745      0.978 0.846                  0.699"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 50;\n",
              "                var nbb_unformatted_code = \"# Calculating different metrics on validation set\\nbagging_random_val = model_performance_classification_sklearn(\\n    bagging_tuned, X_val, y_val\\n)\\nprint(\\\"Validation performance:\\\")\\nbagging_random_val\";\n",
              "                var nbb_formatted_code = \"# Calculating different metrics on validation set\\nbagging_random_val = model_performance_classification_sklearn(\\n    bagging_tuned, X_val, y_val\\n)\\nprint(\\\"Validation performance:\\\")\\nbagging_random_val\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Calculating different metrics on validation set\n",
        "bagging_random_val = model_performance_classification_sklearn(\n",
        "    bagging_tuned, X_val, y_val\n",
        ")\n",
        "print(\"Validation performance:\")\n",
        "bagging_random_val"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FfYY0AcCYze"
      },
      "source": [
        "- The best hyperparameters using RandomizedSearch CV for Bagging Classifier were found to be: n_estimator 50, max_samples 0.9, max_features 0.8\n",
        "- The average 5 fold cross validation training performance score (customized metric) using the best parameter Bagging classifier is 0.71. This is similar to the performance score (customized metric) on the validation set i.e., 0.70. This indicates the model may generalize with a performance score of ~0.69-0.71\n",
        "- The model does however have a tendency to overfit the training set as can be observed from training performance (customized metric score of 0.982)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9JNnpxa4jau"
      },
      "source": [
        "## Model Performance comparison and choosing the final model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "seWQdJFOCYze",
        "outputId": "5af3abbb-d69c-4fc1-b136-54d6a393dc50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training performance comparison:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>XGBoost Tuned with Random search</th>\n",
              "      <th>Random forest Tuned with Random search</th>\n",
              "      <th>Bagging Tuned with Random Search</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Accuracy</th>\n",
              "      <td>1.000</td>\n",
              "      <td>0.993</td>\n",
              "      <td>0.999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Recall</th>\n",
              "      <td>1.000</td>\n",
              "      <td>0.882</td>\n",
              "      <td>0.989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Precision</th>\n",
              "      <td>0.995</td>\n",
              "      <td>0.998</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>F1</th>\n",
              "      <td>0.997</td>\n",
              "      <td>0.937</td>\n",
              "      <td>0.994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Minimum_Vs_Model_cost</th>\n",
              "      <td>0.998</td>\n",
              "      <td>0.836</td>\n",
              "      <td>0.982</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       XGBoost Tuned with Random search  \\\n",
              "Accuracy                                          1.000   \n",
              "Recall                                            1.000   \n",
              "Precision                                         0.995   \n",
              "F1                                                0.997   \n",
              "Minimum_Vs_Model_cost                             0.998   \n",
              "\n",
              "                       Random forest Tuned with Random search  \\\n",
              "Accuracy                                                0.993   \n",
              "Recall                                                  0.882   \n",
              "Precision                                               0.998   \n",
              "F1                                                      0.937   \n",
              "Minimum_Vs_Model_cost                                   0.836   \n",
              "\n",
              "                       Bagging Tuned with Random Search  \n",
              "Accuracy                                          0.999  \n",
              "Recall                                            0.989  \n",
              "Precision                                         1.000  \n",
              "F1                                                0.994  \n",
              "Minimum_Vs_Model_cost                             0.982  "
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 72;\n",
              "                var nbb_unformatted_code = \"# training performance comparison\\n\\nmodels_train_comp_df = pd.concat(\\n    [xgboost_random_train.T, rf_random_train.T, bagging_random_train.T,], axis=1,\\n)\\nmodels_train_comp_df.columns = [\\n    \\\"XGBoost Tuned with Random search\\\",\\n    \\\"Random forest Tuned with Random search\\\",\\n    \\\"Bagging Tuned with Random Search\\\",\\n]\\nprint(\\\"Training performance comparison:\\\")\\nmodels_train_comp_df\";\n",
              "                var nbb_formatted_code = \"# training performance comparison\\n\\nmodels_train_comp_df = pd.concat(\\n    [xgboost_random_train.T, rf_random_train.T, bagging_random_train.T,], axis=1,\\n)\\nmodels_train_comp_df.columns = [\\n    \\\"XGBoost Tuned with Random search\\\",\\n    \\\"Random forest Tuned with Random search\\\",\\n    \\\"Bagging Tuned with Random Search\\\",\\n]\\nprint(\\\"Training performance comparison:\\\")\\nmodels_train_comp_df\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# training performance comparison\n",
        "\n",
        "models_train_comp_df = pd.concat(\n",
        "    [xgboost_random_train.T, rf_random_train.T, bagging_random_train.T,], axis=1,\n",
        ")\n",
        "models_train_comp_df.columns = [\n",
        "    \"XGBoost Tuned with Random search\",\n",
        "    \"Random forest Tuned with Random search\",\n",
        "    \"Bagging Tuned with Random Search\",\n",
        "]\n",
        "print(\"Training performance comparison:\")\n",
        "models_train_comp_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JR5r4eZyCYzf",
        "outputId": "4bdf41c1-b0c7-4dfb-8d30-ed913da90a72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation performance comparison:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>XGBoost Tuned with Random search</th>\n",
              "      <th>Random forest Tuned with Random search</th>\n",
              "      <th>Bagging Tuned with Random Search</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Accuracy</th>\n",
              "      <td>0.991</td>\n",
              "      <td>0.985</td>\n",
              "      <td>0.985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Recall</th>\n",
              "      <td>0.877</td>\n",
              "      <td>0.741</td>\n",
              "      <td>0.745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Precision</th>\n",
              "      <td>0.962</td>\n",
              "      <td>0.988</td>\n",
              "      <td>0.978</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>F1</th>\n",
              "      <td>0.917</td>\n",
              "      <td>0.847</td>\n",
              "      <td>0.846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Minimum_Vs_Model_cost</th>\n",
              "      <td>0.821</td>\n",
              "      <td>0.697</td>\n",
              "      <td>0.699</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       XGBoost Tuned with Random search  \\\n",
              "Accuracy                                          0.991   \n",
              "Recall                                            0.877   \n",
              "Precision                                         0.962   \n",
              "F1                                                0.917   \n",
              "Minimum_Vs_Model_cost                             0.821   \n",
              "\n",
              "                       Random forest Tuned with Random search  \\\n",
              "Accuracy                                                0.985   \n",
              "Recall                                                  0.741   \n",
              "Precision                                               0.988   \n",
              "F1                                                      0.847   \n",
              "Minimum_Vs_Model_cost                                   0.697   \n",
              "\n",
              "                       Bagging Tuned with Random Search  \n",
              "Accuracy                                          0.985  \n",
              "Recall                                            0.745  \n",
              "Precision                                         0.978  \n",
              "F1                                                0.846  \n",
              "Minimum_Vs_Model_cost                             0.699  "
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 73;\n",
              "                var nbb_unformatted_code = \"# training performance comparison\\n\\nmodels_val_comp_df = pd.concat(\\n    [xgboost_random_val.T, rf_random_val.T, bagging_random_val.T,], axis=1,\\n)\\nmodels_val_comp_df.columns = [\\n    \\\"XGBoost Tuned with Random search\\\",\\n    \\\"Random forest Tuned with Random search\\\",\\n    \\\"Bagging Tuned with Random Search\\\",\\n]\\nprint(\\\"Validation performance comparison:\\\")\\nmodels_val_comp_df\";\n",
              "                var nbb_formatted_code = \"# training performance comparison\\n\\nmodels_val_comp_df = pd.concat(\\n    [xgboost_random_val.T, rf_random_val.T, bagging_random_val.T,], axis=1,\\n)\\nmodels_val_comp_df.columns = [\\n    \\\"XGBoost Tuned with Random search\\\",\\n    \\\"Random forest Tuned with Random search\\\",\\n    \\\"Bagging Tuned with Random Search\\\",\\n]\\nprint(\\\"Validation performance comparison:\\\")\\nmodels_val_comp_df\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# training performance comparison\n",
        "\n",
        "models_val_comp_df = pd.concat(\n",
        "    [xgboost_random_val.T, rf_random_val.T, bagging_random_val.T,], axis=1,\n",
        ")\n",
        "models_val_comp_df.columns = [\n",
        "    \"XGBoost Tuned with Random search\",\n",
        "    \"Random forest Tuned with Random search\",\n",
        "    \"Bagging Tuned with Random Search\",\n",
        "]\n",
        "print(\"Validation performance comparison:\")\n",
        "models_val_comp_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpx9yJ16CYzg"
      },
      "source": [
        "- The XGBoost Tuned model with Random Search is giving the highest performance score (Minimum_Vs_Model_cost) of 0.821 on the Validation Set. Although this algorithm is giving much higher performance on training set (0.998) indicating overfitting, we still observe the following -\n",
        "  - The average cross validation Training performance score (Minimum_Vs_Model_cost) with this model is 0.80, similar to the validation score of 0.821\n",
        "  - The accuracy, precision and F1 scores of the training & validation models are very much comparable\n",
        "    \n",
        "    \n",
        "- We will choose this tuned model to see if it can generalize well on the testing dataset to give a likewise high performance score (Minimum_Vs_Model_cost) ~ 0.8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_pDMFAz4jav"
      },
      "source": [
        "## Test set final performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BIAUzQhTCYzh",
        "outputId": "56d303fb-62c6-407d-cc06-c91afb172e2a"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 51;\n",
              "                var nbb_unformatted_code = \"# Loading the dataset\\ntest = pd.read_csv(\\\"test.csv\\\")\";\n",
              "                var nbb_formatted_code = \"# Loading the dataset\\ntest = pd.read_csv(\\\"test.csv\\\")\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Loading the dataset\n",
        "test = pd.read_csv(\"https://raw.githubusercontent.com/rochitasundar/Predictive-maintenance-cost-minimization-using-ML-ReneWind/master/Test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Sf7syoxCYzh",
        "outputId": "9b5c560d-482f-47ce-c6b2-097604807512"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 52;\n",
              "                var nbb_unformatted_code = \"X_test = test.drop([\\\"Target\\\"], axis=1)\\ny_test = test[\\\"Target\\\"]\";\n",
              "                var nbb_formatted_code = \"X_test = test.drop([\\\"Target\\\"], axis=1)\\ny_test = test[\\\"Target\\\"]\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "X_test = test.drop([\"Target\"], axis=1)\n",
        "y_test = test[\"Target\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URBEW-1mCYzh",
        "outputId": "c6cdf47b-5676-4c7e-d6ac-ba1d60223f61"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    9453\n",
              "1     547\n",
              "Name: Target, dtype: int64"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 53;\n",
              "                var nbb_unformatted_code = \"y_test.value_counts()\";\n",
              "                var nbb_formatted_code = \"y_test.value_counts()\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "y_test.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ebcRJnhCYzi"
      },
      "source": [
        "- The test data has likewise 94.53% \"0\" or \"No failures\" and 5.47% \"1\" or \"Failures\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-KOmsBECYzl",
        "outputId": "900e9622-3bef-45e5-a319-5f1c3d539946"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 40 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   V1      9989 non-null   float64\n",
            " 1   V2      9993 non-null   float64\n",
            " 2   V3      10000 non-null  float64\n",
            " 3   V4      10000 non-null  float64\n",
            " 4   V5      10000 non-null  float64\n",
            " 5   V6      10000 non-null  float64\n",
            " 6   V7      10000 non-null  float64\n",
            " 7   V8      10000 non-null  float64\n",
            " 8   V9      10000 non-null  float64\n",
            " 9   V10     10000 non-null  float64\n",
            " 10  V11     10000 non-null  float64\n",
            " 11  V12     10000 non-null  float64\n",
            " 12  V13     10000 non-null  float64\n",
            " 13  V14     10000 non-null  float64\n",
            " 14  V15     10000 non-null  float64\n",
            " 15  V16     10000 non-null  float64\n",
            " 16  V17     10000 non-null  float64\n",
            " 17  V18     10000 non-null  float64\n",
            " 18  V19     10000 non-null  float64\n",
            " 19  V20     10000 non-null  float64\n",
            " 20  V21     10000 non-null  float64\n",
            " 21  V22     10000 non-null  float64\n",
            " 22  V23     10000 non-null  float64\n",
            " 23  V24     10000 non-null  float64\n",
            " 24  V25     10000 non-null  float64\n",
            " 25  V26     10000 non-null  float64\n",
            " 26  V27     10000 non-null  float64\n",
            " 27  V28     10000 non-null  float64\n",
            " 28  V29     10000 non-null  float64\n",
            " 29  V30     10000 non-null  float64\n",
            " 30  V31     10000 non-null  float64\n",
            " 31  V32     10000 non-null  float64\n",
            " 32  V33     10000 non-null  float64\n",
            " 33  V34     10000 non-null  float64\n",
            " 34  V35     10000 non-null  float64\n",
            " 35  V36     10000 non-null  float64\n",
            " 36  V37     10000 non-null  float64\n",
            " 37  V38     10000 non-null  float64\n",
            " 38  V39     10000 non-null  float64\n",
            " 39  V40     10000 non-null  float64\n",
            "dtypes: float64(40)\n",
            "memory usage: 3.1 MB\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 54;\n",
              "                var nbb_unformatted_code = \"X_test.info()\";\n",
              "                var nbb_formatted_code = \"X_test.info()\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "X_test.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_Yv2fKhCYzl"
      },
      "source": [
        "- There are 11 & 7 missing values for attributes \"V1\" and \"V2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vw1BxbWDCYzl",
        "outputId": "a2e31577-0a53-470f-bf88-35773720ef1c"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 55;\n",
              "                var nbb_unformatted_code = \"imputer = SimpleImputer(strategy=\\\"median\\\")\\nimpute = imputer.fit(X_test)\\nX_test = imputer.transform(X_test)\";\n",
              "                var nbb_formatted_code = \"imputer = SimpleImputer(strategy=\\\"median\\\")\\nimpute = imputer.fit(X_test)\\nX_test = imputer.transform(X_test)\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "imputer = SimpleImputer(strategy=\"median\")\n",
        "impute = imputer.fit(X_test)\n",
        "X_test = imputer.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7FODQBzCYzl",
        "outputId": "72bccf41-a8df-4be1-a545-4dcc720fa1f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test Performance:\n",
            "\n",
            "XGboost_tuned: 0.791988416988417\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 56;\n",
              "                var nbb_unformatted_code = \"print(\\\"\\\\n\\\" \\\"Test Performance:\\\" \\\"\\\\n\\\")\\n\\nfinal_model = XGBClassifier(\\n    subsample=0.9,\\n    scale_pos_weight=10,\\n    n_estimators=250,\\n    learning_rate=0.1,\\n    gamma=3,\\n    random_state=1,\\n    eval_metric=\\\"logloss\\\")\\nname = \\\"XGboost_tuned\\\"\\n\\nfinal_model.fit(X_train, y_train)\\nfinal_scores = Minimum_Vs_Model_cost(y_test, final_model.predict(X_test))\\nprint(\\\"{}: {}\\\".format(name, final_scores))\";\n",
              "                var nbb_formatted_code = \"print(\\\"\\\\n\\\" \\\"Test Performance:\\\" \\\"\\\\n\\\")\\n\\nfinal_model = XGBClassifier(\\n    subsample=0.9,\\n    scale_pos_weight=10,\\n    n_estimators=250,\\n    learning_rate=0.1,\\n    gamma=3,\\n    random_state=1,\\n    eval_metric=\\\"logloss\\\",\\n)\\nname = \\\"XGboost_tuned\\\"\\n\\nfinal_model.fit(X_train, y_train)\\nfinal_scores = Minimum_Vs_Model_cost(y_test, final_model.predict(X_test))\\nprint(\\\"{}: {}\\\".format(name, final_scores))\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(\"\\n\" \"Test Performance:\" \"\\n\")\n",
        "\n",
        "final_model = XGBClassifier(\n",
        "    subsample=0.9,\n",
        "    scale_pos_weight=10,\n",
        "    n_estimators=250,\n",
        "    learning_rate=0.1,\n",
        "    gamma=3,\n",
        "    random_state=1,\n",
        "    eval_metric=\"logloss\",\n",
        ")\n",
        "name = \"XGboost_tuned\"\n",
        "\n",
        "final_model.fit(X_train, y_train)\n",
        "final_scores = Minimum_Vs_Model_cost(y_test, final_model.predict(X_test))\n",
        "print(\"{}: {}\".format(name, final_scores))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdMSnIjtCYzm",
        "outputId": "6b329596-1b3f-4d9a-8257-030a795fbd05"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Precision</th>\n",
              "      <th>F1</th>\n",
              "      <th>Minimum_Vs_Model_cost</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.990</td>\n",
              "      <td>0.850</td>\n",
              "      <td>0.957</td>\n",
              "      <td>0.900</td>\n",
              "      <td>0.792</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Accuracy  Recall  Precision    F1  Minimum_Vs_Model_cost\n",
              "0     0.990   0.850      0.957 0.900                  0.792"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 57;\n",
              "                var nbb_unformatted_code = \"xgboost_test = model_performance_classification_sklearn(final_model, X_test, y_test)\\nxgboost_test\";\n",
              "                var nbb_formatted_code = \"xgboost_test = model_performance_classification_sklearn(final_model, X_test, y_test)\\nxgboost_test\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "xgboost_test = model_performance_classification_sklearn(final_model, X_test, y_test)\n",
        "xgboost_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1WOLLhAdCYzm",
        "outputId": "fa2c0dc1-b9ff-41d6-a84e-192978995dc1"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 75;\n",
              "                var nbb_unformatted_code = \"# creating confusion matrix\\nconfusion_matrix_sklearn(final_model, X_test, y_test)\";\n",
              "                var nbb_formatted_code = \"# creating confusion matrix\\nconfusion_matrix_sklearn(final_model, X_test, y_test)\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# creating confusion matrix\n",
        "confusion_matrix_sklearn(final_model, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QiimoWsCYzm"
      },
      "source": [
        "- The XGBoost tuned model is generalizing well on the test data with a Minimum_Vs_Model_cost of 0.792 (the cross validation training average score was 0.799 and the validation score was 0.821)\n",
        "- The model is able to make predictions resulting in a maintenance cost ~ (1/0.792 or ~1.26) times the minimum maintenance cost possible"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X34eznm5CYzm",
        "outputId": "d539400a-fbe6-4267-8a17-36182ea1c3ee"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x864 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 74;\n",
              "                var nbb_unformatted_code = \"feature_names = data.columns\\nimportances = final_model.feature_importances_\\nindices = np.argsort(importances)\\n\\nplt.figure(figsize=(12, 12))\\nplt.title(\\\"Feature Importances\\\")\\nplt.barh(range(len(indices)), importances[indices], color=\\\"violet\\\", align=\\\"center\\\")\\nplt.yticks(range(len(indices)), [feature_names[i] for i in indices])\\nplt.xlabel(\\\"Relative Importance\\\")\\nplt.show()\";\n",
              "                var nbb_formatted_code = \"feature_names = data.columns\\nimportances = final_model.feature_importances_\\nindices = np.argsort(importances)\\n\\nplt.figure(figsize=(12, 12))\\nplt.title(\\\"Feature Importances\\\")\\nplt.barh(range(len(indices)), importances[indices], color=\\\"violet\\\", align=\\\"center\\\")\\nplt.yticks(range(len(indices)), [feature_names[i] for i in indices])\\nplt.xlabel(\\\"Relative Importance\\\")\\nplt.show()\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "feature_names = data.columns\n",
        "importances = final_model.feature_importances_\n",
        "indices = np.argsort(importances)\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "plt.title(\"Feature Importances\")\n",
        "plt.barh(range(len(indices)), importances[indices], color=\"violet\", align=\"center\")\n",
        "plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
        "plt.xlabel(\"Relative Importance\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zjUADLTCYzn"
      },
      "source": [
        "- The top attributes which have the maximum importance for making accurate failure/ no-failure predictions are \"V18\", \"V39\", \"V26\", \"V3\" & \"V10\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TM6VZTRn4jav"
      },
      "source": [
        "## Pipelines to build the final model\n",
        "\n",
        "- Pipelines can be used to put the final model in production"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kFb2sq_0CYzn",
        "outputId": "9c01a888-1a7d-446e-8bbd-7ef75aa7ff5c"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 59;\n",
              "                var nbb_unformatted_code = \"# As we already know the final model, we will not be splitting test set into test and validation sets\\n\\nX_train_pipeline = train.drop(\\\"Target\\\", axis=1)\\ny_train_pipeline = train[\\\"Target\\\"]\";\n",
              "                var nbb_formatted_code = \"# As we already know the final model, we will not be splitting test set into test and validation sets\\n\\nX_train_pipeline = train.drop(\\\"Target\\\", axis=1)\\ny_train_pipeline = train[\\\"Target\\\"]\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# As we already know the final model, we will not be splitting train set into train and validation sets\n",
        "\n",
        "X_train_pipeline = train.drop(\"Target\", axis=1)\n",
        "y_train_pipeline = train[\"Target\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNnD18eWCYzn",
        "outputId": "599c8f10-743b-4181-9952-5c5edd8787d5"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 60;\n",
              "                var nbb_unformatted_code = \"X_test_pipeline = test.drop(\\\"Target\\\", axis=1)\\ny_test_pipeline = test[\\\"Target\\\"]\";\n",
              "                var nbb_formatted_code = \"X_test_pipeline = test.drop(\\\"Target\\\", axis=1)\\ny_test_pipeline = test[\\\"Target\\\"]\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "X_test_pipeline = test.drop(\"Target\", axis=1)\n",
        "y_test_pipeline = test[\"Target\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zzg12gvx4jav",
        "outputId": "a61649bc-856b-456d-8d13-d3f4f2ba99c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
              "                ('XGB',\n",
              "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
              "                               colsample_bylevel=1, colsample_bynode=1,\n",
              "                               colsample_bytree=1, eval_metric='logloss',\n",
              "                               gamma=3, gpu_id=-1, importance_type='gain',\n",
              "                               interaction_constraints='', learning_rate=0.1,\n",
              "                               max_delta_step=0, max_depth=6,\n",
              "                               min_child_weight=1, missing=nan,\n",
              "                               monotone_constraints='()', n_estimators=250,\n",
              "                               n_jobs=4, num_parallel_tree=1, random_state=1,\n",
              "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=10,\n",
              "                               subsample=0.9, tree_method='exact',\n",
              "                               validate_parameters=1, verbosity=None))])"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 61;\n",
              "                var nbb_unformatted_code = \"model_pipeline = Pipeline(\\n    steps=[\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\\"XGB\\\", XGBClassifier(\\n    subsample=0.9,\\n    scale_pos_weight=10,\\n    n_estimators=250,\\n    learning_rate=0.1,\\n    gamma=3,\\n    random_state=1,\\n    eval_metric=\\\"logloss\\\")),\\n    ]\\n)\\n# Fit the model on training data\\nmodel_pipeline.fit(X_train_pipeline, y_train_pipeline)\";\n",
              "                var nbb_formatted_code = \"model_pipeline = Pipeline(\\n    steps=[\\n        (\\\"imputer\\\", SimpleImputer(strategy=\\\"median\\\")),\\n        (\\n            \\\"XGB\\\",\\n            XGBClassifier(\\n                subsample=0.9,\\n                scale_pos_weight=10,\\n                n_estimators=250,\\n                learning_rate=0.1,\\n                gamma=3,\\n                random_state=1,\\n                eval_metric=\\\"logloss\\\",\\n            ),\\n        ),\\n    ]\\n)\\n# Fit the model on training data\\nmodel_pipeline.fit(X_train_pipeline, y_train_pipeline)\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model_pipeline = Pipeline(\n",
        "    steps=[\n",
        "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "        (\n",
        "            \"XGB\",\n",
        "            XGBClassifier(\n",
        "                subsample=0.9,\n",
        "                scale_pos_weight=10,\n",
        "                n_estimators=250,\n",
        "                learning_rate=0.1,\n",
        "                gamma=3,\n",
        "                random_state=1,\n",
        "                eval_metric=\"logloss\",\n",
        "            ),\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "# Fit the model on training data\n",
        "model_pipeline.fit(X_train_pipeline, y_train_pipeline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spbNbyiBCYzn",
        "outputId": "9e494af0-bf61-4b64-8ee0-0d8a63f91e86"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 62;\n",
              "                var nbb_unformatted_code = \"# transforming and predicting on test data\\nmodel_pipeline.predict(X_test_pipeline)\";\n",
              "                var nbb_formatted_code = \"# transforming and predicting on test data\\nmodel_pipeline.predict(X_test_pipeline)\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# transforming and predicting on test data\n",
        "model_pipeline.predict(X_test_pipeline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAXrYM4ICYzo",
        "outputId": "d8b1ff80-79e2-46e5-a9a0-adc900ef8508"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7997076023391813"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "            setTimeout(function() {\n",
              "                var nbb_cell_id = 63;\n",
              "                var nbb_unformatted_code = \"Minimum_Vs_Model_cost(y_test_pipeline, model_pipeline.predict(X_test_pipeline))\";\n",
              "                var nbb_formatted_code = \"Minimum_Vs_Model_cost(y_test_pipeline, model_pipeline.predict(X_test_pipeline))\";\n",
              "                var nbb_cells = Jupyter.notebook.get_cells();\n",
              "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
              "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
              "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
              "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
              "                        }\n",
              "                        break;\n",
              "                    }\n",
              "                }\n",
              "            }, 500);\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "Minimum_Vs_Model_cost(y_test_pipeline, model_pipeline.predict(X_test_pipeline))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brYd-DUECYzo"
      },
      "source": [
        "- The pipeline performance is as expected (Minimum_Vs_Model_cost 0.799) indicating it was built accurately to replicate the final chosen model after necessary pre processing "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5hPmHyR4jaw"
      },
      "source": [
        "# Business Insights and Conclusions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnBbg6sH4jaw"
      },
      "source": [
        "- A machine learning model has been built to minimize the total maintenance cost of machinery/processes used for wind energy production\n",
        "    - The final tuned model (XGBoost) was chosen after building ~7 different machine learning algorithms & further optimizing for target class imbalance (having few \"failures\" and many \"no failures\" in dataset) as well as finetuning the algorithm performance (hyperparameter and cross validation techniques)\n",
        "\n",
        "    - A pipeline was additionally built to productionise the final chosen model\n",
        "   \n",
        "   \n",
        "- The model is expected to generalize well in terms of predictions & expected to result in a maintenance cost ~1.26 times minimum possible maintenance cost. Having no model in place for predictions could potentially result in costs as high as ~2.67 minimum possible maintenance cost. Hence, productionising the model has a large cost saving advantage\n",
        "\n",
        "- The main attributes of importance for predicting failures vs. no failures were found to be \"V18\", \"V39\", \"V26\", \"V3\" & \"V10\" in order of decreasing importance. This added knowledge can be used to refine the process of collecting more frequent sensor information to be used in improving the machine learning model to further decrease maintenance costs "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
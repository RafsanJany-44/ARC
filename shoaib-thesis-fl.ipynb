{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4245283,"sourceId":7315757,"sourceType":"datasetVersion"}],"dockerImageVersionId":30627,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd","metadata":{},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf","metadata":{},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#pip install pandas openpyxl\n","metadata":{},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_excel('DS-Healthcare.xlsx',header = 0)\n","metadata":{},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"data.head(20)","metadata":{},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>Unnamed: 1</th>\n","      <th>Unnamed: 2</th>\n","      <th>Unnamed: 3</th>\n","      <th>Unnamed: 4</th>\n","      <th>Unnamed: 5</th>\n","      <th>Unnamed: 6</th>\n","      <th>Unnamed: 7</th>\n","      <th>Unnamed: 8</th>\n","      <th>Unnamed: 9</th>\n","      <th>Unnamed: 10</th>\n","      <th>Unnamed: 11</th>\n","      <th>Unnamed: 12</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Subject</td>\n","      <td>Type</td>\n","      <td>Cycle</td>\n","      <td>Time</td>\n","      <td>RR-I</td>\n","      <td>HR</td>\n","      <td>R-H</td>\n","      <td>P-H</td>\n","      <td>QRS</td>\n","      <td>PRQ</td>\n","      <td>QT</td>\n","      <td>QTC</td>\n","      <td>ST</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>E1</td>\n","      <td>ischemic</td>\n","      <td>1</td>\n","      <td>1.072</td>\n","      <td>0.932</td>\n","      <td>64.377682</td>\n","      <td>3.305</td>\n","      <td>3.81</td>\n","      <td>0.088</td>\n","      <td>0.16</td>\n","      <td>0.384</td>\n","      <td>0.397762</td>\n","      <td>0.296</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>E1</td>\n","      <td>ischemic</td>\n","      <td>2</td>\n","      <td>2.004</td>\n","      <td>1.004</td>\n","      <td>59.760956</td>\n","      <td>3.285</td>\n","      <td>3.81</td>\n","      <td>0.1</td>\n","      <td>0.16</td>\n","      <td>0.64</td>\n","      <td>0.638724</td>\n","      <td>0.54</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>E1</td>\n","      <td>ischemic</td>\n","      <td>3</td>\n","      <td>3.008</td>\n","      <td>0.996</td>\n","      <td>60.240964</td>\n","      <td>3.34</td>\n","      <td>3.83</td>\n","      <td>0.128</td>\n","      <td>0.148</td>\n","      <td>0.628</td>\n","      <td>0.62926</td>\n","      <td>0.5</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>E1</td>\n","      <td>ischemic</td>\n","      <td>4</td>\n","      <td>4.004</td>\n","      <td>1.016</td>\n","      <td>59.055118</td>\n","      <td>3.325</td>\n","      <td>3.81</td>\n","      <td>0.108</td>\n","      <td>0.172</td>\n","      <td>0.388</td>\n","      <td>0.384933</td>\n","      <td>0.28</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>E1</td>\n","      <td>ischemic</td>\n","      <td>5</td>\n","      <td>5.02</td>\n","      <td>0.972</td>\n","      <td>61.728395</td>\n","      <td>3.29</td>\n","      <td>3.765</td>\n","      <td>0.1</td>\n","      <td>0.16</td>\n","      <td>0.372</td>\n","      <td>0.37732</td>\n","      <td>0.272</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>E1</td>\n","      <td>ischemic</td>\n","      <td>6</td>\n","      <td>5.992</td>\n","      <td>1.04</td>\n","      <td>57.692308</td>\n","      <td>3.27</td>\n","      <td>3.855</td>\n","      <td>0.112</td>\n","      <td>0.168</td>\n","      <td>0.376</td>\n","      <td>0.368698</td>\n","      <td>0.264</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>E1</td>\n","      <td>ischemic</td>\n","      <td>7</td>\n","      <td>7.032</td>\n","      <td>1.028</td>\n","      <td>58.365759</td>\n","      <td>3.355</td>\n","      <td>3.93</td>\n","      <td>0.092</td>\n","      <td>0.168</td>\n","      <td>0.384</td>\n","      <td>0.378734</td>\n","      <td>0.292</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>E1</td>\n","      <td>ischemic</td>\n","      <td>8</td>\n","      <td>8.06</td>\n","      <td>0.988</td>\n","      <td>60.728745</td>\n","      <td>3.38</td>\n","      <td>3.91</td>\n","      <td>0.092</td>\n","      <td>0.164</td>\n","      <td>0.368</td>\n","      <td>0.370228</td>\n","      <td>0.276</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>E1</td>\n","      <td>ischemic</td>\n","      <td>9</td>\n","      <td>9.048</td>\n","      <td>0.96</td>\n","      <td>62.5</td>\n","      <td>3.39</td>\n","      <td>3.875</td>\n","      <td>0.104</td>\n","      <td>0.164</td>\n","      <td>0.38</td>\n","      <td>0.387836</td>\n","      <td>0.276</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>E1</td>\n","      <td>ischemic</td>\n","      <td>10</td>\n","      <td>10.008</td>\n","      <td>0.96</td>\n","      <td>62.5</td>\n","      <td>3.365</td>\n","      <td>3.885</td>\n","      <td>0.1</td>\n","      <td>0.164</td>\n","      <td>0.38</td>\n","      <td>0.387836</td>\n","      <td>0.28</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>E1</td>\n","      <td>ischemic</td>\n","      <td>11</td>\n","      <td>10.968</td>\n","      <td>0.964</td>\n","      <td>62.240664</td>\n","      <td>3.345</td>\n","      <td>3.85</td>\n","      <td>0.088</td>\n","      <td>0.164</td>\n","      <td>0.36</td>\n","      <td>0.36666</td>\n","      <td>0.272</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>E1</td>\n","      <td>ischemic</td>\n","      <td>12</td>\n","      <td>11.932</td>\n","      <td>0.956</td>\n","      <td>62.761506</td>\n","      <td>3.325</td>\n","      <td>3.795</td>\n","      <td>0.104</td>\n","      <td>0.16</td>\n","      <td>0.576</td>\n","      <td>0.589106</td>\n","      <td>0.472</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>E1</td>\n","      <td>ischemic</td>\n","      <td>13</td>\n","      <td>12.888</td>\n","      <td>0.984</td>\n","      <td>60.97561</td>\n","      <td>3.34</td>\n","      <td>3.875</td>\n","      <td>0.104</td>\n","      <td>0.16</td>\n","      <td>0.404</td>\n","      <td>0.407271</td>\n","      <td>0.3</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>E1</td>\n","      <td>ischemic</td>\n","      <td>14</td>\n","      <td>13.872</td>\n","      <td>1.004</td>\n","      <td>59.760956</td>\n","      <td>3.34</td>\n","      <td>3.9</td>\n","      <td>0.088</td>\n","      <td>0.168</td>\n","      <td>0.376</td>\n","      <td>0.37525</td>\n","      <td>0.288</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>E1</td>\n","      <td>ischemic</td>\n","      <td>15</td>\n","      <td>14.876</td>\n","      <td>0.94</td>\n","      <td>63.829787</td>\n","      <td>3.375</td>\n","      <td>3.925</td>\n","      <td>0.1</td>\n","      <td>0.144</td>\n","      <td>0.512</td>\n","      <td>0.528088</td>\n","      <td>0.412</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>E1</td>\n","      <td>ischemic</td>\n","      <td>16</td>\n","      <td>15.816</td>\n","      <td>0.956</td>\n","      <td>62.761506</td>\n","      <td>3.415</td>\n","      <td>3.9</td>\n","      <td>0.256</td>\n","      <td>0.164</td>\n","      <td>0.564</td>\n","      <td>0.576833</td>\n","      <td>0.488</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>E1</td>\n","      <td>ischemic</td>\n","      <td>17</td>\n","      <td>16.772</td>\n","      <td>0.976</td>\n","      <td>61.47541</td>\n","      <td>3.43</td>\n","      <td>3.85</td>\n","      <td>0.088</td>\n","      <td>0.18</td>\n","      <td>0.368</td>\n","      <td>0.372497</td>\n","      <td>0.28</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>E1</td>\n","      <td>ischemic</td>\n","      <td>18</td>\n","      <td>17.748</td>\n","      <td>0.96</td>\n","      <td>62.5</td>\n","      <td>3.34</td>\n","      <td>3.835</td>\n","      <td>0.088</td>\n","      <td>0.168</td>\n","      <td>0.364</td>\n","      <td>0.371506</td>\n","      <td>0.276</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>E1</td>\n","      <td>ischemic</td>\n","      <td>19</td>\n","      <td>18.708</td>\n","      <td>0.992</td>\n","      <td>60.483871</td>\n","      <td>3.355</td>\n","      <td>3.795</td>\n","      <td>0.128</td>\n","      <td>0.164</td>\n","      <td>0.396</td>\n","      <td>0.397594</td>\n","      <td>0.268</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0 Unnamed: 1 Unnamed: 2 Unnamed: 3 Unnamed: 4 Unnamed: 5  \\\n","0     Subject       Type      Cycle       Time       RR-I         HR   \n","1          E1   ischemic          1      1.072      0.932  64.377682   \n","2          E1   ischemic          2      2.004      1.004  59.760956   \n","3          E1   ischemic          3      3.008      0.996  60.240964   \n","4          E1   ischemic          4      4.004      1.016  59.055118   \n","5          E1   ischemic          5       5.02      0.972  61.728395   \n","6          E1   ischemic          6      5.992       1.04  57.692308   \n","7          E1   ischemic          7      7.032      1.028  58.365759   \n","8          E1   ischemic          8       8.06      0.988  60.728745   \n","9          E1   ischemic          9      9.048       0.96       62.5   \n","10         E1   ischemic         10     10.008       0.96       62.5   \n","11         E1   ischemic         11     10.968      0.964  62.240664   \n","12         E1   ischemic         12     11.932      0.956  62.761506   \n","13         E1   ischemic         13     12.888      0.984   60.97561   \n","14         E1   ischemic         14     13.872      1.004  59.760956   \n","15         E1   ischemic         15     14.876       0.94  63.829787   \n","16         E1   ischemic         16     15.816      0.956  62.761506   \n","17         E1   ischemic         17     16.772      0.976   61.47541   \n","18         E1   ischemic         18     17.748       0.96       62.5   \n","19         E1   ischemic         19     18.708      0.992  60.483871   \n","\n","   Unnamed: 6 Unnamed: 7 Unnamed: 8 Unnamed: 9 Unnamed: 10 Unnamed: 11  \\\n","0         R-H        P-H        QRS        PRQ          QT         QTC   \n","1       3.305       3.81      0.088       0.16       0.384    0.397762   \n","2       3.285       3.81        0.1       0.16        0.64    0.638724   \n","3        3.34       3.83      0.128      0.148       0.628     0.62926   \n","4       3.325       3.81      0.108      0.172       0.388    0.384933   \n","5        3.29      3.765        0.1       0.16       0.372     0.37732   \n","6        3.27      3.855      0.112      0.168       0.376    0.368698   \n","7       3.355       3.93      0.092      0.168       0.384    0.378734   \n","8        3.38       3.91      0.092      0.164       0.368    0.370228   \n","9        3.39      3.875      0.104      0.164        0.38    0.387836   \n","10      3.365      3.885        0.1      0.164        0.38    0.387836   \n","11      3.345       3.85      0.088      0.164        0.36     0.36666   \n","12      3.325      3.795      0.104       0.16       0.576    0.589106   \n","13       3.34      3.875      0.104       0.16       0.404    0.407271   \n","14       3.34        3.9      0.088      0.168       0.376     0.37525   \n","15      3.375      3.925        0.1      0.144       0.512    0.528088   \n","16      3.415        3.9      0.256      0.164       0.564    0.576833   \n","17       3.43       3.85      0.088       0.18       0.368    0.372497   \n","18       3.34      3.835      0.088      0.168       0.364    0.371506   \n","19      3.355      3.795      0.128      0.164       0.396    0.397594   \n","\n","   Unnamed: 12  \n","0           ST  \n","1        0.296  \n","2         0.54  \n","3          0.5  \n","4         0.28  \n","5        0.272  \n","6        0.264  \n","7        0.292  \n","8        0.276  \n","9        0.276  \n","10        0.28  \n","11       0.272  \n","12       0.472  \n","13         0.3  \n","14       0.288  \n","15       0.412  \n","16       0.488  \n","17        0.28  \n","18       0.276  \n","19       0.268  "]},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nnew_column_names = data.iloc[0]  \ndata.columns = new_column_names  \ndata = data[1:]  \n","metadata":{},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"data.head(10)","metadata":{},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Subject</th>\n","      <th>Type</th>\n","      <th>Cycle</th>\n","      <th>Time</th>\n","      <th>RR-I</th>\n","      <th>HR</th>\n","      <th>R-H</th>\n","      <th>P-H</th>\n","      <th>QRS</th>\n","      <th>PRQ</th>\n","      <th>QT</th>\n","      <th>QTC</th>\n","      <th>ST</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>E1</td>\n","      <td>ischemic</td>\n","      <td>1</td>\n","      <td>1.072</td>\n","      <td>0.932</td>\n","      <td>64.377682</td>\n","      <td>3.305</td>\n","      <td>3.81</td>\n","      <td>0.088</td>\n","      <td>0.16</td>\n","      <td>0.384</td>\n","      <td>0.397762</td>\n","      <td>0.296</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>E1</td>\n","      <td>ischemic</td>\n","      <td>2</td>\n","      <td>2.004</td>\n","      <td>1.004</td>\n","      <td>59.760956</td>\n","      <td>3.285</td>\n","      <td>3.81</td>\n","      <td>0.1</td>\n","      <td>0.16</td>\n","      <td>0.64</td>\n","      <td>0.638724</td>\n","      <td>0.54</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>E1</td>\n","      <td>ischemic</td>\n","      <td>3</td>\n","      <td>3.008</td>\n","      <td>0.996</td>\n","      <td>60.240964</td>\n","      <td>3.34</td>\n","      <td>3.83</td>\n","      <td>0.128</td>\n","      <td>0.148</td>\n","      <td>0.628</td>\n","      <td>0.62926</td>\n","      <td>0.5</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>E1</td>\n","      <td>ischemic</td>\n","      <td>4</td>\n","      <td>4.004</td>\n","      <td>1.016</td>\n","      <td>59.055118</td>\n","      <td>3.325</td>\n","      <td>3.81</td>\n","      <td>0.108</td>\n","      <td>0.172</td>\n","      <td>0.388</td>\n","      <td>0.384933</td>\n","      <td>0.28</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>E1</td>\n","      <td>ischemic</td>\n","      <td>5</td>\n","      <td>5.02</td>\n","      <td>0.972</td>\n","      <td>61.728395</td>\n","      <td>3.29</td>\n","      <td>3.765</td>\n","      <td>0.1</td>\n","      <td>0.16</td>\n","      <td>0.372</td>\n","      <td>0.37732</td>\n","      <td>0.272</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>E1</td>\n","      <td>ischemic</td>\n","      <td>6</td>\n","      <td>5.992</td>\n","      <td>1.04</td>\n","      <td>57.692308</td>\n","      <td>3.27</td>\n","      <td>3.855</td>\n","      <td>0.112</td>\n","      <td>0.168</td>\n","      <td>0.376</td>\n","      <td>0.368698</td>\n","      <td>0.264</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>E1</td>\n","      <td>ischemic</td>\n","      <td>7</td>\n","      <td>7.032</td>\n","      <td>1.028</td>\n","      <td>58.365759</td>\n","      <td>3.355</td>\n","      <td>3.93</td>\n","      <td>0.092</td>\n","      <td>0.168</td>\n","      <td>0.384</td>\n","      <td>0.378734</td>\n","      <td>0.292</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>E1</td>\n","      <td>ischemic</td>\n","      <td>8</td>\n","      <td>8.06</td>\n","      <td>0.988</td>\n","      <td>60.728745</td>\n","      <td>3.38</td>\n","      <td>3.91</td>\n","      <td>0.092</td>\n","      <td>0.164</td>\n","      <td>0.368</td>\n","      <td>0.370228</td>\n","      <td>0.276</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>E1</td>\n","      <td>ischemic</td>\n","      <td>9</td>\n","      <td>9.048</td>\n","      <td>0.96</td>\n","      <td>62.5</td>\n","      <td>3.39</td>\n","      <td>3.875</td>\n","      <td>0.104</td>\n","      <td>0.164</td>\n","      <td>0.38</td>\n","      <td>0.387836</td>\n","      <td>0.276</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>E1</td>\n","      <td>ischemic</td>\n","      <td>10</td>\n","      <td>10.008</td>\n","      <td>0.96</td>\n","      <td>62.5</td>\n","      <td>3.365</td>\n","      <td>3.885</td>\n","      <td>0.1</td>\n","      <td>0.164</td>\n","      <td>0.38</td>\n","      <td>0.387836</td>\n","      <td>0.28</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["0  Subject      Type Cycle    Time   RR-I         HR    R-H    P-H    QRS  \\\n","1       E1  ischemic     1   1.072  0.932  64.377682  3.305   3.81  0.088   \n","2       E1  ischemic     2   2.004  1.004  59.760956  3.285   3.81    0.1   \n","3       E1  ischemic     3   3.008  0.996  60.240964   3.34   3.83  0.128   \n","4       E1  ischemic     4   4.004  1.016  59.055118  3.325   3.81  0.108   \n","5       E1  ischemic     5    5.02  0.972  61.728395   3.29  3.765    0.1   \n","6       E1  ischemic     6   5.992   1.04  57.692308   3.27  3.855  0.112   \n","7       E1  ischemic     7   7.032  1.028  58.365759  3.355   3.93  0.092   \n","8       E1  ischemic     8    8.06  0.988  60.728745   3.38   3.91  0.092   \n","9       E1  ischemic     9   9.048   0.96       62.5   3.39  3.875  0.104   \n","10      E1  ischemic    10  10.008   0.96       62.5  3.365  3.885    0.1   \n","\n","0     PRQ     QT       QTC     ST  \n","1    0.16  0.384  0.397762  0.296  \n","2    0.16   0.64  0.638724   0.54  \n","3   0.148  0.628   0.62926    0.5  \n","4   0.172  0.388  0.384933   0.28  \n","5    0.16  0.372   0.37732  0.272  \n","6   0.168  0.376  0.368698  0.264  \n","7   0.168  0.384  0.378734  0.292  \n","8   0.164  0.368  0.370228  0.276  \n","9   0.164   0.38  0.387836  0.276  \n","10  0.164   0.38  0.387836   0.28  "]},"metadata":{}}]},{"cell_type":"code","source":"data.tail(100)","metadata":{},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Subject</th>\n","      <th>Type</th>\n","      <th>Cycle</th>\n","      <th>Time</th>\n","      <th>RR-I</th>\n","      <th>HR</th>\n","      <th>R-H</th>\n","      <th>P-H</th>\n","      <th>QRS</th>\n","      <th>PRQ</th>\n","      <th>QT</th>\n","      <th>QTC</th>\n","      <th>ST</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1048475</th>\n","      <td>M28</td>\n","      <td>arrhythmic</td>\n","      <td>644</td>\n","      <td>420.280556</td>\n","      <td>0.647222</td>\n","      <td>92.703863</td>\n","      <td>0.7</td>\n","      <td>-0.18</td>\n","      <td>0.058333</td>\n","      <td>0.147222</td>\n","      <td>0.388889</td>\n","      <td>0.483391</td>\n","      <td>0.330556</td>\n","    </tr>\n","    <tr>\n","      <th>1048476</th>\n","      <td>M28</td>\n","      <td>arrhythmic</td>\n","      <td>645</td>\n","      <td>420.927778</td>\n","      <td>0.638889</td>\n","      <td>93.913043</td>\n","      <td>0.73</td>\n","      <td>-0.195</td>\n","      <td>0.091667</td>\n","      <td>0.144444</td>\n","      <td>0.433333</td>\n","      <td>0.542137</td>\n","      <td>0.341667</td>\n","    </tr>\n","    <tr>\n","      <th>1048477</th>\n","      <td>M28</td>\n","      <td>arrhythmic</td>\n","      <td>646</td>\n","      <td>421.566667</td>\n","      <td>0.652778</td>\n","      <td>91.914894</td>\n","      <td>0.74</td>\n","      <td>-0.165</td>\n","      <td>0.058333</td>\n","      <td>0.163889</td>\n","      <td>0.394444</td>\n","      <td>0.488206</td>\n","      <td>0.336111</td>\n","    </tr>\n","    <tr>\n","      <th>1048478</th>\n","      <td>M28</td>\n","      <td>arrhythmic</td>\n","      <td>647</td>\n","      <td>422.219444</td>\n","      <td>0.655556</td>\n","      <td>91.525424</td>\n","      <td>0.6</td>\n","      <td>-0.185</td>\n","      <td>0.055556</td>\n","      <td>0.155556</td>\n","      <td>0.405556</td>\n","      <td>0.500894</td>\n","      <td>0.35</td>\n","    </tr>\n","    <tr>\n","      <th>1048479</th>\n","      <td>M28</td>\n","      <td>arrhythmic</td>\n","      <td>648</td>\n","      <td>422.875</td>\n","      <td>0.647222</td>\n","      <td>92.703863</td>\n","      <td>0.705</td>\n","      <td>-0.175</td>\n","      <td>0.061111</td>\n","      <td>0.158333</td>\n","      <td>0.416667</td>\n","      <td>0.517919</td>\n","      <td>0.355556</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1048570</th>\n","      <td>M28</td>\n","      <td>arrhythmic</td>\n","      <td>739</td>\n","      <td>482.161111</td>\n","      <td>0.652778</td>\n","      <td>91.914894</td>\n","      <td>0.66</td>\n","      <td>-0.335</td>\n","      <td>0.066667</td>\n","      <td>0.163889</td>\n","      <td>0.411111</td>\n","      <td>0.508834</td>\n","      <td>0.355556</td>\n","    </tr>\n","    <tr>\n","      <th>1048571</th>\n","      <td>M28</td>\n","      <td>arrhythmic</td>\n","      <td>740</td>\n","      <td>482.813889</td>\n","      <td>0.675</td>\n","      <td>88.888889</td>\n","      <td>0.605</td>\n","      <td>-0.345</td>\n","      <td>0.066667</td>\n","      <td>0.172222</td>\n","      <td>0.413889</td>\n","      <td>0.50377</td>\n","      <td>0.358333</td>\n","    </tr>\n","    <tr>\n","      <th>1048572</th>\n","      <td>M28</td>\n","      <td>arrhythmic</td>\n","      <td>741</td>\n","      <td>483.488889</td>\n","      <td>0.647222</td>\n","      <td>92.703863</td>\n","      <td>0.795</td>\n","      <td>-0.335</td>\n","      <td>0.055556</td>\n","      <td>0.161111</td>\n","      <td>0.397222</td>\n","      <td>0.49375</td>\n","      <td>0.341667</td>\n","    </tr>\n","    <tr>\n","      <th>1048573</th>\n","      <td>M28</td>\n","      <td>arrhythmic</td>\n","      <td>742</td>\n","      <td>484.136111</td>\n","      <td>0.647222</td>\n","      <td>92.703863</td>\n","      <td>0.825</td>\n","      <td>-0.33</td>\n","      <td>0.069444</td>\n","      <td>0.152778</td>\n","      <td>0.4</td>\n","      <td>0.497202</td>\n","      <td>0.344444</td>\n","    </tr>\n","    <tr>\n","      <th>1048574</th>\n","      <td>M28</td>\n","      <td>arrhythmic</td>\n","      <td>743</td>\n","      <td>484.783333</td>\n","      <td>0.641667</td>\n","      <td>93.506494</td>\n","      <td>0.625</td>\n","      <td>-0.3</td>\n","      <td>0.066667</td>\n","      <td>0.161111</td>\n","      <td>0.391667</td>\n","      <td>0.488947</td>\n","      <td>0.336111</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>100 rows Ã— 13 columns</p>\n","</div>"],"text/plain":["0       Subject        Type Cycle        Time      RR-I         HR    R-H  \\\n","1048475     M28  arrhythmic   644  420.280556  0.647222  92.703863    0.7   \n","1048476     M28  arrhythmic   645  420.927778  0.638889  93.913043   0.73   \n","1048477     M28  arrhythmic   646  421.566667  0.652778  91.914894   0.74   \n","1048478     M28  arrhythmic   647  422.219444  0.655556  91.525424    0.6   \n","1048479     M28  arrhythmic   648     422.875  0.647222  92.703863  0.705   \n","...         ...         ...   ...         ...       ...        ...    ...   \n","1048570     M28  arrhythmic   739  482.161111  0.652778  91.914894   0.66   \n","1048571     M28  arrhythmic   740  482.813889     0.675  88.888889  0.605   \n","1048572     M28  arrhythmic   741  483.488889  0.647222  92.703863  0.795   \n","1048573     M28  arrhythmic   742  484.136111  0.647222  92.703863  0.825   \n","1048574     M28  arrhythmic   743  484.783333  0.641667  93.506494  0.625   \n","\n","0          P-H       QRS       PRQ        QT       QTC        ST  \n","1048475  -0.18  0.058333  0.147222  0.388889  0.483391  0.330556  \n","1048476 -0.195  0.091667  0.144444  0.433333  0.542137  0.341667  \n","1048477 -0.165  0.058333  0.163889  0.394444  0.488206  0.336111  \n","1048478 -0.185  0.055556  0.155556  0.405556  0.500894      0.35  \n","1048479 -0.175  0.061111  0.158333  0.416667  0.517919  0.355556  \n","...        ...       ...       ...       ...       ...       ...  \n","1048570 -0.335  0.066667  0.163889  0.411111  0.508834  0.355556  \n","1048571 -0.345  0.066667  0.172222  0.413889   0.50377  0.358333  \n","1048572 -0.335  0.055556  0.161111  0.397222   0.49375  0.341667  \n","1048573  -0.33  0.069444  0.152778       0.4  0.497202  0.344444  \n","1048574   -0.3  0.066667  0.161111  0.391667  0.488947  0.336111  \n","\n","[100 rows x 13 columns]"]},"metadata":{}}]},{"cell_type":"code","source":"data.Type.value_counts()","metadata":{},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":["ischemic      705983\n","healthy       284849\n","arrhythmic     57742\n","Name: Type, dtype: int64"]},"metadata":{}}]},{"cell_type":"code","source":"data['Type'] = data['Type'].map({'arrhythmic': 'unhealthy', 'ischemic': 'unhealthy', 'healthy': 'healthy'})\n\n\n","metadata":{},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Subject</th>\n","      <th>Type</th>\n","      <th>Cycle</th>\n","      <th>Time</th>\n","      <th>RR-I</th>\n","      <th>HR</th>\n","      <th>R-H</th>\n","      <th>P-H</th>\n","      <th>QRS</th>\n","      <th>PRQ</th>\n","      <th>QT</th>\n","      <th>QTC</th>\n","      <th>ST</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>E1</td>\n","      <td>unhealthy</td>\n","      <td>1</td>\n","      <td>1.072</td>\n","      <td>0.932</td>\n","      <td>64.377682</td>\n","      <td>3.305</td>\n","      <td>3.81</td>\n","      <td>0.088</td>\n","      <td>0.16</td>\n","      <td>0.384</td>\n","      <td>0.397762</td>\n","      <td>0.296</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>E1</td>\n","      <td>unhealthy</td>\n","      <td>2</td>\n","      <td>2.004</td>\n","      <td>1.004</td>\n","      <td>59.760956</td>\n","      <td>3.285</td>\n","      <td>3.81</td>\n","      <td>0.1</td>\n","      <td>0.16</td>\n","      <td>0.64</td>\n","      <td>0.638724</td>\n","      <td>0.54</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>E1</td>\n","      <td>unhealthy</td>\n","      <td>3</td>\n","      <td>3.008</td>\n","      <td>0.996</td>\n","      <td>60.240964</td>\n","      <td>3.34</td>\n","      <td>3.83</td>\n","      <td>0.128</td>\n","      <td>0.148</td>\n","      <td>0.628</td>\n","      <td>0.62926</td>\n","      <td>0.5</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>E1</td>\n","      <td>unhealthy</td>\n","      <td>4</td>\n","      <td>4.004</td>\n","      <td>1.016</td>\n","      <td>59.055118</td>\n","      <td>3.325</td>\n","      <td>3.81</td>\n","      <td>0.108</td>\n","      <td>0.172</td>\n","      <td>0.388</td>\n","      <td>0.384933</td>\n","      <td>0.28</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>E1</td>\n","      <td>unhealthy</td>\n","      <td>5</td>\n","      <td>5.02</td>\n","      <td>0.972</td>\n","      <td>61.728395</td>\n","      <td>3.29</td>\n","      <td>3.765</td>\n","      <td>0.1</td>\n","      <td>0.16</td>\n","      <td>0.372</td>\n","      <td>0.37732</td>\n","      <td>0.272</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["0 Subject       Type Cycle   Time   RR-I         HR    R-H    P-H    QRS  \\\n","1      E1  unhealthy     1  1.072  0.932  64.377682  3.305   3.81  0.088   \n","2      E1  unhealthy     2  2.004  1.004  59.760956  3.285   3.81    0.1   \n","3      E1  unhealthy     3  3.008  0.996  60.240964   3.34   3.83  0.128   \n","4      E1  unhealthy     4  4.004  1.016  59.055118  3.325   3.81  0.108   \n","5      E1  unhealthy     5   5.02  0.972  61.728395   3.29  3.765    0.1   \n","\n","0    PRQ     QT       QTC     ST  \n","1   0.16  0.384  0.397762  0.296  \n","2   0.16   0.64  0.638724   0.54  \n","3  0.148  0.628   0.62926    0.5  \n","4  0.172  0.388  0.384933   0.28  \n","5   0.16  0.372   0.37732  0.272  "]},"metadata":{}}]},{"cell_type":"code","source":"data[\"Type\"].value_counts()","metadata":{},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":["unhealthy    763725\n","healthy      284849\n","Name: Type, dtype: int64"]},"metadata":{}}]},{"cell_type":"code","source":"# Assuming your DataFrame is named 'data'\nnull_count = data.isnull().sum()\n\n# Display the count of null values for each column\nprint(null_count)\n","metadata":{},"execution_count":14,"outputs":[{"name":"stdout","output_type":"stream","text":"0\n\nSubject    0\n\nType       0\n\nCycle      0\n\nTime       0\n\nRR-I       0\n\nHR         0\n\nR-H        0\n\nP-H        0\n\nQRS        0\n\nPRQ        0\n\nQT         0\n\nQTC        0\n\nST         0\n\ndtype: int64\n"}]},{"cell_type":"code","source":"total_null_count = null_count.sum()\nprint(f'Total number of null values: {total_null_count}')\n","metadata":{},"execution_count":15,"outputs":[{"name":"stdout","output_type":"stream","text":"Total number of null values: 0\n"}]},{"cell_type":"code","source":"!pip install -U imbalanced-learn\n","metadata":{},"execution_count":16,"outputs":[{"name":"stdout","output_type":"stream","text":"Requirement already satisfied: imbalanced-learn in e:\\conda\\lib\\site-packages (0.11.0)\n\nRequirement already satisfied: numpy>=1.17.3 in e:\\conda\\lib\\site-packages (from imbalanced-learn) (1.24.3)\n\nRequirement already satisfied: scipy>=1.5.0 in e:\\conda\\lib\\site-packages (from imbalanced-learn) (1.10.1)\n\nRequirement already satisfied: scikit-learn>=1.0.2 in e:\\conda\\lib\\site-packages (from imbalanced-learn) (1.3.0)\n\nRequirement already satisfied: joblib>=1.1.1 in e:\\conda\\lib\\site-packages (from imbalanced-learn) (1.2.0)\n\nRequirement already satisfied: threadpoolctl>=2.0.0 in e:\\conda\\lib\\site-packages (from imbalanced-learn) (2.2.0)\n"}]},{"cell_type":"code","source":"data= data.drop('Subject', axis=1)\ndata= data.drop('Cycle', axis=1)      #added by Rafsan\ndata= data.drop('Time', axis=1)      # added by Rafsan","metadata":{},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Type</th>\n","      <th>RR-I</th>\n","      <th>HR</th>\n","      <th>R-H</th>\n","      <th>P-H</th>\n","      <th>QRS</th>\n","      <th>PRQ</th>\n","      <th>QT</th>\n","      <th>QTC</th>\n","      <th>ST</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>unhealthy</td>\n","      <td>0.932</td>\n","      <td>64.377682</td>\n","      <td>3.305</td>\n","      <td>3.81</td>\n","      <td>0.088</td>\n","      <td>0.16</td>\n","      <td>0.384</td>\n","      <td>0.397762</td>\n","      <td>0.296</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>unhealthy</td>\n","      <td>1.004</td>\n","      <td>59.760956</td>\n","      <td>3.285</td>\n","      <td>3.81</td>\n","      <td>0.1</td>\n","      <td>0.16</td>\n","      <td>0.64</td>\n","      <td>0.638724</td>\n","      <td>0.54</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>unhealthy</td>\n","      <td>0.996</td>\n","      <td>60.240964</td>\n","      <td>3.34</td>\n","      <td>3.83</td>\n","      <td>0.128</td>\n","      <td>0.148</td>\n","      <td>0.628</td>\n","      <td>0.62926</td>\n","      <td>0.5</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>unhealthy</td>\n","      <td>1.016</td>\n","      <td>59.055118</td>\n","      <td>3.325</td>\n","      <td>3.81</td>\n","      <td>0.108</td>\n","      <td>0.172</td>\n","      <td>0.388</td>\n","      <td>0.384933</td>\n","      <td>0.28</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>unhealthy</td>\n","      <td>0.972</td>\n","      <td>61.728395</td>\n","      <td>3.29</td>\n","      <td>3.765</td>\n","      <td>0.1</td>\n","      <td>0.16</td>\n","      <td>0.372</td>\n","      <td>0.37732</td>\n","      <td>0.272</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["0       Type   RR-I         HR    R-H    P-H    QRS    PRQ     QT       QTC  \\\n","1  unhealthy  0.932  64.377682  3.305   3.81  0.088   0.16  0.384  0.397762   \n","2  unhealthy  1.004  59.760956  3.285   3.81    0.1   0.16   0.64  0.638724   \n","3  unhealthy  0.996  60.240964   3.34   3.83  0.128  0.148  0.628   0.62926   \n","4  unhealthy  1.016  59.055118  3.325   3.81  0.108  0.172  0.388  0.384933   \n","5  unhealthy  0.972  61.728395   3.29  3.765    0.1   0.16  0.372   0.37732   \n","\n","0     ST  \n","1  0.296  \n","2   0.54  \n","3    0.5  \n","4   0.28  \n","5  0.272  "]},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\n# Assuming your DataFrame is named 'data'\nlabel_encoder = LabelEncoder()\n\n# Apply label encoding to the 'Type' column\ndata['Type'] = label_encoder.fit_transform(data['Type'])\n","metadata":{},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"data.Type.value_counts()","metadata":{},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":["1    763725\n","0    284849\n","Name: Type, dtype: int64"]},"metadata":{}}]},{"cell_type":"code","source":"data.head()","metadata":{},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Type</th>\n","      <th>RR-I</th>\n","      <th>HR</th>\n","      <th>R-H</th>\n","      <th>P-H</th>\n","      <th>QRS</th>\n","      <th>PRQ</th>\n","      <th>QT</th>\n","      <th>QTC</th>\n","      <th>ST</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.932</td>\n","      <td>64.377682</td>\n","      <td>3.305</td>\n","      <td>3.81</td>\n","      <td>0.088</td>\n","      <td>0.16</td>\n","      <td>0.384</td>\n","      <td>0.397762</td>\n","      <td>0.296</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>1.004</td>\n","      <td>59.760956</td>\n","      <td>3.285</td>\n","      <td>3.81</td>\n","      <td>0.1</td>\n","      <td>0.16</td>\n","      <td>0.64</td>\n","      <td>0.638724</td>\n","      <td>0.54</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>0.996</td>\n","      <td>60.240964</td>\n","      <td>3.34</td>\n","      <td>3.83</td>\n","      <td>0.128</td>\n","      <td>0.148</td>\n","      <td>0.628</td>\n","      <td>0.62926</td>\n","      <td>0.5</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>1.016</td>\n","      <td>59.055118</td>\n","      <td>3.325</td>\n","      <td>3.81</td>\n","      <td>0.108</td>\n","      <td>0.172</td>\n","      <td>0.388</td>\n","      <td>0.384933</td>\n","      <td>0.28</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1</td>\n","      <td>0.972</td>\n","      <td>61.728395</td>\n","      <td>3.29</td>\n","      <td>3.765</td>\n","      <td>0.1</td>\n","      <td>0.16</td>\n","      <td>0.372</td>\n","      <td>0.37732</td>\n","      <td>0.272</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["0  Type   RR-I         HR    R-H    P-H    QRS    PRQ     QT       QTC     ST\n","1     1  0.932  64.377682  3.305   3.81  0.088   0.16  0.384  0.397762  0.296\n","2     1  1.004  59.760956  3.285   3.81    0.1   0.16   0.64  0.638724   0.54\n","3     1  0.996  60.240964   3.34   3.83  0.128  0.148  0.628   0.62926    0.5\n","4     1  1.016  59.055118  3.325   3.81  0.108  0.172  0.388  0.384933   0.28\n","5     1  0.972  61.728395   3.29  3.765    0.1   0.16  0.372   0.37732  0.272"]},"metadata":{}}]},{"cell_type":"code","source":"data.Type.value_counts()","metadata":{},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":["1    763725\n","0    284849\n","Name: Type, dtype: int64"]},"metadata":{}}]},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\nfrom sklearn.impute import SimpleImputer\nimport pandas as pd\n\n# Assuming your data is in a DataFrame named 'data'\nX = data.drop('Type', axis=1)\ny = data['Type']\n\n# Handle missing values (replace NaN with mean, median, or other strategies)\nimputer = SimpleImputer(strategy='mean')\nX_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n\n# Apply SMOTE to the entire dataset\nsmote = SMOTE(random_state=42)\nX_resampled, y_resampled = smote.fit_resample(X_imputed, y)\n\n# Create a new DataFrame with the resampled data\ndata = pd.DataFrame(X_resampled, columns=X_imputed.columns)\ndata['Type'] = y_resampled\n\n# Verify the class distribution after applying SMOTE\nprint(data['Type'].value_counts())\n","metadata":{},"execution_count":36,"outputs":[{"name":"stdout","output_type":"stream","text":"1    763725\n\n0    763725\n\nName: Type, dtype: int64\n"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.Type.value_counts()","metadata":{},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":["1    763725\n","0    763725\n","Name: Type, dtype: int64"]},"metadata":{}}]},{"cell_type":"markdown","source":"__________________________________________________________________________________________________________________________________________","metadata":{}},{"cell_type":"markdown","source":"# New Code Added","metadata":{}},{"cell_type":"code","source":"data.info()","metadata":{},"execution_count":41,"outputs":[{"name":"stdout","output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\n\nRangeIndex: 1527450 entries, 0 to 1527449\n\nData columns (total 10 columns):\n\n #   Column  Non-Null Count    Dtype  \n\n---  ------  --------------    -----  \n\n 0   RR-I    1527450 non-null  float64\n\n 1   HR      1527450 non-null  float64\n\n 2   R-H     1527450 non-null  float64\n\n 3   P-H     1527450 non-null  float64\n\n 4   QRS     1527450 non-null  float64\n\n 5   PRQ     1527450 non-null  float64\n\n 6   QT      1527450 non-null  float64\n\n 7   QTC     1527450 non-null  float64\n\n 8   ST      1527450 non-null  float64\n\n 9   Type    1527450 non-null  int32  \n\ndtypes: float64(9), int32(1)\n\nmemory usage: 110.7 MB\n"}]},{"cell_type":"code","source":"data= data.apply(pd.to_numeric, errors='coerce') #added by rafsan","metadata":{},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{},"execution_count":43,"outputs":[{"name":"stdout","output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\n\nRangeIndex: 1527450 entries, 0 to 1527449\n\nData columns (total 10 columns):\n\n #   Column  Non-Null Count    Dtype  \n\n---  ------  --------------    -----  \n\n 0   RR-I    1527450 non-null  float64\n\n 1   HR      1527450 non-null  float64\n\n 2   R-H     1527450 non-null  float64\n\n 3   P-H     1527450 non-null  float64\n\n 4   QRS     1527450 non-null  float64\n\n 5   PRQ     1527450 non-null  float64\n\n 6   QT      1527450 non-null  float64\n\n 7   QTC     1527450 non-null  float64\n\n 8   ST      1527450 non-null  float64\n\n 9   Type    1527450 non-null  int32  \n\ndtypes: float64(9), int32(1)\n\nmemory usage: 110.7 MB\n"}]},{"cell_type":"code","source":"X = data.loc[:,data.columns!='Type']\ny = data['Type']","metadata":{"execution":{"iopub.execute_input":"2024-01-01T06:14:51.811605Z","iopub.status.busy":"2024-01-01T06:14:51.810728Z","iopub.status.idle":"2024-01-01T06:14:51.841777Z","shell.execute_reply":"2024-01-01T06:14:51.840832Z","shell.execute_reply.started":"2024-01-01T06:14:51.811571Z"}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.execute_input":"2024-01-01T06:14:52.981892Z","iopub.status.busy":"2024-01-01T06:14:52.981396Z","iopub.status.idle":"2024-01-01T06:14:53.101602Z","shell.execute_reply":"2024-01-01T06:14:53.100501Z","shell.execute_reply.started":"2024-01-01T06:14:52.981858Z"}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"X_train = tf.convert_to_tensor(X_train.values.astype(np.float64))\nX_test = tf.convert_to_tensor(X_test.values.astype(np.float64))\ny_train = tf.convert_to_tensor(y_train.values.astype(np.float64))\ny_test = tf.convert_to_tensor(y_test.values.astype(np.float64))","metadata":{"execution":{"iopub.execute_input":"2024-01-01T06:14:54.245442Z","iopub.status.busy":"2024-01-01T06:14:54.245076Z","iopub.status.idle":"2024-01-01T06:14:54.380387Z","shell.execute_reply":"2024-01-01T06:14:54.379466Z","shell.execute_reply.started":"2024-01-01T06:14:54.245414Z"}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"X_train.shape, y_train.shape","metadata":{"execution":{"iopub.execute_input":"2024-01-01T06:14:57.179669Z","iopub.status.busy":"2024-01-01T06:14:57.178820Z","iopub.status.idle":"2024-01-01T06:14:57.185786Z","shell.execute_reply":"2024-01-01T06:14:57.184851Z","shell.execute_reply.started":"2024-01-01T06:14:57.179625Z"}},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":["(TensorShape([1221960, 9]), TensorShape([1221960]))"]},"metadata":{}}]},{"cell_type":"code","source":"data.Type.value_counts()","metadata":{},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":["1    763725\n","0    763725\n","Name: Type, dtype: int64"]},"metadata":{}}]},{"cell_type":"markdown","source":"### LSTM","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom keras.layers import Conv2D, Flatten, Dense\n# Define the LSTM model\nmodel = tf.keras.Sequential()\nmodel.add(tf.keras.layers.LSTM(64, input_shape=(X_train.shape[1], 1)))\n#model.add(Flatten())\nmodel.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n\n# Compile the model\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n# Train the model\n\nmodel.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.15)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom kerastuner.tuners import RandomSearch\nfrom kerastuner.engine.hyperparameters import HyperParameters\n\n# Define the model building function\ndef build_model(hp):\n    model = Sequential()\n    model.add(LSTM(units=hp.Int('units', min_value=16, max_value=64, step=16),\n                   input_shape=(X_train.shape[1], 1)))\n    model.add(Dropout(rate=0.2))  # Adjust the dropout rate as needed\n    model.add(Dense(1, activation='sigmoid', kernel_regularizer='l2'))  # Adjust regularization strength as needed\n\n    model.compile(\n        optimizer=Adam(learning_rate=hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n        loss='binary_crossentropy',\n        metrics=['accuracy']\n    )\n\n    return model\n\n# Instantiate the tuner\ntuner = RandomSearch(\n    build_model,\n    objective='val_accuracy',\n    max_trials=5,\n    directory='hyperparameter_tuning',\n    project_name='lstm_tuning'\n)\n\n# Perform the hyperparameter search\ntuner.search(X_train, y_train, epochs=50, batch_size=32, validation_split=0.15, callbacks=[EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)])\n\n# Get the best hyperparameters\nbest_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\nprint(f\"Best Hyperparameters: {best_hps}\")\n\n# Build and compile the model with the best hyperparameters\nbest_model = tuner.hypermodel.build(best_hps)\nbest_model.compile(\n    optimizer=Adam(learning_rate=best_hps.get('learning_rate')),\n    loss='binary_crossentropy',\n    metrics=['accuracy']\n)\n\n# Train the model with the best hyperparameters\nbest_model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.15)\n","metadata":{},"execution_count":49,"outputs":[{"name":"stdout","output_type":"stream","text":"Reloading Tuner from hyperparameter_tuning\\lstm_tuning\\tuner0.json\n\nBest Hyperparameters: <keras_tuner.src.engine.hyperparameters.hyperparameters.HyperParameters object at 0x000001B00DC3D310>\n\nEpoch 1/50\n\n64917/64917 [==============================] - 162s 2ms/step - loss: 0.2394 - accuracy: 0.9062 - val_loss: 0.1865 - val_accuracy: 0.9376\n\nEpoch 2/50\n\n64917/64917 [==============================] - 161s 2ms/step - loss: 0.1847 - accuracy: 0.9378 - val_loss: 0.1741 - val_accuracy: 0.9414\n\nEpoch 3/50\n\n64917/64917 [==============================] - 160s 2ms/step - loss: 0.1724 - accuracy: 0.9403 - val_loss: 0.1612 - val_accuracy: 0.9424\n\nEpoch 4/50\n\n64917/64917 [==============================] - 158s 2ms/step - loss: 0.1616 - accuracy: 0.9423 - val_loss: 0.1639 - val_accuracy: 0.9414\n\nEpoch 5/50\n\n64917/64917 [==============================] - 159s 2ms/step - loss: 0.1547 - accuracy: 0.9447 - val_loss: 0.1473 - val_accuracy: 0.9472\n\nEpoch 6/50\n\n64917/64917 [==============================] - 160s 2ms/step - loss: 0.1491 - accuracy: 0.9474 - val_loss: 0.1428 - val_accuracy: 0.9513\n\nEpoch 7/50\n\n64917/64917 [==============================] - 159s 2ms/step - loss: 0.1444 - accuracy: 0.9496 - val_loss: 0.1377 - val_accuracy: 0.9531\n\nEpoch 8/50\n\n64917/64917 [==============================] - 159s 2ms/step - loss: 0.1405 - accuracy: 0.9518 - val_loss: 0.1352 - val_accuracy: 0.9547\n\nEpoch 9/50\n\n64917/64917 [==============================] - 162s 2ms/step - loss: 0.1369 - accuracy: 0.9536 - val_loss: 0.1357 - val_accuracy: 0.9535\n\nEpoch 10/50\n\n64917/64917 [==============================] - 162s 2ms/step - loss: 0.1333 - accuracy: 0.9550 - val_loss: 0.1300 - val_accuracy: 0.9552\n\nEpoch 11/50\n\n64917/64917 [==============================] - 164s 3ms/step - loss: 0.1299 - accuracy: 0.9565 - val_loss: 0.1273 - val_accuracy: 0.9567\n\nEpoch 12/50\n\n64917/64917 [==============================] - 158s 2ms/step - loss: 0.1267 - accuracy: 0.9578 - val_loss: 0.1233 - val_accuracy: 0.9587\n\nEpoch 13/50\n\n64917/64917 [==============================] - 159s 2ms/step - loss: 0.1238 - accuracy: 0.9589 - val_loss: 0.1202 - val_accuracy: 0.9604\n\nEpoch 14/50\n\n64917/64917 [==============================] - 159s 2ms/step - loss: 0.1212 - accuracy: 0.9599 - val_loss: 0.1187 - val_accuracy: 0.9610\n\nEpoch 15/50\n\n64917/64917 [==============================] - 158s 2ms/step - loss: 0.1190 - accuracy: 0.9607 - val_loss: 0.1186 - val_accuracy: 0.9607\n\nEpoch 16/50\n\n64917/64917 [==============================] - 158s 2ms/step - loss: 0.1168 - accuracy: 0.9619 - val_loss: 0.1147 - val_accuracy: 0.9619\n\nEpoch 17/50\n\n64917/64917 [==============================] - 158s 2ms/step - loss: 0.1148 - accuracy: 0.9628 - val_loss: 0.1125 - val_accuracy: 0.9633\n\nEpoch 18/50\n\n64917/64917 [==============================] - 162s 2ms/step - loss: 0.1133 - accuracy: 0.9635 - val_loss: 0.1130 - val_accuracy: 0.9633\n\nEpoch 19/50\n\n64917/64917 [==============================] - 161s 2ms/step - loss: 0.1116 - accuracy: 0.9641 - val_loss: 0.1112 - val_accuracy: 0.9642\n\nEpoch 20/50\n\n64917/64917 [==============================] - 160s 2ms/step - loss: 0.1102 - accuracy: 0.9648 - val_loss: 0.1093 - val_accuracy: 0.9648\n\nEpoch 21/50\n\n64917/64917 [==============================] - 160s 2ms/step - loss: 0.1089 - accuracy: 0.9653 - val_loss: 0.1076 - val_accuracy: 0.9658\n\nEpoch 22/50\n\n64917/64917 [==============================] - 160s 2ms/step - loss: 0.1078 - accuracy: 0.9659 - val_loss: 0.1044 - val_accuracy: 0.9670\n\nEpoch 23/50\n\n64917/64917 [==============================] - 160s 2ms/step - loss: 0.1064 - accuracy: 0.9664 - val_loss: 0.1074 - val_accuracy: 0.9656\n\nEpoch 24/50\n\n64917/64917 [==============================] - 159s 2ms/step - loss: 0.1052 - accuracy: 0.9668 - val_loss: 0.1045 - val_accuracy: 0.9674\n\nEpoch 25/50\n\n64917/64917 [==============================] - 160s 2ms/step - loss: 0.1041 - accuracy: 0.9674 - val_loss: 0.1019 - val_accuracy: 0.9682\n\nEpoch 26/50\n\n64917/64917 [==============================] - 160s 2ms/step - loss: 0.1030 - accuracy: 0.9677 - val_loss: 0.1014 - val_accuracy: 0.9687\n\nEpoch 27/50\n\n64917/64917 [==============================] - 157s 2ms/step - loss: 0.1021 - accuracy: 0.9682 - val_loss: 0.1029 - val_accuracy: 0.9676\n\nEpoch 28/50\n\n64917/64917 [==============================] - 157s 2ms/step - loss: 0.1012 - accuracy: 0.9686 - val_loss: 0.0991 - val_accuracy: 0.9694\n\nEpoch 29/50\n\n64917/64917 [==============================] - 158s 2ms/step - loss: 0.1002 - accuracy: 0.9688 - val_loss: 0.0983 - val_accuracy: 0.9693\n\nEpoch 30/50\n\n64917/64917 [==============================] - 161s 2ms/step - loss: 0.0993 - accuracy: 0.9693 - val_loss: 0.0995 - val_accuracy: 0.9683\n\nEpoch 31/50\n\n64917/64917 [==============================] - 161s 2ms/step - loss: 0.0985 - accuracy: 0.9695 - val_loss: 0.0986 - val_accuracy: 0.9699\n\nEpoch 32/50\n\n64917/64917 [==============================] - 160s 2ms/step - loss: 0.0975 - accuracy: 0.9699 - val_loss: 0.1040 - val_accuracy: 0.9661\n\nEpoch 33/50\n\n64917/64917 [==============================] - 161s 2ms/step - loss: 0.0967 - accuracy: 0.9704 - val_loss: 0.0978 - val_accuracy: 0.9702\n\nEpoch 34/50\n\n64917/64917 [==============================] - 160s 2ms/step - loss: 0.0959 - accuracy: 0.9707 - val_loss: 0.0965 - val_accuracy: 0.9699\n\nEpoch 35/50\n\n64917/64917 [==============================] - 159s 2ms/step - loss: 0.0950 - accuracy: 0.9712 - val_loss: 0.0936 - val_accuracy: 0.9715\n\nEpoch 36/50\n\n64917/64917 [==============================] - 158s 2ms/step - loss: 0.0943 - accuracy: 0.9713 - val_loss: 0.0928 - val_accuracy: 0.9724\n\nEpoch 37/50\n\n64917/64917 [==============================] - 159s 2ms/step - loss: 0.0937 - accuracy: 0.9717 - val_loss: 0.0930 - val_accuracy: 0.9722\n\nEpoch 38/50\n\n64917/64917 [==============================] - 158s 2ms/step - loss: 0.0929 - accuracy: 0.9719 - val_loss: 0.0907 - val_accuracy: 0.9725\n\nEpoch 39/50\n\n64917/64917 [==============================] - 158s 2ms/step - loss: 0.0922 - accuracy: 0.9724 - val_loss: 0.0917 - val_accuracy: 0.9722\n\nEpoch 40/50\n\n64917/64917 [==============================] - 158s 2ms/step - loss: 0.0915 - accuracy: 0.9725 - val_loss: 0.0904 - val_accuracy: 0.9730\n\nEpoch 41/50\n\n64917/64917 [==============================] - 159s 2ms/step - loss: 0.0909 - accuracy: 0.9729 - val_loss: 0.0892 - val_accuracy: 0.9737\n\nEpoch 42/50\n\n64917/64917 [==============================] - 159s 2ms/step - loss: 0.0902 - accuracy: 0.9730 - val_loss: 0.0881 - val_accuracy: 0.9740\n\nEpoch 43/50\n\n64917/64917 [==============================] - 159s 2ms/step - loss: 0.0895 - accuracy: 0.9734 - val_loss: 0.0881 - val_accuracy: 0.9739\n\nEpoch 44/50\n\n64917/64917 [==============================] - 159s 2ms/step - loss: 0.0889 - accuracy: 0.9736 - val_loss: 0.0884 - val_accuracy: 0.9740\n\nEpoch 45/50\n\n64917/64917 [==============================] - 160s 2ms/step - loss: 0.0884 - accuracy: 0.9739 - val_loss: 0.0859 - val_accuracy: 0.9753\n\nEpoch 46/50\n\n64917/64917 [==============================] - 159s 2ms/step - loss: 0.0878 - accuracy: 0.9741 - val_loss: 0.0861 - val_accuracy: 0.9742\n\nEpoch 47/50\n\n64917/64917 [==============================] - 158s 2ms/step - loss: 0.0871 - accuracy: 0.9745 - val_loss: 0.0904 - val_accuracy: 0.9733\n\nEpoch 48/50\n\n64917/64917 [==============================] - 158s 2ms/step - loss: 0.0867 - accuracy: 0.9746 - val_loss: 0.0885 - val_accuracy: 0.9729\n\nEpoch 49/50\n\n64917/64917 [==============================] - 158s 2ms/step - loss: 0.0860 - accuracy: 0.9748 - val_loss: 0.0844 - val_accuracy: 0.9758\n\nEpoch 50/50\n\n64917/64917 [==============================] - 158s 2ms/step - loss: 0.0855 - accuracy: 0.9751 - val_loss: 0.0841 - val_accuracy: 0.9756\n"},{"execution_count":49,"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x1b002853ed0>"]},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# FL IMPLEMENTATION","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport random\nimport cv2\nimport os\nfrom tqdm import tqdm\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import accuracy_score\n\nimport tensorflow as tf\nfrom tensorflow import expand_dims\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, Input, Lambda\nfrom tensorflow.keras.layers import MaxPooling2D\nfrom tensorflow.keras.layers import Activation\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.optimizers import SGD\nfrom tensorflow.keras import backend as K","metadata":{},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"!pip install imutils\nfrom imutils import paths","metadata":{},"execution_count":74,"outputs":[{"name":"stdout","output_type":"stream","text":"Collecting imutils\n\n  Using cached imutils-0.5.4.tar.gz (17 kB)\n\n  Preparing metadata (setup.py): started\n\n  Preparing metadata (setup.py): finished with status 'done'\n\nBuilding wheels for collected packages: imutils\n\n  Building wheel for imutils (setup.py): started\n\n  Building wheel for imutils (setup.py): finished with status 'done'\n\n  Created wheel for imutils: filename=imutils-0.5.4-py3-none-any.whl size=25854 sha256=5e9f31716b56f55ce63233fe132fa134ad6d6a7896911b2032647fe1291f6cec\n\n  Stored in directory: c:\\users\\asus\\appdata\\local\\pip\\cache\\wheels\\31\\d0\\2c\\87ce38f6052879e5b7b18f0f8b4a10ad2a9d210e908d449f16\n\nSuccessfully built imutils\n\nInstalling collected packages: imutils\n\nSuccessfully installed imutils-0.5.4\n"}]},{"cell_type":"code","source":"debug = 0","metadata":{},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"def load(paths, verbose=-1):\n    '''expects images for each class in seperate dir, \n    e.g all digits in 0 class in the directory named 0 '''\n    data = list()\n    labels = list()\n    # loop over the input images\n    for (i, imgpath) in enumerate(paths):\n        # load the image and extract the class labels        \n        im_gray = cv2.imread(imgpath , cv2.IMREAD_GRAYSCALE)\n        image = np.array(im_gray).flatten() # cv2.imread(imgpath) \n        # print(image.shape)\n        label = imgpath.split(os.path.sep)[-2]\n        # scale the image to [0, 1] and add to list\n        data.append(image/255)\n        labels.append(label)\n        # show an update every `verbose` images\n        if verbose > 0 and i > 0 and (i + 1) % verbose == 0:\n            print(\"[INFO] processed {}/{}\".format(i + 1, len(paths)))\n    # return a tuple of the data and labels\n    \n    return data, labels\n\ndef create_clients(image_list, label_list, num_clients=100, initial='clients'):\n    ''' return: a dictionary with keys clients' names and value as \n                data shards - tuple of images and label lists.\n        args: \n            image_list: a list of numpy arrays of training images\n            label_list:a list of binarized labels for each image\n            num_client: number of fedrated members (clients)\n            initials: the clients'name prefix, e.g, clients_1 \n            \n    '''\n\n    #create a list of client names\n    client_names = ['{}_{}'.format(initial, i+1) for i in range(num_clients)]\n\n    #randomize the data\n    data = list(zip(image_list, label_list))\n    random.shuffle(data)  # <- IID\n    \n    # sort data for non-iid\n#     max_y = np.argmax(label_list, axis=-1)\n#     sorted_zip = sorted(zip(max_y, label_list, image_list), key=lambda x: x[0])\n#     data = [(x,y) for _,y,x in sorted_zip]\n\n    #shard data and place at each client\n    size = len(data)//num_clients\n    shards = [data[i:i + size] for i in range(0, size*num_clients, size)]\n\n    #number of clients must equal number of shards\n    assert(len(shards) == len(client_names))\n\n    return {client_names[i] : shards[i] for i in range(len(client_names))} \n\n\ndef batch_data(data_shard, bs=32):\n    '''Takes in a clients data shard and create a tfds object off it\n    args:\n        shard: a data, label constituting a client's data shard\n        bs:batch size\n    return:\n        tfds object'''\n    #seperate shard into data and labels lists\n    data, label = zip(*data_shard)\n    dataset = tf.data.Dataset.from_tensor_slices((list(data), list(label)))\n    return dataset.shuffle(len(label)).batch(bs)\n\n\ndef weight_scalling_factor(clients_trn_data, client_name):\n    client_names = list(clients_trn_data.keys())\n    #get the bs\n    bs = list(clients_trn_data[client_name])[0][0].shape[0]\n    #first calculate the total training data points across clinets\n    global_count = sum([tf.data.experimental.cardinality(clients_trn_data[client_name]).numpy() for client_name in client_names])*bs\n    # get the total number of data points held by a client\n    local_count = tf.data.experimental.cardinality(clients_trn_data[client_name]).numpy()*bs\n    \n    \n    if debug:\n        print('global_count', global_count, 'local_count', local_count, 'bs', bs)\n    \n    return local_count/global_count\n\n\ndef scale_model_weights(weight, scalar):\n    '''function for scaling a models weights'''\n    weight_final = []\n    steps = len(weight)\n    for i in range(steps):\n        weight_final.append(scalar * weight[i])\n    return weight_final\n\n\n\ndef sum_scaled_weights(scaled_weight_list):\n    '''Return the sum of the listed scaled weights. The is equivalent to scaled avg of the weights'''\n    avg_grad = list()\n    #get the average grad accross all client gradients\n    for grad_list_tuple in zip(*scaled_weight_list):\n        layer_mean = tf.math.reduce_sum(grad_list_tuple, axis=0)\n        avg_grad.append(layer_mean)\n        \n    return avg_grad\n\n\ndef test_model(X_test, Y_test,  model, comm_round):\n    cce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n    #logits = model.predict(X_test, batch_size=100)\n    logits = model.predict(X_test)\n    loss = cce(Y_test, logits)\n    acc = accuracy_score(tf.argmax(logits, axis=1), tf.argmax(Y_test, axis=1))\n    print('comm_round: {} | global_acc: {:.3%} | global_loss: {}'.format(comm_round, acc, loss))\n    return acc, loss\n","metadata":{},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"class SimpleMLP:\n    @staticmethod\n    def build(shape, classes):\n        model = Sequential()\n        model.add(Dense(200, input_shape=(shape,)))\n        model.add(Activation(\"relu\"))\n        model.add(Dense(200))\n        model.add(Activation(\"relu\"))\n        model.add(Dense(classes))\n        model.add(Activation(\"softmax\"))\n        return model\n    \n#     def build(shape, classes):\n#         model = Sequential()\n#         model.add(Input(shape=(shape[0], shape[1], shape[2])))\n#         #model.add(Lambda(lambda x: expand_dims(x, axis=-1)))\n#         model.add(Conv2D(filters=64, kernel_size=3, padding=\"same\"))\n#         model.add(Activation(\"relu\"))\n#         model.add(Conv2D(filters=64, kernel_size=3, padding=\"same\"))\n#         model.add(Activation(\"relu\"))\n#         model.add(MaxPooling2D())\n#         model.add(Conv2D(filters=128, kernel_size=3, padding=\"same\"))\n#         model.add(Activation(\"relu\"))\n#         model.add(Conv2D(filters=128, kernel_size=3, padding=\"same\"))\n#         model.add(Activation(\"relu\"))\n#         model.add(MaxPooling2D())\n#         model.add(Activation(\"relu\"))\n#         model.add(Conv2D(filters=256, kernel_size=3, padding=\"same\"))\n#         model.add(Activation(\"relu\"))\n#         model.add(Conv2D(filters=256, kernel_size=3, padding=\"same\"))\n#         model.add(Activation(\"relu\"))\n#         model.add(MaxPooling2D())\n#         model.add(Activation(\"relu\"))\n#         model.add(Conv2D(filters=512, kernel_size=3, padding=\"same\"))\n#         model.add(Activation(\"relu\"))\n#         model.add(Conv2D(filters=512, kernel_size=3, padding=\"same\"))\n#         model.add(Activation(\"relu\"))\n#         model.add(MaxPooling2D())\n#         model.add(Flatten())\n#         model.add(Dense(32))\n#         model.add(Dense(classes))\n#         model.add(Activation(\"softmax\"))\n#         return model","metadata":{},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"len(X_train), len(X_test), len(y_train), len(y_test)","metadata":{},"execution_count":78,"outputs":[{"execution_count":78,"output_type":"execute_result","data":{"text/plain":["(1221960, 305490, 1221960, 305490)"]},"metadata":{}}]},{"cell_type":"code","source":"clients = create_clients(X_train, y_train, num_clients=100, initial='client')","metadata":{},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"#process and batch the training data for each client\nclients_batched = dict()\nfor (client_name, data) in clients.items():\n    clients_batched[client_name] = batch_data(data)\n    \n#process and batch the test set  \ntest_batched = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(len(y_test))","metadata":{},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.optimizers import SGD\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay\n\ninitial_lr = 0.01\ncomms_round = 300\ndecay_factor = 0.95  # Adjust as needed\n\nlr_schedule = ExponentialDecay(initial_lr, decay_steps=comms_round, decay_rate=decay_factor, staircase=True)\n\noptimizer = SGD(learning_rate=lr_schedule, momentum=0.9, nesterov=True)\n","metadata":{},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"#initialize global model\n\nbuild_shape = 784 #(28, 28, 3)  # 1024 <- CIFAR-10    # 784 # for MNIST\n\nsmlp_global = SimpleMLP()\nglobal_model = smlp_global.build(build_shape, 10) \nglobal_acc_list = []\nglobal_loss_list = []","metadata":{},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"#commence global training loop\nfor comm_round in range(comms_round):\n            \n    # get the global model's weights - will serve as the initial weights for all local models\n    global_weights = global_model.get_weights()\n    \n    #initial list to collect local model weights after scalling\n    scaled_local_weight_list = list()\n\n    #randomize client data - using keys\n    all_client_names = list(clients_batched.keys())\n           \n    client_names = random.sample(all_client_names, k=10)\n    # print(client_names, len(client_names))\n    random.shuffle(client_names)\n    \n#     if debug: \n#         # print('all_client_names', all_client_names)\n#         print('client_names', client_names, len(client_names))\n                \n    \n    #loop through each client and create new local model\n    for client in client_names:\n        smlp_local = SimpleMLP()\n        local_model = smlp_local.build(build_shape, 10)\n        local_model.compile(loss=loss, \n                      optimizer=optimizer, \n                      metrics=metrics)\n        \n        #set local model weight to the weight of the global model\n        local_model.set_weights(global_weights)\n        \n        #fit local model with client's data\n        local_model.fit(clients_batched[client], epochs=1, verbose=0)\n        \n        #scale the model weights and add to list\n        scaling_factor = 0.1 # weight_scalling_factor(clients_batched, client)\n        # print('scaling_factor', scaling_factor)\n        scaled_weights = scale_model_weights(local_model.get_weights(), scaling_factor)\n        scaled_local_weight_list.append(scaled_weights)\n        \n        #clear session to free memory after each communication round\n        K.clear_session()\n        \n    #to get the average over all the local model, we simply take the sum of the scaled weights\n    average_weights = sum_scaled_weights(scaled_local_weight_list)\n    \n    #update global model \n    global_model.set_weights(average_weights)\n\n    #test global model and print out metrics after each communications round\n    for(X_test, Y_test) in test_batched:\n        global_acc, global_loss = test_model(X_test, Y_test, global_model, comm_round)\n        global_acc_list.append(global_acc)\n        global_loss_list.append(global_loss)","metadata":{},"execution_count":87,"outputs":[{"ename":"ValueError","evalue":"in user code:\n\n    File \"E:\\Conda\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"E:\\Conda\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"E:\\Conda\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"E:\\Conda\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1080, in train_step\n        y_pred = self(x, training=True)\n    File \"E:\\Conda\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"E:\\Conda\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_9\" is incompatible with the layer: expected shape=(None, 784), found shape=(None, 9, 1)\n","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[87], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m local_model\u001b[38;5;241m.\u001b[39mset_weights(global_weights)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m#fit local model with client's data\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m \u001b[43mlocal_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclients_batched\u001b[49m\u001b[43m[\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m#scale the model weights and add to list\u001b[39;00m\n\u001b[0;32m     37\u001b[0m scaling_factor \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m \u001b[38;5;66;03m# weight_scalling_factor(clients_batched, client)\u001b[39;00m\n","File \u001b[1;32mE:\\Conda\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filebkobkonr.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n","\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"E:\\Conda\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"E:\\Conda\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"E:\\Conda\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"E:\\Conda\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1080, in train_step\n        y_pred = self(x, training=True)\n    File \"E:\\Conda\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"E:\\Conda\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_9\" is incompatible with the layer: expected shape=(None, 784), found shape=(None, 9, 1)\n"]}]},{"cell_type":"code","source":"def create_clients(image_list, label_list, num_clients=100, initial='clients'):\n    ''' return: a dictionary with keys clients' names and value as \n                data shards - tuple of images and label lists.\n        args: \n            image_list: a list of numpy arrays of training images\n            label_list:a list of binarized labels for each image\n            num_client: number of fedrated members (clients)\n            initials: the clients'name prefix, e.g, clients_1 \n            \n    '''\n\n    #create a list of client names\n    client_names = ['{}_{}'.format(initial, i+1) for i in range(num_clients)]\n\n    #randomize the data\n    # data = list(zip(image_list, label_list))\n    # random.shuffle(data)  # <- IID\n    \n    # sort data for non-iid\n    max_y = np.argmax(label_list, axis=-1)\n    sorted_zip = sorted(zip(max_y, label_list, image_list), key=lambda x: x[0])\n    data = [(x,y) for _,y,x in sorted_zip]\n\n    #shard data and place at each client\n    size = len(data)//num_clients\n    shards = [data[i:i + size] for i in range(0, size*num_clients, size)]\n\n    #number of clients must equal number of shards\n    assert(len(shards) == len(client_names))\n\n    return {client_names[i] : shards[i] for i in range(len(client_names))} ","metadata":{},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clients = create_clients(X_train, y_train, num_clients=100, initial='client')","metadata":{},"execution_count":89,"outputs":[{"ename":"TypeError","evalue":"'numpy.int64' object is not iterable","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[89], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m clients \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_clients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_clients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclient\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n","Cell \u001b[1;32mIn[88], line 21\u001b[0m, in \u001b[0;36mcreate_clients\u001b[1;34m(image_list, label_list, num_clients, initial)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m#randomize the data\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# data = list(zip(image_list, label_list))\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# random.shuffle(data)  # <- IID\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# sort data for non-iid\u001b[39;00m\n\u001b[0;32m     20\u001b[0m max_y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(label_list, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 21\u001b[0m sorted_zip \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmax_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_list\u001b[49m\u001b[43m)\u001b[49m, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     22\u001b[0m data \u001b[38;5;241m=\u001b[39m [(x,y) \u001b[38;5;28;01mfor\u001b[39;00m _,y,x \u001b[38;5;129;01min\u001b[39;00m sorted_zip]\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m#shard data and place at each client\u001b[39;00m\n","\u001b[1;31mTypeError\u001b[0m: 'numpy.int64' object is not iterable"]}]},{"cell_type":"code","source":"#process and batch the training data for each client\nclients_batched = dict()\nfor (client_name, data) in clients.items():\n    clients_batched[client_name] = batch_data(data)\n    \n#process and batch the test set  \ntest_batched = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(len(y_test))","metadata":{},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"lr = 0.01 \ncomms_round = 300\nloss='categorical_crossentropy'\nmetrics = ['accuracy']\noptimizer = SGD(lr=lr, \n                decay=lr / comms_round, \n                momentum=0.9\n               )          ","metadata":{},"execution_count":91,"outputs":[{"name":"stderr","output_type":"stream","text":"WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"},{"ename":"ValueError","evalue":"decay is deprecated in the new Keras optimizer, please check the docstring for valid arguments, or use the legacy optimizer, e.g., tf.keras.optimizers.legacy.SGD.","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[91], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      4\u001b[0m metrics \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 5\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mSGD\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                \u001b[49m\u001b[43mdecay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcomms_round\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\n\u001b[0;32m      8\u001b[0m \u001b[43m               \u001b[49m\u001b[43m)\u001b[49m          \n","File \u001b[1;32mE:\\Conda\\Lib\\site-packages\\keras\\src\\optimizers\\sgd.py:114\u001b[0m, in \u001b[0;36mSGD.__init__\u001b[1;34m(self, learning_rate, momentum, nesterov, weight_decay, clipnorm, clipvalue, global_clipnorm, use_ema, ema_momentum, ema_overwrite_frequency, jit_compile, name, **kwargs)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    100\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    113\u001b[0m ):\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclipnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclipnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclipvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclipvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mglobal_clipnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mglobal_clipnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_ema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_ema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mema_momentum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mema_momentum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mema_overwrite_frequency\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mema_overwrite_frequency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjit_compile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjit_compile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_learning_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_learning_rate(learning_rate)\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmomentum \u001b[38;5;241m=\u001b[39m momentum\n","File \u001b[1;32mE:\\Conda\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py:1094\u001b[0m, in \u001b[0;36mOptimizer.__init__\u001b[1;34m(self, name, weight_decay, clipnorm, clipvalue, global_clipnorm, use_ema, ema_momentum, ema_overwrite_frequency, jit_compile, **kwargs)\u001b[0m\n\u001b[0;32m   1092\u001b[0m mesh \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmesh\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   1093\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mesh \u001b[38;5;241m=\u001b[39m mesh\n\u001b[1;32m-> 1094\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1095\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1096\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclipnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1098\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclipvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1099\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobal_clipnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1100\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_ema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mema_momentum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mema_overwrite_frequency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1103\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjit_compile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1104\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1105\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distribution_strategy \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mget_strategy()\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_with_dtensor \u001b[38;5;241m=\u001b[39m dtensor_utils\u001b[38;5;241m.\u001b[39mrunning_with_dtensor_strategy()\n","File \u001b[1;32mE:\\Conda\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py:106\u001b[0m, in \u001b[0;36m_BaseOptimizer.__init__\u001b[1;34m(self, name, weight_decay, clipnorm, clipvalue, global_clipnorm, use_ema, ema_momentum, ema_overwrite_frequency, jit_compile, **kwargs)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variables \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_iteration_variable()\n\u001b[1;32m--> 106\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mE:\\Conda\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py:135\u001b[0m, in \u001b[0;36m_BaseOptimizer._process_kwargs\u001b[1;34m(self, kwargs)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m legacy_kwargs:\n\u001b[1;32m--> 135\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    136\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is deprecated in the new Keras optimizer, please \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    137\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheck the docstring for valid arguments, or use the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    138\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlegacy optimizer, e.g., \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    139\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.keras.optimizers.legacy.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    140\u001b[0m         )\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    143\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a valid argument, kwargs should be empty \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    144\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m for `optimizer_experimental.Optimizer`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    145\u001b[0m         )\n","\u001b[1;31mValueError\u001b[0m: decay is deprecated in the new Keras optimizer, please check the docstring for valid arguments, or use the legacy optimizer, e.g., tf.keras.optimizers.legacy.SGD."]}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### RNN","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import SimpleRNN, Dense\n\nmodel = Sequential()\nmodel.add(SimpleRNN(50, input_shape=(X_train.shape[1],1)))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nmodel.summary()\n\n# Train the model (Assuming X_train and y_train are your training data)\nmodel.fit(X_train, y_train, epochs=5, batch_size=32)\n","metadata":{},"execution_count":50,"outputs":[{"name":"stdout","output_type":"stream","text":"Model: \"sequential_3\"\n\n_________________________________________________________________\n\n Layer (type)                Output Shape              Param #   \n\n=================================================================\n\n simple_rnn (SimpleRNN)      (None, 50)                2600      \n\n                                                                 \n\n dense_3 (Dense)             (None, 1)                 51        \n\n                                                                 \n\n=================================================================\n\nTotal params: 2651 (10.36 KB)\n\nTrainable params: 2651 (10.36 KB)\n\nNon-trainable params: 0 (0.00 Byte)\n\n_________________________________________________________________\n\nEpoch 1/5\n\n38187/38187 [==============================] - 51s 1ms/step - loss: 0.1195 - accuracy: 0.9549\n\nEpoch 2/5\n\n38187/38187 [==============================] - 49s 1ms/step - loss: 0.0772 - accuracy: 0.9724\n\nEpoch 3/5\n\n38187/38187 [==============================] - 49s 1ms/step - loss: 0.0673 - accuracy: 0.9766\n\nEpoch 4/5\n\n38187/38187 [==============================] - 52s 1ms/step - loss: 0.0624 - accuracy: 0.9784\n\nEpoch 5/5\n\n38187/38187 [==============================] - 49s 1ms/step - loss: 0.0592 - accuracy: 0.9797\n"},{"execution_count":50,"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x1b0877e5b90>"]},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### CNN from (previous notebook from shoaib)","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n\nmodel = Sequential()\nmodel.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\nmodel.add(MaxPooling1D(pool_size=2))\nmodel.add(Flatten())\nmodel.add(Dense(50, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1, activation='sigmoid'))\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nmodel.fit(X_train, y_train, epochs=2, batch_size=32, validation_split=0.2)\n","metadata":{},"execution_count":54,"outputs":[{"name":"stdout","output_type":"stream","text":"Epoch 1/2\n\n30549/30549 [==============================] - 30s 977us/step - loss: 0.2111 - accuracy: 0.9211 - val_loss: 0.1415 - val_accuracy: 0.9520\n\nEpoch 2/2\n\n30549/30549 [==============================] - 29s 940us/step - loss: 0.1583 - accuracy: 0.9476 - val_loss: 0.1313 - val_accuracy: 0.9561\n"},{"execution_count":54,"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x1b0885aab50>"]},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"________________________________________________________________________________________________________________________\n________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________\n________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
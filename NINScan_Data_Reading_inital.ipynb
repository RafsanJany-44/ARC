{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMEFgkxyRC75MYsIdC1cKfm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RafsanJany-44/ARC/blob/master/NINScan_Data_Reading_inital.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Copyright Gary Strangman & Massachusetts General Hospital 2022; All rights reserved.\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import print_function\n",
        "import os\n",
        "import sys\n",
        "import math\n",
        "import glob\n",
        "import time\n",
        "import string\n",
        "import struct\n",
        "#from types import list, int, str, tuple\n",
        "\n",
        "import numpy as np\n",
        "import pylab\n",
        "import scipy.io\n",
        "import scipy.stats\n",
        "import scipy.ndimage.interpolation\n",
        "import scipy.signal\n",
        "from six.moves import map\n",
        "from six.moves import range\n",
        "from six.moves import zip\n",
        "from six.moves import input\n",
        "\n",
        "try:\n",
        "    import tables\n",
        "except:\n",
        "    pass\n",
        "\n",
        "###\n",
        "### TO DO ...\n",
        "###\n",
        "### check history string outputs for accuracy\n",
        "### hdf5_AF\n",
        "###\n",
        "\n",
        "\n",
        "\"\"\"Optical functions ...\n",
        "\n",
        "### FILE I/O ###\n",
        "def loada(fname,header=True,headtype='dict'):\n",
        "def get_oh2a_channel(fname,rate=250.):\n",
        "def read_oh2a(fname,rate=250.):\n",
        "def read_oh2a8(fname,rate=250.):\n",
        "def zero_oh2a(d,zeros,rate=250.):\n",
        "def get_oh2a_maxima(fname):\n",
        "def get_oh2a_minima(fname):\n",
        "\n",
        "def read_homer_mat(fname):\n",
        "def read_homer_npz(fname):\n",
        "def read_cw5(fname):\n",
        "def read_cw5bin(fname):\n",
        "def read_cwa(fname):\n",
        "def read_hdf5(fname,mode='a'):\n",
        "def cw5_to_homer(prefix,verbose=1):\n",
        "def cw5_to_npz(prefix,geom=None,verbose=1):\n",
        "def cw5_to_hdf5(prefix,geom=None,verbose=1):\n",
        "def cw5_to_hdf5_noshuffle(prefix,geom=None,verbose=1):\n",
        "def homer_to_hdf5(fname,d,t,aux10,ml,gains,pSrc=None,pDet=None):\n",
        "def homermat_to_hdf5(inname,outname):\n",
        "def homernpz_to_hdf5(inname,outname):\n",
        "def hdf5_to_homer(hdf5struct):\n",
        "def hdf5_to_homerfile(hdf5struct):\n",
        "def read_nirs1(fname):\n",
        "def saveNIR(fname, *args):\n",
        "def saveNSPM(fname, *args):\n",
        "def read_cw5bin_chunk(fid,datatype):\n",
        "\n",
        "\n",
        "def findonset(a,val):\n",
        "def get_oh2a_mean_in_range(fname,xmin=0,xmax=None,rate=250):\n",
        "\n",
        "def hdf5_addgeom(h5, geomstruct):\n",
        "def hdf5_addvars(h5, *args):\n",
        "def hdf5_delete_nodes(h5,*args):\n",
        "def create_new_hdf5_file(hdf5,outname,overwrite=False):\n",
        "def printhist(h5):\n",
        "def addtohist(h5,txt):\n",
        "\n",
        "### HELPER FUNCTIONS\n",
        "def lowpass(d,flp,samplerate):\n",
        "def hipass(d,fhp,samplerate):\n",
        "def hipassND(d,fhp,samplerate):\n",
        "def AF(ref,y,H):\n",
        "def sdidx(ml,s=None,d=None,w=None):\n",
        "def findpeaks(d,samplerate,fhp,flp,posneg):\n",
        "def findpeaks_and_troughs(d,samplerate,fhp,flp):\n",
        "def find_closest(a,val,col=None):\n",
        "def find_closest_smaller(a,val,col=None):\n",
        "def getidx(src,det,ml):\n",
        "def addsuffix(inname,suffix):\n",
        "\n",
        "\n",
        "\n",
        "def regress(X,Y):\n",
        "\n",
        "\n",
        "### OPTICAL PRUNING/PROCESSING\n",
        "def hdf5_preprocess(hdf5,flp=3,fhp=1/100.,suffix='preproc',overwrite=False):\n",
        "def pruned_ml(pSrc,pDet,separations=[0,1000]):\n",
        "def hdf5_prune(hdf5,separations,intensities,SNRthresh,det2prune=[],suffix='prune',overwrite=False):\n",
        "def hdf5_filt(hdf5,fhp=0,regressSD=None,adapfilt=None,suffix='filt',overwrite=False):\n",
        "def hdf5_makeOD(hdf5,baseline=None, suffix='OD',overwrite=False):\n",
        "def hdf5_od2hbhbo_bls(hdf5, wavelengths, BLs, suffix='HB',overwrite=False):\n",
        "def hdf5_easyavg(hdf5,onsets,preseconds=-5,postseconds=25,suffix='avg',overwrite=False):\n",
        "def hdf5_snrs(h5):\n",
        "def hdf5_c1vsc2(h5,factor=1.0):\n",
        "def homer_preprocess(d,t,flp=3,fhp=1/60.):\n",
        "def homer_preprocess_mat(fname,flp=3,fhp=1/60.,suffix='-pp'):\n",
        "def homer_preprocess_npz(fname,flp=3,fhp=1/60.,suffix='-pp'):\n",
        "def homer_prune(data,ml,pSrc,pDet,separations,intensities,SNRthresh,det2prune=[]):\n",
        "def homer_filt(d,t,ml,fhp=0,regressSD=None,adapfilt=None):\n",
        "def ml_prune_by_dist(pSrc,pDet,separations,return_dist=False):\n",
        "def ml_to_channels(pSrc,pDet,ml):\n",
        "def homer_prune_mat(inname,pSrc,pDet,separations,intensities,SNRthresh,det2prune=[],suffix='-prune'):\n",
        "def homer_prune_npz(inname,pSrc,pDet,separations,intensities,SNRthresh,det2prune=[],suffix='-prune'):\n",
        "\n",
        "### OPTICAL SPECIFIC\n",
        "def makeOD(data,baseline=None):\n",
        "def homer_makeOD(data, baseline=None):\n",
        "def od2hbhbo_bls(data, wavelengths, BLs):\n",
        "def homer_od2hbhbo_bls(data, wavelengths, BLs):\n",
        "def nirs1_od2hbhbo_bls(data, wavelengths, BLs):\n",
        "def nirs1_raw2hbhbo_bls(data, baseline=None, wavelengths=[690,830], BLs=[18,18]):\n",
        "def homer_raw2hbhbo_file(fname, wavelengths=[830,690], BLs=[6,6], baseline=None, suffix='-hbhbo'):\n",
        "\n",
        "def homer_c1vsc2(d,factor=1.0):\n",
        "def homer_loginten(d):\n",
        "def homer_getsnrs(input):\n",
        "\n",
        "### CONSTANTS\n",
        "def getExtinctions(lambdas,molecule='hb'):\n",
        "def spm_hrf(TR,P=None,fMRI_T=16.):\n",
        "\n",
        "### PLOTTING ###\n",
        "def fillbetween(x1,x2,ymin=-100,ymax=100,facecolor='y',edgecolor='none'):\n",
        "def fillseveral(onsets,durations,ymin=-100,ymax=100,facecolor='y',edgecolor='none'):\n",
        "def parse_fillfile(fname):\n",
        "def plot(*args,**kw):\n",
        "def plotSD(src,det,d,ml,t=None):\n",
        "def raw_to_trio(d,t=None,wavelengths=[690,830],baseline=None,BLs=[18,18],title=None):\n",
        "def QCplots(pSrc,pDet,ml,d):\n",
        "def plotOverlapsColor(pSrc,pDet,ml,d,\n",
        "def plotCoverage(pSrc,pDet,ml,\n",
        "def plotSDpos(pSrc,pDet,outname=None,figsize=None):\n",
        "def plotChanpos(pChan,outname=None,figsize=None):\n",
        "def plotExtremaHist(d):\n",
        "def plotMeanHist(d):\n",
        "def linkedplots(pSrc,pDet,d,t,ml,cutoffs=None,colors=None,widths=None):\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "################## LOADING AND SAVING FUNCTIONS ####################\n",
        "\n",
        "def get (namepatterns,verbose=1):\n",
        "    \"\"\"\n",
        "Loads a list of lists from text files (specified by a UNIX-style\n",
        "wildcard filename pattern) and converts all numeric values to floats.\n",
        "Uses the glob module for filename pattern conversion.  Loaded filename\n",
        "is printed if verbose=1.\n",
        "\n",
        "Usage:   get (namepatterns,verbose=1)\n",
        "Returns: a 1D or 2D list of lists from whitespace delimited text files\n",
        "         specified by namepatterns; numbers that can be converted to floats\n",
        "         are so converted\n",
        "\"\"\"\n",
        "    fnames = []\n",
        "    if type(namepatterns) in [list,tuple]:\n",
        "        for item in namepatterns:\n",
        "            fnames = fnames + glob.glob(item)\n",
        "    else:\n",
        "        fnames = glob.glob(namepatterns)\n",
        "\n",
        "    if len(fnames) == 0:\n",
        "        if verbose:\n",
        "            print('NO FILENAMES MATCH ('+namepatterns+') !!')\n",
        "        return None\n",
        "\n",
        "    if verbose:\n",
        "        print(fnames)             # so user knows what has been loaded\n",
        "    elements = []\n",
        "    for i in range(len(fnames)):\n",
        "        file = open(fnames[i])\n",
        "        newelements = list(map(string.split,file.readlines()))\n",
        "        for i in range(len(newelements)):\n",
        "            for j in range(len(newelements[i])):\n",
        "                try:\n",
        "                    newelements[i][j] = string.atoi(newelements[i][j])\n",
        "                except ValueError:\n",
        "                    try:\n",
        "                        newelements[i][j] = string.atof(newelements[i][j])\n",
        "                    except:\n",
        "                        pass\n",
        "        elements = elements + newelements\n",
        "    if len(elements)==1:  elements = elements[0]\n",
        "    return elements\n",
        "\n",
        "\n",
        "def loada(fname,header=True,headtype='dict'):\n",
        "    \"\"\"\n",
        "Read a text file into an array using numpy.loadtxt(), and also gets the\n",
        "column headers as a 'dict' or as a 'list'.\n",
        "\n",
        "Usage:   loada(fname,header=True,headtype='dict')\n",
        "Returns: d, h\n",
        "\"\"\"\n",
        "    d = np.loadtxt(fname)\n",
        "    h = None\n",
        "    if header:\n",
        "        f = open(fname)\n",
        "        h = f.readline()\n",
        "        f.close()\n",
        "        if h[0]=='#':\n",
        "            h = string.split(h[1:])\n",
        "            if headtype=='dict':\n",
        "                h = dict(zip(h,list(range(len(h)))))\n",
        "    if h not in [None,0,False]:\n",
        "        return d,h\n",
        "    else:\n",
        "        return d\n",
        "\n",
        "\n",
        "def get_oh2a_channel(fname,rate=250.):\n",
        "    \"\"\"\n",
        "Read raw data from a single channel file of OH2a data.\n",
        "\n",
        "d,t = get_oh2a_channel(fname,rate=250.)\n",
        "\"\"\"\n",
        "    d = np.fromfile(fname,np.int16)\n",
        "    t = np.arange(len(d))/float(rate)\n",
        "    return d,t\n",
        "\n",
        "\n",
        "def read_oh2a(fname,rate=250.):\n",
        "    \"\"\"\n",
        "Read raw data from six different channel files of OH2a data.\n",
        "\n",
        "d,t = get_oh2a_channel(fname,rate=250.)  . d = 1k1,8k1,1k2,8k2,ecg,rsp\n",
        "\"\"\"\n",
        "    suffixes   = ['.1k1','.8k1','.1k2','.8k2','.ecg','.rsp']\n",
        "    d = []\n",
        "    for suffix in suffixes:\n",
        "        chd, t = get_oh2a_channel(fname+suffix,rate)\n",
        "        d.append(chd)\n",
        "        print(fname+suffix,chd.shape, t.shape, len(d))\n",
        "    d = np.array(d).T\n",
        "    return d,t\n",
        "\n",
        "\n",
        "def read_oh2a8(fname,rate=250.):\n",
        "    \"\"\"\n",
        "Read raw data from all 8 channel files of an OH2a 8-channel dataset.\n",
        "\n",
        "d,t = get_oh2a_channel(fname,rate=250.)   d = 1k1,8k1,1k2,8k2,ecg,rsp,aux1,aux2\n",
        "\"\"\"\n",
        "    suffixes   = ['.1k1','.8k1','.1k2','.8k2','.ecg','.rsp','.ax1','.ax2']\n",
        "    d = []\n",
        "    for suffix in suffixes:\n",
        "        chd, t = get_oh2a_channel(fname+suffix,rate)\n",
        "        d.append(chd)\n",
        "        print(fname+suffix,chd.shape, t.shape, len(d))\n",
        "    d = np.array(d).T\n",
        "    return d,t\n",
        "\n",
        "\n",
        "def zero_oh2a(d,zeros,rate=250.):\n",
        "    \"\"\"\n",
        "Fix data in d given either zeros values (one per column in d),\n",
        "or a oh2a zeros filename (from which it extracts the maximum values\n",
        "as the zeros offsets)..\n",
        "\n",
        "Usage:   zero_oh2a(d,zeros,rate=250.)\n",
        "Returns: zeros minus d\n",
        "\"\"\"\n",
        "    if type(zeros)==str:\n",
        "        zd,t = read_oh2a(zeros,rate)\n",
        "        zero_vals = np.max(zd,0)\n",
        "    else:\n",
        "        zero_vals = np.asarray(zeros)\n",
        "    return zero_vals - d\n",
        "\n",
        "\n",
        "def get_oh2a_maxima(fname):\n",
        "    \"\"\"\n",
        "Usage:   get_oh2a_zeros(fname)\n",
        "Returns: zeros for each column\n",
        "\"\"\"\n",
        "    zd,t = read_oh2a(fname)\n",
        "    zero_vals = np.max(zd,0)\n",
        "    return zero_vals\n",
        "\n",
        "\n",
        "def get_oh2a_minima(fname):\n",
        "    \"\"\"\n",
        "Usage:   get_oh2a_zeros(fname)\n",
        "Returns: zeros for each column\n",
        "\"\"\"\n",
        "    zd,t = read_oh2a(fname)\n",
        "    zero_vals = np.max(zd,0)\n",
        "    return zero_vals\n",
        "\n",
        "\n",
        "def read_oh4a_event(prefix):\n",
        "    f = open(prefix+'.event.txt')\n",
        "    d = f.readlines()\n",
        "    f.close()\n",
        "    d = list(map(string.split,d))\n",
        "    e1 = []\n",
        "    e2 = []\n",
        "    for row in d:\n",
        "        if row[-1]=='EVENT1':\n",
        "            e1.append(string.atoi(row[-3][1:]))\n",
        "        elif row[-1]=='EVENT2':\n",
        "            e2.append(string.atoi(row[-3][1:]))\n",
        "    return e1,e2\n",
        "\n",
        "\n",
        "def read_oh4a8(fname,rate=250,downsample=1,\n",
        "               LPFopt=0,HPFopt=0,LPFecg=0,LPFaux=0,\n",
        "               crop_start=0,crop_end=100000,verbose=1):\n",
        "    \"\"\"\n",
        "Read raw data from all 8 channel files of a NINscan 8-channel dataset.\n",
        "\n",
        "d,t = get_oh2a_channel(fname,\n",
        "                       rate=250,downsample=1,\n",
        "                       LPFopt=0,HPFopt=0,LPFecg=0,LPFaux=0,\n",
        "                       crop_start=crop_start,crop_end=crop_end):\n",
        "       d = 1k1,8k1,1k2,8k2,ecg,aux1,aux2,aux3\n",
        "\"\"\"\n",
        "    suffixes   = ['.1k1','.8k1','.1k2','.8k2','.ecg','.amx','.amy','.amz']\n",
        "    d = []\n",
        "    for suffix in suffixes:\n",
        "        chd, t, rawt = get_oh4a_channel(fname+suffix,rate,downsample,LPFopt,HPFopt,LPFecg,LPFaux,crop_start,crop_end,verbose)\n",
        "        d.append(np.ravel(chd))\n",
        "        if verbose:\n",
        "            print(fname+suffix,chd.shape, t.shape, len(d))\n",
        "    d = np.array(d).T\n",
        "    return d,t,rawt\n",
        "\n",
        "\n",
        "def get_oh4a_channel(fname,\n",
        "                     rawrate=250,downsample=1,\n",
        "                     LPFopt=0,HPFopt=0,LPFecg=0,LPFaux=0,\n",
        "                     crop_start=0,crop_end=100000,verbose=1):\n",
        "    \"\"\"\n",
        "Read raw data from a single channel file of NINscan data.\n",
        "\n",
        "d,t = get_oh2a_channel(fname,\n",
        "                       rawrate=250,downsample=1,\n",
        "                       LPFopt=0,LPFecg=0,LPFaux=0,\n",
        "                       crop_start=crop_start,crop_end=crop_end,verbose=1):\n",
        "\"\"\"\n",
        "    d = np.fromfile(fname,np.int16)\n",
        "    rawt = np.arange(len(d))/float(rawrate)\n",
        "    # LPF, if requested\n",
        "    if 'k' in fname[-3:] and HPFopt:\n",
        "        if verbose:\n",
        "            print(\"hipass filtering OPT\")\n",
        "        mn = np.mean(d)\n",
        "        d = hipass(d,HPFopt,rawrate)\n",
        "        d = d +mn  # add mean value back in\n",
        "    if 'k' in fname[-3:] and LPFopt:\n",
        "        if verbose:\n",
        "            print(\"lowpass filtering OPT\")\n",
        "        d = lowpass(d,LPFopt,rawrate)\n",
        "    if 'ecg' in fname[-3:] and LPFecg:\n",
        "        if verbose:\n",
        "            print(\"filtering ECG\")\n",
        "        d = lowpass(d,LPFecg,rawrate)\n",
        "    if 'am' in fname[-3:] and LPFaux:\n",
        "        if verbose:\n",
        "            print(\"filtering AUX\")\n",
        "        d = lowpass(d,LPFaux,rawrate)\n",
        "    # downsample\n",
        "    t = rawt[::downsample]\n",
        "    d = d[::downsample]\n",
        "    # crop it, if needed\n",
        "    startd = int(crop_start*rawrate/float(downsample))\n",
        "    endd = int(crop_end*rawrate/float(downsample))\n",
        "    d = d[startd:endd]\n",
        "    t = t[startd:endd]\n",
        "    return d,t,rawt\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def findonset(a,val):\n",
        "    \"\"\"\n",
        "Returns index of first value of a sorted list greater than or equal to val\n",
        "\n",
        "Usage:   findonset(a,val)\n",
        "\"\"\"\n",
        "    tmp = a>=val\n",
        "    return tmp.nonzero()[0][0]\n",
        "\n",
        "\n",
        "def get_oh2a_mean_in_range(fname,xmin=0,xmax=None,rate=250):\n",
        "    \"\"\"\n",
        "Usage:   get_oh2a_mean_in_range(fname,xmin=0,xmax=None,rate=250)\n",
        "Returns: zeros for each column\n",
        "\"\"\"\n",
        "    zd,t = read_oh2a(fname)\n",
        "    minidx = findonset(t,xmin)\n",
        "    if xmax is None:\n",
        "        xmax = t[-1]+1\n",
        "    maxidx = findonset(t,xmax)\n",
        "    vals = np.mean(zd[minidx:maxidx,:],0)\n",
        "    return vals\n",
        "\n",
        "\n",
        "def read_homer_mat(fname):\n",
        "    \"\"\"\n",
        "Loads homerized .MAT file (crashes if it doesn't have all variables)\n",
        "\n",
        "Usage:   read_homer_mat(fname)\n",
        "Returns: d,t,aux10,ml,gains\n",
        "\"\"\"\n",
        "    cwd = os.getcwd()\n",
        "    if cwd not in sys.path:\n",
        "        sys.path = [os.getcwd()]+sys.path\n",
        "    x = scipy.io.loadmat(fname)\n",
        "    d = x['d']\n",
        "    t = x['t']\n",
        "    aux10 = x['aux10']\n",
        "    ml = x['ml']\n",
        "    gains = x['gains']\n",
        "    return d,t,aux10,ml,gains\n",
        "\n",
        "\n",
        "def read_homer_npz(fname):\n",
        "    \"\"\"\n",
        "Loads homerized .npz file.\n",
        "\n",
        "Usage:   read_homer_npz(fname)\n",
        "Returns: d,t,ml,aux10,gains,rate,timestamp,lambdas\n",
        "\"\"\"\n",
        "    cwd = os.getcwd()\n",
        "    if cwd not in sys.path:\n",
        "        sys.path = [os.getcwd()]+sys.path\n",
        "    f = np.load(fname)\n",
        "    for item in f.files:\n",
        "        cmd = \"%s = f['%s']\" %(item,item)\n",
        "        exec(cmd)\n",
        "    return d,t,ml,aux10,gains,rate,timestamp,lambdas\n",
        "\n",
        "\n",
        "def read_cw5(fname):\n",
        "    \"\"\"\n",
        "Read in a .cw5 file. Doesn't parse /all/ header information, but a bunch of it. This\n",
        "function will tack on .cw5 to the filename if it is missing one.\n",
        "\n",
        "Usage:   read_cw5(fname)\n",
        "Returns: d,t,ml,gains,rate,timestamp,lambdas\n",
        "\"\"\"\n",
        "    # TACK ON .cw5 IF NEEDED\n",
        "    if fname[-4:] != '.cw5':\n",
        "        fname = fname + '.cw5'\n",
        "\n",
        "    try:\n",
        "        f = open(fname,'rb')\n",
        "    except:\n",
        "        raise ValueError(\"File not found: %s\" %fname)\n",
        "\n",
        "    # EXTRACT APPROPRIATE GAIN NUMBERS, DEPENDING ON WHICH BOARD WE'RE ON (others are 1s)\n",
        "    if '0A' in fname[-6:]:\n",
        "        gainpos = list(range(8))\n",
        "    elif '0B' in fname[-6:]:\n",
        "        gainpos = list(range(8,16))\n",
        "    elif '0C' in fname[-6:]:\n",
        "        gainpos = list(range(16,24))\n",
        "    elif '0D' in fname[-6:]:\n",
        "        gainpos = list(range(24,32))\n",
        "\n",
        "    # SCAN THROUGH HEADER INFORMATION, GRABBING PIECES AS WE GO\n",
        "    ml = []\n",
        "    gains = []\n",
        "    row = f.readline()\n",
        "    while 'BeginData' not in row:\n",
        "\n",
        "        # GRAB FIRST COLOR\n",
        "        if 'Lambda(1)' in row:\n",
        "            color1 = string.atoi(string.split(row)[-1])\n",
        "\n",
        "        # GRAB 2ND COLOR\n",
        "        if 'Lambda(2)' in row:\n",
        "            color2 = string.atoi(string.split(row)[-1])\n",
        "\n",
        "        # GRAB DATASET FILTERED RATE\n",
        "        if 'Sample Rate' in row:\n",
        "            idx = row.rfind('=')+1\n",
        "            idx2 = row.rfind(\"'\")\n",
        "            rate = string.atof(row[idx:idx2])\n",
        "\n",
        "        # GRAB DATASET START-TIME TIMESTAMP\n",
        "        if 'Timestamp' in row:\n",
        "            idx = row.rfind('=')+1\n",
        "            idx2 = row.rfind(\"'\")\n",
        "            timestamp = row[idx:idx2]\n",
        "\n",
        "        # GRAB AND MODIFY RAW MEASUREMENT LIST\n",
        "        if 'Meas(' in row:\n",
        "            idx = row.rfind('[')\n",
        "            idx2 = row.rfind(']')\n",
        "            nums = list(map(string.atoi,string.split(row[idx+1:idx2]))) # [src,det,lambda]\n",
        "            src = nums[0] #np.floor((nums[0]-1)/2)+1  # convert laser# to optode#\n",
        "            lmbda = ((nums[-1]-1)%2)+1\n",
        "            newnums = [src,nums[1],1,lmbda]  # HARDCODED 1 is for CW, I believe\n",
        "#            print nums,\"  -->  \",newnums\n",
        "            ml.append(newnums)\n",
        "\n",
        "        # GET GAINS\n",
        "        for i in gainpos:\n",
        "            if 'DetPos(%i)'%(i+1) in row:\n",
        "                idx = row.rfind('000')+4\n",
        "                idx2 = row.rfind(']')\n",
        "                gains.append(string.atoi(row[idx:idx2]))\n",
        "\n",
        "        # AND PREPARE FOR NEXT TIME THRU LOOP\n",
        "        row = f.readline()\n",
        "\n",
        "    # convert raw data to complex64\n",
        "    d = np.fromfile(f,np.complex64)\n",
        "\n",
        "    # reshape it to TIME x MEAS\n",
        "    d = np.reshape(d,(len(d)/len(ml),len(ml)))  # use matlab/Fortran order\n",
        "\n",
        "    # convert to complex conjugate to match the matlab readPMIData results\n",
        "    d = np.conjugate(d)\n",
        "\n",
        "    # create an appropriate t vector\n",
        "    t = np.arange(d.shape[0])/float(rate)\n",
        "\n",
        "    # convert ml from list to array\n",
        "    ml = np.array(ml)\n",
        "\n",
        "    # make lambdas an array\n",
        "    lambdas = np.array([color1,color2])\n",
        "\n",
        "    return d,t,ml,gains,rate,timestamp,lambdas\n",
        "\n",
        "\n",
        "def read_cw5bin(fname):\n",
        "    \"\"\"\n",
        "Read in a raw .bin file from CW5. Needed for the aux cards.\n",
        "\n",
        "Usage:   read_cw5bin(fname)\n",
        "Returns: data, header\n",
        "\"\"\"\n",
        "    f = open(fname,'rb')\n",
        "    data = None\n",
        "\n",
        "    while 1:\n",
        "        d,h = read_cw5bin_chunk(f,np.int16)\n",
        "        if len(d)>0:\n",
        "            if data==None:\n",
        "                data = d.copy()\n",
        "                hdr = h.copy()  # save first header (last is empty)\n",
        "            else:\n",
        "                data = np.concatenate((data,d),1)\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    print('Data in %s sampled at %d samples/sec/channel' %(fname,hdr['data_rate']))\n",
        "    print(\"Timestamp = \", hdr['timestamp'])\n",
        "\n",
        "    return np.transpose(data),hdr\n",
        "\n",
        "\n",
        "def read_cwa(fname):\n",
        "    \"\"\"\n",
        "Read in a .cwa file (auxiliary file).\n",
        "\n",
        "Usage:   read_cwa(fname)\n",
        "Returns: d,t\n",
        "\"\"\"\n",
        "    f = open(fname,'rb')\n",
        "    d = f.read()\n",
        "    d = struct.unpack(len(d)/2*'h',d)  # signed int16\n",
        "    f.close()\n",
        "    d = np.reshape(d,(len(d)/8,8))\n",
        "    t = np.arange(len(d))/100.159\n",
        "    return d,t\n",
        "\n",
        "\n",
        "def read_hdf5(fname,mode='a'):\n",
        "    \"\"\"\n",
        "Read in and returns an editable hdf5 file.\n",
        "\n",
        "Usage:   hdf5open(fname,mode='a')\n",
        "Returns: hdf5format\n",
        "\"\"\"\n",
        "    return tables.openFile(fname, mode=mode)\n",
        "\n",
        "\n",
        "def cw5_to_homer(prefix,verbose=1):\n",
        "    \"\"\"\n",
        "Looks for prefix??.cw5 files in current directory (0A, 0B ...),\n",
        "load them in, sticks them together, and sorts on wavelength so the\n",
        "first half of d is lambda1 and the second half is lambda2.\n",
        "\n",
        "Usage:   cw5_to_homer(prefix,verbose=1):\n",
        "Returns: d,t,ml,aux10,gains,rate,timestamp,lambdas\n",
        "\"\"\"\n",
        "    match = prefix+'??.cw5'\n",
        "    fnames = glob.glob(match)\n",
        "    if not len(fnames):\n",
        "        print(\"NO files matching:\",match)\n",
        "        return\n",
        "    fnames.sort()\n",
        "\n",
        "    e = None\n",
        "    for fname in fnames:\n",
        "        if verbose:\n",
        "            print(fname)\n",
        "\n",
        "        data,t,ml,gains,rate,timestamp,lambdas = read_cw5(fname)\n",
        "\n",
        "        if e is None: # first time thru, make a copy\n",
        "            e = data*1\n",
        "            m = ml*1\n",
        "            g = gains*1\n",
        "        else:         # after the first time, append\n",
        "            e = np.concatenate((e,data),1)\n",
        "            m = np.concatenate((m,ml),0)\n",
        "            g = np.concatenate((g,gains),0)\n",
        "\n",
        "    # sort according to wavelength\n",
        "    i1 = 0\n",
        "    i2 = 0\n",
        "    nd1 = []\n",
        "    nd2 = []\n",
        "    nml1 = []\n",
        "    nml2 = []\n",
        "    for i in range(len(m)):\n",
        "        if (m[i][0]%2)==1:  # ODD sources are 690s\n",
        "#            print 'ML1: %i  %i --> ' %(i,i1), m[i]\n",
        "            nd1.append(np.ravel(e[:,i]))\n",
        "            nml1.append(m[i].copy())\n",
        "            i1 += 1\n",
        "        else:               # EVEN sources are 830s\n",
        "#            print 'ML2: %i  %i --> ' %(i,i2), m[i]\n",
        "            nd2.append(np.ravel(e[:,i]))\n",
        "            nml2.append(m[i].copy())\n",
        "            i2 += 1\n",
        "\n",
        "    d = np.array(nd1+nd2)   # stick lambda1 and lambda2 together\n",
        "    d = np.transpose(d)     # get TIME x MEAS\n",
        "    ml = np.array(nml1+nml2)\n",
        "    gains = np.array(g)\n",
        "\n",
        "    # CONVERT LASER NUMBERS TO SOURCE NUMBERS\n",
        "    ml[:,0] = np.floor((ml[:,0]-1)/2.)+1\n",
        "\n",
        "    # TRY TO GET AUXILIARY DATA\n",
        "    fnames = glob.glob(prefix+'??.cwa')\n",
        "    if fnames:  # try to load in an existing .cwa file\n",
        "        aux10, t_aux10 = read_cwa(fnames[0])\n",
        "    else:\n",
        "        fnames = glob.glob(prefix+'_2A?????.bin')\n",
        "        if fnames:  # next try to get a .bin file\n",
        "            aux10, h_aux10 = read_cw5bin(fnames[0])\n",
        "            # @@@ may need to fatten pulses on stimchannel so downsampling doesn't miss any\n",
        "\n",
        "            # downsample aux10 variables\n",
        "            numpts = d.shape[0] #h_aux10['data_rate']/float(rate)\n",
        "            aux10 = scipy.signal.resample(aux10,numpts)\n",
        "            aux10 = aux10[:len(d)]\n",
        "\n",
        "    return abs(d),t,ml,aux10,gains,rate,timestamp,lambdas\n",
        "\n",
        "\n",
        "def cw5_to_npz(prefix,geom=None,verbose=1):\n",
        "    \"\"\"\n",
        "Looks for prefix??.cw5 files in current directory (0A, 0B ...),\n",
        "load them in, sticks them together, and sorts on wavelength so the\n",
        "first half of d is lambda1 and the second half is lambda2. Data is then\n",
        "saved using numpy.savez().\n",
        "\n",
        "Usage:   cw5_to_homer_npz(prefix,geom=None,verbose=1):\n",
        "Returns: d,t,ml,aux10,gains,rate,timestamp,lambdas\n",
        "\"\"\"\n",
        "    d,t,ml,aux10,gains,rate,timestamp,lambdas = cw5_to_homer(prefix)\n",
        "    if geom is not None:\n",
        "        np.savez(prefix,d=d,t=t,ml=ml,aux10=aux10,gains=gains,rate=rate,\n",
        "                        timestamp=timestamp,lambdas=lambdas)\n",
        "    else:\n",
        "        np.savez(prefix,d=d,t=t,ml=ml,aux10=aux10,gains=gains,rate=rate,\n",
        "                        timestamp=timestamp,lambdas=lambdas,\n",
        "                        pSrc=geom.pSrc,pDet=geom.pDet)\n",
        "    return d,t,ml,aux10,gains,rate,timestamp,lambdas\n",
        "\n",
        "\n",
        "def cw5_to_hdf5(prefix,geom=None,verbose=1):\n",
        "    \"\"\"\n",
        "Looks for prefix??.cw5 files in current directory (0A, 0B ...),\n",
        "load them in, sticks them together, and sorts on wavelength so the\n",
        "first half of d is lambda1 and the second half is lambda2.\n",
        "Can also add the geometry info at this stage (pass a structure\n",
        "with the pSrc and pDet variables defined).\n",
        "\n",
        "Usage:   cw5_to_hdf5(prefix,geom=None,verbose=1):\n",
        "Returns: hdf5 file handle\n",
        "\"\"\"\n",
        "    match = prefix+'??.cw5'\n",
        "    fnames = glob.glob(match)\n",
        "    if not len(fnames):\n",
        "        print(\"NO files matching:\",match)\n",
        "        return\n",
        "    fnames.sort()\n",
        "\n",
        "    e = None\n",
        "    for fname in fnames:\n",
        "        if verbose:\n",
        "            print(fname)\n",
        "\n",
        "        data,t,ml,gains,rate,timestamp,colors = read_cw5(fname)\n",
        "\n",
        "        if e is None: # first time thru, make a copy\n",
        "            e = data*1\n",
        "            m = ml*1\n",
        "            g = gains*1\n",
        "        else:         # after the first time, append\n",
        "            e = np.concatenate((e,data),1)\n",
        "            m = np.concatenate((m,ml),0)\n",
        "            g = np.concatenate((g,gains),0)\n",
        "\n",
        "    # sort according to wavelength\n",
        "    i1 = 0\n",
        "    i2 = 0\n",
        "    nd1 = []\n",
        "    nd2 = []\n",
        "    nml1 = []\n",
        "    nml2 = []\n",
        "    for i in range(len(m)):\n",
        "        if m[i][3]==1:  # lambda1\n",
        "            nd1.append(np.ravel(e[:,i]))\n",
        "            nml1.append(m[i])\n",
        "            i1 += 1\n",
        "        elif m[i][3]==2:  # lambda2\n",
        "            nd2.append(np.ravel(e[:,i]))\n",
        "            nml2.append(m[i])\n",
        "            i2 += 1\n",
        "        else:\n",
        "            raise ValueError(\"CW5 should only have wavelength 1 or 2\")\n",
        "\n",
        "    d = np.array(nd1+nd2)\n",
        "    d = np.transpose(d)\n",
        "    ml = np.array(nml1+nml2)\n",
        "    gains = np.array(g)\n",
        "\n",
        "    # CONVERT LASER NUMBERS TO SOURCE NUMBERS\n",
        "    ml[:,0] = np.floor((ml[:,0]-1)/2.)+1\n",
        "\n",
        "    # TRY TO GET AUXILIARY DATA\n",
        "    fnames = glob.glob(prefix+'??.cwa')\n",
        "    if fnames:  # try to load in an existing .cwa file\n",
        "        aux10, t_aux10 = read_cwa(fnames[0])\n",
        "    else:\n",
        "        fnames = glob.glob(prefix+'_2A?????.bin')\n",
        "        if fnames:  # next try to get a .bin file\n",
        "            aux10, h_aux10 = read_cw5bin(fnames[0])\n",
        "            # @@@ may need to fatten pulses on stimchannel so downsampling doesn't miss any\n",
        "\n",
        "            # downsample aux10 variables\n",
        "            numpts = d.shape[0] #h_aux10['data_rate']/float(rate)\n",
        "            aux10 = scipy.signal.resample(aux10,numpts)\n",
        "            aux10 = aux10[:len(d)]\n",
        "\n",
        "    # STUFF THE VARIABLES INTO AN HDF5 FILE\n",
        "    outname = prefix+'.h5'\n",
        "    h5 = tables.openFile(outname,mode='w')\n",
        "\n",
        "    h5.createArray(h5.root, 'd', d, 'Raw optical data (time X meas)')\n",
        "    h5.createArray(h5.root, 't', t, 'Optical data time base')\n",
        "    h5.createArray(h5.root, 'ml', ml, 'Measurement list (meas X 4)')\n",
        "    h5.createArray(h5.root, 'aux10', aux10, 'Auxiliary data (time X channel')\n",
        "    h5.createArray(h5.root, 'gains', gains, 'Detector gains')\n",
        "\n",
        "    # AND ADD THE EXTRA VARIABLES\n",
        "    thishist = \"CW5 datafile prefix: %s\\n\" %prefix\n",
        "    thishist +=  \"CW5 data timestamp:  %s\\n\" %timestamp\n",
        "    thishist += \"=========================================\\n\"\n",
        "    thishist += time.asctime()+\": cw5_to_hdf5('%s')\\n\"%prefix\n",
        "    h5 = hdf5_addvars(h5,{'original_timestamp':timestamp,\n",
        "                          'lambdas':colors,\n",
        "                          'history': thishist})\n",
        "    if geom is not None:\n",
        "        h5 = hdf5_addgeom(h5,geom)\n",
        "\n",
        "    return h5\n",
        "\n",
        "\n",
        "def cw5_to_hdf5_noshuffle(prefix,geom=None,verbose=1):\n",
        "    \"\"\"\n",
        "Looks for prefix??.cw5 files in current directory (0A, 0B ...),\n",
        "load them in, sticks them together, and sorts on wavelength so the\n",
        "first half of d is lambda1 and the second half is lambda2.\n",
        "Can also add the geometry info at this stage (pass a structure\n",
        "with the pSrc and pDet variables defined).\n",
        "\n",
        "Usage:   cw5_to_hdf5_noshuffle(prefix,geom=None,verbose=1):\n",
        "Returns: hdf5 file handle\n",
        "\"\"\"\n",
        "    match = prefix+'??.cw5'\n",
        "    fnames = glob.glob(match)\n",
        "    if not len(fnames):\n",
        "        print(\"NO files matching:\",match)\n",
        "        return\n",
        "    fnames.sort()\n",
        "\n",
        "    e = None\n",
        "    for fname in fnames:\n",
        "        if verbose:\n",
        "            print(fname)\n",
        "\n",
        "        data,t,ml,gains,rate,timestamp,colors = read_cw5(fname)\n",
        "\n",
        "        if e is None: # first time thru, make a copy\n",
        "            e = data*1\n",
        "            m = ml*1\n",
        "            g = gains*1\n",
        "        else:         # after the first time, append\n",
        "            e = np.concatenate((e,data),1)\n",
        "            m = np.concatenate((m,ml),0)\n",
        "            g = np.concatenate((g,gains),0)\n",
        "\n",
        "    ###\n",
        "    ### REMOVED SHUFFLING PROCESS FROM HERE!!!\n",
        "    ###\n",
        "\n",
        "    d = np.array(e)\n",
        "#    d = np.transpose(d)  # no need to transpose in noshuffle\n",
        "    ml = np.array(m)\n",
        "    gains = np.array(g)\n",
        "\n",
        "    # CONVERT LASER NUMBERS TO SOURCE NUMBERS\n",
        "    ml[:,0] = np.floor((ml[:,0]-1)/2.)+1\n",
        "\n",
        "    # TRY TO GET AUXILIARY DATA\n",
        "    fnames = glob.glob(prefix+'??.cwa')\n",
        "    if fnames:  # try to load in an existing .cwa file\n",
        "        aux10, t_aux10 = read_cwa(fnames[0])\n",
        "    else:\n",
        "        fnames = glob.glob(prefix+'_2A?????.bin')\n",
        "        if fnames:  # next try to get a .bin file\n",
        "            aux10, h_aux10 = read_cw5bin(fnames[0])\n",
        "            # @@@ may need to fatten pulses on stimchannel so downsampling doesn't miss any\n",
        "\n",
        "            # downsample aux10 variables\n",
        "            numpts = d.shape[0] #h_aux10['data_rate']/float(rate)\n",
        "            aux10 = scipy.signal.resample(aux10,numpts)\n",
        "            aux10 = aux10[:len(d)]\n",
        "\n",
        "    # STUFF THE VARIABLES INTO AN HDF5 FILE\n",
        "    outname = prefix+'_noshuf.h5'\n",
        "    h5 = tables.openFile(outname,mode='w')\n",
        "\n",
        "    h5.createArray(h5.root, 'd', d, 'Raw optical data (time X meas)')\n",
        "    h5.createArray(h5.root, 't', t, 'Optical data time base')\n",
        "    h5.createArray(h5.root, 'ml', ml, 'Measurement list (meas X 4)')\n",
        "    h5.createArray(h5.root, 'aux10', aux10, 'Auxiliary data (time X channel')\n",
        "    h5.createArray(h5.root, 'gains', gains, 'Detector gains')\n",
        "\n",
        "    # AND ADD THE EXTRA VARIABLES\n",
        "    thishist = \"CW5 datafile prefix: %s\\n\" %prefix\n",
        "    thishist +=  \"CW5 data timestamp:  %s\\n\" %timestamp\n",
        "    thishist += \"=========================================\\n\"\n",
        "    thishist += time.asctime()+\": cw5_to_hdf5('%s')\\n\"%prefix\n",
        "    h5 = hdf5_addvars(h5,{'original_timestamp':timestamp,\n",
        "                          'lambdas':colors,\n",
        "                          'history': thishist})\n",
        "    if geom is not None:\n",
        "        h5 = hdf5_addgeom(h5,geom)\n",
        "\n",
        "    return h5\n",
        "\n",
        "\n",
        "def homer_to_hdf5(fname,d,t,aux10,ml,gains,pSrc=None,pDet=None):\n",
        "    \"\"\"\n",
        "Usage:   homer_to_hdf5(fname,d,t,aux10,ml,gains,pSrc=None,pDet=None)\n",
        "Returns: an open, loaded hdf5 structure\n",
        "\"\"\"\n",
        "    h5file = tables.openFile(fname,mode='w')\n",
        "\n",
        "    h5file.createArray(h5file.root, 'd', d, 'Raw optical data (time X meas)')\n",
        "    h5file.createArray(h5file.root, 't', t, 'Optical data time base')\n",
        "    h5file.createArray(h5file.root, 'ml', ml, 'Measurement list (meas X 4)')\n",
        "    h5file.createArray(h5file.root, 'aux10', aux10, 'Auxiliary data (time X channel')\n",
        "    h5file.createArray(h5file.root, 'gains', gains, 'Detector gains')\n",
        "    if pSrc is not None:\n",
        "        h5file.createArray(h5file.root, 'pSrc', pSrc, 'Source positions (x,y,z)')\n",
        "    if pDet is not None:\n",
        "        h5file.createArray(h5file.root, 'pDet', pDet, 'Detector positions (x,y,z)')\n",
        "\n",
        "    thishist = \"Homer datafile: %s\\n\" %fname\n",
        "    thishist += \"=========================================\\n\"\n",
        "    thishist += time.asctime()+\": homer_to_hdf5('%s',...)\\n\"%fname\n",
        "    h5file = hdf5_addvars(h5file,{'history': thishist})\n",
        "\n",
        "    return h5file\n",
        "\n",
        "\n",
        "def homermat_to_hdf5(inname,outname):\n",
        "    \"\"\"\n",
        "Usage:   homerfile_to_hdf5(inname,outname)\n",
        "Returns: an open, loaded hdf5 structure\n",
        "\"\"\"\n",
        "    d,t,aux10,ml,gains = read_homer_mat(inname)\n",
        "    h5 = homer_to_hdf5(outname,d,t,aux10,ml,gains)\n",
        "    return h5\n",
        "\n",
        "\n",
        "def homernpz_to_hdf5(inname,outname):\n",
        "    \"\"\"\n",
        "Usage:   homerfile_to_hdf5(inname,outname)\n",
        "Returns: an open, loaded hdf5 structure\n",
        "\"\"\"\n",
        "    d,t,aux10,ml,gains = read_homer_npz(inname)\n",
        "    h5 = homer_to_hdf5(outname,d,t,aux10,ml,gains)\n",
        "    return h5\n",
        "\n",
        "\n",
        "def hdf5_to_homer(hdf5struct):\n",
        "    \"\"\"\n",
        "Not generally recommended, generally, as hdf5 files can have more\n",
        "in them than homer files. But, this will yank out the standard\n",
        "Homer variables from an hdf5 structure and return them in the\n",
        "order indicated below.\n",
        "\n",
        "Usage:   hdf5_to_homer(hdf5structure)\n",
        "Returns: d,t,aux10,ml,gains\n",
        "\"\"\"\n",
        "    dct = {}\n",
        "    for node in hdf5struct.walkNodes(\"/\", \"Array\"):\n",
        "        str = '%s = %s[:]' %(node.name, node.name)\n",
        "        exec(str)\n",
        "    return d,t,aux10,ml,gains\n",
        "\n",
        "\n",
        "def hdf5_to_homerfile(hdf5struct):\n",
        "    \"\"\"\n",
        "Takes the variables in hdf5struct and saves them in a homer-style\n",
        ".mat file using the hdf5struct.filename as a basename (plus .mat).\n",
        "\n",
        "Usage:   hdf5_to_homerfile(hdf5structure)\n",
        "Returns: d,t,aux10,ml,gains\n",
        "\"\"\"\n",
        "    dct = {}\n",
        "    for node in hdf5struct.walkNodes(\"/\", \"Array\"):\n",
        "        try:\n",
        "            dct[node.name] = node[:]\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    outname = hdf5struct.filename\n",
        "    outname = outname[:outname.rfind('.')]+'.mat'\n",
        "    scipy.io.savemat(outname,dct)\n",
        "    return None\n",
        "\n",
        "\n",
        "def read_nirs1(fname):\n",
        "    \"\"\"Loads in NIRS1 data assuming 2 instrument use (two halves stacked).\n",
        "\n",
        "Usage:   nirs1load2(fname)\n",
        "Returns: h, t, d   ... header info, timebase, data\n",
        "\"\"\"\n",
        "    f = open(fname)\n",
        "\n",
        "    # strip off commented header\n",
        "    test = '%'  # pre-set it to get into the while loop\n",
        "    h = []      # initial comment lines are headers\n",
        "    while test in ['%','#','!','']:\n",
        "        line = f.readline()\n",
        "        test = line[0]\n",
        "        h = h + [line]\n",
        "    h = h[:-1] # while loop grabs an extra line, strip it\n",
        "    f.close()\n",
        "\n",
        "    # get all file data\n",
        "    print('reading')\n",
        "    f = open(fname)\n",
        "    d = f.readlines()   # get everything (again)\n",
        "    f.close()\n",
        "    print('reading DONE')\n",
        "\n",
        "    # parse it into integers\n",
        "    print('parsing')\n",
        "    for i in range(len(d)-1,-1,-1):\n",
        "        if d[i][0] not in ['','%','#','!']:    # avoid blank and commented lines\n",
        "            d[i] = list(map(string.atoi,string.split(d[i])))\n",
        "        else:\n",
        "            del d[i]\n",
        "    d = np.array(d)\n",
        "\n",
        "    # reshape it (assumes 2 NIRS1 instruments; stick halves side-by-side)\n",
        "    d = np.hstack((d[:len(d)/2], d[len(d)/2:]))\n",
        "    print('parsing DONE')\n",
        "\n",
        "    # now create the timebase off the header info\n",
        "    for row in h:\n",
        "        if row.find('Sample Rate=')>=0:\n",
        "            idx1 = row.find('=')+1\n",
        "            idx2 = row.find(',')\n",
        "            samplerate = string.atof(string.strip(row[idx1:idx2]))\n",
        "    t = np.arange(len(d))/samplerate\n",
        "\n",
        "    return h, t, d\n",
        "\n",
        "\n",
        "def saveNIR(fname, *args):\n",
        "    \"\"\"\n",
        "Save a .nir file (for NIRS-SPM). Requires either d,t arguments,\n",
        "a .npz filename, or an hdf5 structure.\n",
        "\n",
        "Usage:   saveNIR(outfname, d, t) ... OR\n",
        "         saveNIR(outfname, hdf5struct) ... OR\n",
        "         saveNIR(outfname, npz_infname)\n",
        "Returns: None\n",
        "\"\"\"\n",
        "    if type(args[1])==str:    # must be a npz filename\n",
        "        d,t,ml,aux10,gains,rate,timestamp,lambdas = read_homer_npz(args[1])\n",
        "    elif type(args[1])==np.ndarray:  # must be homer data\n",
        "        d = args[0]\n",
        "        t = args[1]\n",
        "    else:                            # must be an hdf5 structure\n",
        "        d = args[0].root.d[:]\n",
        "        t = args[0].root.t[:]\n",
        "\n",
        "    f = open(fname,'w')\n",
        "    for i in range(len(d)):\n",
        "        minutes = int(t[i]/60.)\n",
        "        hrs = int(minutes/60.)\n",
        "        sec = round(t[i]%60,2)\n",
        "        time = str(hrs) +':' +fixstr(minutes,2) +':' +fixstr(sec,2)\n",
        "        f.write(string.join([time]+list(map(str,d[i])),','))\n",
        "    f.close()\n",
        "    return\n",
        "\n",
        "\n",
        "def saveNSPM(fname, *args):\n",
        "    \"\"\"\n",
        "Save a .nspm file (for NIRS-SPM). Requires either d,t arguments,\n",
        "a .npz filename, or an hdf5 structure.\n",
        "\n",
        "Usage:   saveNSPM(outfname, d, t) ... OR\n",
        "         saveNSPM(outfname, hdf5struct) ... OR\n",
        "         saveNSPM(outfname, npz_infname)\n",
        "Returns: None\n",
        "\"\"\"\n",
        "    if type(args[1])==str:    # must be a npz filename\n",
        "        d,t,ml,aux10,gains,rate,timestamp,lambdas = read_homer_npz(args[1])\n",
        "    elif type(args[1])==np.ndarray:  # must be homer data\n",
        "        d = args[0]\n",
        "        t = args[1]\n",
        "    else:                            # must be an hdf5 structure\n",
        "        d = args[0].root.d[:]\n",
        "        t = args[0].root.t[:]\n",
        "\n",
        "    f = open(fname,'w')\n",
        "    halfmeas = len(d[0])/2\n",
        "    for row in range(len(d)):\n",
        "        for col in range(halfmeas-1):\n",
        "            f.write( '%1.5f,%1.5f,' %(d[row][col],d[row][col+halfmeas]) )\n",
        "        # do the last SD pair bit different\n",
        "        f.write( '%1.5f,%1.5f\\n' %(d[row][col+1],d[row][col+1+halfmeas]) )\n",
        "    f.close()\n",
        "    return\n",
        "\n",
        "\n",
        "def saveNSPMparams(fname,distances,freq,lambdas=[690,830],DPF=6,correction='yes'):\n",
        "    \"\"\"\n",
        "Save the parameter file for a NIRS-SPM analysis.\n",
        "    fname = output filename\n",
        "    distances = list/tuple/array of distances for [ch1, ch2, ch3 ...]\n",
        "    freq = sampling frequency\n",
        "    lambdas = list/tuple/array of wavelengths used\n",
        "    DPF = correction factor\n",
        "    correction = 'yes' or 'no' for whether to use DPF or not\n",
        "\n",
        "Usage:   saveNSPMparams(fname,distances,freq,lambdas=[690,830],DPF=6,correction='yes')\n",
        "    \"\"\"\n",
        "    outstring = \"Total_number_of_Ch. %i\\nSampling_freq.[Hz] %f\\nDistance[cm] %s\\nWave_length[nm] %s\\nDPF %f\\ncorrection %s\\n\"\n",
        "    numchannels = len(distances)\n",
        "    distances = string.join(map(str,distances))\n",
        "    lambdas = string.join(map(str,lambdas))\n",
        "    params = (numchannels, freq, distances, lambdas, DPF, correction)\n",
        "    outstring = outstring %params\n",
        "    f = open(fname,'w')\n",
        "    f.write(outstring)\n",
        "    f.close()\n",
        "\n",
        "\n",
        "def read_cw5bin_chunk(fid,datatype):\n",
        "    \"\"\"\n",
        "Utility function used by read_cw5bin to read 30sec chunks of .bin\n",
        "files saved by CW5.\n",
        "\n",
        "Usage:   read_cw5bin_chunk(fid,datatype)\n",
        "Returns: data, header\n",
        "\"\"\"\n",
        "    # GET INITIAL HEADER INFO\n",
        "    d = fid.read(6*4)\n",
        "    hc = len(d)\n",
        "    if len(d)==0:\n",
        "        return np.array([]), None # out of data\n",
        "    d = struct.unpack(6*'I',d)\n",
        "\n",
        "    dec_cookie = 52229*65536+514\n",
        "    if d[0] != dec_cookie:\n",
        "        raise ValueError(\"Header does not begin with CW5 v2 tag.\")\n",
        "    hdr = {}\n",
        "    hdr['cookie'] = d[0]\n",
        "    hdr['hdr_len'] = d[1]\n",
        "    hdr['data_len'] = d[2]\n",
        "    hdr['pad_len'] = d[3]\n",
        "    hdr['data_rate'] = d[4]\n",
        "    hdr['vrng'] = d[5]\n",
        "\n",
        "    ctbl = fid.read(32*1)\n",
        "    hc = hc +len(ctbl)\n",
        "    ctbl = struct.unpack(32*'B',ctbl)\n",
        "    hdr['detectors'] = ctbl\n",
        "\n",
        "    s = 'Channel Array: '\n",
        "    ccnt = 0\n",
        "    for k in range(32):\n",
        "        if hdr['detectors'][k] != 255:\n",
        "            s = s+'+'\n",
        "            ccnt += 1\n",
        "        else:\n",
        "            s = s+'-'\n",
        "\n",
        "    stbl = fid.read(32*1)\n",
        "    hc = hc +len(stbl)\n",
        "    stbl = struct.unpack(32*'B',stbl)\n",
        "    hdr['sources'] = stbl\n",
        "\n",
        "    dtime = fid.read(8*2)\n",
        "    hc = hc +len(dtime)\n",
        "    dtime = struct.unpack(8*'H',dtime)\n",
        "    seconds = int(dtime[6]+dtime[7]/1000.)\n",
        "    ndate = time.asctime([dtime[0],dtime[1],dtime[3],dtime[4],dtime[5],seconds,0,0,0])\n",
        "    hdr['timestamp'] = ndate\n",
        "\n",
        "    gn = fid.read(32*1)\n",
        "    hc = hc+len(gn)\n",
        "    gn = struct.unpack(32*'B',gn)\n",
        "    hdr['gainA'] = gn\n",
        "\n",
        "    gn = fid.read(32*1)\n",
        "    hc = hc+len(gn)\n",
        "    gn = struct.unpack(32*'B',gn)\n",
        "    hdr['gainB'] = gn\n",
        "\n",
        "    # read padding between chunks\n",
        "    junk = fid.read(hdr['hdr_len']-hc)  # uint8s\n",
        "\n",
        "    if hdr['data_len']>0:\n",
        "        vdata = fid.read(hdr['data_len']*2)  # *2 is for int16\n",
        "        if len(vdata)==0:\n",
        "            return np.array([]),hdr\n",
        "        vdata = struct.unpack(hdr['data_len']*'H', vdata)\n",
        "        vdata = np.array(vdata)\n",
        "    else:\n",
        "        return np.array([]), hdr\n",
        "\n",
        "    if len(vdata) != hdr['data_len']:\n",
        "        # size doesn't match\n",
        "        return np.array([]), hdr\n",
        "\n",
        "    data = np.reshape(vdata,(ccnt,len(vdata)/ccnt))\n",
        "    del vdata\n",
        "\n",
        "    if hdr['pad_len']>0:\n",
        "        fid.seek(hdr['pad_len'],1)  # from current file pos\n",
        "\n",
        "    return data, hdr\n",
        "\n",
        "\n",
        "####################### HDF5 UTILITIES ######################\n",
        "\n",
        "def hdf5_addgeom(h5, geomstruct):\n",
        "    \"\"\"\n",
        "Add pSrc and pDet to an hdf5 structure from a structure containing\n",
        "these gemoetry variables (e.g., probe_mr.py)\n",
        "\n",
        "Usage:   hdf5 = hdf5_geom(h5, probe_mr)\n",
        "\"\"\"\n",
        "    hdf5_delete_nodes(h5,'pSrc','pDet')\n",
        "    h5.createArray(h5.root, 'pSrc', geomstruct.pSrc, 'Source locations')\n",
        "    h5.createArray(h5.root, 'pDet', geomstruct.pDet, 'Detector locations')\n",
        "    return h5\n",
        "\n",
        "\n",
        "def hdf5_addvars(h5, *args):\n",
        "    \"\"\"\n",
        "Add variables to an hdf5 structure. Either pass a varname and\n",
        "varvalue, or a dictionary of varname:varvalue pairs.\n",
        "\n",
        "Usage:   hdf5 = hdf5_addvars(h5, *args)\n",
        "Returns: hdf5\n",
        "\"\"\"\n",
        "    if len(args)==1:  # must be a dict\n",
        "        args = args[0]\n",
        "        for key in args.keys():\n",
        "            if key=='history':\n",
        "                t = h5.createTable(h5.root,'history',{'text':tables.StringCol(itemsize=256)},expectedrows=100)\n",
        "                element = t.row\n",
        "                element['text'] = args[key]\n",
        "                element.append()\n",
        "                t.flush()\n",
        "            else:\n",
        "                h5.createArray(h5.root, key, args[key], '')\n",
        "    else:   # must be a name and value (and optional description)\n",
        "        if len(args)==3:\n",
        "            descr = args[2]\n",
        "        else:\n",
        "            descr = ''\n",
        "        if key=='history':\n",
        "            t = h5.createTable(h5.root,'history',{'text':tables.StringCol(itemsize=256)},expectedrows=100)\n",
        "            element = t.row\n",
        "            element['text'] = args[1]\n",
        "            element.append()\n",
        "            t.flush()\n",
        "        else:\n",
        "            h5.createArray(h5.root, args[0], args[1], descr)\n",
        "    return h5\n",
        "\n",
        "\n",
        "def hdf5_delete_nodes(h5,*args):\n",
        "    \"\"\"\n",
        "Delete all nodes given in args from h5.root, IN-PLACE!! args should\n",
        "be one or more strings.\n",
        "\n",
        "Usage:   hdf5_delete_nodes(h5,*args)\n",
        "Returns: None\n",
        "\"\"\"\n",
        "    for item in args:\n",
        "        try:\n",
        "            s = \"h5.root.%s._f_remove()\" %item\n",
        "            eval(s)\n",
        "        except:\n",
        "            pass\n",
        "    return\n",
        "\n",
        "\n",
        "def create_new_hdf5_file(hdf5,outname,overwrite=False):\n",
        "    \"\"\"\n",
        "Copy hdf5 file contents to outname, close it, and open outname. Used\n",
        "by all hdf5 functions to keep forms of data separate. Outname\n",
        "appended with .h5 if not present.\n",
        "\n",
        "Usage:   create_new_hdf5_file(hdf5,outname,overwrite=False)\n",
        "Returns: h5 (pointer to new file)\n",
        "\"\"\"\n",
        "    if outname[-3:] != '.h5':\n",
        "        outname += '.h5'\n",
        "    print(outname)\n",
        "\n",
        "    # make a copy, close out existing file\n",
        "    if overwrite:\n",
        "        hdf5.copyFile(outname,overwrite=True)\n",
        "    else:\n",
        "        try:\n",
        "            hdf5.copyFile(outname)\n",
        "        except IOError:\n",
        "            x=input(\"\\nFILENAME '%s' EXISTS! Overwrite (y/n)? \" %outname)\n",
        "            if x in ['y','Y','Yes','YES','yes']:\n",
        "                hdf5.copyFile(outname,overwrite=True)\n",
        "            else:\n",
        "                print(\"ABORTING create_new_hdf5_file().\")\n",
        "                return\n",
        "    hdf5.close()\n",
        "\n",
        "    # open new file and operate on it in-place\n",
        "    h5 = tables.openFile(outname,'a')\n",
        "    return h5\n",
        "\n",
        "\n",
        "def printhist(h5):\n",
        "    \"\"\"\n",
        "Print history information from hdf5 handle (or hdf5 filename).\n",
        "\n",
        "Usage:  print_hist(hdf5)\n",
        "\"\"\"\n",
        "    if type(h5)==str:\n",
        "        h5 = tables.openFile(h5)\n",
        "    print()\n",
        "    for row in h5.root.history:\n",
        "        print(row[0])\n",
        "    print()\n",
        "    return\n",
        "\n",
        "\n",
        "def addtohist(h5,txt):\n",
        "    \"\"\"\n",
        "Adds a text row to the history table.\n",
        "\n",
        "Usage:   addtohist(h5,txt)\n",
        "Returns: None  (modified in-place)\n",
        "\"\"\"\n",
        "    element = h5.root.history.row\n",
        "    element['text'] = txt\n",
        "    element.append()\n",
        "    h5.root.history.flush()\n",
        "    return\n",
        "\n",
        "\n",
        "################## HELPER/FIND FUNCTIONS ####################\n",
        "\n",
        "def dist(x,y):\n",
        "    return np.sqrt(np.sum((np.asarray(x)-np.asarray(y))**2))\n",
        "\n",
        "\n",
        "def fixstr(x,fixlen=3):\n",
        "    \"\"\"\n",
        "Usage:   fixstr(x,fixlen=3)\n",
        "Returns: string version of x, with a minimum length of fixlen (0s prepended)\n",
        "\"\"\"\n",
        "    s = str(x)\n",
        "    mul = fixlen-len(s)\n",
        "    if mul>0:\n",
        "        return '0'*mul+s\n",
        "    else:\n",
        "        return s\n",
        "\n",
        "\n",
        "def filtfilt(b, a, x):\n",
        "    \"\"\"filtfilt(b, a, x)\"\"\"\n",
        "\n",
        "    if len(x.shape)==1:\n",
        "        x.shape = (x.shape[0],1)\n",
        "\n",
        "    b = np.ravel(b)\n",
        "    a = np.ravel(a)\n",
        "    nb = len(b)\n",
        "    na = len(a)\n",
        "    nfilt = max(nb,na)\n",
        "    n = len(x)\n",
        "\n",
        "    nfact = 3*(nfilt-1)  # length of edge transients\n",
        "    part1 = 2*x[0]-x[(nfact+1):1:-1]\n",
        "    part3 = 2*x[-1]-x[-2:n-nfact-2:-1]\n",
        "    ylongorig = np.concatenate((part1, x, part3))\n",
        "\n",
        "    # filter, reverse data, filter again, and reverse data again\n",
        "    ylong = scipy.signal.lfilter(b,a,ylongorig,axis=0)\n",
        "    ylong = ylong[::-1]\n",
        "    ylong = scipy.signal.lfilter(b,a,ylong,axis=0)\n",
        "    ylong = ylong[::-1]\n",
        "\n",
        "    # remove extrapolated pieces of y\n",
        "    y = ylong[nfact:-nfact]\n",
        "    return y #, ylong, ylongorig\n",
        "\n",
        "\n",
        "def lowpass(d,flp,samplerate):\n",
        "    \"\"\"lowpass(d,flp,samplerate):\"\"\"\n",
        "    if flp == 0:\n",
        "        return d\n",
        "    wwid = int(samplerate/float(flp))\n",
        "    b = np.ones((wwid,1))/float(wwid)\n",
        "    a = 1\n",
        "    return filtfilt(b,a,d)\n",
        "\n",
        "\n",
        "def hipass(d,fhp,samplerate):\n",
        "    \"\"\"hipass(d,fhp,samplerate):\"\"\"\n",
        "    if fhp == 0:\n",
        "        return d\n",
        "    wwid = int(samplerate/float(fhp))\n",
        "    b = np.ones((wwid,1))/float(wwid)\n",
        "    a = 1\n",
        "    return d - filtfilt(b,a,d)\n",
        "\n",
        "\n",
        "def hipassND(d,fhp,samplerate):\n",
        "    \"\"\"hipassND(d,fhp,samplerate):\"\"\"\n",
        "    if fhp == 0:\n",
        "        return d\n",
        "    wwid = int(samplerate/float(fhp))\n",
        "    b = np.ones((wwid,1))/float(wwid)\n",
        "    a = 1\n",
        "    fd = filtfilt(b,a,d)\n",
        "    print(d.shape, fd.shape)\n",
        "    return d - fd\n",
        "\n",
        "\n",
        "def filter_regress(ref,y,demean=True):\n",
        "    \"\"\"\n",
        "Filter data in y using data in ref as reference and linear-regression subtraction. If\n",
        "demean=True, ref will be demeaned before fitting and subtracting. Note that y can be\n",
        "a single timeseries (same length as ref), or an array of timeseries' (length of ref).\n",
        "\n",
        "Usage:   filter_regress(ref,y,demean=True)\n",
        "Returns: filtered y where newy = y - A*ref\n",
        "\"\"\"\n",
        "    if demean:\n",
        "        ref = ref-ref.mean()\n",
        "    if y.shape==ref.shape:\n",
        "        slope,intercept,r,prob,sterr = scipy.stats.linregress(ref,y)\n",
        "        newy = y - (ref*slope+intercept)\n",
        "    else:\n",
        "        newy = []\n",
        "        for col in y.T:\n",
        "            slope,intercept,r,prob,sterr = scipy.stats.linregress(ref,col)\n",
        "            newy.append(col - (ref*slope+intercept))\n",
        "        newy = np.asarray(newy).T\n",
        "    return newy\n",
        "\n",
        "\n",
        "def AF(ref,y,H):\n",
        "    \"\"\"\n",
        "Adaptive filter, using the LMS algorithm. A reasonable default H is\n",
        "[1,0,0,0 ...] up to how ever many nodes you wish to use.\n",
        "\n",
        "Usage:   AF(ref,y,H)  ... y=target, ref=reference, H=pre-set nodes\n",
        "Returns: yy, hRec     ... yy=filtered target, hRec = new nodes\n",
        "\"\"\"\n",
        "    n = len(y)  # length of input data\n",
        "    WN = len(H) # nodes (window size)\n",
        "    u = 0.0001  # convergence parameter; 0.0001 gives good results if the initial guess is zeros\n",
        "\n",
        "    # Initialize all variables\n",
        "    hRec = np.zeros((n,WN)) # historical record of all Hs\n",
        "    ww = 0                  # prediction at current point\n",
        "    wwRec = np.zeros((n,1)) # historical record of fits\n",
        "    e = np.zeros((n,1))     # resulting filtered signal\n",
        "    X = np.zeros(WN)        # the reference signal to use for this timepoint\n",
        "    XRec = np.zeros((n,WN)) # historical record of X\n",
        "\n",
        "    # Start filtering\n",
        "    for ii in range(n):\n",
        "#        print hRec.shape, H.shape\n",
        "        hRec[ii,:] = H\n",
        "        if ii<WN:\n",
        "            X[:ii+1] = np.ravel(ref[ii::-1])\n",
        "        else:\n",
        "            X = np.ravel(ref[ii:(ii-WN):-1])\n",
        "        ww = np.dot(H[np.newaxis,:],X)\n",
        "        wwRec[ii] = ww\n",
        "        e[ii] = y[ii]-ww\n",
        "        H = H +2*u*e[ii]*X\n",
        "        XRec[ii,:] = e[ii]*X\n",
        "\n",
        "    yy = e\n",
        "    return yy, hRec\n",
        "\n",
        "\n",
        "def filter_AF(ref,y,H):\n",
        "    \"\"\"\n",
        "Adaptive filter, using the LMS algorithm. A reasonable default H is\n",
        "[1,0,0,0 ...] up to how ever many nodes you wish to use.\n",
        "\n",
        "Usage:   AF(ref,y,H)  ... y=target, ref=reference, H=pre-set nodes\n",
        "Returns: yy, hRec     ... yy=filtered target, hRec = new nodes\n",
        "\"\"\"\n",
        "    if y.shape==ref.shape:\n",
        "        yy,hRec = AF(ref,y,H)\n",
        "        newy = yy\n",
        "    else:\n",
        "        newy = []\n",
        "        for col in y.T:\n",
        "            yy,hRec = AF(ref,y,H)\n",
        "            newy.append(yy)\n",
        "        newy = np.asarray(newy).T\n",
        "    return newy\n",
        "\n",
        "\n",
        "#def find(a,value):\n",
        "#    \"\"\"equivalent of matlab's 'find' function; found in pylab\"\"\"\n",
        "#    return np.argmax(a==value)\n",
        "\n",
        "\n",
        "def sdidx(ml,s=None,d=None,w=None):\n",
        "    \"\"\"\n",
        "Find indices for a particular source, detector, wavelength, or combos.\n",
        "Set a variable to None to ignore it. s=Src, d=Det, w=wavelength (1 or 2).\n",
        "\n",
        "Usage:   sdidx(ml,s=None,d=None,wavelength=None)\n",
        "Returns: numpy array of indices\n",
        "\"\"\"\n",
        "    if s is None and d is None and w is None:\n",
        "        return None  # no matches\n",
        "    elif s is None and d is None and w is not None:\n",
        "        return np.nonzero(ml[:,3]==w)\n",
        "    elif s is None and d is not None and w is None:\n",
        "        return np.nonzero(ml[:,1]==d)\n",
        "    elif s is not None and d is None and w is None:\n",
        "        return np.nonzero(ml[:,0]==s)\n",
        "    elif s is None and d is not None and w is not None:\n",
        "        return np.nonzero((ml[:,1]==d) & (ml[:,3]==w))\n",
        "    elif s is not None and d is None and w is not None:\n",
        "        return np.nonzero((ml[:,0]==s) & (ml[:,3]==w))\n",
        "    elif s is not None and d is not None and w is None:\n",
        "        return np.nonzero((ml[:,0]==s) & (ml[:,1]==d))\n",
        "    elif s is not None and d is not None and w is not None:\n",
        "        return np.nonzero((ml[:,0]==s) & (ml[:,1]==d) & (ml[:,3]==w))\n",
        "\n",
        "\n",
        "def findpeaks(d,samplerate,fhp,flp,posneg):\n",
        "    \"\"\"\n",
        "d = data to be prefiltered and disected for peaks\n",
        "samplerate = sampling rate of data in dorig\n",
        "fhp = high-pass filter cutoff (Hz)\n",
        "flp = low-pass filter cutoff (Hz)\n",
        "posneg = -1 to find negative-going peaks, +1 to find positive-going peaks\n",
        "\n",
        "Usage:   peakx,peaky = findpeaks(dorig,samplerate,fhp,flp,posneg)\n",
        "\"\"\"\n",
        "    if fhp:\n",
        "        dhp = hipass(d,fhp,samplerate)\n",
        "    else:\n",
        "        dhp = d\n",
        "    if flp:\n",
        "        dhplp = lowpass(dhp,flp,samplerate)\n",
        "    else:\n",
        "        dhplp = dhp\n",
        "\n",
        "    # calculate derivative\n",
        "    deriv = np.diff(np.ravel(dhplp),1)\n",
        "\n",
        "    # find peaks (i.e., look for zero-crossings in the\n",
        "    if posneg > 0:\n",
        "        peakx = np.where((deriv[:-1]>0) * (deriv[1:]<0))\n",
        "    elif posneg < 0:\n",
        "        peakx = np.where((deriv[:-1]<0) * (deriv[1:]>0))\n",
        "\n",
        "    return peakx[0], dhplp[peakx]\n",
        "\n",
        "\n",
        "def findfirst(x,val):\n",
        "    return np.nonzero(x>=val)[0][0]\n",
        "\n",
        "\n",
        "def timeslice(d,t,tstart,tend):\n",
        "    \"\"\"\n",
        "Slice data from d, along first axis, given a timebase and start/end times.\n",
        "\n",
        "Usage:   timeslice(d,t,tstart,tend)\n",
        "Returns: d,t ... sliced between time tstart and tend, in/ex-clusive\n",
        "\"\"\"\n",
        "    idx1 = findfirst(t,tstart)\n",
        "    idx2 = findfirst(t,tend)\n",
        "    return d[idx1:idx2,...],t[idx1:idx2]\n",
        "\n",
        "\n",
        "def pruneclose(d,dist):\n",
        "    last = 0\n",
        "    newd = [d[0]]\n",
        "    for i in range(1,len(d)):\n",
        "        if i>last+dist:\n",
        "            newd.append(d[i])\n",
        "    return np.array(newd)\n",
        "\n",
        "\n",
        "def pruneclosetime(d,t,timedist):\n",
        "    newt = [t[0]]\n",
        "    newd = [d[0]]\n",
        "    for i in range(1,len(t)):\n",
        "        if t[i]>t[i-1]+timedist:\n",
        "            newt.append(t[i])\n",
        "            newd.append(d[i])\n",
        "#        else:\n",
        "#            print \"skipped one\", i, t[i]\n",
        "    return np.array(newd), np.array(newt)\n",
        "\n",
        "\n",
        "def findnarrowpeaks(d,width,drop,mindist=0):\n",
        "    \"\"\"\n",
        "d = raw data\n",
        "width = width in points of peak\n",
        "drop = drop in value required to count as a peak\n",
        "mindist = minimum number of points between peaks\n",
        "\n",
        "Usage:   peakx,peaky = findnarrowpeaks(d,width,drop,mindist)\n",
        "\"\"\"\n",
        "    peakx = []\n",
        "    peaky = []\n",
        "    for i in range(width/2,len(d)-width/2):\n",
        "        if d[i-width/2]<(d[i]-drop) and d[i+width/2]<(d[i]-drop):\n",
        "            if not peakx:  # if empty list, just append\n",
        "                peakx.append(i)\n",
        "                peaky.append(d[i])\n",
        "            else:          # if list is not empty, make sure this one is far enough away\n",
        "                if i > peakx[-1]+mindist:\n",
        "                    peakx.append(i)\n",
        "                    peaky.append(d[i])\n",
        "\n",
        "    return np.array(peakx), np.array(peaky)\n",
        "\n",
        "\n",
        "def findpeaks_and_troughs(d,samplerate,fhp,flp):\n",
        "    \"\"\"\n",
        "dorig = data to be prefiltered and disected for peaks\n",
        "samplerate = sampling rate of data in dorig\n",
        "fhp = high-pass filter cutoff (Hz)\n",
        "flp = low-pass filter cutoff (Hz)\n",
        "\n",
        "Usage:   peakx,peaky,dhp,dhplp,dorig = findpeaks(dorig,samplerate,fhp,flp,posneg)\n",
        "\"\"\"\n",
        "    dhp = hipass(d,fhp,samplerate)\n",
        "    dhplp = lowpass(dhp,flp,samplerate)\n",
        "\n",
        "    # calculate derivative\n",
        "    deriv = np.diff(np.ravel(dhplp),1)\n",
        "\n",
        "    # find peaks (i.e., look for zero-crossings in the derivative)\n",
        "    peakx = np.where((deriv[:-1]>0) * (deriv[1:]<0))[0]\n",
        "    troughx = np.where((deriv[:-1]<0) * (deriv[1:]>0))[0]\n",
        "\n",
        "    return peakx, dhplp[peakx], troughx, dhplp[troughx], dhplp\n",
        "\n",
        "\n",
        "def find_means_around_points(d,points,winwidth):\n",
        "    mdp = []\n",
        "    for i in range(len(points)):\n",
        "        p = points[i]\n",
        "        idx1 = max(0,p-winwidth/2)\n",
        "        idx2 = p+winwidth/2\n",
        "#        print i, idx1, idx2, d.shape\n",
        "        mdp.append(np.mean(d[idx1:idx2,...],0))\n",
        "    return np.array(mdp)\n",
        "\n",
        "\n",
        "def find_closest(a,val,col=None):\n",
        "    \"\"\"\n",
        "Finds the element and index of a that's closest to value val. If col is\n",
        "an integer (and not None), then the column specified will be used.\n",
        "\n",
        "Usage:   find_closest(a,val,col=None)\n",
        "Returns: index-into-a, closest-val\n",
        "\"\"\"\n",
        "    if col is not None:\n",
        "        a = np.asarray(a[:,col])\n",
        "    tmp = np.sort(a)\n",
        "    bigindices = np.where(a>=val)[0]\n",
        "    smallindices = np.where(a<val)[0]\n",
        "    if len(bigindices):  # if there are values in a that are >=val\n",
        "        biggerval = a[np.min(bigindices)]\n",
        "    if len(smallindices):        # if no such value, get the biggest\n",
        "        smallerval = a[np.max(smallindices)]\n",
        "    if not len(bigindices):  # all elements are smaller than target val\n",
        "        val = smallerval\n",
        "    elif not len(smallindices): # all elements are bigger than target val\n",
        "        val = biggerval\n",
        "    else:                    # some bigger and some smaller, figure out which is closest\n",
        "        if abs(val-biggerval) < abs(val-smallerval):\n",
        "            val = biggerval\n",
        "        else:\n",
        "            val = smallerval\n",
        "    idx = np.where(a==val)[0]  # find time index where a==closest_val\n",
        "    return idx, val\n",
        "\n",
        "\n",
        "def find_closest_smaller(a,val,col=None):\n",
        "    \"\"\"\n",
        "Finds the element and index of a that's closest to value val. If col is\n",
        "an integer (and not None), then the column specified will be used.\n",
        "\n",
        "Usage:   find_closest_smaller(a,val,col=None)\n",
        "Returns: index-into-a, closest-but-smaller-val\n",
        "\"\"\"\n",
        "    if col is not None:\n",
        "        a = np.asarray(a[:,col])\n",
        "    tmp = np.sort(a)\n",
        "    smallindices = np.where(a<val)[0]\n",
        "    if len(smallindices):        # if no such value, get the biggest\n",
        "        smallerval = a[np.max(smallindices)]\n",
        "    if not len(smallindices): # all elements are bigger than target val\n",
        "        val = a[-1]\n",
        "    else:                    # some bigger and some smaller, figure out which is closest\n",
        "        val = smallerval\n",
        "    idx = np.where(a==val)[0]  # find time index where a==closest_val\n",
        "    return idx, val\n",
        "\n",
        "\n",
        "def find_extrema(lst):\n",
        "    \"\"\"\n",
        "Return the minima and maxima in each dimension (column) of lst.\n",
        "\n",
        "Usage:  find_extrema(lst)\n",
        "Returns: minima, maxima\n",
        "\"\"\"\n",
        "    minima = lst[0]*1  # make copies\n",
        "    maxima = lst[0]*1\n",
        "    for row in lst:\n",
        "        for j in range(len(row)):  # loop over x,y(,z)\n",
        "            if row[j] < minima[j]:\n",
        "                minima[j] = row[j]  # found a smaller one\n",
        "            if row[j] > maxima[j]:\n",
        "                maxima[j] = row[j]  # found a bigger one\n",
        "    return np.array(minima), np.array(maxima)\n",
        "\n",
        "\n",
        "def getidx(src,det,ml):\n",
        "    \"\"\"\n",
        "Finds the indices (in ml) for this particular src/det pair (should get two).\n",
        "\n",
        "Usage:   getidx(src,det,ml)\n",
        "Returns: list of 2 indices\n",
        "\"\"\"\n",
        "    if src not in [None,0] and det not in [None,0]:\n",
        "        return np.where((ml[:,0]==src) & (ml[:,1]==det))\n",
        "    elif src not in [None,0]:\n",
        "        return np.where(ml[:,0]==src)\n",
        "    elif det not in [None,0]:\n",
        "        return np.where(ml[:,1]==det)\n",
        "\n",
        "\n",
        "def addsuffix(inname,suffix):\n",
        "    \"\"\"\n",
        "Sticks 'suffix' onto inname before the fname extension.\n",
        "Removes any previous -suffix.ext first.\n",
        "\n",
        "Usage:   addsuffix(inname,suffix)\n",
        "Returns: outname\n",
        "\"\"\"\n",
        "    base,ext = os.path.splitext(inname)\n",
        "\n",
        "    # HARD CODED filename components to look for\n",
        "    tests = ['-preproc','-prune','-filt','-OD','-HB']\n",
        "    testflag = False\n",
        "    for test in tests:\n",
        "        if test in base:\n",
        "            testflag = True\n",
        "            idx = base.rfind('-') # find the dash in the name\n",
        "            outname = base[:idx]+'-%s%s' %(suffix,ext)\n",
        "            break  # skip the rest of the loop\n",
        "\n",
        "    if not testflag:\n",
        "        outname = base+'-%s%s'%(suffix,ext)\n",
        "    return outname\n",
        "\n",
        "\n",
        "def regress(X,Y):\n",
        "    \"\"\"\n",
        "Perform a multiple linear regression of y onto X. X is a num\n",
        "observations by (num variables +1) array. X should contain a\n",
        "column of ones to generate the intercept. y is a num observations\n",
        "array of independent variables\n",
        "\n",
        "Usage:   fit_regressors(X,Y):\n",
        "Returns: value B, residuals, stats\n",
        "\n",
        "B: the regression coeffients; Ypred = B.T * X.T\n",
        "residuals: array( y - Ypred.T)\n",
        "stats = Rsquared, F, p\n",
        "\"\"\"\n",
        "    # regression coeffs are given by (Xt*X)-1*Xt*y\n",
        "    N = X.shape[0]\n",
        "#    Y.shape = (N, 1)\n",
        "    Xt = X.T\n",
        "    Xi_X_i = np.linalg.pinv(np.dot(Xt,X))\n",
        "    B = np.dot(np.dot(Xi_X_i,Xt),Y)\n",
        "\n",
        "    Ypred = np.dot(B.T,Xt)\n",
        "    residuals = np.array(Y-Ypred.T)\n",
        "    CF = N*Y.mean()**2 # correction factor\n",
        "\n",
        "    SStotal = float(np.dot(Y,Y)-CF)\n",
        "    SSregress = float(np.dot(np.dot(B.T,Xt),Y) - CF)\n",
        "    SSerror = SStotal - SSregress\n",
        "\n",
        "    Rsquared = SSregress/SStotal\n",
        "\n",
        "    dfTotal = N-1\n",
        "    dfRegress = len(B)-1\n",
        "    dfError = dfTotal - dfRegress\n",
        "\n",
        "    try:\n",
        "        F = SSregress/dfRegress / (SSerror/dfError)\n",
        "    except ZeroDivisionError:\n",
        "        F = 0\n",
        "    prob = 1-scipy.stats.f.cdf(F, dfRegress, dfError)\n",
        "\n",
        "    stats = Rsquared, F, prob\n",
        "    return B, residuals, stats\n",
        "\n",
        "\n",
        "################### HDF5 FUNCTIONS #################\n",
        "\n",
        "def hdf5_preprocess(hdf5,flp=3,fhp=1/100.,suffix='preproc',overwrite=False):\n",
        "    \"\"\"\n",
        "A function to preprocess a hdf5 structure.\n",
        "\n",
        "h5.root.d = Time X Measurements array\n",
        "h5.root.t = time base for data\n",
        "\n",
        "Process: load raw data\n",
        "         take ABS() to blow away any phase information\n",
        "         \"fix\" initial 6 timepoints\n",
        "         \"fix\" final 3 timepoints\n",
        "         lowpass at flp (DEFAULT=3 Hz)\n",
        "         hipass at FHP (DEFAULT=1/60 Hz), use 0 to skip highpass filtering\n",
        "         add back in the mean signal values\n",
        "         plot (if requested)\n",
        "\n",
        "Usage:   hdf5_preprocess(hdf5,flp=3,fhp=1/100.,suffix='preproc',overwrite=False)\n",
        "Returns: None (hdf5 modified in-place)\n",
        "\"\"\"\n",
        "    # determine output filename\n",
        "    inname = hdf5.filename\n",
        "    outname = addsuffix(inname,suffix)\n",
        "\n",
        "    # get a copy of the input file to operate on\n",
        "    h5 = create_new_hdf5_file(hdf5,outname=outname,overwrite=overwrite)\n",
        "\n",
        "    d = h5.root.d[:]\n",
        "    t = h5.root.t[:]\n",
        "\n",
        "    # Blow away phase\n",
        "    print(\"Taking abs() of all data.\")\n",
        "    d = np.abs(d)\n",
        "\n",
        "    rate = 1. / (t[1]-t[0])\n",
        "\n",
        "    print(\"Fixing initial 6 timepoints.\")\n",
        "    mn = np.mean(d[6:17,:],0)\n",
        "    d[:6,:] = mn\n",
        "\n",
        "    print(\"Fixing final 3 timepoints.\")\n",
        "    for i in range(-3,0):\n",
        "        d[i,:] = np.mean(d[-13:-4,:],0)\n",
        "\n",
        "    print(\"Low-pass filtering.\")\n",
        "    dlp = lowpass(d,flp,rate)\n",
        "\n",
        "    # delete existing d variable\n",
        "    hdf5_delete_nodes(h5,'d')\n",
        "\n",
        "    if fhp != 0:\n",
        "        print(\"High-pass filtering and adding means back in.\")\n",
        "        means = np.mean(dlp,0)\n",
        "        dlphp = hipassND(dlp,fhp,rate)\n",
        "        dlphp = dlphp + means\n",
        "        h5.createArray(h5.root, 'd', dlphp,'Low-pass and high-pass filtered data')\n",
        "    else:\n",
        "#        print dlp.shape\n",
        "#        print h5\n",
        "        h5.createArray(h5.root, 'd', dlp,'Low-pass filtered data')\n",
        "\n",
        "    # update history log\n",
        "    thishist = time.asctime()+\": hdf5_preprocess('%s',flp=%s,fhp=%s,outname='%s')\\n\"%(inname,str(flp),str(fhp),outname)\n",
        "    addtohist(h5,thishist)\n",
        "\n",
        "    return h5\n",
        "\n",
        "\n",
        "def pruned_ml(pSrc,pDet,separations=[0,1000]):\n",
        "    \"\"\"\n",
        "Takes a pSrc and pDet list, and creates a pruned measurement list where only the\n",
        "SD pairs within the bracketed range of \"separations\" is included.\n",
        "\n",
        "pruned_ml(pSrc,pDet,separations=[0,1000])\n",
        "    separations = [minseparation,maxseparation] in centimeters ... [2 8]\n",
        "\"\"\"\n",
        "    # check if separations were provided in wrong order\n",
        "    if separations[0]>separations[1]:\n",
        "        # if wrong order, swap them\n",
        "        separations[0],separations[1] = separations[1],separations[0]\n",
        "\n",
        "    ml = []\n",
        "    for i in range(len(pSrc)):\n",
        "        for j in range(len(pDet)):\n",
        "            dst = dist(pSrc[i],pDet[j])\n",
        "            if dst>=separations[0] and dst<=separations[1]:  # separation filter\n",
        "                ml.append([i+1,j+1])\n",
        "    return np.array(ml)\n",
        "\n",
        "\n",
        "def hdf5_prune(hdf5,separations,intensities,SNRthresh,det2prune=[],suffix='prune',overwrite=False):\n",
        "    \"\"\"\n",
        "Prunes an hdf5 structure using 3-4 parameters, storing the results\n",
        "in outname. If outname==None, the existing .h5 suffix (-raw or -preproc\n",
        "or whatever is replaced with -prune).\n",
        "\n",
        "hdf5_prune(hdf5,separations,intensities,SNRthresh,det2prune=[],outname=None,overwrite=False)\n",
        "    hdf5 = pytables/hdf5 structure\n",
        "    separations = [minseparation,maxseparation] in centimeters ... [2 8]\n",
        "    intensities = [minintensity,maxintensity] in optical watts ... [0 1e-9]\n",
        "    SNRthresh = signal-to-noise threshold  ... e.g., 3\n",
        "    det_to_prune = detectors to remove entirely from the\n",
        "                   measurement list (DEFAULT=[])\n",
        "    outname = output filename; None --> inname-prune.h5\n",
        "\"\"\"\n",
        "    # determine output filename\n",
        "    inname = hdf5.filename\n",
        "    outname = addsuffix(inname,suffix)\n",
        "\n",
        "    # get a copy of the input file to operate on\n",
        "    h5 = create_new_hdf5_file(hdf5,outname=outname,overwrite=overwrite)\n",
        "\n",
        "    data = h5.root.d[:]\n",
        "    ml = h5.root.ml[:]\n",
        "    pSrc = h5.root.pSrc[:]\n",
        "    pDet = h5.root.pDet[:]\n",
        "\n",
        "    # check if intensities were provided in wrong order\n",
        "    if intensities[0]>intensities[1]:\n",
        "        # if wrong order, swap them\n",
        "        intensities[0],intensities[1] = intensities[1],intensities[0]\n",
        "\n",
        "    cnt = 0\n",
        "    origmeas = data.shape[1]\n",
        "    halforigmeas = int(origmeas/2.)\n",
        "    dc1 = []\n",
        "    dc2 = []\n",
        "    mlc1 = []\n",
        "    mlc2 = []\n",
        "    for i in range(halforigmeas,origmeas):  # look at 2nd set of measuremnts (690s?)\n",
        "        spos = pSrc[ml[i,0]-1,:]\n",
        "        dpos = pDet[ml[i,1]-1,:]\n",
        "        dist = np.sqrt(np.sum((spos-dpos)*(spos-dpos)))\n",
        "        if dist>=separations[0] and dist<=separations[1]:  # separation filter\n",
        "            mn = np.mean(np.abs(data[:,i]))\n",
        "            if mn>=intensities[0] and mn<=intensities[1]:  # intensity filter\n",
        "                snr = mn/np.std(np.abs(data[:,i]))\n",
        "                if snr > SNRthresh:    # SNR filter\n",
        "                    cnt += 1\n",
        "                    dc1.append(data[:,i-halforigmeas])  # gets a vector (interpreted as a row)\n",
        "                    dc2.append(data[:,i])\n",
        "                    mlc1.append(ml[i-halforigmeas,:])\n",
        "                    mlc2.append(ml[i,:])\n",
        "    dc1 = np.array(dc1)  # so this is Meas x Time now (whereas data was Time x Meas)\n",
        "    dc2 = np.array(dc2)\n",
        "    d = np.concatenate((dc1,dc2),0)\n",
        "    d = np.transpose(d)\n",
        "    ml = np.vstack((np.array(mlc1),np.array(mlc2)))\n",
        "\n",
        "    # whole-detector filter\n",
        "    for i in range(len(det2prune)):\n",
        "        keepindices = pylab.find(ml[:,1] != det2prune[i])\n",
        "        print(keepindices)\n",
        "        d = d[keepindices,:]\n",
        "        ml = ml[keepindices,:]\n",
        "\n",
        "    # delete existing d and ml variables\n",
        "    hdf5_delete_nodes(h5,'d','ml')\n",
        "\n",
        "    # stick results into hdf5 structure\n",
        "    h5.createArray(h5.root, 'd', d, 'Pruned data')\n",
        "    h5.createArray(h5.root, 'ml', ml, 'Pruned measurement list')\n",
        "\n",
        "    # update history log\n",
        "    thishist = time.asctime()+\": hdf5_prune('%s', separations=%s, intensities=%s, SNRthresh=%s, det2prune=%s, outname='%s')\\n\"%(inname,str(separations),str(intensities),str(SNRthresh),str(det2prune),outname)\n",
        "    addtohist(h5,thishist)\n",
        "\n",
        "    return h5\n",
        "\n",
        "\n",
        "def hdf5_filt(hdf5,fhp=0,regressSD=None,adapfilt=None,suffix='filt',overwrite=False):\n",
        "    \"\"\"\n",
        "A function to do highpass/motion/regression filtering.\n",
        "\n",
        "* If fhp!=0, performs a highpass filter at given cutoff (e.g., 1/128. sec)\n",
        "* If regressSD!=None, regresses the passed [src,det] pair data against\n",
        "each channel in d and removes the result.\n",
        "* If adapfilt!=None, it must be hold 3 elements [src,det,H], where src-det is\n",
        "the pair to use as a reference, and H is the starting number and value\n",
        "of nodes (typically: [1,0,0,0...] and perhaps 100-200 nodes at 10Hz).\n",
        "\n",
        "h5.root.d = Time X Measurements array\n",
        "h5.root.t = time base for data\n",
        "\n",
        "Usage:   hdf5_filt(hdf5,fhp=0,regressSD=None,adapfilt=None,suffix='filt',overwrite=False)\n",
        "Returns: None (hdf5 modified in-place)\n",
        "\"\"\"\n",
        "    # determine output filename\n",
        "    inname = hdf5.filename\n",
        "    outname = addsuffix(inname,suffix)\n",
        "\n",
        "    # get a copy of the input file to operate on\n",
        "    h5 = create_new_hdf5_file(hdf5,outname=outname,overwrite=overwrite)\n",
        "\n",
        "    d = h5.root.d[:]\n",
        "    t = h5.root.t[:]\n",
        "    ml = h5.root.ml[:]\n",
        "\n",
        "    if fhp != 0:\n",
        "        print(\"High-pass filtering and adding means back in.\")\n",
        "        means = np.mean(d,0)\n",
        "        rate = 1./(t[1]-t[0])\n",
        "        d = hipassND(d,fhp,rate)\n",
        "        d = d + means\n",
        "\n",
        "    if regressSD is not None:\n",
        "        print(\"Regressing out SD-pair: %s\" % str(regressSD))\n",
        "        idx = getidx(regressSD[0],regressSD[1],ml)[0] # regress=[src,det]\n",
        "        print(regressSD, idx)\n",
        "        ref1 = d[:,idx[0]]  # get reference timeseries for 690/HHb\n",
        "        ref1 = ref1 -ref1.mean()\n",
        "        ref1.shape = (len(ref1),1)\n",
        "        ref2 = d[:,idx[1]]  # get reference timeseries for 830/O2Hb\n",
        "        ref2 = ref2 -ref2.mean()\n",
        "        ref2.shape = (len(ref2),1)\n",
        "        print(ref1.shape, ref2.shape, d.shape)\n",
        "        nd = np.zeros(d.shape,np.float)\n",
        "        half = len(ml)/2\n",
        "        for i in range(half):\n",
        "            fm1 = regress(ref1,d[:,i]) # 690/HHb\n",
        "            nd[:,i] = fm1[1]\n",
        "            fm2 = regress(ref2,d[:,i+half]) # 830/O2Hb\n",
        "            nd[:,i+half] = fm2[1]\n",
        "        d = nd  # replace d in case AF is also requested\n",
        "\n",
        "    if adapfilt is not None:\n",
        "        print(\"Adaptive filtering using SD-pair: %s\" % str(adapfilt[:2]))\n",
        "        idx = getidx(adapfilt[0],adapfilt[1],ml)[0] # reference=[src,det]\n",
        "        print(adapfilt[:2], idx, adapfilt[2].shape)\n",
        "        ref1 = d[:,idx[0]]  # get reference timeseries for 690/HHb\n",
        "        ref1 = ref1 -ref1.mean()\n",
        "        ref2 = d[:,idx[1]]  # get reference timeseries for 830/O2Hb\n",
        "        ref2 = ref2 -ref2.mean()\n",
        "        print(ref1.shape, ref2.shape, d.shape)\n",
        "        nd = np.zeros(d.shape,np.float)\n",
        "        half = len(ml)/2\n",
        "        for i in range(half):\n",
        "            if i%10==0:\n",
        "                print(\"  Adaptive filtering index: %i / %i\" %(i,half))\n",
        "            yy,H2 = AF(ref1,d[:,i],adapfilt[2]) # 690/HHb\n",
        "            yfinal,H2 = AF(ref1,d[:,i],H2[:,-1]) # re-filter with better starting point\n",
        "            nd[:,i] = np.ravel(yfinal)\n",
        "            yy,H2 = AF(ref2,d[:,i+half],adapfilt[2]) # 690/HHb\n",
        "            yfinal,H2 = AF(ref2,d[:,i+half],H2[:,-1]) # re-filter with better starting point\n",
        "            nd[:,i+half] = np.ravel(yfinal)\n",
        "        d = nd  # replace d in case AF is also requested\n",
        "\n",
        "\n",
        "    # delete existing d variable and put it back in\n",
        "    hdf5_delete_nodes(h5,'d')\n",
        "    h5.createArray(h5.root, 'd', d,'Filtered data')\n",
        "\n",
        "    # update history log\n",
        "    thishist = time.asctime()+\": hdf5_filt(inname='%s',fhp=%s,regressSD=%s,AF=%s,outname='%s')\\n\"%(inname,str(fhp),str(regressSD),str(AF),outname)\n",
        "    addtohist(h5,thishist)\n",
        "\n",
        "    return h5\n",
        "\n",
        "\n",
        "def hdf5_makeOD(hdf5,baseline=None, suffix='OD',overwrite=False):\n",
        "    \"\"\"\n",
        "makeOD(hdf5struct, baseline=None, suffix='OD',overwrite=False)\n",
        "\n",
        "    data = offset corrected data (TIME x CHAN)\n",
        "    baseline = indices into data (e.g., integer number-of-points from start,\n",
        "    OR 1D list of indices into data to use, OR data used to calc mean OR None\n",
        "    to use entire dataset mean. Default = None.\n",
        "    outname = output filename (default=inname+'-OD.h5')\n",
        "\"\"\"\n",
        "    # determine output filename\n",
        "    inname = hdf5.filename\n",
        "    outname = addsuffix(inname,suffix)\n",
        "\n",
        "    # get a copy of the input file to operate on\n",
        "    h5 = create_new_hdf5_file(hdf5,outname=outname,overwrite=overwrite)\n",
        "    data = h5.root.d[:]  # if none, use raw data\n",
        "\n",
        "    if baseline == None:\n",
        "        baseline = np.mean(data,0)\n",
        "    elif type(baseline)==int:\n",
        "        baseline = np.mean(data[:baseline],0)\n",
        "    elif type(baseline)==list:  # must be indices\n",
        "        baseline = np.mean(data[baseline],0)\n",
        "    elif len(baseline.shape) == 2:  # must be data\n",
        "        baseline = np.mean(baseline,0)\n",
        "    else:\n",
        "        print(\"Not appropriate size/shape for baseline in makeOD\")\n",
        "        return\n",
        "\n",
        "    # now calculate OD\n",
        "    normalized_fluence = (1./baseline)*data\n",
        "    ODdata = -np.log(normalized_fluence)\n",
        "\n",
        "    # delete existing d variable\n",
        "    hdf5_delete_nodes(h5,'d')\n",
        "\n",
        "    # stick results onto hdf5 structure\n",
        "    h5.createArray(h5.root, 'd', ODdata,'OD data')\n",
        "    h5.createArray(h5.root, 'baseline', baseline, 'Baseline used for OD conversion')\n",
        "\n",
        "    # update history log\n",
        "    baselinestr = str(baseline)\n",
        "    if len(baselinestr)>100:\n",
        "        baselinestr = baselinestr[:100]+' ...'\n",
        "    thishist = time.asctime()+\": hdf5_makeOD('%s', baseline=%s, outname='%s')\\n\"%(inname,baselinestr,outname)\n",
        "    addtohist(h5,thishist)\n",
        "\n",
        "    return h5\n",
        "\n",
        "\n",
        "def hdf5_od2hbhbo_bls(hdf5, wavelengths, BLs, suffix='HB',overwrite=False):\n",
        "    \"\"\"\n",
        "Uses od2hbhbo_bls to convert each channel of a hdf5 dataset IN-PLACE!\n",
        "\n",
        "Usage:   hdf5_od2hbhbo_bls(hdf5, wavelengths, BLs, suffix='HB',overwrite=False)\n",
        "Returns: h5 file handle\n",
        "\"\"\"\n",
        "    # determine output filename\n",
        "    inname = hdf5.filename\n",
        "    outname = addsuffix(inname,suffix)\n",
        "\n",
        "    # get a copy of the input file to operate on\n",
        "    h5 = create_new_hdf5_file(hdf5,outname=outname,overwrite=overwrite)\n",
        "    data = h5.root.d[:]\n",
        "\n",
        "    half = int(data.shape[1]/2.)\n",
        "    hbdata = np.zeros((data.shape[0],half),dtype=np.float)\n",
        "    hbodata = np.zeros((data.shape[0],half),dtype=np.float)\n",
        "    for i in range(half):\n",
        "        tmp = np.vstack((data[:,i],data[:,i+half]))\n",
        "        tmp = od2hbhbo_bls(tmp,wavelengths,BLs)\n",
        "        hbdata[:,i] = tmp[:,0]\n",
        "        hbodata[:,i] = tmp[:,1]\n",
        "\n",
        "    # delete existing d variable\n",
        "    hdf5_delete_nodes(h5,'d')\n",
        "\n",
        "    # stick results onto hdf5 structure\n",
        "    h5.createArray(h5.root,'d',np.concatenate((hbdata,hbodata),1),'HbHbO data')\n",
        "    h5.createArray(h5.root, 'hhb', hbdata, 'Deoxy-hb data')\n",
        "    h5.createArray(h5.root, 'o2hb', hbodata, 'Oxy-hb data')\n",
        "\n",
        "    # update history log\n",
        "    thishist = time.asctime()+\": hdf5_od2hbhbo_BLs('%s', wavelengths=%s, BLs=%s, outname='%s')\\n\"%(inname,str(wavelengths),str(BLs),outname)\n",
        "    addtohist(h5,thishist)\n",
        "\n",
        "    return h5\n",
        "\n",
        "\n",
        "def hdf5_easyavg(hdf5,onsets,preseconds=-5,postseconds=25,suffix='avg',overwrite=False):\n",
        "    \"\"\"\n",
        "Chops up hdf5.root.d into chunks based on onset times and the size of\n",
        "the chunk (pre- and post-onset time) you request. Flattens the onset\n",
        "list, if it is 2D(!!).\n",
        "\n",
        "Usage:   hdf5_easyavg(hdf5,onsets,preseconds=-5,postseconds=25,suffix='avg',overwrite=False)\n",
        "Returns: h5 file handle\n",
        "\"\"\"\n",
        "    # determine output filename\n",
        "    inname = hdf5.filename\n",
        "    outname = addsuffix(inname,suffix)\n",
        "\n",
        "    # get a copy of the input file to operate on\n",
        "    h5 = create_new_hdf5_file(hdf5,outname=outname,overwrite=overwrite)\n",
        "    d = h5.root.d[:]\n",
        "    t = h5.root.t[:]\n",
        "    rate = 1./(t[1]-t[0])\n",
        "\n",
        "    ravelonsets = []\n",
        "    for item in onsets:\n",
        "        if type(item) in [list,tuple]:\n",
        "            ravelonsets += item\n",
        "        else:\n",
        "            ravelonsets += [item]\n",
        "    onsets = np.array(ravelonsets)\n",
        "    onsetindices = np.round(onsets*rate).astype(np.int)  # convert to points\n",
        "\n",
        "    prepoints = np.floor(abs(preseconds)*rate)\n",
        "    postpoints = np.floor(postseconds*rate)\n",
        "    totalpoints = prepoints+postpoints\n",
        "    outdata = [] #np.zeros(totalpoints,d.shape[1]);\n",
        "    for i in range(len(onsetindices)):\n",
        "        if (onsetindices[i]-prepoints>0) and (onsetindices[i]+postpoints<d.shape[0]):\n",
        "            cut = d[onsetindices[i]-prepoints:onsetindices[i]+postpoints,:]\n",
        "            outdata.append(cut)\n",
        "    N = len(outdata)\n",
        "    outdata = np.array(outdata)\n",
        "    outt = np.arange(totalpoints)/float(rate) -abs(preseconds)\n",
        "\n",
        "    # delete existing d,t variables\n",
        "    hdf5_delete_nodes(h5,'d')\n",
        "    hdf5_delete_nodes(h5,'t')\n",
        "\n",
        "    # stick results onto hdf5 structure\n",
        "    h5.createArray(h5.root,'d',outdata.mean(0),'Avg data; N=%i' %N)\n",
        "    h5.createArray(h5.root,'slices',outdata,'Individual cuts of data prior to averaging')\n",
        "    h5.createArray(h5.root,'t',outt,'Timebase for average/slices')\n",
        "\n",
        "    # update history log\n",
        "    thishist = time.asctime()+\": hdf5_easyavg('%s', onsets=%s, preseconds=%s, postseconds=%s, outname='%s')\\n\"%(inname,str(onsets),str(preseconds),str(postseconds),outname)\n",
        "    addtohist(h5,thishist)\n",
        "\n",
        "    return h5\n",
        "\n",
        "\n",
        "def hdf5_snrs(h5):\n",
        "    \"\"\"\n",
        "Computes the SNR for the passed-in data hdf5 structure, saving\n",
        "the results as h5.root.snrs\n",
        "\n",
        "Usage:   hdf5_snrs(h5)\n",
        "Returns: None   (h5 modified in-place)\n",
        "\"\"\"\n",
        "    snrs = h5.root.d[:].mean(0) / h5.root.d[:].std(0)\n",
        "    h5.createArray(h5.root, 'snrs', snrs, 'SNR of raw data')\n",
        "    return\n",
        "\n",
        "\n",
        "def hdf5_c1vsc2(h5,factor=1.0):\n",
        "    \"\"\"\n",
        "Determines which channels have mean c1 > (factor*c2). Assumes\n",
        "the first half of the measurements are color1 and the second\n",
        "half are color2. Puts results as h5.root.c1vsc2.\n",
        "\n",
        "Usage:   hdf5_c1vsc2(h5,factor=1.0)\n",
        "Returns: None   (h5 modified in-place)\n",
        "\"\"\"\n",
        "    d = h5.root.d[:]\n",
        "    md = d.mean(0)\n",
        "    half = len(md)/2\n",
        "    test = (md[:half]>factor*md[half:])*1\n",
        "    h5.createArray(h5.root,'c1vsc2',np.concatenate((test,test)),'C1>C2')\n",
        "    return\n",
        "\n",
        "\n",
        "################## HOMER FUNCTIONS ####################\n",
        "\n",
        "def easyavg(d,t,onsets,preseconds=-5,postseconds=25):\n",
        "    \"\"\"\n",
        "Chops up d into chunks based on onset times and the size of\n",
        "the chunk (pre- and post-onset time) you request. Flattens the onset\n",
        "list, if it is 2D(!!).\n",
        "\n",
        "Usage:   easyavg(d,t,onsets,preseconds=-5,postseconds=25)\n",
        "Returns: avgd, avgt\n",
        "\"\"\"\n",
        "    rate = 1./(t[1]-t[0])\n",
        "\n",
        "    ravelonsets = []\n",
        "    for item in onsets:\n",
        "        if type(item) in [list,tuple]:\n",
        "            ravelonsets += item\n",
        "        else:\n",
        "            ravelonsets += [item]\n",
        "    onsets = np.array(ravelonsets)\n",
        "    onsetindices = np.round(onsets*rate).astype(np.int)  # convert to points\n",
        "\n",
        "    prepoints = np.floor(abs(preseconds)*rate)\n",
        "    postpoints = np.floor(postseconds*rate)\n",
        "    totalpoints = prepoints+postpoints\n",
        "    outdata = []     #np.zeros(totalpoints,d.shape[1]);\n",
        "    for i in range(len(onsetindices)):\n",
        "        if (onsetindices[i]-prepoints>0) and (onsetindices[i]+postpoints<d.shape[0]):\n",
        "            cut = d[onsetindices[i]-prepoints:onsetindices[i]+postpoints,:]\n",
        "            outdata.append(cut)\n",
        "    N = len(outdata)\n",
        "    outdata = np.array(outdata)\n",
        "    outt = np.arange(totalpoints)/float(rate) -abs(preseconds)\n",
        "\n",
        "    return outdata,outt\n",
        "\n",
        "\n",
        "\n",
        "def homer_preprocess(d,t,flp=3,fhp=1/60.):\n",
        "    \"\"\"\n",
        "A function to preprocess homer-style data variables\n",
        "(that is TIME x MEASUREMENTS)\n",
        "\n",
        "data  = Time X Measurements array\n",
        "t = time base for data\n",
        "\n",
        "Process: load raw data\n",
        "         take ABS() to blow away any phase information\n",
        "         \"fix\" initial 6 timepoints\n",
        "         \"fix\" final 3 timepoints\n",
        "         lowpass at flp (DEFAULT=3 Hz)\n",
        "         hipass at FHP (DEFAULT=1/60 Hz), use 0 to skip highpass filtering\n",
        "         add back in the mean signal values\n",
        "         plot (if requested)\n",
        "         save prefix-pp.mat (if requested)\n",
        "\n",
        "Usage:   homer_preprocess(data,t,flp=3,fhp=1/60.)\n",
        "Returns: d = [time x channels], lowpass then hipass filtered\n",
        "\"\"\"\n",
        "    # Blow away phase\n",
        "    print(\"Taking abs() of all data.\")\n",
        "    d = np.abs(d)\n",
        "\n",
        "    rate = 1. / (t[1]-t[0])\n",
        "\n",
        "    print(\"Fixing initial 6 timepoints.\")\n",
        "    mn = np.mean(d[6:17,:],0)\n",
        "    d[:6,:] = mn\n",
        "\n",
        "    print(\"Fixing final 3 timepoints.\")\n",
        "    for i in range(-3,0):\n",
        "        d[i,:] = np.mean(d[-13:-4,:],0)\n",
        "\n",
        "    print(\"Low-pass filtering.\")\n",
        "    dlp = lowpass(d,flp,rate)\n",
        "\n",
        "    if fhp != 0:\n",
        "        print(\"High-pass filtering and adding means back in.\")\n",
        "        means = np.mean(dlp,0)\n",
        "        dlphp = hipassND(dlp,fhp,rate)\n",
        "        dlphp = dlphp + means\n",
        "        return dlphp\n",
        "    else:\n",
        "        return dlp\n",
        "\n",
        "\n",
        "def homer_preprocess_mat(fname,flp=3,fhp=1/60.,suffix='-pp'):\n",
        "    \"\"\"\n",
        "A function to preprocess homer-style data FILES.\n",
        "\n",
        "Process: load raw data\n",
        "         take ABS() to blow away any phase information\n",
        "         \"fix\" initial 6 timepoints\n",
        "         \"fix\" final 3 timepoints\n",
        "         lowpass at flp (DEFAULT=3 Hz)\n",
        "         hipass at FHP (DEFAULT=1/60 Hz), use 0 to skip highpass filtering\n",
        "         add back in the mean signal values\n",
        "         plot (if requested)\n",
        "         save prefix-pp.mat (if requested)\n",
        "\n",
        "Usage:   homer_preprocess_mat(fname,flp=3,fhp=1/60.,suffix='-pp')\n",
        "Returns: d = [time x channels] which has been lowpass then hipass filtered\n",
        "\"\"\"\n",
        "    d,t,aux10,ml,gains = read_homer_mat(fname)\n",
        "    d = homer_preprocess(d,t,flp,fhp)\n",
        "    tmpdic = {'d':d, 't':t, 'aux10':aux10, 'ml':ml, 'gains':gains}\n",
        "    outname = fname[:fname.rfind('.')] +suffix\n",
        "    scipy.io.savemat(outname,tmpdic,appendmat=True)\n",
        "    return d\n",
        "\n",
        "\n",
        "def homer_preprocess_npz(fname,flp=3,fhp=1/60.,suffix='-pp'):\n",
        "    \"\"\"\n",
        "A function to preprocess homer-style data FILES.\n",
        "\n",
        "Process: load raw data\n",
        "         take ABS() to blow away any phase information\n",
        "         \"fix\" initial 6 timepoints\n",
        "         \"fix\" final 3 timepoints\n",
        "         lowpass at flp (DEFAULT=3 Hz)\n",
        "         hipass at FHP (DEFAULT=1/60 Hz), use 0 to skip highpass filtering\n",
        "         add back in the mean signal values\n",
        "         plot (if requested)\n",
        "         save prefix-pp.npz (if requested)\n",
        "\n",
        "Usage:   homer_preprocess_mat(fname,flp=3,fhp=1/60.,suffix='-pp')\n",
        "Returns: d = [time x channels] which has been lowpass then hipass filtered\n",
        "\"\"\"\n",
        "    d,t,ml,aux10,gains,rate,timestamp,lambdas = read_homer_npz(fname)\n",
        "    d = homer_preprocess(d,t,flp,fhp)\n",
        "    tmpdic = {'d':d, 't':t, 'aux10':aux10, 'ml':ml, 'gains':gains}\n",
        "    outname = fname[:fname.rfind('.')] +suffix\n",
        "    np.savez(outname,kw=tmpdic)\n",
        "    return d\n",
        "\n",
        "\n",
        "def homer_prune(data,ml,pSrc,pDet,separations,intensities,SNRthresh,det2prune=[]):\n",
        "    \"\"\"\n",
        "Prunes a homer-style datafile (in prefix), on 3 parameters, saving data\n",
        "in prefix+suffix file\n",
        "\n",
        "d,ml = homer_prune(data,ml,pSrc,pDet,separations,intensities,\n",
        "                      SNRthresh,det_to_prune=[])\n",
        "\n",
        "    prefix = everything before the . in the cw5tohomer .MAT file output\n",
        "    geometryfcn = file containing the source/detector positions ('longstrip_sd')\n",
        "    separations = [minseparation,maxseparation] in centimeters ... [2 8]\n",
        "    intensities = [minintensity,maxintensity] in optical watts ... [0 1e-9]\n",
        "    SNRthresh = signal-to-noise threshold  ... e.g., 3\n",
        "    det_to_prune = detectors to remove entirely from the\n",
        "                   measurement list (DEFAULT=[])\n",
        "\"\"\"\n",
        "    pSrc = np.array(pSrc)\n",
        "    pDet = np.array(pDet)\n",
        "\n",
        "    if intensities[0]>intensities[1]:\n",
        "        # if wrong order, swap them\n",
        "        intensities[0],intensities[1] = intensities[1],intensities[0]\n",
        "\n",
        "    cnt = 0\n",
        "    origmeas = data.shape[1]\n",
        "    halforigmeas = int(origmeas/2.)\n",
        "    dc1 = []\n",
        "    dc2 = []\n",
        "    mlc1 = []\n",
        "    mlc2 = []\n",
        "    for i in range(halforigmeas,origmeas):  # look at 2nd set of measuremnts (690s?)\n",
        "        spos = pSrc[ml[i,0]-1,:]\n",
        "        dpos = pDet[ml[i,1]-1,:]\n",
        "        dist = np.sqrt(np.sum((spos-dpos)*(spos-dpos)))\n",
        "        if dist>=separations[0] and dist<=separations[1]:  # separation filter\n",
        "            mn = np.mean(np.abs(data[:,i]))\n",
        "            if mn>=intensities[0] and mn<=intensities[1]:  # intensity filter\n",
        "                snr = mn/np.std(np.abs(data[:,i]))\n",
        "                if snr > SNRthresh:    # SNR filter\n",
        "                    cnt += 1\n",
        "                    dc1.append(data[:,i-halforigmeas])  # gets a vector (interpreted as a row)\n",
        "                    dc2.append(data[:,i])\n",
        "                    mlc1.append(ml[i-halforigmeas,:])\n",
        "                    mlc2.append(ml[i,:])\n",
        "    dc1 = np.array(dc1)  # so this is Meas x Time now (whereas data was Time x Meas)\n",
        "    dc2 = np.array(dc2)\n",
        "#    print dc1.shape, dc2.shape\n",
        "    d = np.concatenate((dc1,dc2),0)\n",
        "    ml = np.vstack((np.array(mlc1),np.array(mlc2)))\n",
        "    d = np.transpose(d)\n",
        "    print(\"Final pruned size (TIME x MEAS):\",d.shape)\n",
        "\n",
        "    # whole-detector filter\n",
        "    for i in range(len(det2prune)):\n",
        "        keepindices = pylab.find(ml[:,1] != det2prune[i])\n",
        "        print(keepindices)\n",
        "        d = d[keepindices,:]\n",
        "        ml = ml[keepindices,:]\n",
        "\n",
        "    return d, ml\n",
        "\n",
        "\n",
        "def homer_filt(d,t,ml,fhp=0,regressSD=None,adapfilt=None):\n",
        "    \"\"\"\n",
        "A function to do highpass/motion/regression filtering.\n",
        "\n",
        "* If fhp!=0, performs a highpass filter at given cutoff (e.g., 1/128. sec)\n",
        "* If regressSD!=None, regresses the passed [src,det] pair data against\n",
        "each channel in d and removes the result.\n",
        "* If adapfilt!=None, it must be hold 3 elements [src,det,H], where src-det is\n",
        "the pair to use as a reference, and H is the starting number and value\n",
        "of nodes (typically: [1,0,0,0...] and perhaps 100-200 nodes at 10Hz).\n",
        "\n",
        "h5.root.d = Time X Measurements array\n",
        "h5.root.t = time base for data\n",
        "\n",
        "Usage:   homer_filt(d,t,ml,fhp=0,regressSD=None,adapfilt=None,suffix='filt',overwrite=False)\n",
        "Returns: d (filtered)\n",
        "\"\"\"\n",
        "    if fhp != 0:\n",
        "        print(\"High-pass filtering and adding means back in.\")\n",
        "        means = np.mean(d,0)\n",
        "        rate = 1./(t[1]-t[0])\n",
        "        d = hipassND(d,fhp,rate)\n",
        "        d = d + means\n",
        "\n",
        "    if regressSD is not None:\n",
        "        print(\"Regressing out SD-pair: %s\" % str(regressSD))\n",
        "        idx = getidx(regressSD[0],regressSD[1],ml)[0] # regress=[src,det]\n",
        "        print(regressSD, idx)\n",
        "        ref1 = d[:,idx[0]]  # get reference timeseries for 690/HHb\n",
        "        ref1 = ref1 -ref1.mean()\n",
        "        ref1.shape = (len(ref1),1)\n",
        "        ref2 = d[:,idx[1]]  # get reference timeseries for 830/O2Hb\n",
        "        ref2 = ref2 -ref2.mean()\n",
        "        ref2.shape = (len(ref2),1)\n",
        "        print(ref1.shape, ref2.shape, d.shape)\n",
        "        nd = np.zeros(d.shape,np.float)\n",
        "        half = len(ml)/2\n",
        "        for i in range(half):\n",
        "            fm1 = regress(ref1,d[:,i]) # 690/HHb\n",
        "            nd[:,i] = fm1[1]\n",
        "            fm2 = regress(ref2,d[:,i+half]) # 830/O2Hb\n",
        "            nd[:,i+half] = fm2[1]\n",
        "        d = nd  # replace d in case AF is also requested\n",
        "\n",
        "    if adapfilt is not None:\n",
        "        print(\"Adaptive filtering using SD-pair: %s\" % str(adapfilt[:2]))\n",
        "        idx = getidx(adapfilt[0],adapfilt[1],ml)[0] # reference=[src,det]\n",
        "        print(adapfilt[:2], idx, adapfilt[2].shape)\n",
        "        ref1 = d[:,idx[0]]  # get reference timeseries for 690/HHb\n",
        "        ref1 = ref1 -ref1.mean()\n",
        "        ref2 = d[:,idx[1]]  # get reference timeseries for 830/O2Hb\n",
        "        ref2 = ref2 -ref2.mean()\n",
        "        print(ref1.shape, ref2.shape, d.shape)\n",
        "        nd = np.zeros(d.shape,np.float)\n",
        "        half = len(ml)/2\n",
        "        for i in range(half):\n",
        "            if i%10==0:\n",
        "                print(\"  Adaptive filtering index: %i / %i\" %(i,half))\n",
        "            yy,H2 = AF(ref1,d[:,i],adapfilt[2]) # 690/HHb\n",
        "            yfinal,H2 = AF(ref1,d[:,i],H2[:,-1]) # re-filter with better starting point\n",
        "            nd[:,i] = np.ravel(yfinal)\n",
        "            yy,H2 = AF(ref2,d[:,i+half],adapfilt[2]) # 690/HHb\n",
        "            yfinal,H2 = AF(ref2,d[:,i+half],H2[:,-1]) # re-filter with better starting point\n",
        "            nd[:,i+half] = np.ravel(yfinal)\n",
        "        d = nd  # replace d in case AF is also requested\n",
        "\n",
        "    return d\n",
        "\n",
        "\n",
        "def pruneall_by_dist(pSrc,pDet,minmax_separations,return_dist=False):\n",
        "    \"\"\"\n",
        "Prunes a list of source and detector positions according to their separations\n",
        "and returns the resulting measurement list ... [src#, det#\n",
        "                                                src#, det#\n",
        "                                                etc.]\n",
        "\n",
        "ml = pruneall_by_dist(pSrc,pDet,minmax_separations,return_dist=False)\n",
        "\n",
        "    pSrc = list of [x,y,z] positions of source fibers\n",
        "    pDet = list of [x,y,z] positions of detector fibers\n",
        "    separations = [minseparation,maxseparation] in units of pSrc/pDet... [2 8]\n",
        "    return_dist = put distance between this pair in last column\n",
        "\"\"\"\n",
        "    pSrc = np.array(pSrc)\n",
        "    pDet = np.array(pDet)\n",
        "\n",
        "    ml = []\n",
        "    for i in range(len(pSrc)):\n",
        "        for j in range(len(pDet)):\n",
        "            spos = pSrc[i,:]\n",
        "            dpos = pDet[j,:]\n",
        "            dist = np.sqrt(np.sum((spos-dpos)*(spos-dpos)))\n",
        "            if dist>=separations[0] and dist<=separations[1]:  # separation filter\n",
        "                if return_dist:\n",
        "                    ml.append([i+1,j+1,dist])\n",
        "                else:\n",
        "                    ml.append([i+1,j+1])\n",
        "    return np.array(ml)\n",
        "\n",
        "\n",
        "def pruneml_by_dist(ml,pSrc,pDet,minmax_separations,return_dist=False):\n",
        "    \"\"\"\n",
        "Prunes a list of source and detector positions according to their separations\n",
        "and returns the resulting measurement list ... [src#, det#\n",
        "                                                src#, det#\n",
        "                                                etc.]\n",
        "\n",
        "ml = pruneml_by_dist(ml,pSrc,pDet,minmax_separations,return_dist=False)\n",
        "\n",
        "    ml = current measurement list (potentially pre-pruned)\n",
        "    pSrc = list of [x,y,z] positions of source fibers\n",
        "    pDet = list of [x,y,z] positions of detector fibers\n",
        "    separations = [minseparation,maxseparation] in units of pSrc/pDet... [2 8]\n",
        "    return_dist = put distance between this pair in last column\n",
        "\"\"\"\n",
        "    pSrc = np.array(pSrc)\n",
        "    pDet = np.array(pDet)\n",
        "\n",
        "    newml = []\n",
        "    for src,det in ml:\n",
        "        spos = pSrc[src,:]\n",
        "        dpos = pDet[det,:]\n",
        "        dist = np.sqrt(np.sum((spos-dpos)*(spos-dpos)))\n",
        "        if dist>=separations[0] and dist<=separations[1]:  # separation filter\n",
        "            if return_dist:\n",
        "                newml.append([src,det,dist])\n",
        "            else:\n",
        "                newml.append([src,det])\n",
        "    return np.array(newml)\n",
        "\n",
        "\n",
        "def ml_to_channels(pSrc,pDet,ml):\n",
        "    \"\"\"\n",
        "    Convert src positions, detector positions, and a measurement list to an\n",
        "array of channel positions (midpoints between each measurement list SD pair).\n",
        "\n",
        "Usage:   ml_to_channels(pSrc,pDet,ml)\n",
        "Returns: pChan\n",
        "\"\"\"\n",
        "    pChan = []\n",
        "    for row in ml:\n",
        "        psrc = pSrc[row[0]-1,:]\n",
        "        pdet = pDet[row[1]-1,:]\n",
        "        midpt = (psrc+pdet)/2.\n",
        "        pChan.append(midpt)\n",
        "    return np.array(pChan)\n",
        "\n",
        "\n",
        "def homer_prune_mat(inname,pSrc,pDet,separations,intensities,SNRthresh,det2prune=[],suffix='-prune'):\n",
        "    \"\"\"\n",
        " [d,ml] = homer_prune_mat(inname,ml,pSrc,pDet,separations,intensities,\n",
        "                      SNRthresh,det_to_prune=[],outname=None)\n",
        "\n",
        "Prunes a homer-style datafile (in inname), on 3 parameters, saving data\n",
        "in prefix+suffix file\n",
        "\n",
        "    prefix = everything before the . in the cw5tohomer .MAT file output\n",
        "    geometryfcn = file containing the source/detector positions ('longstrip_sd')\n",
        "    separations = [minseparation,maxseparation] in centimeters ... [2 8]\n",
        "    intensities = [minintensity,maxintensity] in optical watts ... [0 1e-9]\n",
        "    SNRthresh = signal-to-noise threshold  ... e.g., 3\n",
        "    det_to_prune = detectors to remove entirely from the\n",
        "                   measurement list (defaults to [])\n",
        "    suffix = suffix for output file (DEFAULT='-prune')\n",
        "\"\"\"\n",
        "    d,t,aux10,ml,gains = read_homer_mat(inname)\n",
        "    d,ml = homer_prune(d,ml,pSrc,pDet,separations,intensities,SNRthresh,[])\n",
        "    tmpdic = {'d':d.T, 't':t, 'aux10':aux10, 'ml':ml, 'gains':gains}\n",
        "    outname = inname[:inname.rfind('.')] +suffix\n",
        "    scipy.io.savemat(outname,tmpdic,appendmat=True)\n",
        "    return d.T, ml\n",
        "\n",
        "\n",
        "def homer_prune_npz(inname,pSrc,pDet,separations,intensities,SNRthresh,det2prune=[],suffix='-prune'):\n",
        "    \"\"\"\n",
        " [d,ml] = homer_prune_npz(inname,ml,pSrc,pDet,separations,intensities,\n",
        "                      SNRthresh,det_to_prune=[],outname=None)\n",
        "\n",
        "Prunes a homer-style datafile (in inname), on 3 parameters, saving data\n",
        "in prefix+suffix file\n",
        "\n",
        "    prefix = everything before the . in the cw5tohomer .MAT file output\n",
        "    geometryfcn = file containing the source/detector positions ('longstrip_sd')\n",
        "    separations = [minseparation,maxseparation] in centimeters ... [2 8]\n",
        "    intensities = [minintensity,maxintensity] in optical watts ... [0 1e-9]\n",
        "    SNRthresh = signal-to-noise threshold  ... e.g., 3\n",
        "    det_to_prune = detectors to remove entirely from the\n",
        "                   measurement list (defaults to [])\n",
        "    suffix = suffix for output file (DEFAULT='-prune')\n",
        "\"\"\"\n",
        "    d,t,ml,aux10,gains,rate,timestamp,lambdas = read_homer_npz(inname)\n",
        "    d,ml = homer_prune(d,ml,pSrc,pDet,separations,intensities,SNRthresh,[])\n",
        "    tmpdic = {'d':d.T, 't':t, 'aux10':aux10, 'ml':ml, 'gains':gains}\n",
        "    outname = inname[:inname.rfind('.')] +suffix\n",
        "    np.savez(outname,tmpdic)\n",
        "    return d.T, ml\n",
        "\n",
        "\n",
        "def makeOD(data,baseline=None):\n",
        "    \"\"\"ODdata = makeOD(data, baseline=None) where data = offset corrected data (TIME x CHAN)\n",
        "    and baseline = indices into data (e.g., integer number-of-points from start,\n",
        "    OR 1D list of indices into data to use, OR data used to calc mean OR None\n",
        "    to use entire dataset mean. Default = None.\n",
        "\"\"\"\n",
        "    if baseline == None:\n",
        "        baseline = np.mean(data,0)\n",
        "    elif type(baseline)==int:\n",
        "        baseline = np.mean(data[:baseline],0)\n",
        "    elif type(baseline)==list:  # must be indices\n",
        "        baseline = np.mean(data[baseline],0)\n",
        "    elif len(baseline.shape) == 2:  # must be data\n",
        "        baseline = np.mean(baseline,0)\n",
        "    else:\n",
        "        print(\"Not appropriate size/shape for baseline in makeOD\")\n",
        "        return\n",
        "\n",
        "    # now calculate OD\n",
        "    normalized_fluence = (1./baseline)*data\n",
        "    ODdata = -np.log(normalized_fluence)\n",
        "\n",
        "    return ODdata\n",
        "\n",
        "\n",
        "def makemua(data,d,baseline=None):\n",
        "    \"\"\"muas = makemua(data, d, baseline=None) where\n",
        "    data = offset corrected data (TIME x CHAN)\n",
        "    d = distance (separation) for each CHAN, and\n",
        "    baseline = indices into data, with options as follows:\n",
        "        integer number-of-points from start, OR\n",
        "        1D list of indices into data to use, OR\n",
        "        data used to calc mean, OR\n",
        "        None to use entire dataset mean.\n",
        "        Default = None (dataset mean)\n",
        "\"\"\"\n",
        "    # calculate OD\n",
        "    ODdata = makeOD(data,baseline)\n",
        "    # back-out d(istance)\n",
        "    mua = ODdata/d\n",
        "\n",
        "    return mua\n",
        "\n",
        "\n",
        "def homer_makeOD(data, baseline=None):\n",
        "    \"\"\"\n",
        "    Uses makeOD to convert each channel of a homerized dataset.\n",
        "\n",
        "Usage:   homer_makeOD(data, baseline=None)\n",
        "Returns: ODdata (same shape as data)\n",
        "\"\"\"\n",
        "    ODdata = np.zeros(data.shape,dtype=np.float)\n",
        "    for i in range(ODdata.shape[1]):\n",
        "        ODdata[:,i] = makeOD(data[:,i],baseline)\n",
        "    return ODdata\n",
        "\n",
        "\n",
        "def od2hbhbo_bls(data, wavelengths, BLs):\n",
        "    \"\"\"%\n",
        "  Converts ONE channel's worth of optical data (in OD units) to hb/hbo data,\n",
        "  given appropriate wavelength-dependent scaling factors (BLs)\n",
        "  Assumes: the absorbtion is proportional to the fluence\n",
        "\n",
        "  [hbhbo,A]=od2hbhbo_BLs(\n",
        "    data,         # OD data for these 2+ wavelengths (e.g., [data(:,(830col)), data(:,785col)])\n",
        "    wavelengths,  # 2+ wavelengths used (e.g., [830 785])\n",
        "    BLs)          # k's to be used for this source-detector pair ==> fluence/BL\n",
        "                  # (e.g., [18 18]\n",
        "\n",
        "   hb,hbo,A = Hb and HbO timeseries' in units of [Moles/Liter], A-matrix\n",
        "\"\"\"\n",
        "    nLambda = len(wavelengths)\n",
        "    [hb,hbo] = getExtinctions(wavelengths,'hb')\n",
        "#    print hb\n",
        "#    print hbo\n",
        "    A = np.array([hb,hbo])\n",
        "    wavelengths = np.array(wavelengths)\n",
        "    BLs = np.array(BLs)\n",
        "\n",
        "    # in case it was passed in incorrectly\n",
        "    m,n = data.shape\n",
        "    if m<n:\n",
        "        data = data.T\n",
        "        m,n = data.shape\n",
        "\n",
        "    # Make sure we have enough wavelengths\n",
        "    if nLambda<2 or nLambda<data.shape[1]:\n",
        "        n = max(2,data.shape[1])\n",
        "        print(\"Need %s wavelengths to do [hb,hbo] transform on %s columns.\" %(nLambda,n))\n",
        "        return\n",
        "\n",
        "    data = (1./BLs)*data\n",
        "\n",
        "    # Least squares does not buy you anything if you only have a two by\n",
        "    # two so don't do the processing on it.\n",
        "    if len(np.unique(wavelengths))==2:\n",
        "        hbhbo = np.dot(data,np.linalg.inv(A))\n",
        "    else:  # This means we have an overdetermined case, so do the least squares\n",
        "        print(A)\n",
        "        hbhbo = np.dot(np.linalg.inv(np.dot(A.T,A)),A.T)  # compute (A.T*A)^-1 * A.T\n",
        "        hbhbo = np.dot(hbhbo.T,data.T)\n",
        "#        hbhbo = hbhbo.T\n",
        "\n",
        "    hb=hbhbo[:,0]\n",
        "    hbo=hbhbo[:,1]\n",
        "    return hbhbo/np.log(10)\n",
        "\n",
        "\n",
        "def od2hbhboh2o_bls(data, wavelengths, BLs):\n",
        "    \"\"\"%\n",
        "  Converts ONE channel's worth of optical data (in OD units) to hb/hbo/h2o data,\n",
        "  given appropriate wavelength-dependent scaling factors (BLs)\n",
        "  Assumes: the absorbtion is proportional to the fluence\n",
        "\n",
        "  [hbhbo,A]=od2hbhboh2o_BLs(\n",
        "    data,         # OD data for these 3+ wavelengths (e.g., [data(:,(830col)), data(:,785col)])\n",
        "    wavelengths,  # 3+ wavelengths used (e.g., [830 785])\n",
        "    BLs)          # k's to be used for this source-detector pair ==> fluence/BL\n",
        "                  # (e.g., [18 18]\n",
        "\n",
        "   hb,hbo,A = Hb and HbO timeseries' in units of [Moles/Liter], A-matrix\n",
        "\"\"\"\n",
        "    nLambda = len(wavelengths)\n",
        "    [hb,hbo] = getExtinctions(wavelengths,'hb')\n",
        "    h2o = getExtinctions(wavelengths,'h2o')\n",
        "#    print hb\n",
        "#    print hbo\n",
        "    A = np.array([hb,hbo,h2o])\n",
        "    wavelengths = np.array(wavelengths)\n",
        "    BLs = np.array(BLs)\n",
        "\n",
        "    # in case it was passed in incorrectly\n",
        "    m,n = data.shape\n",
        "    if m<n:\n",
        "        data = data.T\n",
        "        m,n = data.shape\n",
        "\n",
        "    # Make sure we have enough wavelengths\n",
        "    if nLambda<3 or nLambda<data.shape[1]:\n",
        "        n = max(3,data.shape[1])\n",
        "        print(\"Need %s wavelengths to do [hb,hbo] transform on %s columns.\" %(nLambda,n))\n",
        "        return\n",
        "\n",
        "    data = (1./BLs)*data\n",
        "\n",
        "    # Least squares does not buy you anything if you only have a two by\n",
        "    # two so don't do the processing on it.\n",
        "    if len(np.unique(wavelengths))==3:\n",
        "        hbhboh2o = np.dot(data,np.linalg.inv(A))\n",
        "        hbhboh2o = hbhboh2o.T\n",
        "    else:  # This means we have an overdetermined case, so do the least squares\n",
        "        print(A)\n",
        "        hbhboh2o = np.dot(np.linalg.inv(np.dot(A.T,A)),A.T)  # compute (A.T*A)^-1 * A.T\n",
        "        hbhboh2o = np.dot(hbhboh2o.T,data.T)\n",
        "\n",
        "#    hb=hbhboh2o[:,0]\n",
        "#    hbo=hbhboh2o[:,1]\n",
        "    return hbhboh2o/np.log(10)\n",
        "\n",
        "\n",
        "def homer_od2hbhbo_bls(data, wavelengths, BLs):\n",
        "    \"\"\"\n",
        "    Uses od2hbhbo_bls to convert each channel of a homerized dataset.\n",
        "\n",
        "Usage:   homer_od2hbhbo_bls(data, wavelengths, BLs)\n",
        "Returns: [hbdata, hbodata]\n",
        "\"\"\"\n",
        "    half = int(data.shape[1]/2.)\n",
        "    hbdata = np.zeros((data.shape[0],half),dtype=np.float)\n",
        "    hbodata = np.zeros((data.shape[0],half),dtype=np.float)\n",
        "    for i in range(half):\n",
        "        tmp = np.vstack((data[:,i],data[:,i+half]))\n",
        "        tmp = od2hbhbo_bls(tmp,wavelengths,BLs)\n",
        "        hbdata[:,i] = tmp[:,0]\n",
        "        hbodata[:,i] = tmp[:,1]\n",
        "    return hbdata, hbodata\n",
        "\n",
        "\n",
        "def nirs1_od2hbhbo_bls(data, wavelengths, BLs):\n",
        "    \"\"\"\n",
        "Uses od2hbhbo_bls to convert each channel of OD data in a NIRS1-style\n",
        "dataset (TIME x CHANNELS, with wavelengths interleaved) to concentrations.\n",
        "\n",
        "Usage:   nirs1_od2hbhbo_bls(data, wavelengths, BLs)\n",
        "Returns: [hbdata, hbodata]\n",
        "\"\"\"\n",
        "    nlambda = len(wavelengths)\n",
        "    SDpairs = int(data.shape[1]/nlambda)\n",
        "    hbdata = np.zeros((data.shape[0],SDpairs),dtype=np.float)\n",
        "    hbodata = np.zeros((data.shape[0],SDpairs),dtype=np.float)\n",
        "    for i in range(SDpairs):\n",
        "        tmp = od2hbhbo_bls(data[:,i*nlambda:(i+1)*nlambda],wavelengths,BLs)\n",
        "        hbdata[:,i] = tmp[:,0]\n",
        "        hbodata[:,i] = tmp[:,1]\n",
        "    return hbdata, hbodata\n",
        "\n",
        "\n",
        "def nirs1_raw2hbhbo_bls(data, baseline=None, wavelengths=[690,830], BLs=[18,18]):\n",
        "    \"\"\"\n",
        "Uses makeOD and od2hbhbo_bls to convert each channel of OD data in a NIRS1-style\n",
        "dataset (TIME x CHANNELS, with wavelengths interleaved) to concentrations.\n",
        "\n",
        "Usage:   nirs1_od2hbhbo_bls(data, wavelengths, BLs)\n",
        "Returns: [hbdata, hbodata]\n",
        "\"\"\"\n",
        "    data = makeOD(data,baseline)\n",
        "    nlambda = len(wavelengths)\n",
        "    SDpairs = int(data.shape[1]/nlambda) # truncate in case there's a 9th/17th column\n",
        "    hbdata = np.zeros((data.shape[0],SDpairs),dtype=np.float)\n",
        "    hbodata = np.zeros((data.shape[0],SDpairs),dtype=np.float)\n",
        "    for i in range(SDpairs):\n",
        "        tmp = od2hbhbo_bls(data[:,i*nlambda:(i+1)*nlambda],wavelengths,BLs)\n",
        "        hbdata[:,i] = tmp[:,0]\n",
        "        hbodata[:,i] = tmp[:,1]\n",
        "    return hbdata, hbodata\n",
        "\n",
        "\n",
        "def homer_raw2hbhbo_file(fname, wavelengths=[830,690], BLs=[6,6], baseline=None, suffix='-hbhbo'):\n",
        "    \"\"\"\n",
        "    Uses makeOD and od2hbhbo_bls to convert each channel of a homerized dataset.\n",
        "\n",
        "Usage:   homer_raw2hbhbo_file(fname, wavelengths=[830,690], BLs=[6,6], baseline=None, suffix='-hbhbo')\n",
        "Returns: hbhbodata = [hbdata, hbodata]\n",
        "\"\"\"\n",
        "    d,t,aux10,ml,gains = read_homer(fname)\n",
        "    dod = homer_makeOD(d,baseline)\n",
        "    hb,hbo = homer_od2hbhbo_bls(dod,wavelengths,BLs)\n",
        "    d = np.concatenate([hb,hbo],1)\n",
        "    tmpdic = {'d':d, 't':t, 'aux10':aux10, 'ml':ml, 'gains':gains}\n",
        "    outname = fname[:fname.rfind('.')] +suffix\n",
        "    scipy.io.savemat(outname,tmpdic,appendmat=True)\n",
        "    return d  # first half of measurements=Hb; second half=Hbo\n",
        "\n",
        "\n",
        "def homer_c1vsc2(d,factor=1.0):\n",
        "    \"\"\"\n",
        "Determines which channels have mean c1 > (factor*c2). Assumes\n",
        "the first half of the measurements are color1 and the second\n",
        "half are color2.\n",
        "\n",
        "Usage:   homer_c1vsc2(d,factor=1.0)\n",
        "Returns: an array of 0s and 1s (false/true)\n",
        "\"\"\"\n",
        "    md = d.mean(0)\n",
        "    half = len(md)/2\n",
        "    test = (md[:half]>factor*md[half:])*1\n",
        "    return np.concatenate((test,test))\n",
        "\n",
        "\n",
        "def homer_loginten(d):\n",
        "    \"\"\"\n",
        "Calculates the log10 of the mean intensity of d (Time X Meas).\n",
        "\n",
        "Usage:   homer_loginten(d)\n",
        "Returns: an array of intensities\n",
        "\"\"\"\n",
        "    return np.log10(d.mean(0))\n",
        "\n",
        "\n",
        "def homer_getsnrs(input):\n",
        "    \"\"\"\n",
        "    Computes the SNR for the passed-in data (on dimension 0) OR for MAT file name\n",
        "\n",
        "Usage:   homer_getsnrs(fname)\n",
        "Returns: an array of SNRs (mean/SD)\"\"\"\n",
        "    if type(input)==str:\n",
        "        d,t,aux10,ml,gains = read_homer(fname)\n",
        "    else:\n",
        "        d = input\n",
        "    return d.mean(0) / d.std(0)  # dim0 = time, dim1=channels\n",
        "\n",
        "\n",
        "######################### CONSTANTS ########################\n",
        "\n",
        "def getExtinctions(lambdas,molecule='hb'):\n",
        "    \"\"\"Gets the extinction coefficients from data table in this optical.py file.\n",
        "\n",
        "    Usage:   getExtinctions(lambdas,molecule='hb')  moledule='h2o' or 'aa3' or 'lipid'\n",
        "    Returns: returns lists of extinction coefficients for each wavelength (Hb, HbO)\n",
        "    \"\"\"\n",
        "\n",
        "    # extinction matrix holds the lambda,Hb,HbO\n",
        "    A = hbohb_extinctions*1   # data embedded at the end of this file\n",
        "\n",
        "    nLambda = len(lambdas)\n",
        "\n",
        "    if molecule == 'hb':\n",
        "        Hb = np.zeros(nLambda)\n",
        "        HbO = np.zeros(nLambda)\n",
        "\n",
        "        for i in range(nLambda):\n",
        "            # If we have an odd wavelength interpulate the epsilon\n",
        "            if np.mod(lambdas[i],2)==1:\n",
        "                idx      = np.argmax(A[:,0]==lambdas[i]-1)  # -1 because table values are even\n",
        "                Hb[i]    = (A[idx,2]+A[idx+1,2]) / 2.\n",
        "                HbO[i]   = (A[idx,1]+A[idx+1,1]) / 2.\n",
        "#                print idx, Hb[i], HbO[i]\n",
        "            else:\n",
        "                idx      = np.argmax(A[:,0]==lambdas[i])\n",
        "                Hb[i]    = A[idx,2]\n",
        "                HbO[i]   = A[idx,1]\n",
        "#                print idx, Hb[i], HbO[i]\n",
        "\n",
        "        # For humans the fudge factor is 1.15e-4\n",
        "        # If you do this then you get percent of 4% whole blood not molar concentration\n",
        "        #Hb=Hb*1.15e-4\n",
        "        #HbO=HHbo*1.15e-4\n",
        "\n",
        "        # molar weight too small; fix extinction coeff\n",
        "#        Hb = Hb * 4\n",
        "#        HbO = HbO * 4\n",
        "\n",
        "        return Hb, HbO\n",
        "\n",
        "    elif molecule == 'h2o':\n",
        "        h2o = np.zeros(nLambda)\n",
        "\n",
        "        for i in range(nLambda):\n",
        "            # find closest wavelength\n",
        "            idx = 0\n",
        "            while h2o_abscoef[idx,0] < lambdas[i]:\n",
        "                idx += 1\n",
        "            h2o[i] = h2o_abscoef[idx,1]\n",
        "        return h2o\n",
        "\n",
        "    elif molecule == 'aa3':\n",
        "        aa3 = np.zeros(nLambda)\n",
        "\n",
        "        for i in range(nLambda):\n",
        "            # If we have an odd wavelength interpulate the epsilon\n",
        "            if np.mod(lambdas[i],2)==1:\n",
        "                idx    = np.argmax(aa3_abscoef[:,0]==lambdas[i])-1  # -1 because table values are even\n",
        "                aa3[i] = (aa3_abscoef[idx,1]+aa3_abscoef[idx+1,1]) / 2.\n",
        "            else:\n",
        "                idx    = np.argmax(aa3_abscoef[:,0]==lambdas[i])\n",
        "                aa3[i] = aa3_abscoef[idx,1]\n",
        "        return aa3\n",
        "\n",
        "        # round to closest\n",
        "        for i in range(nLambda):\n",
        "            idx = np.floor((lambdas[i]-650)/2)\n",
        "            aa3[i] = aa3_abscoef[idx,1]\n",
        "        return aa3\n",
        "\n",
        "    elif molecule == 'lipid':\n",
        "        lipid = np.zeros(nLambda)\n",
        "\n",
        "        for i in range(nLambda):\n",
        "            # If we have an odd wavelength interpulate the epsilon\n",
        "            if np.mod(lambdas[i],2)==1:\n",
        "                idx      = np.argmax(lipid_abscoef[:,0]==lambdas[i])-1  # -1 because table values are even\n",
        "                lipid[i]    = (lipid_abscoef[idx,1]+lipid_abscoef[idx+1,1]) / 2.\n",
        "            else:\n",
        "                idx      = np.argmax(lipid_abscoef[:,0]==lambdas[i])\n",
        "                lipid[i] = lipid_abscoef[idx,1]\n",
        "        return lipid\n",
        "\n",
        "\n",
        "\n",
        "SNRcolors = [(0, 0, 0),    # black\n",
        "             (0.5, 0, 0),  # dk red\n",
        "             (1, 0, 0),    # red\n",
        "             (1, 0.5, 0),  # dk orange\n",
        "             (1, 1, 0),    # orange\n",
        "             (0, 1, 0)]    # green\n",
        "\n",
        "\n",
        "SNRgrays = [(0, 0, 0),     # grayscale (dark to bright)\n",
        "            (0.2,0.2,0.2),\n",
        "            (0.4,0.4,0.4),\n",
        "            (0.5,0.5,0.5),\n",
        "            (0.6,0.6,0.6),\n",
        "            (0.7,0.7,0.7)]\n",
        "\n",
        "\n",
        "def spm_hrf(TR,P=None,fMRI_T=16.):\n",
        "    \"\"\"\n",
        "Compute SPM's Canonical HRF, from SPM5 spm_hrf.m\n",
        "\n",
        "Usage:   spm_hrf(TR,P=None,fMRI_T=16.)   ... P = parameter list (7 params), or None\n",
        "             DEFAULT P = [6, 16 sec HRF window?, 1, 1, 6, 0, 32]\n",
        "Returns: values of HRF at TRs\n",
        "    \"\"\"\n",
        "    p = [6., 16., 1., 1., 6., 0., 32.]\n",
        "    if P is not None:\n",
        "        p[:len(P)] = P\n",
        "\n",
        "    dt    = TR/fMRI_T\n",
        "    u     = np.arange(0,(p[6])/dt) -p[5]/dt\n",
        "    gamma1 = scipy.stats.gamma.pdf(u, p[0]/p[2], scale=p[2]/dt)\n",
        "    gamma2 = scipy.stats.gamma.pdf(u, p[1]/p[3], scale=p[3]/dt)/p[4]\n",
        "    hrf = gamma1 - gamma2\n",
        "    hrf   = hrf[(np.arange(0,(p[6]/TR))*fMRI_T).tolist()]\n",
        "    hrf   = hrf/np.sum(hrf)\n",
        "    return hrf\n",
        "\n",
        "\n",
        "########################## DISPLAY FUNCTIONS ###########################\n",
        "\n",
        "def fillbetween(x1,x2,ymin=-100,ymax=100,facecolor='y',edgecolor='none'):\n",
        "    \"\"\"\n",
        "Plot filled rectangles (e.g., to indicate stimulus periods.\n",
        "Helper function around matplotlib's \"fill()\" command.\n",
        "\n",
        "Usage:   fillbetween(x1,x2,ymin=-100,ymax=100,facecolor='y',edgecolor='none'):\n",
        "Returns: None\n",
        "\"\"\"\n",
        "    pylab.fill([x1,x2,x2,x1],[ymin,ymin,ymax,ymax],fc=facecolor,ec=edgecolor)\n",
        "\n",
        "\n",
        "def fillseveral(onsets,durations,ymin=-100,ymax=100,facecolor='y',edgecolor='none'):\n",
        "    \"\"\"\n",
        "Plot a bunch of filled rectangles (e.g., to indicate stimulus periods.\n",
        "Helper function around matplotlib's \"fill()\" command.\n",
        "\n",
        "Usage:   fillseveral(onsets,durations,ymin=-100,ymax=100,facecolor='y',edgecolor='none')\n",
        "Returns: None\n",
        "\"\"\"\n",
        "    for i in range(len(onsets)):\n",
        "        if type(durations) in [list,tuple,np.ndarray]:\n",
        "            fillbetween(onsets[i],onsets[i]+durations[i],\n",
        "                        ymin=ymin,ymax=ymax,\n",
        "                        facecolor=facecolor,edgecolor=edgecolor)\n",
        "        else:\n",
        "            fillbetween(onsets[i],onsets[i]+durations,\n",
        "                        ymin=ymin,ymax=ymax,\n",
        "                        facecolor=facecolor,edgecolor=edgecolor)\n",
        "\n",
        "\n",
        "def parse_fillfile(fname):\n",
        "    \"\"\"\n",
        "Plot filled rectangles based on entries in a 2D file of four columns, in the\n",
        "following order:\n",
        "\n",
        "onsettime = time, in sec (or x-axis units) to start the rectangle\n",
        "duration = width of rectangle, in sec (or x-axis units)\n",
        "color = integer (0,1,2 ...) to pick which color; 0=yellow, 1=gray, 2=lt blue\n",
        "label = string description of what happened then\n",
        "\n",
        "Usage:   parse_fillfile(fname)\n",
        "Returns: None\n",
        "\"\"\"\n",
        "    # load in task paradigm file\n",
        "    f = get(fname)\n",
        "    print(f)\n",
        "\n",
        "    # initialize variables, including all unique colors\n",
        "    colors = np.unique(np.array(f,np.object)[:,2])  # list for finding indices\n",
        "    onsets = [None]*len(colors)\n",
        "    durations = [None]*len(colors)\n",
        "    labels = [None]*len(colors)\n",
        "    # loop through rows in file and separate into lists for different colors\n",
        "    for row in f:\n",
        "        idx = colors.index(row[2])\n",
        "#        print idx, row\n",
        "        # if first time through, make onsets and durations into lists\n",
        "        if onsets[idx]==None:\n",
        "            onsets[idx] = [row[0]]\n",
        "            durations[idx] = [row[1]]\n",
        "        # otherwise append the existing lists\n",
        "        else:\n",
        "            onsets[idx].append(row[0])\n",
        "            durations[idx].append(row[1])\n",
        "        labels[idx] = str(row[3])\n",
        "    # convert each group of onsets to an array for easy shifting/math later\n",
        "    for i in range(len(onsets)):\n",
        "        onsets[i] = np.array(onsets[i])\n",
        "    return onsets, durations, colors, labels\n",
        "\n",
        "\n",
        "def plot(*args,**kw):\n",
        "    \"\"\"\n",
        "Plots a 2D array like matlab does ... plot(*args) takes a d or a t,d tuple\n",
        "\"\"\"\n",
        "    # deal with the variable number of input arguments\n",
        "    if len(args) == 2:  # is it t,d?\n",
        "        t = args[0]\n",
        "        d = args[1]\n",
        "    else:               # or just d?\n",
        "        d = args[0]\n",
        "        t = np.arange(len(d))\n",
        "\n",
        "    # now make the plot, a trace at a time\n",
        "#    pylab.figure()\n",
        "    pylab.hold('on')\n",
        "    for i in range(d.shape[1]):\n",
        "        pylab.plot(t,d[:,i])\n",
        "    if 'show' in kw:\n",
        "        if kw['show']==True:\n",
        "            pylab.show(block=False)\n",
        "    pylab.hold('off')\n",
        "    return\n",
        "\n",
        "\n",
        "def plotSD(src,det,d,ml,t=None):\n",
        "    \"\"\"\n",
        "Plot timeseries data from a given src-detector pair OR\n",
        "plot all traces seen by a given src or det. If either src\n",
        "(or det) is None, plots all traces seen by that src (or det).\n",
        "\n",
        "Usage:   plotSD(src,det,d,ml,t=None)\n",
        "\"\"\"\n",
        "    idx = getidx(src,det,ml)\n",
        "    if idx is None or len(idx[0])==0:  # s,d doesn't exist in this ml\n",
        "        return  # short-circuit (don't try plotting)\n",
        "\n",
        "    # PLOT SD PAIR\n",
        "    if src is not None and det is not None:\n",
        "        idx690 = idx[0][0]\n",
        "        idx830 = idx[0][1]\n",
        "        if t is not None:\n",
        "            pylab.plot(t,d[:,idx830],'b',t,d[:,idx690],'g')\n",
        "            pylab.legend(['830nm','690nm'],'upper right')\n",
        "        else:\n",
        "            pylab.plot(d[:,idx830],'b',d[:,idx690],'g')\n",
        "            pylab.legend(['830nm','690nm'],'upper right')\n",
        "\n",
        "    # PLOT SRC-ONLY or DET-ONLY\n",
        "    elif src is not None or det is not None:\n",
        "        if t is not None:\n",
        "            plot(t,d[:,idx])\n",
        "        else:\n",
        "            plot(d[:,idx])\n",
        "\n",
        "\n",
        "def raw_to_trio(d,t=None,wavelengths=[690,830],baseline=None,BLs=[18,18],title=None):\n",
        "    \"\"\"\n",
        "Converts an array of raw wavelength data (TIME x WAVELENGTH) to OD and then to\n",
        "concentrations and plots the results in 3 panels (top=raw, middle=OD, bottom=conc).\n",
        "\n",
        "Usage:   raw_to_trio(d,t=None,wavelengths=[690,830],baseline=None,BLs=[18,18])\n",
        "Returns: d,dod,dhbhbo\n",
        "\"\"\"\n",
        "    if baseline is None:\n",
        "        baseline = 100\n",
        "    if t is None:\n",
        "        t = np.arange(len(d))\n",
        "    dod = makeOD(d,baseline)\n",
        "    hbhbo = od2hbhbo_bls(dod,wavelengths,BLs)\n",
        "\n",
        "    pylab.figure()\n",
        "    pylab.subplot(3,1,1)\n",
        "    if title is not None:\n",
        "        pylab.title(title)\n",
        "    pylab.plot(t,d[:,0],'r')\n",
        "    pylab.hold(True)\n",
        "    pylab.plot(t,d[:,1],'m')\n",
        "    pylab.ylabel('Intensity')\n",
        "    pylab.legend(list(map(str,wavelengths)))\n",
        "\n",
        "    pylab.subplot(3,1,2)\n",
        "    pylab.plot(t,dod[:,0],'r')\n",
        "    pylab.hold(True)\n",
        "    pylab.plot(t,dod[:,1],'m')\n",
        "    pylab.ylabel('O.D.')\n",
        "    pylab.legend(list(map(str,wavelengths)))\n",
        "\n",
        "    pylab.subplot(3,1,3)\n",
        "    pylab.plot(t,hbhbo[:,0]*1e6,'r')\n",
        "    pylab.hold(True)\n",
        "    pylab.plot(t,hbhbo[:,1]*1e6,'b')\n",
        "    pylab.ylabel('Conc (uM)')\n",
        "    pylab.xlabel('Time (s)')\n",
        "    pylab.legend(['oxy','deoxy'])\n",
        "\n",
        "    return d,dod,hbhbo\n",
        "\n",
        "\n",
        "def QCplots(pSrc,pDet,ml,d):\n",
        "    \"\"\"\n",
        "Create some quality-control plots: mean signal, std signal, SNR.\n",
        "\n",
        "Usage:   QCplots(pSrc,pDet,ml,d)\n",
        "Returns: None\n",
        "\"\"\"\n",
        "    # COMPUTE MEASURES\n",
        "    dmean = d.mean(0)\n",
        "    print('Mean: min=',min(np.ravel(dmean)),'  max=',max(np.ravel(dmean)))\n",
        "    dstd = (d/dmean).std(0)\n",
        "    print('STD:  min=',min(np.ravel(dstd)),'  max=',max(np.ravel(dstd)))\n",
        "    dsnr = dmean/d.std(0)\n",
        "    print('SNR:  min=',min(np.ravel(dsnr)),'  max=',max(np.ravel(dsnr)))\n",
        "\n",
        "    # MAKE A FIGURE\n",
        "    pylab.figure(figsize=(7,12))\n",
        "    pylab.subplot(3,1,1)\n",
        "    pylab.title('Avg Signal')\n",
        "    cutoffs=[1e-12, 3e-12, 1e-11, 3e-11, 1e-10 ,3e-10, 1e-9]\n",
        "    plotOverlapsColor(pSrc,pDet,ml,dmean,cutoffs=cutoffs,makelegend=False)\n",
        "\n",
        "    pylab.subplot(3,1,2)\n",
        "    pylab.title('Noise (std)')\n",
        "    cutoffs = [0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2]\n",
        "    plotOverlapsColor(pSrc,pDet,ml,dstd,cutoffs=cutoffs,makelegend=False)\n",
        "\n",
        "    pylab.subplot(3,1,3)\n",
        "    pylab.title('SNR')\n",
        "    cutoffs = [2, 4, 6, 8, 10, 15, 20]\n",
        "    plotOverlapsColor(pSrc,pDet,ml,dsnr,cutoffs=cutoffs,makelegend=False)\n",
        "\n",
        "    return\n",
        "\n",
        "\n",
        "def plotOverlapsColor(pSrc,pDet,ml,d,\n",
        "                      cutoffs=[5, 10, 20, 30, 40, 50],\n",
        "                      widths =[1,  3,  4,  6,  8, 10],\n",
        "                      colors=SNRcolors,\n",
        "                      makelegend=True,\n",
        "                      figsize=None,outname=None):\n",
        "    \"\"\"\n",
        "plotoverlapscolor(pSrc,pDet,ml,d,\n",
        "                  cutoffs=[5, 10, 20, 30, 40, 50],\n",
        "                  widths =[1,  3,  4,  6,  8, 10],\n",
        "                  colors=SNRcolors,\n",
        "                  makelegend=True,\n",
        "                  figsize=None,outname=None)\n",
        "\n",
        "plots triangles for srcs, circles for detectors, and lines between given ml pairs.\n",
        "Lines are weighted & colored according to the data in d (assumed to be as many entries\n",
        "as rows in ml) and the cutoff values in cutoffs. Colorizes thusly:\n",
        "\n",
        " Cutoff Color\n",
        " ====== =====\n",
        " >50    Green\n",
        " 40-50  Yellow\n",
        " 30-40  Orange\n",
        " 20-30  Red\n",
        " 10-20  Dark red\n",
        "  5-10  Black\n",
        " <5     (none)\n",
        "\n",
        "The above colors are appropriate for NIRS SNR data, as in:  md = np.mean(d,0)/np.std(d,0)\n",
        "Other sets of cutoffs, colors and widths can be provided (must all be same length as cutoffs).\n",
        "\n",
        "Multiple return possibilities. If ...\n",
        "outname=None ... show the figure, return None\n",
        "outname='_return_' ... return a handle to the figure, don't display\n",
        "outname='fname.png' ... save figure to file, return None\n",
        "\"\"\"\n",
        "    pylab.ioff()  # don't be slow as molases ;-)\n",
        "    if figsize is not None:\n",
        "        pylab.figure(figsize=figsize)\n",
        "        pylab.hold(True)\n",
        "\n",
        "    # fix improperly-ordered items\n",
        "    cutoffs.sort()\n",
        "\n",
        "    for row in range(len(ml)):\n",
        "        ps = pSrc[ml[row,0]-1,:]  # Srcs are 1-16 (index 0-15)\n",
        "        pd = pDet[ml[row,1]-1,:]  # Dets are 1-32 (index 0-31)\n",
        "        rowmean = d[row]\n",
        "        if rowmean >=cutoffs[0]:  # is it worth plotting?\n",
        "            h = pylab.plot([ps[0],pd[0]],[ps[1],pd[1]])\n",
        "            for i in range(len(cutoffs)-1):\n",
        "                if rowmean>=cutoffs[i] and rowmean<cutoffs[i+1]:\n",
        "                    pylab.setp(h,'Color',colors[i]);\n",
        "                    pylab.setp(h,'LineWidth',widths[i]);\n",
        "                elif rowmean>=cutoffs[-1]:\n",
        "                    pylab.setp(h,'Color',colors[-1]);\n",
        "                    pylab.setp(h,'LineWidth',widths[-1]);\n",
        "\n",
        "    # figure out the x/y ranges of this plot\n",
        "    xextra = 0.025\n",
        "    yextra = 0.4\n",
        "    xmin = min(min(pSrc[:,0]),min(pDet[:,0]))\n",
        "    xmax = max(max(pSrc[:,0]),max(pDet[:,0]))\n",
        "    ymin = min(min(pSrc[:,1]),min(pDet[:,1]))\n",
        "    ymax = max(max(pSrc[:,1]),max(pDet[:,1]))\n",
        "    xrange = xmax-xmin\n",
        "    yrange = ymax-ymin\n",
        "    xmin = xmin-xrange*xextra\n",
        "    xmax = xmax+xrange*xextra\n",
        "    ymin = ymin-yrange*yextra\n",
        "    ymax = ymax+yrange*yextra\n",
        "\n",
        "    # put down legend colorbar patches\n",
        "    if makelegend:\n",
        "        startx = np.array([0,0,1,1])               # a 1-unit square\n",
        "        y = np.array([0,1,1,0])+ymax*(1+yextra)  # the rest of the 1-unit square\n",
        "        texty = ymax*(1+yextra/2.)\n",
        "        pylab.hold(True)\n",
        "        pylab.text(0,texty,'SNR:')\n",
        "        for i in range(len(colors)):\n",
        "            pylab.fill(startx+3*(i+1),y,facecolor=colors[i])\n",
        "            pylab.text(startx[0]+3*(i+1),texty,'>%i'%cutoffs[i])\n",
        "\n",
        "    # then put down source positions as red Xs\n",
        "    plotSDpos(pSrc,pDet,outname=outname)\n",
        "\n",
        "#    pylab.xlabel('X-position (cm)')\n",
        "#    pylab.ylabel('Y-position (cm)')\n",
        "    pylab.axis('equal')\n",
        "    pylab.axis([ xmin, xmax, ymin, ymax])\n",
        "\n",
        "    if outname is None:\n",
        "        pylab.show(block=False)\n",
        "    else:\n",
        "        if outname=='_return_':\n",
        "            return pylab.gcf()\n",
        "        else:\n",
        "            pylab.savefig(outname,dpi=150)\n",
        "    return\n",
        "\n",
        "\n",
        "def plotCoverage(pSrc,pDet,ml,\n",
        "                 figsize=None,outname=None):\n",
        "    \"\"\"\n",
        "plotCoverage(pSrc,pDet,ml,\n",
        "                  figsize=None,outname=None)\n",
        "\n",
        "plots triangles for srcs, circles for detectors, and lines between\n",
        "all ml pairs.\n",
        "\n",
        "Returns: Multiple return possibilities. If ...\n",
        "  outname=None ... show the figure, return None\n",
        "  outname='_return_' ... return a handle to the figure, don't display\n",
        "  outname='fname.png' ... save figure to file, return None\n",
        "\"\"\"\n",
        "    pylab.ioff()  # don't be slow as molases\n",
        "    if figsize is not None:\n",
        "        pylab.figure(figsize=figsize)\n",
        "        pylab.hold(True)\n",
        "\n",
        "    for row in range(len(ml)):\n",
        "        ps = pSrc[ml[row,0]-1,:]  # Srcs are 1-16 (index 0-15)\n",
        "        pd = pDet[ml[row,1]-1,:]  # Dets are 1-32 (index 0-31)\n",
        "        pylab.plot([ps[0],pd[0]],[ps[1],pd[1]],'k')\n",
        "\n",
        "    # figure out the x/y ranges of this plot\n",
        "    xextra = 0.05\n",
        "    yextra = 0.4\n",
        "    xmin = min(min(pSrc[:,0]),min(pDet[:,0]))\n",
        "    xmax = max(max(pSrc[:,0]),max(pDet[:,0]))\n",
        "    ymin = min(min(pSrc[:,1]),min(pDet[:,1]))\n",
        "    ymax = max(max(pSrc[:,1]),max(pDet[:,1]))\n",
        "    xrange = xmax-xmin\n",
        "    yrange = ymax-ymin\n",
        "    xmin = xmin-xrange*xextra\n",
        "    xmax = xmax+xrange*xextra\n",
        "    ymin = ymin-yrange*yextra\n",
        "    ymax = ymax+yrange*yextra\n",
        "\n",
        "    # then put down source positions as red Xs\n",
        "    plotSDpos(pSrc,pDet,outname=outname)\n",
        "\n",
        "    pylab.xlabel('X-position (cm)')\n",
        "    pylab.ylabel('Y-position (cm)')\n",
        "    pylab.axis('equal')\n",
        "    pylab.axis([ xmin, xmax, ymin, ymax])\n",
        "\n",
        "    if outname is None:\n",
        "        pylab.show(block=False)\n",
        "    else:\n",
        "        if outname=='_return_':\n",
        "            return pylab.gcf()\n",
        "        else:\n",
        "            pylab.savefig(outname,dpi=150)\n",
        "    return\n",
        "\n",
        "\n",
        "def plotSDpos(pSrc,pDet,outname=None,figsize=None):\n",
        "    \"\"\"\n",
        "plotSDpos(pSrc,pDet,outname=None,figsize=None)\n",
        "\n",
        "plots triangles for srcs, circles for detectors in the relevant geometry\n",
        "\n",
        "Multiple return possibilities. If ...\n",
        "outname=None ... show the figure, return None\n",
        "outname='_return_' ... return a handle to the figure, don't display\n",
        "outname='fname.png' ... save figure to file, return None\n",
        "\"\"\"\n",
        "    pylab.ioff()\n",
        "    pylab.hold(True)\n",
        "    symax = max(pSrc[:,1])\n",
        "    symin = min(pSrc[:,1])\n",
        "    dymax = max(pDet[:,1])\n",
        "    dymin = min(pDet[:,1])\n",
        "    yrange = max(symax,dymax)-min(symin,dymin)\n",
        "\n",
        "    # put down source positions as red Xs\n",
        "    for row in range(len(pSrc)):\n",
        "        pylab.plot([pSrc[row,0]],[pSrc[row,1]],'k^')\n",
        "        pylab.text(pSrc[row,0],pSrc[row,1]+0.05*yrange,'S'+str(row+1))\n",
        "\n",
        "    # put down detector positions as blue Os\n",
        "    for row in range(len(pDet)):\n",
        "        pylab.plot([pDet[row,0]],[pDet[row,1]],'ko')\n",
        "        pylab.text(pDet[row,0],pDet[row,1]+0.05*yrange,'D'+str(row+1))\n",
        "\n",
        "    pylab.xlabel('X-position (cm)')\n",
        "    pylab.ylabel('Y-position (cm)')\n",
        "    xextra = 0.05\n",
        "    yextra = 0.2\n",
        "    xmin = min(min(pSrc[:,0]),min(pDet[:,0]))\n",
        "    xmax = max(max(pSrc[:,0]),max(pDet[:,0]))\n",
        "    ymin = min(min(pSrc[:,1]),min(pDet[:,1]))\n",
        "    ymax = max(max(pSrc[:,1]),max(pDet[:,1]))\n",
        "    xrange = xmax-xmin\n",
        "    yrange = ymax-ymin\n",
        "    xmin = xmin-xrange*xextra\n",
        "    xmax = xmax+xrange*xextra\n",
        "    ymin = ymin-yrange*yextra\n",
        "    ymax = ymax+yrange*yextra\n",
        "    pylab.axis('equal')\n",
        "    pylab.axis([ xmin, xmax, ymin, ymax])\n",
        "\n",
        "    if outname is None:\n",
        "        pylab.show(block=False)\n",
        "    else:\n",
        "        if outname=='_return_':\n",
        "            return pylab.gcf()\n",
        "        else:\n",
        "            pylab.savefig(outname,dpi=150)\n",
        "    return\n",
        "\n",
        "\n",
        "def plotChanpos(pChan,outname=None,figsize=None):\n",
        "    \"\"\"\n",
        "plotChanpos(pChan,outname=None,figsize=None)\n",
        "\n",
        "plots open circles for each channel\n",
        "\n",
        "Multiple return possibilities. If ...\n",
        "outname=None ... show the figure, return None\n",
        "outname='_return_' ... return a handle to the figure, don't display\n",
        "outname='fname.png' ... save figure to file, return None\n",
        "\"\"\"\n",
        "    pylab.ioff()\n",
        "    pylab.hold(True)\n",
        "    symax = max(pChan[:,1])\n",
        "    symin = min(pChan[:,1])\n",
        "    yrange = symax-symin\n",
        "\n",
        "    # put down source positions as red Xs\n",
        "    for row in range(len(pChan)):\n",
        "        pylab.plot([pChan[row,0]],[pChan[row,1]],'kx')\n",
        "        pylab.text(pChan[row,0],pChan[row,1]+0.05*yrange,'C'+str(row+1))\n",
        "\n",
        "    pylab.xlabel('X-position (cm)')\n",
        "    pylab.ylabel('Y-position (cm)')\n",
        "    xextra = 0.05\n",
        "    yextra = 0.2\n",
        "    xmin = min(pChan[:,0])\n",
        "    xmax = max(pChan[:,0])\n",
        "    ymin = min(pChan[:,1])\n",
        "    ymax = max(pChan[:,1])\n",
        "    xrange = xmax-xmin\n",
        "    yrange = ymax-ymin\n",
        "    xmin = xmin-xrange*xextra\n",
        "    xmax = xmax+xrange*xextra\n",
        "    ymin = ymin-yrange*yextra\n",
        "    ymax = ymax+yrange*yextra\n",
        "    pylab.axis('equal')\n",
        "    pylab.axis([ xmin, xmax, ymin, ymax])\n",
        "\n",
        "    if outname is None:\n",
        "        pylab.show(block=False)\n",
        "    else:\n",
        "        if outname=='_return_':\n",
        "            return pylab.gcf()\n",
        "        else:\n",
        "            pylab.savefig(outname,dpi=150)\n",
        "    return\n",
        "\n",
        "\n",
        "def addy(t,d,color='b',format='-',ylabel='',subplotnum=111):\n",
        "    \"\"\"\n",
        "Usage:   addy(d,t,color='b',format='-',ylabel='',subplotnum=111)\n",
        "\"\"\"\n",
        "    ax1 = pylab.subplot(subplotnum)\n",
        "    ax2 = ax1.twinx()\n",
        "    ax2.plot(t, d, color+format)\n",
        "    # change color of yaxis tick labels\n",
        "    for item in ax2.get_yaxis().get_ticklabels():\n",
        "        item.set_color(color)\n",
        "    if ylabel:\n",
        "        ax2.set_ylabel(ylabel, color=color)\n",
        "    return ax1,ax2\n",
        "\n",
        "\n",
        "def plotyy(x1,y1,x2,y2,format1='b',format2='g',xlabel='',ylabel1='',ylabel2='',subplotnum=111):\n",
        "    \"\"\"\n",
        "Usage:   plotyy(x1,y1,x2,y2,format1='b',format2='g',xlabel='',ylabel1='',ylabel2='',subplotnum=111)\n",
        "\"\"\"\n",
        "    ax1 = pylab.subplot(subplotnum)\n",
        "    ax1.plot(x1, y1, format1)\n",
        "    # change color of yaxis tick labels\n",
        "    for item in ax1.get_yaxis().get_ticklabels():\n",
        "        item.set_color(format1)\n",
        "    if xlabel:\n",
        "        ax1.set_xlabel(xlabel)\n",
        "    if ylabel1:\n",
        "        ax1.set_ylabel(ylabel1, color=format1)\n",
        "    ax2 = ax1.twinx()\n",
        "    ax2.plot(x2, y2, format2)\n",
        "    # change color of yaxis tick labels\n",
        "    for item in ax2.get_yaxis().get_ticklabels():\n",
        "        item.set_color(format2)\n",
        "    if ylabel2:\n",
        "        ax2.set_ylabel(ylabel2, color=format2)\n",
        "    return ax1,ax2\n",
        "\n",
        "\n",
        "def plotHB(t,hbhbo,shift=[0,0,0],scale=[1,1,1],plot_hbt=True,hbt_color='k',detrendfirst=False):\n",
        "    \"\"\"\n",
        "Take a Time x [hb,hbo] array and plot HHb (blue), O2Hb (red) and HbT (default=\n",
        "black) together, possibly multiplicatively scaled by [hbscale,hboscale,hbtscale]\n",
        "and/or additively shifted vertically by [hbshift,hboshift,hbtshift].\n",
        "\n",
        "Usage:   plotHB(t,hbhbo,shift=[0,0,0],plot_htb=True,hbt_color='k',detrendfirst=False)\n",
        "Returns: axis\n",
        "\"\"\"\n",
        "    if detrendfirst:\n",
        "        hbhbo[:,0] = scipy.signal.detrend(hbhbo[:,0])\n",
        "        hbhbo[:,1] = scipy.signal.detrend(hbhbo[:,1])\n",
        "    pylab.plot(t,hbhbo[:,0]*scale[0]+shift[0],'b')\n",
        "    pylab.plot(t,hbhbo[:,1]*scale[1]+shift[1],'r')\n",
        "    if plot_hbt:\n",
        "        pylab.plot(t,(hbhbo[:,0]+hbhbo[:,1])*scale[2]+shift[2],hbt_color)\n",
        "    return pylab.gca()\n",
        "\n",
        "\n",
        "def plotExtremaHist(d):\n",
        "    \"\"\"\n",
        "Plot two histograms of the -log10() of all maxima and all minima in d (where d = Time X Meas)\n",
        "\n",
        "Usage:   plotExtremaHist(d)\n",
        "\"\"\"\n",
        "    pylab.ioff()\n",
        "    pylab.figure()\n",
        "\n",
        "    # put Maxima on top\n",
        "    pylab.subplot(2,1,1)\n",
        "    h1 = pylab.hist(-np.log10(np.min(d,0)),np.arange(30)/2.)\n",
        "    pylab.vlines(8,0,d.shape[1])  # mark 1e-8 (generally 2.5+cm --> optical power <1e-8)\n",
        "    pylab.title('-log10(Maxima)')\n",
        "    pylab.ylabel('Counts')\n",
        "\n",
        "    # put Minima on bottom\n",
        "    pylab.subplot(2,1,2)\n",
        "    h2 = pylab.hist(-np.log10(np.max(d,0)),np.arange(30)/2.)\n",
        "    pylab.vlines(8,0,d.shape[1])\n",
        "    pylab.title('-log10(Minima)')\n",
        "    pylab.xlabel('-log10(mean_optical_signal)')\n",
        "    pylab.ylabel('Counts')\n",
        "\n",
        "    # now set scales to the same height\n",
        "    ymax = max(h1[0].tolist()+h2[0].tolist())\n",
        "    ymax = ymax*1.05\n",
        "    pylab.subplot(2,1,1)\n",
        "    a = pylab.gca()\n",
        "    a.set_ylim(0,ymax)\n",
        "    pylab.subplot(2,1,2)\n",
        "    a = pylab.gca()\n",
        "    a.set_ylim(0,ymax)\n",
        "\n",
        "    pylab.show(block=False)\n",
        "    return\n",
        "\n",
        "\n",
        "def plotMeanHist(d):\n",
        "    \"\"\"\n",
        "Plot histogram of the -log10() of the mean of each channel in d (where d = Time X Meas).\n",
        "\n",
        "Usage:   plotExtremaHist(d)\n",
        "\"\"\"\n",
        "    pylab.ioff()\n",
        "    pylab.figure()\n",
        "    h = pylab.hist(-np.log10(np.mean(d,0)),np.arange(30)/2.)\n",
        "    pylab.vlines(8,0,d.shape[1])  # mark 1e-8 (generally 2.5+cm --> optical power <1e-8)\n",
        "    pylab.title('-log10(Mean)')\n",
        "    pylab.xlabel('-log10(mean_optical_signal)')\n",
        "    pylab.ylabel('Counts')\n",
        "\n",
        "    # set ylimits appropriately\n",
        "    ymax = max(h[0].tolist())\n",
        "    ymax = ymax*1.05\n",
        "    a = pylab.gca()\n",
        "    a.set_ylim(0,ymax)\n",
        "\n",
        "    pylab.show(block=False)\n",
        "    return\n",
        "\n",
        "\n",
        "######################### DATA SURFING ########################\n",
        "\n",
        "class SDFinder:\n",
        "  \"\"\"\n",
        "Callback for matplotlib to display an annotation when points are clicked on.  The\n",
        "point which is closest to the click and within xtol and ytol is identified.\n",
        "\n",
        "Register this function like this:\n",
        "\n",
        "  scatter(xdata, ydata)\n",
        "  af = AnnoteFinder(xdata, ydata, annotes)\n",
        "  connect('button_press_event', af)\n",
        "\"\"\"\n",
        "\n",
        "  def __init__(self, xdata, ydata, annotes, d, t, ml, axis=None, xtol=None, ytol=None):\n",
        "    self.data = list(zip(xdata, ydata, annotes))\n",
        "    if xtol is None:\n",
        "      xtol = ((max(xdata) - min(xdata))/float(len(xdata)))/2\n",
        "    if ytol is None:\n",
        "      ytol = ((max(ydata) - min(ydata))/float(len(ydata)))/2\n",
        "    self.xtol = xtol\n",
        "    self.ytol = ytol\n",
        "    if axis is None:\n",
        "      self.axis = pylab.gca()\n",
        "    else:\n",
        "      self.axis= axis\n",
        "    self.drawnAnnotations = {}\n",
        "    self.links = []\n",
        "    self.det = None\n",
        "    self.src = None\n",
        "    self.srcx = None\n",
        "    self.srcy = None\n",
        "    self.detx = None\n",
        "    self.dety = None\n",
        "    self.d = d\n",
        "    self.t = t\n",
        "    self.ml = ml\n",
        "\n",
        "  def distance(self, x1, x2, y1, y2):\n",
        "    \"\"\"\n",
        "    return the distance between two points\n",
        "    \"\"\"\n",
        "    return(math.sqrt( (x1 - x2)**2 + (y1 - y2)**2 ))\n",
        "\n",
        "  def __call__(self, event):\n",
        "    if event.inaxes:\n",
        "      clickX = event.xdata\n",
        "      clickY = event.ydata\n",
        "      if (self.axis is None) or (self.axis==event.inaxes):\n",
        "        annotes = []\n",
        "        for x,y,a in self.data:\n",
        "          if  (clickX-self.xtol < x < clickX+self.xtol) and  (clickY-self.ytol < y < clickY+self.ytol) :\n",
        "            annotes.append((self.distance(x,clickX,y,clickY),x,y, a) )\n",
        "        if annotes:\n",
        "          annotes.sort()\n",
        "          distance, x, y, annote = annotes[0]\n",
        "          self.drawAnnote(event.inaxes, x, y, annote)\n",
        "          for l in self.links:\n",
        "            l.drawDpecificAnnote(annote)\n",
        "\n",
        "  def drawAnnote(self, axis, x, y, annote):\n",
        "    \"\"\"\n",
        "    Draw the annotation on the plot\n",
        "    \"\"\"\n",
        "    # IF THE MARKER ALREADY EXISTS, CHANGE ITS VISIBILITY LEVEL AND SET FLAGS\n",
        "    if (x,y) in self.drawnAnnotations:\n",
        "      annote,markers = self.drawnAnnotations[(x,y)]\n",
        "      for m in markers:  # in case there are multiple markers (text, circle, red dot, etc)\n",
        "\n",
        "        # IF EXISTING MARKER IS VISIBLE, MAKE IT INVISIBLE AND CHANGE FLAGS\n",
        "        if m.get_visible():  # if it's VISIBLE\n",
        "          m.set_visible(False)  # ... make it invisible\n",
        "          # and reset self.src or self.det to None, as appropriate\n",
        "          if annote[0]=='S':\n",
        "            self.src = None\n",
        "            self.srcx = None\n",
        "            self.srcy = None\n",
        "          elif annote[0]=='D':\n",
        "            self.det = None\n",
        "            self.detx = None\n",
        "            self.dety = None\n",
        "\n",
        "        # IF EXISTING MARKER IS CURRENTLY INVISIBLE, MAKE IT VISIBLE AND /CHANGE/ FLAGS\n",
        "        else:  # this marker was INVISIBLE\n",
        "\n",
        "          # first try to set previous marker(s) to invisible (maybe there wasn't one)\n",
        "          try:\n",
        "            if annote[0]=='S': # if the new one is an S, turn off the old S\n",
        "              oldannote,oldmarkers = self.drawnAnnotations[(self.srcx,self.srcy)]\n",
        "            elif annote[0]=='D': # if the new one is a D, turn off the old D\n",
        "              oldannote,oldmarkers = self.drawnAnnotations[(self.detx,self.dety)]\n",
        "            for om in oldmarkers:  # in case of multiple markers (text, circle, red dot, etc)\n",
        "              om.set_visible(False)  # turn off previous marker\n",
        "          except:\n",
        "            pass\n",
        "\n",
        "          # now make the new one visible\n",
        "          m.set_visible(True)  # ... make it visible\n",
        "\n",
        "          # set new flags\n",
        "          if annote[0]=='S':\n",
        "            self.src = string.atoi(annote[1:])\n",
        "            self.srcx = x\n",
        "            self.srcy = y\n",
        "          elif annote[0]=='D':\n",
        "            self.det = string.atoi(annote[1:])\n",
        "            self.detx = x\n",
        "            self.dety = y\n",
        "\n",
        "    # MARKER DOESN'T EXIST, CREATE IT AND SET FLAGS\n",
        "    else:\n",
        "      pylab.ioff()\n",
        "      pylab.subplot(212)\n",
        "#      t = axis.text(x,y, \"%s\"%annote )\n",
        "      m = axis.scatter([x],[y], s=100, marker='d', c='b', zorder=100)\n",
        "\n",
        "      # IF NEW CLICK IS AN S (and is a newly created marker, of course)\n",
        "      if annote[0]=='S':\n",
        "        if self.src is not None:  # we're /changing/ the src position\n",
        "          oldannote,oldmarkers = self.drawnAnnotations[(self.srcx,self.srcy)]\n",
        "          # make the previous src marker(s) invisible\n",
        "          for om in oldmarkers:\n",
        "            om.set_visible(False)  # make it invisible\n",
        "        # regardless, set the new variables\n",
        "        self.src = string.atoi(annote[1:])\n",
        "        self.srcx = x\n",
        "        self.srcy = y\n",
        "\n",
        "      elif annote[0]=='D':\n",
        "        if self.det is not None:  # we're /changing/ the det position\n",
        "          oldannote,oldmarkers = self.drawnAnnotations[(self.detx,self.dety)]\n",
        "          # make the previous det marker(s) invisible\n",
        "          for om in oldmarkers:\n",
        "            # RESET either self.src or self.det (whichever was just clicked)\n",
        "            om.set_visible(False)  # make it invisible\n",
        "        # regardless, set the new variables\n",
        "        self.det = string.atoi(annote[1:])\n",
        "        self.detx = x\n",
        "        self.dety = y\n",
        "\n",
        "      pylab.ion()\n",
        "      self.drawnAnnotations[(x,y)] = (annote,(m,))\n",
        "\n",
        "    # FINALLY, IF SRC AND DET ARE SELECTED, PLOT THE CHANNELS; OTHERWISE JUST CLEAR AXIS\n",
        "    pylab.subplot(211)\n",
        "    pylab.cla()\n",
        "    plotSD(self.src,self.det,self.d,self.ml,self.t)\n",
        "    titlestr = ''\n",
        "    if self.src is not None:\n",
        "      titlestr += 'S%i' %self.src\n",
        "    if self.det is not None:\n",
        "      titlestr += '  D%i' %self.det\n",
        "    pylab.title(titlestr)\n",
        "    pylab.xlabel('Time (s)')\n",
        "    pylab.ylabel('Signal')\n",
        "\n",
        "    pylab.subplot(212)\n",
        "    pylab.axis(axis4tuple)\n",
        "    self.axis.figure.canvas.draw()\n",
        "\n",
        "  def drawDpecificAnnote(self, annote):\n",
        "    annotesToDraw = [(x,y,a) for x,y,a in self.data if a==annote]\n",
        "    for x,y,a in annotesToDraw:\n",
        "      self.drawAnnote(self.axis, x, y, a)\n",
        "\n",
        "\n",
        "def linkedplots(pSrc,pDet,d,t,ml,cutoffs=None,colors=None,widths=None):\n",
        "    \"\"\"\n",
        "Plots the probe grid from pSrc and pDet, with color overlaps, and a\n",
        "linked timeseries graph. Need to pass in the data, timebase (for the\n",
        "timeseries graph), measurement list, geometery. Can also specify what\n",
        "cutoffs/colors/widths to use in the overlaps display.\n",
        "\n",
        "Usage:   linkedplots(pSrc,pDet,d,t,ml,cutoffs=None,colors=None,widths=None)\n",
        "Returns: None (plots)\n",
        "\"\"\"\n",
        "    test = max(np.ravel(d))\n",
        "    print(test)\n",
        "    print(d.shape)\n",
        "    if test<1e-5:  # if so, take log10 of it (to see more with multiple traces)\n",
        "      d = np.log10(d)\n",
        "\n",
        "    # MAKE MAIN FIGURE\n",
        "    pylab.ioff()\n",
        "    pylab.figure(figsize=(12,8))\n",
        "\n",
        "    # lower panel shows probe geometry\n",
        "    pylab.subplot(212)\n",
        "    h = plotOverlapsColor(pSrc,pDet,ml,d,colors=colors,\n",
        "                            widths=widths, cutoffs=cutoffs,\n",
        "                            outname=\"_return_\",makelegend=False)\n",
        "    axis4tuple = h.axes[0].axis()\n",
        "\n",
        "    x = pSrc[:,0].tolist() + pDet[:,0].tolist()\n",
        "    y = pSrc[:,1].tolist() + pDet[:,1].tolist()\n",
        "    annotes = ['S1','S2','S3','S4','S5','S6','S7','S8','S9','S10','S11','S12','S13','S14','S15','S16']+ ['D1','D2','D3','D4','D5','D6','D7','D8','D9','D10','D11','D12','D13','D14','D15','D16']+ ['D17','D18','D19','D20','D21','D22','D23','D24','D25','D26','D27','D28','D29','D30','D31','D32']\n",
        "    af1 = SDFinder(x,y, annotes, xtol=0.5, ytol=0.5, d=d, ml=ml, t=t)\n",
        "    pylab.connect('button_press_event', af1)\n",
        "\n",
        "    # upper panel shows timeseries data (blank to start)\n",
        "    pylab.subplot(211)\n",
        "\n",
        "    pylab.show(block=False)\n",
        "\n",
        "\n",
        "#****************************** EXTINCTION COEFFICIENTS **********************************\n",
        "# These values for the molar extinction coefficient e in [cm-1/(moles/liter)] were compiled\n",
        "# by Scott Prahl (prahl@ece.ogi.edu) using data from\n",
        "#\n",
        "# W. B. Gratzer, Med. Res. Council Labs, Holly Hill, London\n",
        "# N. Kollias, Wellman Laboratories, Harvard Medical School, Boston\n",
        "# To convert this data to absorbance A, multiply by the molar concentration and the\n",
        "# pathlength. For example, if x is the number of grams per liter and a 1 cm cuvette\n",
        "# is being used, then the absorbance is given by\n",
        "#\n",
        "#        (e) [(1/cm)/(moles/liter)] (x) [g/liter] (1) [cm]\n",
        "#  A =  ---------------------------------------------------\n",
        "#                          66,500 [g/mole]\n",
        "#\n",
        "# using 66,500 as the gram molecular weight of hemoglobin.\n",
        "# To convert this data to absorption coefficient in (cm-1), multiply by the molar\n",
        "# concentration and 2.303,\n",
        "#\n",
        "# mua = (2.303) e (x g / liter)/(66,500 g Hb / mole)\n",
        "# where x is the number of grams per liter. A typical value of x for whole blood\n",
        "# is x=150 g Hb/liter.\n",
        "\n",
        "hbohb_extinctions = np.array([\n",
        "#Lambda  O2Hb    HHb\n",
        "[250,   106112, 112736],\n",
        "[252,   105552, 112736],\n",
        "[254,   107660, 112736],\n",
        "[256,   109788, 113824],\n",
        "[258,   112944, 115040],\n",
        "[260,   116376, 116296],\n",
        "[262,   120188, 117564],\n",
        "[264,   124412, 118876],\n",
        "[266,   128696, 120208],\n",
        "[268,   133064, 121544],\n",
        "[270,   136068, 122880],\n",
        "[272,   137232, 123096],\n",
        "[274,   138408, 121952],\n",
        "[276,   137424, 120808],\n",
        "[278,   135820, 119840],\n",
        "[280,   131936, 118872],\n",
        "[282,   127720, 117628],\n",
        "[284,   122280, 114820],\n",
        "[286,   116508, 112008],\n",
        "[288,   108484, 107140],\n",
        "[290,   104752, 98364],\n",
        "[292,   98936,  91636],\n",
        "[294,   88136,  85820],\n",
        "[296,   79316,  77100],\n",
        "[298,   70884,  69444],\n",
        "[300,   65972,  64440],\n",
        "[302,   63208,  61300],\n",
        "[304,   61952,  58828],\n",
        "[306,   62352,  56908],\n",
        "[308,   62856,  57620],\n",
        "[310,   63352,  59156],\n",
        "[312,   65972,  62248],\n",
        "[314,   69016,  65344],\n",
        "[316,   72404,  68312],\n",
        "[318,   75536,  71208],\n",
        "[320,   78752,  74508],\n",
        "[322,   82256,  78284],\n",
        "[324,   85972,  82060],\n",
        "[326,   89796,  85592],\n",
        "[328,   93768,  88516],\n",
        "[330,   97512,  90856],\n",
        "[332,   100964, 93192],\n",
        "[334,   103504, 95532],\n",
        "[336,   104968, 99792],\n",
        "[338,   106452, 104476],\n",
        "[340,   107884, 108472],\n",
        "[342,   109060, 110996],\n",
        "[344,   110092, 113524],\n",
        "[346,   109032, 116052],\n",
        "[348,   107984, 118752],\n",
        "[350,   106576, 122092],\n",
        "[352,   105040, 125436],\n",
        "[354,   103696, 128776],\n",
        "[356,   101568, 132120],\n",
        "[358,   97828,  133632],\n",
        "[360,   94744,  134940],\n",
        "[362,   92248,  136044],\n",
        "[364,   89836,  136972],\n",
        "[366,   88484,  137900],\n",
        "[368,   87512,  138856],\n",
        "[370,   88176,  139968],\n",
        "[372,   91592,  141084],\n",
        "[374,   95140,  142196],\n",
        "[376,   98936,  143312],\n",
        "[378,   103432, 144424],\n",
        "[380,   109564, 145232],\n",
        "[382,   116968, 145232],\n",
        "[384,   125420, 148668],\n",
        "[386,   135132, 153908],\n",
        "[388,   148100, 159544],\n",
        "[390,   167748, 167780],\n",
        "[392,   189740, 180004],\n",
        "[394,   212060, 191540],\n",
        "[396,   231612, 202124],\n",
        "[398,   248404, 212712],\n",
        "[400,   266232, 223296],\n",
        "[402,   284224, 236188],\n",
        "[404,   308716, 253368],\n",
        "[406,   354208, 270548],\n",
        "[408,   422320, 287356],\n",
        "[410,   466840, 303956],\n",
        "[412,   500200, 321344],\n",
        "[414,   524280, 342596],\n",
        "[416,   521880, 363848],\n",
        "[418,   515520, 385680],\n",
        "[420,   480360, 407560],\n",
        "[422,   431880, 429880],\n",
        "[424,   376236, 461200],\n",
        "[426,   326032, 481840],\n",
        "[428,   283112, 500840],\n",
        "[430,   246072, 528600],\n",
        "[432,   214120, 552160],\n",
        "[434,   165332, 552160],\n",
        "[436,   132820, 547040],\n",
        "[438,   119140, 501560],\n",
        "[440,   102580, 413280],\n",
        "[442,   92780,  363240],\n",
        "[444,   81444,  282724],\n",
        "[446,   76324,  237224],\n",
        "[448,   67044,  173320],\n",
        "[450,   62816,  103292],\n",
        "[452,   58864,  62640],\n",
        "[454,   53552,  36170],\n",
        "[456,   49496,  30698.8],\n",
        "[458,   47496,  25886.4],\n",
        "[460,   44480,  23388.8],\n",
        "[462,   41320,  20891.2],\n",
        "[464,   39807.2,    19260.8],\n",
        "[466,   37073.2,    18142.4],\n",
        "[468,   34870.8,    17025.6],\n",
        "[470,   33209.2,    16156.4],\n",
        "[472,   31620,  15310],\n",
        "[474,   30113.6,    15048.4],\n",
        "[476,   28850.8,    14792.8],\n",
        "[478,   27718,  14657.2],\n",
        "[480,   26629.2,    14550],\n",
        "[482,   25701.6,    14881.2],\n",
        "[484,   25180.4,    15212.4],\n",
        "[486,   24669.6,    15543.6],\n",
        "[488,   24174.8,    15898],\n",
        "[490,   23684.4,    16684],\n",
        "[492,   23086.8,    17469.6],\n",
        "[494,   22457.6,    18255.6],\n",
        "[496,   21850.4,    19041.2],\n",
        "[498,   21260,  19891.2],\n",
        "[500,   20932.8,    20862],\n",
        "[502,   20596.4,    21832.8],\n",
        "[504,   20418,  22803.6],\n",
        "[506,   19946,  23774.4],\n",
        "[508,   19996,  24745.2],\n",
        "[510,   20035.2,    25773.6],\n",
        "[512,   20150.4,    26936.8],\n",
        "[514,   20429.2,    28100],\n",
        "[516,   21001.6,    29263.2],\n",
        "[518,   22509.6,    30426.4],\n",
        "[520,   24202.4,    31589.6],\n",
        "[522,   26450.4,    32851.2],\n",
        "[524,   29269.2,    34397.6],\n",
        "[526,   32496.4,    35944],\n",
        "[528,   35990,  37490],\n",
        "[530,   39956.8,    39036.4],\n",
        "[532,   43876,  40584],\n",
        "[534,   46924,  42088],\n",
        "[536,   49752,  43592],\n",
        "[538,   51712,  45092],\n",
        "[540,   53236,  46592],\n",
        "[542,   53292,  48148],\n",
        "[544,   52096,  49708],\n",
        "[546,   49868,  51268],\n",
        "[548,   46660,  52496],\n",
        "[550,   43016,  53412],\n",
        "[552,   39675.2,    54080],\n",
        "[554,   36815.2,    54520],\n",
        "[556,   34476.8,    54540],\n",
        "[558,   33456,  54164],\n",
        "[560,   32613.2,    53788],\n",
        "[562,   32620,  52276],\n",
        "[564,   33915.6,    50572],\n",
        "[566,   36495.2,    48828],\n",
        "[568,   40172,  46948],\n",
        "[570,   44496,  45072],\n",
        "[572,   49172,  43340],\n",
        "[574,   53308,  41716],\n",
        "[576,   55540,  40092],\n",
        "[578,   54728,  38467.6],\n",
        "[580,   50104,  37020],\n",
        "[582,   43304,  35676.4],\n",
        "[584,   34639.6,    34332.8],\n",
        "[586,   26600.4,    32851.6],\n",
        "[588,   19763.2,    31075.2],\n",
        "[590,   14400.8,    28324.4],\n",
        "[592,   10468.4,    25470],\n",
        "[594,   7678.8, 22574.8],\n",
        "[596,   5683.6, 19800],\n",
        "[598,   4504.4, 17058.4],\n",
        "[600,   3200,   14677.2],\n",
        "[602,   2664,   13622.4],\n",
        "[604,   2128,   12567.6],\n",
        "[606,   1789.2, 11513.2],\n",
        "[608,   1647.6, 10477.6],\n",
        "[610,   1506,   9443.6],\n",
        "[612,   1364.4, 8591.2],\n",
        "[614,   1222.8, 7762],\n",
        "[616,   1110,   7344.8],\n",
        "[618,   1026,   6927.2],\n",
        "[620,   942,    6509.6],\n",
        "[622,   858,    6193.2],\n",
        "[624,   774,    5906.8],\n",
        "[626,   707.6,  5620],\n",
        "[628,   658.8,  5366.8],\n",
        "[630,   610,    5148.8],\n",
        "[632,   561.2,  4930.8],\n",
        "[634,   512.4,  4730.8],\n",
        "[636,   478.8,  4602.4],\n",
        "[638,   460.4,  4473.6],\n",
        "[640,   442,    4345.2],\n",
        "[642,   423.6,  4216.8],\n",
        "[644,   405.2,  4088.4],\n",
        "[646,   390.4,  3965.08],\n",
        "[648,   379.2,  3857.6],\n",
        "[650,   368,    3750.12],\n",
        "[652,   356.8,  3642.64],\n",
        "[654,   345.6,  3535.16],\n",
        "[656,   335.2,  3427.68],\n",
        "[658,   325.6,  3320.2],\n",
        "[660,   319.6,  3226.56],\n",
        "[662,   314,    3140.28],\n",
        "[664,   308.4,  3053.96],\n",
        "[666,   302.8,  2967.68],\n",
        "[668,   298,    2881.4],\n",
        "[670,   294,    2795.12],\n",
        "[672,   290,    2708.84],\n",
        "[674,   285.6,  2627.64],\n",
        "[676,   282,    2554.4],\n",
        "[678,   279.2,  2481.16],\n",
        "[680,   277.6,  2407.92],\n",
        "[682,   276,    2334.68],\n",
        "[684,   274.4,  2261.48],\n",
        "[686,   272.8,  2188.24],\n",
        "[688,   274.4,  2115],\n",
        "[690,   276,    2051.96],\n",
        "[692,   277.6,  2000.48],\n",
        "[694,   279.2,  1949.04],\n",
        "[696,   282,    1897.56],\n",
        "[698,   286,    1846.08],\n",
        "[700,   290,    1794.28],\n",
        "[702,   294,    1741],\n",
        "[704,   298,    1687.76],\n",
        "[706,   302.8,  1634.48],\n",
        "[708,   308.4,  1583.52],\n",
        "[710,   314,    1540.48],\n",
        "[712,   319.6,  1497.4],\n",
        "[714,   325.2,  1454.36],\n",
        "[716,   332,    1411.32],\n",
        "[718,   340,    1368.28],\n",
        "[720,   348,    1325.88],\n",
        "[722,   356,    1285.16],\n",
        "[724,   364,    1244.44],\n",
        "[726,   372.4,  1203.68],\n",
        "[728,   381.2,  1152.8],\n",
        "[730,   390,    1102.2],\n",
        "[732,   398.8,  1102.2],\n",
        "[734,   407.6,  1102.2],\n",
        "[736,   418.8,  1101.76],\n",
        "[738,   432.4,  1100.48],\n",
        "[740,   446,    1115.88],\n",
        "[742,   459.6,  1161.64],\n",
        "[744,   473.2,  1207.4],\n",
        "[746,   487.6,  1266.04],\n",
        "[748,   502.8,  1333.24],\n",
        "[750,   518,    1405.24],\n",
        "[752,   533.2,  1515.32],\n",
        "[754,   548.4,  1541.76],\n",
        "[756,   562,    1560.48],\n",
        "[758,   574,    1560.48],\n",
        "[760,   586,    1548.52],\n",
        "[762,   598,    1508.44],\n",
        "[764,   610,    1459.56],\n",
        "[766,   622.8,  1410.52],\n",
        "[768,   636.4,  1361.32],\n",
        "[770,   650,    1311.88],\n",
        "[772,   663.6,  1262.44],\n",
        "[774,   677.2,  1213],\n",
        "[776,   689.2,  1163.56],\n",
        "[778,   699.6,  1114.8],\n",
        "[780,   710,    1075.44],\n",
        "[782,   720.4,  1036.08],\n",
        "[784,   730.8,  996.72],\n",
        "[786,   740,    957.36],\n",
        "[788,   748,    921.8],\n",
        "[790,   756,    890.8],\n",
        "[792,   764,    859.8],\n",
        "[794,   772,    828.8],\n",
        "[796,   786.4,  802.96],\n",
        "[798,   807.2,  782.36],\n",
        "[800,   816,    761.72],\n",
        "[802,   828,    743.84],\n",
        "[804,   836,    737.08],\n",
        "[806,   844,    730.28],\n",
        "[808,   856,    723.52],\n",
        "[810,   864,    717.08],\n",
        "[812,   872,    711.84],\n",
        "[814,   880,    706.6],\n",
        "[816,   887.2,  701.32],\n",
        "[818,   901.6,  696.08],\n",
        "[820,   916,    693.76],\n",
        "[822,   930.4,  693.6],\n",
        "[824,   944.8,  693.48],\n",
        "[826,   956.4,  693.32],\n",
        "[828,   965.2,  693.2],\n",
        "[830,   974,    693.04],\n",
        "[832,   982.8,  692.92],\n",
        "[834,   991.6,  692.76],\n",
        "[836,   1001.2, 692.64],\n",
        "[838,   1011.6, 692.48],\n",
        "[840,   1022,   692.36],\n",
        "[842,   1032.4, 692.2],\n",
        "[844,   1042.8, 691.96],\n",
        "[846,   1050,   691.76],\n",
        "[848,   1054,   691.52],\n",
        "[850,   1058,   691.32],\n",
        "[852,   1062,   691.08],\n",
        "[854,   1066,   690.88],\n",
        "[856,   1072.8, 690.64],\n",
        "[858,   1082.4, 692.44],\n",
        "[860,   1092,   694.32],\n",
        "[862,   1101.6, 696.2],\n",
        "[864,   1111.2, 698.04],\n",
        "[866,   1118.4, 699.92],\n",
        "[868,   1123.2, 701.8],\n",
        "[870,   1128,   705.84],\n",
        "[872,   1132.8, 709.96],\n",
        "[874,   1137.6, 714.08],\n",
        "[876,   1142.8, 718.2],\n",
        "[878,   1148.4, 722.32],\n",
        "[880,   1154,   726.44],\n",
        "[882,   1159.6, 729.84],\n",
        "[884,   1165.2, 733.2],\n",
        "[886,   1170,   736.6],\n",
        "[888,   1174,   739.96],\n",
        "[890,   1178,   743.6],\n",
        "[892,   1182,   747.24],\n",
        "[894,   1186,   750.88],\n",
        "[896,   1190,   754.52],\n",
        "[898,   1194,   758.16],\n",
        "[900,   1198,   761.84],\n",
        "[902,   1202,   765.04],\n",
        "[904,   1206,   767.44],\n",
        "[906,   1209.2, 769.8],\n",
        "[908,   1211.6, 772.16],\n",
        "[910,   1214,   774.56],\n",
        "[912,   1216.4, 776.92],\n",
        "[914,   1218.8, 778.4],\n",
        "[916,   1220.8, 778.04],\n",
        "[918,   1222.4, 777.72],\n",
        "[920,   1224,   777.36],\n",
        "[922,   1225.6, 777.04],\n",
        "[924,   1227.2, 776.64],\n",
        "[926,   1226.8, 772.36],\n",
        "[928,   1224.4, 768.08],\n",
        "[930,   1222,   763.84],\n",
        "[932,   1219.6, 752.28],\n",
        "[934,   1217.2, 737.56],\n",
        "[936,   1215.6, 722.88],\n",
        "[938,   1214.8, 708.16],\n",
        "[940,   1214,   693.44],\n",
        "[942,   1213.2, 678.72],\n",
        "[944,   1212.4, 660.52],\n",
        "[946,   1210.4, 641.08],\n",
        "[948,   1207.2, 621.64],\n",
        "[950,   1204,   602.24],\n",
        "[952,   1200.8, 583.4],\n",
        "[954,   1197.6, 568.92],\n",
        "[956,   1194,   554.48],\n",
        "[958,   1190,   540.04],\n",
        "[960,   1186,   525.56],\n",
        "[962,   1182,   511.12],\n",
        "[964,   1178,   495.36],\n",
        "[966,   1173.2, 473.32],\n",
        "[968,   1167.6, 451.32],\n",
        "[970,   1162,   429.32],\n",
        "[972,   1156.4, 415.28],\n",
        "[974,   1150.8, 402.28],\n",
        "[976,   1144,   389.288],\n",
        "[978,   1136,   374.944],\n",
        "[980,   1128,   359.656],\n",
        "[982,   1120,   344.372],\n",
        "[984,   1112,   329.084],\n",
        "[986,   1102.4, 313.796],\n",
        "[988,   1091.2, 298.508],\n",
        "[990,   1080,   283.22],\n",
        "[992,   1068.8, 267.932],\n",
        "[994,   1057.6, 252.648],\n",
        "[996,   1046.4, 237.36],\n",
        "[998,   1035.2, 222.072],\n",
        "[1000,  1024,   206.784]])\n",
        "\n",
        "hbohb_abscoef = 1*hbohb_extinctions\n",
        "hbohb_abscoef[:,1:] = hbohb_abscoef[:,1:]*np.log(10)\n",
        "\n",
        "\n",
        "#\n",
        "# ABSORPTION SPECTRUMOF H20\n",
        "# FROM G. M. Hale and M. R. Querry, \"Optical constants of water in the 200nm to\n",
        "# 200micrometers wavelength region,\" Appl. Opt., 12, 555--563, (1973).\n",
        "#\n",
        "# ON THE WEB AT\n",
        "# http://omlc.ogi.edu/spectra/water/abs/index.html\n",
        "#\n",
        "h2o_abscoef = np.array([\n",
        "[200.00,    0.069000],\n",
        "[225.00,    0.027400],\n",
        "[250.00,    0.016800],\n",
        "[275.00,    0.010700],\n",
        "[300.00,    0.0067000],\n",
        "[325.00,    0.0041800],\n",
        "[350.00,    0.0023300],\n",
        "[375.00,    0.0011700],\n",
        "[400.00,    0.00058000],\n",
        "[425.00,    0.00038000],\n",
        "[450.00,    0.00028000],\n",
        "[475.00,    0.00024700],\n",
        "[500.00,    0.00025000],\n",
        "[525.00,    0.00032000],\n",
        "[550.00,    0.00045000],\n",
        "[575.00,    0.00079000],\n",
        "[600.00,    0.0023000],\n",
        "[625.00,    0.0028000],\n",
        "[650.00,    0.0032000],\n",
        "[675.00,    0.0041500],\n",
        "[700.00,    0.0060000],\n",
        "[725.00,    0.015900],\n",
        "[750.00,    0.026000],\n",
        "[775.00,    0.024000],\n",
        "[800.00,    0.020000],\n",
        "[810.00,    0.019858],\n",
        "[820.00,    0.023907],\n",
        "[825.00,    0.028000],\n",
        "[830.00,    0.029069],\n",
        "[840.00,    0.034707],\n",
        "[850.00,    0.043000],\n",
        "[860.00,    0.046759],\n",
        "[870.00,    0.051999],\n",
        "[875.00,    0.056000],\n",
        "[880.00,    0.055978],\n",
        "[890.00,    0.060432],\n",
        "[900.00,    0.068000],\n",
        "[910.00,    0.072913],\n",
        "[920.00,    0.10927],\n",
        "[925.00,    0.14400],\n",
        "[930.00,    0.17296],\n",
        "[940.00,    0.26737],\n",
        "[950.00,    0.39000],\n",
        "[960.00,    0.42000],\n",
        "[970.00,    0.45000],\n",
        "[975.00,    0.45000],\n",
        "[980.00,    0.43000],\n",
        "[990.00,    0.41000],\n",
        "[1000.0,    0.36000]])\n",
        "\n",
        "#\n",
        "# Extinction coefficient for lipid.\n",
        "# I got this from Brian Pogue who got this from Matcher and Cope (DAB)\n",
        "# In units of per mm.\n",
        "#\n",
        "lipid_abscoef = np.array([\n",
        "[650,   0.000080],\n",
        "[652,   0.000080],\n",
        "[654,   0.000080],\n",
        "[656,   0.000080],\n",
        "[658,   0.000080],\n",
        "[660,   0.000080],\n",
        "[662,   0.000080],\n",
        "[664,   0.000080],\n",
        "[666,   0.000080],\n",
        "[668,   0.000080],\n",
        "[670,   0.000080],\n",
        "[672,   0.000080],\n",
        "[674,   0.000080],\n",
        "[676,   0.000080],\n",
        "[678,   0.000080],\n",
        "[680,   0.000080],\n",
        "[682,   0.000080],\n",
        "[684,   0.000080],\n",
        "[686,   0.000080],\n",
        "[688,   0.000080],\n",
        "[690,   0.000080],\n",
        "[692,   0.000080],\n",
        "[694,   0.000080],\n",
        "[696,   0.000080],\n",
        "[698,   0.000080],\n",
        "[700,   0.000080],\n",
        "[702,   0.000080],\n",
        "[704,   0.000080],\n",
        "[706,   0.000080],\n",
        "[708,   0.000080],\n",
        "[710,   0.000080],\n",
        "[712,   0.000080],\n",
        "[714,   0.000080],\n",
        "[716,   0.000080],\n",
        "[718,   0.000080],\n",
        "[720,   0.000096],\n",
        "[722,   0.000101],\n",
        "[724,   0.000096],\n",
        "[726,   0.000100],\n",
        "[728,   0.000090],\n",
        "[730,   0.000089],\n",
        "[732,   0.000093],\n",
        "[734,   0.000105],\n",
        "[736,   0.000123],\n",
        "[738,   0.000148],\n",
        "[740,   0.000179],\n",
        "[742,   0.000214],\n",
        "[744,   0.000254],\n",
        "[746,   0.000296],\n",
        "[748,   0.000341],\n",
        "[750,   0.000385],\n",
        "[752,   0.000426],\n",
        "[754,   0.000462],\n",
        "[756,   0.000491],\n",
        "[758,   0.000510],\n",
        "[760,   0.000515],\n",
        "[762,   0.000498],\n",
        "[764,   0.000458],\n",
        "[766,   0.000399],\n",
        "[768,   0.000333],\n",
        "[770,   0.000267],\n",
        "[772,   0.000206],\n",
        "[774,   0.000155],\n",
        "[776,   0.000106],\n",
        "[778,   0.000063],\n",
        "[780,   0.000033],\n",
        "[782,   0.000021],\n",
        "[784,   0.000023],\n",
        "[786,   0.000029],\n",
        "[788,   0.000027],\n",
        "[790,   0.000017],\n",
        "[792,   0.000006],\n",
        "[794,   0.000000],\n",
        "[796,   0.000002],\n",
        "[798,   0.000009],\n",
        "[800,   0.000021],\n",
        "[802,   0.000037],\n",
        "[804,   0.000055],\n",
        "[806,   0.000073],\n",
        "[808,   0.000091],\n",
        "[810,   0.000109],\n",
        "[812,   0.000128],\n",
        "[814,   0.000146],\n",
        "[816,   0.000163],\n",
        "[818,   0.000178],\n",
        "[820,   0.000193],\n",
        "[822,   0.000205],\n",
        "[824,   0.000214],\n",
        "[826,   0.000219],\n",
        "[828,   0.000221],\n",
        "[830,   0.000219],\n",
        "[832,   0.000213],\n",
        "[834,   0.000205],\n",
        "[836,   0.000193],\n",
        "[838,   0.000180],\n",
        "[840,   0.000167],\n",
        "[842,   0.000155],\n",
        "[844,   0.000145],\n",
        "[846,   0.000138],\n",
        "[848,   0.000135],\n",
        "[852,   0.000130],\n",
        "[854,   0.000130],\n",
        "[856,   0.000137],\n",
        "[858,   0.000153],\n",
        "[860,   0.000179],\n",
        "[862,   0.000216],\n",
        "[864,   0.000265],\n",
        "[866,   0.000329],\n",
        "[868,   0.000408],\n",
        "[870,   0.000505],\n",
        "[872,   0.000618],\n",
        "[874,   0.000758],\n",
        "[876,   0.000919],\n",
        "[878,   0.001103],\n",
        "[880,   0.001314],\n",
        "[882,   0.001552],\n",
        "[884,   0.001809],\n",
        "[886,   0.002082],\n",
        "[888,   0.002365],\n",
        "[890,   0.002653],\n",
        "[892,   0.002939],\n",
        "[894,   0.003224],\n",
        "[896,   0.003521],\n",
        "[898,   0.003833],\n",
        "[900,   0.004168],\n",
        "[902,   0.004545],\n",
        "[904,   0.004976],\n",
        "[906,   0.005451],\n",
        "[908,   0.005969],\n",
        "[910,   0.006522],\n",
        "[912,   0.007106],\n",
        "[914,   0.007686],\n",
        "[916,   0.008235],\n",
        "[918,   0.008744],\n",
        "[920,   0.009179],\n",
        "[922,   0.009484],\n",
        "[924,   0.009644],\n",
        "[926,   0.009602],\n",
        "[928,   0.009363],\n",
        "[930,   0.008895],\n",
        "[932,   0.008275],\n",
        "[934,   0.007497],\n",
        "[936,   0.006648],\n",
        "[938,   0.005792],\n",
        "[940,   0.004947],\n",
        "[942,   0.004166],\n",
        "[944,   0.003467],\n",
        "[946,   0.002859],\n",
        "[948,   0.002337],\n",
        "[950,   0.001898],\n",
        "[952,   0.001544],\n",
        "[954,   0.001258],\n",
        "[956,   0.001022],\n",
        "[958,   0.000830],\n",
        "[960,   0.000678],\n",
        "[962,   0.000553],\n",
        "[964,   0.000451],\n",
        "[966,   0.000365],\n",
        "[968,   0.000298],\n",
        "[970,   0.000244],\n",
        "[972,   0.000204],\n",
        "[974,   0.000176],\n",
        "[976,   0.000163],\n",
        "[978,   0.000165],\n",
        "[980,   0.000185],\n",
        "[982,   0.000221],\n",
        "[984,   0.000278],\n",
        "[986,   0.000351],\n",
        "[988,   0.000448],\n",
        "[990,   0.000564],\n",
        "[992,   0.000698],\n",
        "[994,   0.000853],\n",
        "[996,   0.001027],\n",
        "[998,   0.001215],\n",
        "[1000,  0.001420],\n",
        "[1002,  0.001643],\n",
        "[1004,  0.001882],\n",
        "[1006,  0.002127],\n",
        "[1008,  0.002371],\n",
        "[1010,  0.002619],\n",
        "[1012,  0.002858],\n",
        "[1014,  0.003077],\n",
        "[1016,  0.003279],\n",
        "[1018,  0.003463],\n",
        "[1020,  0.003635],\n",
        "[1022,  0.003793],\n",
        "[1024,  0.003941],\n",
        "[1026,  0.004084],\n",
        "[1028,  0.004220],\n",
        "[1030,  0.004338],\n",
        "[1032,  0.004438],\n",
        "[1034,  0.004505],\n",
        "[1036,  0.004537],\n",
        "[1038,  0.004524],\n",
        "[1040,  0.004468],\n",
        "[1042,  0.004365],\n",
        "[1044,  0.004229],\n",
        "[1046,  0.004065],\n",
        "[1048,  0.003880],\n",
        "[1050,  0.003677],\n",
        "[1052,  0.003469],\n",
        "[1054,  0.003259],\n",
        "[1056,  0.003051],\n",
        "[1058,  0.002843]])\n",
        "\n",
        "# Cytochrome AA3 abscoef\n",
        "aa3_abscoef = np.array([\n",
        "[6.5000000e+002, 1.1361272e+000],\n",
        "[6.5050000e+002, 1.1318779e+000],\n",
        "[6.5100000e+002, 1.1276285e+000],\n",
        "[6.5150000e+002, 1.1233792e+000],\n",
        "[6.5200000e+002, 1.1191298e+000],\n",
        "[6.5250000e+002, 1.1135125e+000],\n",
        "[6.5300000e+002, 1.1078952e+000],\n",
        "[6.5350000e+002, 1.1022779e+000],\n",
        "[6.5400000e+002, 1.0966605e+000],\n",
        "[6.5450000e+002, 1.0903251e+000],\n",
        "[6.5500000e+002, 1.0839896e+000],\n",
        "[6.5550000e+002, 1.0776542e+000],\n",
        "[6.5600000e+002, 1.0713187e+000],\n",
        "[6.5650000e+002, 1.0643820e+000],\n",
        "[6.5700000e+002, 1.0574453e+000],\n",
        "[6.5750000e+002, 1.0505086e+000],\n",
        "[6.5800000e+002, 1.0435719e+000],\n",
        "[6.5850000e+002, 1.0362062e+000],\n",
        "[6.5900000e+002, 1.0288404e+000],\n",
        "[6.5950000e+002, 1.0214747e+000],\n",
        "[6.6000000e+002, 1.0141090e+000],\n",
        "[6.6050000e+002, 1.0062588e+000],\n",
        "[6.6100000e+002, 9.9840857e-001],\n",
        "[6.6150000e+002, 9.9055837e-001],\n",
        "[6.6200000e+002, 9.8270816e-001],\n",
        "[6.6250000e+002, 9.7439221e-001],\n",
        "[6.6300000e+002, 9.6607626e-001],\n",
        "[6.6350000e+002, 9.5776031e-001],\n",
        "[6.6400000e+002, 9.4944435e-001],\n",
        "[6.6450000e+002, 9.4080158e-001],\n",
        "[6.6500000e+002, 9.3215880e-001],\n",
        "[6.6550000e+002, 9.2351603e-001],\n",
        "[6.6600000e+002, 9.1487325e-001],\n",
        "[6.6650000e+002, 9.0655165e-001],\n",
        "[6.6700000e+002, 8.9823004e-001],\n",
        "[6.6750000e+002, 8.8990843e-001],\n",
        "[6.6800000e+002, 8.8158682e-001],\n",
        "[6.6850000e+002, 8.7315553e-001],\n",
        "[6.6900000e+002, 8.6472424e-001],\n",
        "[6.6950000e+002, 8.5629295e-001],\n",
        "[6.7000000e+002, 8.4786166e-001],\n",
        "[6.7050000e+002, 8.3951725e-001],\n",
        "[6.7100000e+002, 8.3117284e-001],\n",
        "[6.7150000e+002, 8.2282843e-001],\n",
        "[6.7200000e+002, 8.1448402e-001],\n",
        "[6.7250000e+002, 8.0625998e-001],\n",
        "[6.7300000e+002, 7.9803594e-001],\n",
        "[6.7350000e+002, 7.8981191e-001],\n",
        "[6.7400000e+002, 7.8158787e-001],\n",
        "[6.7450000e+002, 7.7355802e-001],\n",
        "[6.7500000e+002, 7.6552817e-001],\n",
        "[6.7550000e+002, 7.5749832e-001],\n",
        "[6.7600000e+002, 7.4946847e-001],\n",
        "[6.7650000e+002, 7.4157127e-001],\n",
        "[6.7700000e+002, 7.3367407e-001],\n",
        "[6.7750000e+002, 7.2577687e-001],\n",
        "[6.7800000e+002, 7.1787968e-001],\n",
        "[6.7850000e+002, 7.1103726e-001],\n",
        "[6.7900000e+002, 7.0419484e-001],\n",
        "[6.7950000e+002, 6.9735242e-001],\n",
        "[6.8000000e+002, 6.9051001e-001],\n",
        "[6.8050000e+002, 6.8506908e-001],\n",
        "[6.8100000e+002, 6.7962815e-001],\n",
        "[6.8150000e+002, 6.7418722e-001],\n",
        "[6.8200000e+002, 6.6874629e-001],\n",
        "[6.8250000e+002, 6.6413673e-001],\n",
        "[6.8300000e+002, 6.5952716e-001],\n",
        "[6.8350000e+002, 6.5491759e-001],\n",
        "[6.8400000e+002, 6.5030802e-001],\n",
        "[6.8450000e+002, 6.4610502e-001],\n",
        "[6.8500000e+002, 6.4190202e-001],\n",
        "[6.8550000e+002, 6.3769903e-001],\n",
        "[6.8600000e+002, 6.3349603e-001],\n",
        "[6.8650000e+002, 6.2987997e-001],\n",
        "[6.8700000e+002, 6.2626392e-001],\n",
        "[6.8750000e+002, 6.2264786e-001],\n",
        "[6.8800000e+002, 6.1903181e-001],\n",
        "[6.8850000e+002, 6.1593488e-001],\n",
        "[6.8900000e+002, 6.1283796e-001],\n",
        "[6.8950000e+002, 6.0974103e-001],\n",
        "[6.9000000e+002, 6.0664411e-001],\n",
        "[6.9050000e+002, 6.0393052e-001],\n",
        "[6.9100000e+002, 6.0121692e-001],\n",
        "[6.9150000e+002, 5.9850333e-001],\n",
        "[6.9200000e+002, 5.9578974e-001],\n",
        "[6.9250000e+002, 5.9354479e-001],\n",
        "[6.9300000e+002, 5.9129984e-001],\n",
        "[6.9350000e+002, 5.8905489e-001],\n",
        "[6.9400000e+002, 5.8680994e-001],\n",
        "[6.9450000e+002, 5.8419281e-001],\n",
        "[6.9500000e+002, 5.8157569e-001],\n",
        "[6.9550000e+002, 5.7895857e-001],\n",
        "[6.9600000e+002, 5.7634144e-001],\n",
        "[6.9650000e+002, 5.7395588e-001],\n",
        "[6.9700000e+002, 5.7157032e-001],\n",
        "[6.9750000e+002, 5.6918475e-001],\n",
        "[6.9800000e+002, 5.6679919e-001],\n",
        "[6.9850000e+002, 5.6423313e-001],\n",
        "[6.9900000e+002, 5.6166706e-001],\n",
        "[6.9950000e+002, 5.5910100e-001],\n",
        "[7.0000000e+002, 5.5653494e-001],\n",
        "[7.0050000e+002, 5.5386633e-001],\n",
        "[7.0100000e+002, 5.5119773e-001],\n",
        "[7.0150000e+002, 5.4852912e-001],\n",
        "[7.0200000e+002, 5.4586052e-001],\n",
        "[7.0250000e+002, 5.4295036e-001],\n",
        "[7.0300000e+002, 5.4004020e-001],\n",
        "[7.0350000e+002, 5.3713004e-001],\n",
        "[7.0400000e+002, 5.3421989e-001],\n",
        "[7.0450000e+002, 5.3157177e-001],\n",
        "[7.0500000e+002, 5.2892366e-001],\n",
        "[7.0550000e+002, 5.2627555e-001],\n",
        "[7.0600000e+002, 5.2362744e-001],\n",
        "[7.0650000e+002, 5.2040945e-001],\n",
        "[7.0700000e+002, 5.1719147e-001],\n",
        "[7.0750000e+002, 5.1397349e-001],\n",
        "[7.0800000e+002, 5.1075551e-001],\n",
        "[7.0850000e+002, 5.0755727e-001],\n",
        "[7.0900000e+002, 5.0435903e-001],\n",
        "[7.0950000e+002, 5.0116079e-001],\n",
        "[7.1000000e+002, 4.9796255e-001],\n",
        "[7.1050000e+002, 4.9508362e-001],\n",
        "[7.1100000e+002, 4.9220470e-001],\n",
        "[7.1150000e+002, 4.8932577e-001],\n",
        "[7.1200000e+002, 4.8644684e-001],\n",
        "[7.1250000e+002, 4.8309329e-001],\n",
        "[7.1300000e+002, 4.7973974e-001],\n",
        "[7.1350000e+002, 4.7638620e-001],\n",
        "[7.1400000e+002, 4.7303265e-001],\n",
        "[7.1450000e+002, 4.6986524e-001],\n",
        "[7.1500000e+002, 4.6669783e-001],\n",
        "[7.1550000e+002, 4.6353042e-001],\n",
        "[7.1600000e+002, 4.6036302e-001],\n",
        "[7.1650000e+002, 4.5755399e-001],\n",
        "[7.1700000e+002, 4.5474496e-001],\n",
        "[7.1750000e+002, 4.5193593e-001],\n",
        "[7.1800000e+002, 4.4912691e-001],\n",
        "[7.1850000e+002, 4.4661044e-001],\n",
        "[7.1900000e+002, 4.4409397e-001],\n",
        "[7.1950000e+002, 4.4157750e-001],\n",
        "[7.2000000e+002, 4.3906103e-001],\n",
        "[7.2050000e+002, 4.3703350e-001],\n",
        "[7.2100000e+002, 4.3500597e-001],\n",
        "[7.2150000e+002, 4.3297844e-001],\n",
        "[7.2200000e+002, 4.3095091e-001],\n",
        "[7.2250000e+002, 4.2950659e-001],\n",
        "[7.2300000e+002, 4.2806227e-001],\n",
        "[7.2350000e+002, 4.2661795e-001],\n",
        "[7.2400000e+002, 4.2517362e-001],\n",
        "[7.2450000e+002, 4.2406847e-001],\n",
        "[7.2500000e+002, 4.2296331e-001],\n",
        "[7.2550000e+002, 4.2185816e-001],\n",
        "[7.2600000e+002, 4.2075300e-001],\n",
        "[7.2650000e+002, 4.1981891e-001],\n",
        "[7.2700000e+002, 4.1888482e-001],\n",
        "[7.2750000e+002, 4.1795073e-001],\n",
        "[7.2800000e+002, 4.1701664e-001],\n",
        "[7.2850000e+002, 4.1654428e-001],\n",
        "[7.2900000e+002, 4.1607191e-001],\n",
        "[7.2950000e+002, 4.1559955e-001],\n",
        "[7.3000000e+002, 4.1512718e-001],\n",
        "[7.3050000e+002, 4.1505277e-001],\n",
        "[7.3100000e+002, 4.1497836e-001],\n",
        "[7.3150000e+002, 4.1490395e-001],\n",
        "[7.3200000e+002, 4.1482954e-001],\n",
        "[7.3250000e+002, 4.1477623e-001],\n",
        "[7.3300000e+002, 4.1472291e-001],\n",
        "[7.3350000e+002, 4.1466960e-001],\n",
        "[7.3400000e+002, 4.1461628e-001],\n",
        "[7.3450000e+002, 4.1479630e-001],\n",
        "[7.3500000e+002, 4.1497632e-001],\n",
        "[7.3550000e+002, 4.1515633e-001],\n",
        "[7.3600000e+002, 4.1533635e-001],\n",
        "[7.3650000e+002, 4.1555474e-001],\n",
        "[7.3700000e+002, 4.1577314e-001],\n",
        "[7.3750000e+002, 4.1599153e-001],\n",
        "[7.3800000e+002, 4.1620993e-001],\n",
        "[7.3850000e+002, 4.1670986e-001],\n",
        "[7.3900000e+002, 4.1720980e-001],\n",
        "[7.3950000e+002, 4.1770974e-001],\n",
        "[7.4000000e+002, 4.1820967e-001],\n",
        "[7.4050000e+002, 4.1892740e-001],\n",
        "[7.4100000e+002, 4.1964513e-001],\n",
        "[7.4150000e+002, 4.2036286e-001],\n",
        "[7.4200000e+002, 4.2108058e-001],\n",
        "[7.4250000e+002, 4.2179731e-001],\n",
        "[7.4300000e+002, 4.2251404e-001],\n",
        "[7.4350000e+002, 4.2323076e-001],\n",
        "[7.4400000e+002, 4.2394749e-001],\n",
        "[7.4450000e+002, 4.2453814e-001],\n",
        "[7.4500000e+002, 4.2512878e-001],\n",
        "[7.4550000e+002, 4.2571943e-001],\n",
        "[7.4600000e+002, 4.2631007e-001],\n",
        "[7.4650000e+002, 4.2678948e-001],\n",
        "[7.4700000e+002, 4.2726889e-001],\n",
        "[7.4750000e+002, 4.2774830e-001],\n",
        "[7.4800000e+002, 4.2822770e-001],\n",
        "[7.4850000e+002, 4.2880242e-001],\n",
        "[7.4900000e+002, 4.2937714e-001],\n",
        "[7.4950000e+002, 4.2995185e-001],\n",
        "[7.5000000e+002, 4.3052657e-001],\n",
        "[7.5050000e+002, 4.3148348e-001],\n",
        "[7.5100000e+002, 4.3244039e-001],\n",
        "[7.5150000e+002, 4.3339730e-001],\n",
        "[7.5200000e+002, 4.3435422e-001],\n",
        "[7.5250000e+002, 4.3511742e-001],\n",
        "[7.5300000e+002, 4.3588062e-001],\n",
        "[7.5350000e+002, 4.3664382e-001],\n",
        "[7.5400000e+002, 4.3740702e-001],\n",
        "[7.5450000e+002, 4.3781744e-001],\n",
        "[7.5500000e+002, 4.3822787e-001],\n",
        "[7.5550000e+002, 4.3863830e-001],\n",
        "[7.5600000e+002, 4.3904872e-001],\n",
        "[7.5650000e+002, 4.3940898e-001],\n",
        "[7.5700000e+002, 4.3976923e-001],\n",
        "[7.5750000e+002, 4.4012949e-001],\n",
        "[7.5800000e+002, 4.4048975e-001],\n",
        "[7.5850000e+002, 4.4084169e-001],\n",
        "[7.5900000e+002, 4.4119364e-001],\n",
        "[7.5950000e+002, 4.4154558e-001],\n",
        "[7.6000000e+002, 4.4189753e-001],\n",
        "[7.6050000e+002, 4.4222139e-001],\n",
        "[7.6100000e+002, 4.4254525e-001],\n",
        "[7.6150000e+002, 4.4286911e-001],\n",
        "[7.6200000e+002, 4.4319298e-001],\n",
        "[7.6250000e+002, 4.4377194e-001],\n",
        "[7.6300000e+002, 4.4435090e-001],\n",
        "[7.6350000e+002, 4.4492986e-001],\n",
        "[7.6400000e+002, 4.4550882e-001],\n",
        "[7.6450000e+002, 4.4615044e-001],\n",
        "[7.6500000e+002, 4.4679205e-001],\n",
        "[7.6550000e+002, 4.4743367e-001],\n",
        "[7.6600000e+002, 4.4807529e-001],\n",
        "[7.6650000e+002, 4.4866327e-001],\n",
        "[7.6700000e+002, 4.4925126e-001],\n",
        "[7.6750000e+002, 4.4983925e-001],\n",
        "[7.6800000e+002, 4.5042724e-001],\n",
        "[7.6850000e+002, 4.5104584e-001],\n",
        "[7.6900000e+002, 4.5166445e-001],\n",
        "[7.6950000e+002, 4.5228305e-001],\n",
        "[7.7000000e+002, 4.5290166e-001],\n",
        "[7.7050000e+002, 4.5346397e-001],\n",
        "[7.7100000e+002, 4.5402629e-001],\n",
        "[7.7150000e+002, 4.5458860e-001],\n",
        "[7.7200000e+002, 4.5515091e-001],\n",
        "[7.7250000e+002, 4.5580540e-001],\n",
        "[7.7300000e+002, 4.5645989e-001],\n",
        "[7.7350000e+002, 4.5711438e-001],\n",
        "[7.7400000e+002, 4.5776888e-001],\n",
        "[7.7450000e+002, 4.5874658e-001],\n",
        "[7.7500000e+002, 4.5972429e-001],\n",
        "[7.7550000e+002, 4.6070200e-001],\n",
        "[7.7600000e+002, 4.6167971e-001],\n",
        "[7.7650000e+002, 4.6304014e-001],\n",
        "[7.7700000e+002, 4.6440057e-001],\n",
        "[7.7750000e+002, 4.6576100e-001],\n",
        "[7.7800000e+002, 4.6712143e-001],\n",
        "[7.7850000e+002, 4.6842946e-001],\n",
        "[7.7900000e+002, 4.6973749e-001],\n",
        "[7.7950000e+002, 4.7104552e-001],\n",
        "[7.8000000e+002, 4.7235355e-001],\n",
        "[7.8050000e+002, 4.7364174e-001],\n",
        "[7.8100000e+002, 4.7492993e-001],\n",
        "[7.8150000e+002, 4.7621812e-001],\n",
        "[7.8200000e+002, 4.7750631e-001],\n",
        "[7.8250000e+002, 4.7897505e-001],\n",
        "[7.8300000e+002, 4.8044380e-001],\n",
        "[7.8350000e+002, 4.8191254e-001],\n",
        "[7.8400000e+002, 4.8338128e-001],\n",
        "[7.8450000e+002, 4.8455794e-001],\n",
        "[7.8500000e+002, 4.8573459e-001],\n",
        "[7.8550000e+002, 4.8691125e-001],\n",
        "[7.8600000e+002, 4.8808791e-001],\n",
        "[7.8650000e+002, 4.8910580e-001],\n",
        "[7.8700000e+002, 4.9012369e-001],\n",
        "[7.8750000e+002, 4.9114158e-001],\n",
        "[7.8800000e+002, 4.9215948e-001],\n",
        "[7.8850000e+002, 4.9300490e-001],\n",
        "[7.8900000e+002, 4.9385033e-001],\n",
        "[7.8950000e+002, 4.9469576e-001],\n",
        "[7.9000000e+002, 4.9554119e-001],\n",
        "[7.9050000e+002, 4.9630072e-001],\n",
        "[7.9100000e+002, 4.9706025e-001],\n",
        "[7.9150000e+002, 4.9781978e-001],\n",
        "[7.9200000e+002, 4.9857931e-001],\n",
        "[7.9250000e+002, 5.0001031e-001],\n",
        "[7.9300000e+002, 5.0144130e-001],\n",
        "[7.9350000e+002, 5.0287230e-001],\n",
        "[7.9400000e+002, 5.0430330e-001],\n",
        "[7.9450000e+002, 5.0577552e-001],\n",
        "[7.9500000e+002, 5.0724773e-001],\n",
        "[7.9550000e+002, 5.0871995e-001],\n",
        "[7.9600000e+002, 5.1019217e-001],\n",
        "[7.9650000e+002, 5.1177102e-001],\n",
        "[7.9700000e+002, 5.1334987e-001],\n",
        "[7.9750000e+002, 5.1492872e-001],\n",
        "[7.9800000e+002, 5.1650758e-001],\n",
        "[7.9850000e+002, 5.1767295e-001],\n",
        "[7.9900000e+002, 5.1883832e-001],\n",
        "[7.9950000e+002, 5.2000370e-001],\n",
        "[8.0000000e+002, 5.2116907e-001],\n",
        "[8.0050000e+002, 5.2170964e-001],\n",
        "[8.0100000e+002, 5.2225020e-001],\n",
        "[8.0150000e+002, 5.2279077e-001],\n",
        "[8.0200000e+002, 5.2333133e-001],\n",
        "[8.0250000e+002, 5.2390635e-001],\n",
        "[8.0300000e+002, 5.2448137e-001],\n",
        "[8.0350000e+002, 5.2505639e-001],\n",
        "[8.0400000e+002, 5.2563141e-001],\n",
        "[8.0450000e+002, 5.2629161e-001],\n",
        "[8.0500000e+002, 5.2695181e-001],\n",
        "[8.0550000e+002, 5.2761202e-001],\n",
        "[8.0600000e+002, 5.2827222e-001],\n",
        "[8.0650000e+002, 5.2901213e-001],\n",
        "[8.0700000e+002, 5.2975205e-001],\n",
        "[8.0750000e+002, 5.3049196e-001],\n",
        "[8.0800000e+002, 5.3123187e-001],\n",
        "[8.0850000e+002, 5.3190100e-001],\n",
        "[8.0900000e+002, 5.3257012e-001],\n",
        "[8.0950000e+002, 5.3323925e-001],\n",
        "[8.1000000e+002, 5.3390837e-001],\n",
        "[8.1050000e+002, 5.3437521e-001],\n",
        "[8.1100000e+002, 5.3484206e-001],\n",
        "[8.1150000e+002, 5.3530890e-001],\n",
        "[8.1200000e+002, 5.3577574e-001],\n",
        "[8.1250000e+002, 5.3610282e-001],\n",
        "[8.1300000e+002, 5.3642990e-001],\n",
        "[8.1350000e+002, 5.3675698e-001],\n",
        "[8.1400000e+002, 5.3708406e-001],\n",
        "[8.1450000e+002, 5.3738179e-001],\n",
        "[8.1500000e+002, 5.3767952e-001],\n",
        "[8.1550000e+002, 5.3797726e-001],\n",
        "[8.1600000e+002, 5.3827499e-001],\n",
        "[8.1650000e+002, 5.3858777e-001],\n",
        "[8.1700000e+002, 5.3890055e-001],\n",
        "[8.1750000e+002, 5.3921333e-001],\n",
        "[8.1800000e+002, 5.3952611e-001],\n",
        "[8.1850000e+002, 5.3983715e-001],\n",
        "[8.1900000e+002, 5.4014818e-001],\n",
        "[8.1950000e+002, 5.4045922e-001],\n",
        "[8.2000000e+002, 5.4077026e-001],\n",
        "[8.2050000e+002, 5.4086522e-001],\n",
        "[8.2100000e+002, 5.4096019e-001],\n",
        "[8.2150000e+002, 5.4105515e-001],\n",
        "[8.2200000e+002, 5.4115011e-001],\n",
        "[8.2250000e+002, 5.4097464e-001],\n",
        "[8.2300000e+002, 5.4079916e-001],\n",
        "[8.2350000e+002, 5.4062369e-001],\n",
        "[8.2400000e+002, 5.4044822e-001],\n",
        "[8.2450000e+002, 5.4014545e-001],\n",
        "[8.2500000e+002, 5.3984269e-001],\n",
        "[8.2550000e+002, 5.3953992e-001],\n",
        "[8.2600000e+002, 5.3923716e-001],\n",
        "[8.2650000e+002, 5.3884421e-001],\n",
        "[8.2700000e+002, 5.3845126e-001],\n",
        "[8.2750000e+002, 5.3805832e-001],\n",
        "[8.2800000e+002, 5.3766537e-001],\n",
        "[8.2850000e+002, 5.3726601e-001],\n",
        "[8.2900000e+002, 5.3686664e-001],\n",
        "[8.2950000e+002, 5.3646728e-001],\n",
        "[8.3000000e+002, 5.3606792e-001],\n",
        "[8.3050000e+002, 5.3569046e-001],\n",
        "[8.3100000e+002, 5.3531300e-001],\n",
        "[8.3150000e+002, 5.3493554e-001],\n",
        "[8.3200000e+002, 5.3455808e-001],\n",
        "[8.3250000e+002, 5.3425944e-001],\n",
        "[8.3300000e+002, 5.3396080e-001],\n",
        "[8.3350000e+002, 5.3366216e-001],\n",
        "[8.3400000e+002, 5.3336352e-001],\n",
        "[8.3450000e+002, 5.3316411e-001],\n",
        "[8.3500000e+002, 5.3296470e-001],\n",
        "[8.3550000e+002, 5.3276529e-001],\n",
        "[8.3600000e+002, 5.3256588e-001],\n",
        "[8.3650000e+002, 5.3247892e-001],\n",
        "[8.3700000e+002, 5.3239197e-001],\n",
        "[8.3750000e+002, 5.3230501e-001],\n",
        "[8.3800000e+002, 5.3221806e-001],\n",
        "[8.3850000e+002, 5.3211789e-001],\n",
        "[8.3900000e+002, 5.3201773e-001],\n",
        "[8.3950000e+002, 5.3191756e-001],\n",
        "[8.4000000e+002, 5.3181739e-001],\n",
        "[8.4050000e+002, 5.3159895e-001],\n",
        "[8.4100000e+002, 5.3138050e-001],\n",
        "[8.4150000e+002, 5.3116205e-001],\n",
        "[8.4200000e+002, 5.3094361e-001],\n",
        "[8.4250000e+002, 5.3066563e-001],\n",
        "[8.4300000e+002, 5.3038766e-001],\n",
        "[8.4350000e+002, 5.3010968e-001],\n",
        "[8.4400000e+002, 5.2983171e-001],\n",
        "[8.4450000e+002, 5.2956491e-001],\n",
        "[8.4500000e+002, 5.2929812e-001],\n",
        "[8.4550000e+002, 5.2903132e-001],\n",
        "[8.4600000e+002, 5.2876453e-001],\n",
        "[8.4650000e+002, 5.2859686e-001],\n",
        "[8.4700000e+002, 5.2842920e-001],\n",
        "[8.4750000e+002, 5.2826153e-001],\n",
        "[8.4800000e+002, 5.2809386e-001],\n",
        "[8.4850000e+002, 5.2801195e-001],\n",
        "[8.4900000e+002, 5.2793003e-001],\n",
        "[8.4950000e+002, 5.2784811e-001],\n",
        "[8.5000000e+002, 5.2776619e-001],\n",
        "[8.5050000e+002, 5.2746834e-001],\n",
        "[8.5100000e+002, 5.2717049e-001],\n",
        "[8.5150000e+002, 5.2687263e-001],\n",
        "[8.5200000e+002, 5.2657478e-001],\n",
        "[8.5250000e+002, 5.2601940e-001],\n",
        "[8.5300000e+002, 5.2546403e-001],\n",
        "[8.5350000e+002, 5.2490865e-001],\n",
        "[8.5400000e+002, 5.2435328e-001],\n",
        "[8.5450000e+002, 5.2352321e-001],\n",
        "[8.5500000e+002, 5.2269315e-001],\n",
        "[8.5550000e+002, 5.2186309e-001],\n",
        "[8.5600000e+002, 5.2103302e-001],\n",
        "[8.5650000e+002, 5.2004711e-001],\n",
        "[8.5700000e+002, 5.1906120e-001],\n",
        "[8.5750000e+002, 5.1807528e-001],\n",
        "[8.5800000e+002, 5.1708937e-001],\n",
        "[8.5850000e+002, 5.1629274e-001],\n",
        "[8.5900000e+002, 5.1549610e-001],\n",
        "[8.5950000e+002, 5.1469947e-001],\n",
        "[8.6000000e+002, 5.1390283e-001],\n",
        "[8.6050000e+002, 5.1338676e-001],\n",
        "[8.6100000e+002, 5.1287070e-001],\n",
        "[8.6150000e+002, 5.1235463e-001],\n",
        "[8.6200000e+002, 5.1183857e-001],\n",
        "[8.6250000e+002, 5.1133847e-001],\n",
        "[8.6300000e+002, 5.1083837e-001],\n",
        "[8.6350000e+002, 5.1033827e-001],\n",
        "[8.6400000e+002, 5.0983817e-001],\n",
        "[8.6450000e+002, 5.0916645e-001],\n",
        "[8.6500000e+002, 5.0849474e-001],\n",
        "[8.6550000e+002, 5.0782302e-001],\n",
        "[8.6600000e+002, 5.0715131e-001],\n",
        "[8.6650000e+002, 5.0635557e-001],\n",
        "[8.6700000e+002, 5.0555984e-001],\n",
        "[8.6750000e+002, 5.0476411e-001],\n",
        "[8.6800000e+002, 5.0396838e-001],\n",
        "[8.6850000e+002, 5.0282658e-001],\n",
        "[8.6900000e+002, 5.0168478e-001],\n",
        "[8.6950000e+002, 5.0054299e-001],\n",
        "[8.7000000e+002, 4.9940119e-001],\n",
        "[8.7050000e+002, 4.9772793e-001],\n",
        "[8.7100000e+002, 4.9605467e-001],\n",
        "[8.7150000e+002, 4.9438141e-001],\n",
        "[8.7200000e+002, 4.9270815e-001],\n",
        "[8.7250000e+002, 4.9123397e-001],\n",
        "[8.7300000e+002, 4.8975980e-001],\n",
        "[8.7350000e+002, 4.8828562e-001],\n",
        "[8.7400000e+002, 4.8681145e-001],\n",
        "[8.7450000e+002, 4.8567142e-001],\n",
        "[8.7500000e+002, 4.8453139e-001],\n",
        "[8.7550000e+002, 4.8339137e-001],\n",
        "[8.7600000e+002, 4.8225134e-001],\n",
        "[8.7650000e+002, 4.8129036e-001],\n",
        "[8.7700000e+002, 4.8032938e-001],\n",
        "[8.7750000e+002, 4.7936841e-001],\n",
        "[8.7800000e+002, 4.7840743e-001],\n",
        "[8.7850000e+002, 4.7750085e-001],\n",
        "[8.7900000e+002, 4.7659428e-001],\n",
        "[8.7950000e+002, 4.7568770e-001],\n",
        "[8.8000000e+002, 4.7478112e-001],\n",
        "[8.8050000e+002, 4.7390575e-001],\n",
        "[8.8100000e+002, 4.7303039e-001],\n",
        "[8.8150000e+002, 4.7215502e-001],\n",
        "[8.8200000e+002, 4.7127965e-001],\n",
        "[8.8250000e+002, 4.7019206e-001],\n",
        "[8.8300000e+002, 4.6910447e-001],\n",
        "[8.8350000e+002, 4.6801688e-001],\n",
        "[8.8400000e+002, 4.6692929e-001],\n",
        "[8.8450000e+002, 4.6576740e-001],\n",
        "[8.8500000e+002, 4.6460552e-001],\n",
        "[8.8550000e+002, 4.6344363e-001],\n",
        "[8.8600000e+002, 4.6228175e-001],\n",
        "[8.8650000e+002, 4.6108543e-001],\n",
        "[8.8700000e+002, 4.5988910e-001],\n",
        "[8.8750000e+002, 4.5869278e-001],\n",
        "[8.8800000e+002, 4.5749646e-001],\n",
        "[8.8850000e+002, 4.5599046e-001],\n",
        "[8.8900000e+002, 4.5448446e-001],\n",
        "[8.8950000e+002, 4.5297846e-001],\n",
        "[8.9000000e+002, 4.5147246e-001],\n",
        "[8.9050000e+002, 4.5001098e-001],\n",
        "[8.9100000e+002, 4.4854950e-001],\n",
        "[8.9150000e+002, 4.4708802e-001],\n",
        "[8.9200000e+002, 4.4562653e-001],\n",
        "[8.9250000e+002, 4.4404932e-001],\n",
        "[8.9300000e+002, 4.4247210e-001],\n",
        "[8.9350000e+002, 4.4089488e-001],\n",
        "[8.9400000e+002, 4.3931766e-001],\n",
        "[8.9450000e+002, 4.3759003e-001],\n",
        "[8.9500000e+002, 4.3586239e-001],\n",
        "[8.9550000e+002, 4.3413476e-001],\n",
        "[8.9600000e+002, 4.3240713e-001],\n",
        "[8.9650000e+002, 4.3071228e-001],\n",
        "[8.9700000e+002, 4.2901743e-001],\n",
        "[8.9750000e+002, 4.2732258e-001],\n",
        "[8.9800000e+002, 4.2562773e-001],\n",
        "[8.9850000e+002, 4.2413598e-001],\n",
        "[8.9900000e+002, 4.2264422e-001],\n",
        "[8.9950000e+002, 4.2115247e-001],\n",
        "[9.0000000e+002, 4.1966072e-001],\n",
        "[9.0050000e+002, 4.1850323e-001],\n",
        "[9.0100000e+002, 4.1734574e-001],\n",
        "[9.0150000e+002, 4.1618825e-001],\n",
        "[9.0200000e+002, 4.1503076e-001],\n",
        "[9.0250000e+002, 4.1411717e-001],\n",
        "[9.0300000e+002, 4.1320358e-001],\n",
        "[9.0350000e+002, 4.1228999e-001],\n",
        "[9.0400000e+002, 4.1137640e-001],\n",
        "[9.0450000e+002, 4.1056765e-001],\n",
        "[9.0500000e+002, 4.0975889e-001],\n",
        "[9.0550000e+002, 4.0895014e-001],\n",
        "[9.0600000e+002, 4.0814138e-001],\n",
        "[9.0650000e+002, 4.0740348e-001],\n",
        "[9.0700000e+002, 4.0666558e-001],\n",
        "[9.0750000e+002, 4.0592768e-001],\n",
        "[9.0800000e+002, 4.0518978e-001],\n",
        "[9.0850000e+002, 4.0446823e-001],\n",
        "[9.0900000e+002, 4.0374669e-001],\n",
        "[9.0950000e+002, 4.0302514e-001],\n",
        "[9.1000000e+002, 4.0230360e-001],\n",
        "[9.1050000e+002, 4.0118053e-001],\n",
        "[9.1100000e+002, 4.0005746e-001],\n",
        "[9.1150000e+002, 3.9893439e-001],\n",
        "[9.1200000e+002, 3.9781132e-001],\n",
        "[9.1250000e+002, 3.9667644e-001],\n",
        "[9.1300000e+002, 3.9554156e-001],\n",
        "[9.1350000e+002, 3.9440668e-001],\n",
        "[9.1400000e+002, 3.9327180e-001],\n",
        "[9.1450000e+002, 3.9214808e-001],\n",
        "[9.1500000e+002, 3.9102437e-001],\n",
        "[9.1550000e+002, 3.8990065e-001],\n",
        "[9.1600000e+002, 3.8877694e-001],\n",
        "[9.1650000e+002, 3.8718648e-001],\n",
        "[9.1700000e+002, 3.8559602e-001],\n",
        "[9.1750000e+002, 3.8400556e-001],\n",
        "[9.1800000e+002, 3.8241511e-001],\n",
        "[9.1850000e+002, 3.8079458e-001],\n",
        "[9.1900000e+002, 3.7917406e-001],\n",
        "[9.1950000e+002, 3.7755354e-001],\n",
        "[9.2000000e+002, 3.7593302e-001],\n",
        "[9.2050000e+002, 3.7428388e-001],\n",
        "[9.2100000e+002, 3.7263474e-001],\n",
        "[9.2150000e+002, 3.7098560e-001],\n",
        "[9.2200000e+002, 3.6933647e-001],\n",
        "[9.2250000e+002, 3.6742515e-001],\n",
        "[9.2300000e+002, 3.6551383e-001],\n",
        "[9.2350000e+002, 3.6360251e-001],\n",
        "[9.2400000e+002, 3.6169119e-001],\n",
        "[9.2450000e+002, 3.5935763e-001],\n",
        "[9.2500000e+002, 3.5702408e-001],\n",
        "[9.2550000e+002, 3.5469052e-001],\n",
        "[9.2600000e+002, 3.5235696e-001],\n",
        "[9.2650000e+002, 3.5020949e-001],\n",
        "[9.2700000e+002, 3.4806201e-001],\n",
        "[9.2750000e+002, 3.4591454e-001],\n",
        "[9.2800000e+002, 3.4376706e-001],\n",
        "[9.2850000e+002, 3.4207196e-001],\n",
        "[9.2900000e+002, 3.4037685e-001],\n",
        "[9.2950000e+002, 3.3868174e-001],\n",
        "[9.3000000e+002, 3.3698664e-001],\n",
        "[9.3050000e+002, 3.3531468e-001],\n",
        "[9.3100000e+002, 3.3364273e-001],\n",
        "[9.3150000e+002, 3.3197077e-001],\n",
        "[9.3200000e+002, 3.3029882e-001],\n",
        "[9.3250000e+002, 3.2829975e-001],\n",
        "[9.3300000e+002, 3.2630069e-001],\n",
        "[9.3350000e+002, 3.2430162e-001],\n",
        "[9.3400000e+002, 3.2230256e-001],\n",
        "[9.3450000e+002, 3.2014129e-001],\n",
        "[9.3500000e+002, 3.1798002e-001],\n",
        "[9.3550000e+002, 3.1581875e-001],\n",
        "[9.3600000e+002, 3.1365747e-001],\n",
        "[9.3650000e+002, 3.1151386e-001],\n",
        "[9.3700000e+002, 3.0937026e-001],\n",
        "[9.3750000e+002, 3.0722665e-001],\n",
        "[9.3800000e+002, 3.0508304e-001],\n",
        "[9.3850000e+002, 3.0292138e-001],\n",
        "[9.3900000e+002, 3.0075971e-001],\n",
        "[9.3950000e+002, 2.9859805e-001],\n",
        "[9.4000000e+002, 2.9643639e-001],\n",
        "[9.4050000e+002, 2.9481181e-001],\n",
        "[9.4100000e+002, 2.9318724e-001],\n",
        "[9.4150000e+002, 2.9156266e-001],\n",
        "[9.4200000e+002, 2.8993809e-001],\n",
        "[9.4250000e+002, 2.8864886e-001],\n",
        "[9.4300000e+002, 2.8735962e-001],\n",
        "[9.4350000e+002, 2.8607039e-001],\n",
        "[9.4400000e+002, 2.8478116e-001],\n",
        "[9.4450000e+002, 2.8361146e-001],\n",
        "[9.4500000e+002, 2.8244176e-001],\n",
        "[9.4550000e+002, 2.8127206e-001],\n",
        "[9.4600000e+002, 2.8010236e-001],\n",
        "[9.4650000e+002, 2.7845904e-001],\n",
        "[9.4700000e+002, 2.7681573e-001],\n",
        "[9.4750000e+002, 2.7517241e-001],\n",
        "[9.4800000e+002, 2.7352909e-001],\n",
        "[9.4850000e+002, 2.7153475e-001],\n",
        "[9.4900000e+002, 2.6954041e-001],\n",
        "[9.4950000e+002, 2.6754607e-001],\n",
        "[9.5000000e+002, 2.6555173e-001]])"
      ],
      "metadata": {
        "id": "reT3xduhXsjN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Copyright Gary Strangman & Massachusetts General Hospital 2022; All rights reserved.\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import print_function\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import glob\n",
        "import string\n",
        "import struct\n",
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pylab import *\n",
        "from types import *\n",
        "import scipy.signal as ss\n",
        "import scipy.io as sio\n",
        "import scipy.stats as stats\n",
        "import scipy.interpolate as si\n",
        "from scipy.integrate import simps\n",
        "import scipy.ndimage as snd\n",
        "from six.moves import map\n",
        "from six.moves import range\n",
        "from six.moves import zip\n",
        "from io import open\n",
        "try:\n",
        "    import optical26 as o\n",
        "except:\n",
        "    print(\"No optical26 module; continuing.\")\n",
        "try:\n",
        "    import ningeometries5 as ningeometries\n",
        "    reload(ningeometries)\n",
        "except:\n",
        "    pass\n",
        "\n",
        "\n",
        "\n",
        "######## USER MODIFIABLE PARAMETERS #######\n",
        "######## USER MODIFIABLE PARAMETERS #######\n",
        "######## USER MODIFIABLE PARAMETERS #######\n",
        "CHUNKSIZE = 1000\n",
        "recdur = 1   # sec; for EDF files; NOTE: recdur*samplerate*2*Nsignals must be <61440 bytes\n",
        "DEFAULTcolors = ['b','g','r','c','m','y','k','saddlebrown']\n",
        "figsize = (20,13)\n",
        "\n",
        "\n",
        "FAST_RAW_SIGNALS = ['GYRO','ACCE','EstG','NECG','AUXC']\n",
        "SLOW_RAW_SIGNALS = ['SRC','BKGD','FORC','TEMP']\n",
        "\n",
        "AUX_SIGNALS = FAST_RAW_SIGNALS + SLOW_RAW_SIGNALS\n",
        "\n",
        "\n",
        "default_EEG_ranges = {'delta':[1.0, 4.5],       # Hz; LPF and HPF cutoffs\n",
        "                      'theta':[4.5, 8.0],\n",
        "                      'alpha':[8.0, 14.0],\n",
        "                      'beta' :[14.0,32.0],\n",
        "                      'gamma':[32.0,80.0]}\n",
        "\n",
        "SNRthresh = 3\n",
        "DISTthresh = 60\n",
        "\n",
        "#################### REQUIRED VARIABLES ####################\n",
        "\n",
        "DEFAULTwavelengths = [830,780]\n",
        "\n",
        "# FILTER PARAMETERS\n",
        "DEFAULTfilt_param= {\n",
        "                      'NIRS':[5,0],\n",
        "                      'SRC':[5,0],\n",
        "                      'BKGD':[5,0],\n",
        "                      'ACCE':[100,0],\n",
        "                      'EstG':[0,0],\n",
        "                      'FORC':[1,0],\n",
        "                      'GYRO':[100,0],\n",
        "                      'RESP':[5,0],\n",
        "                      'TEMP':[0.1,0],\n",
        "                      'NECG':[0,0],\n",
        "                     }\n",
        "\n",
        "headersize = 512\n",
        "NUMSRC = 8\n",
        "SLOWRATE = 25\n",
        "FASTRATE = 250\n",
        "ProbeGains = [30., 1500.]\n",
        "BoardGains = [1., 2., 4., 5., 8., 10., 16., 20., 25., 32.,\n",
        "              40., 50., 64., 80., 100., 128., 160., 256., 320., 512., 1024.]\n",
        "\n",
        "srcs = [0]*8+[1]*8+[2]*8+[3]*8+[4]*8+[5]*8+[6]*8+[7]*8\n",
        "dets = list(range(8))*8\n",
        "FULLml = list(zip(srcs,dets))\n",
        "\n",
        "AFparam = {'ref': None,\n",
        "           'estgCHAN': [0,1,2,3,4,5,6],\n",
        "           'nodes': 750,\n",
        "           'step': 0.01\n",
        "           }\n",
        "\n",
        "\n",
        "DEFAULTsensors = {}\n",
        "DEFAULTsensors['NIRS'] = {'samplerate':25,\n",
        "                   'channels':64,\n",
        "                   'LPF':0,\n",
        "                   'HPF':0,\n",
        "                   'label':'NIRS',\n",
        "                   'transducertype':'OPT101',\n",
        "                   'units':'raw',\n",
        "                   'physmin':-32768,\n",
        "                   'physmax':32767,\n",
        "                   'digmin':-32768,\n",
        "                   'digmax':32767\n",
        "                   }\n",
        "\n",
        "DEFAULTsensors['SRC'] = {'samplerate':25,\n",
        "                   'channels':64,\n",
        "                   'LPF':0,\n",
        "                   'HPF':0,\n",
        "                   'label':'SRC',\n",
        "                   'transducertype':'OPT101',\n",
        "                   'units':'raw',\n",
        "                   'physmin':-32768,\n",
        "                   'physmax':32767,\n",
        "                   'digmin':-32768,\n",
        "                   'digmax':32767\n",
        "                   }\n",
        "\n",
        "DEFAULTsensors['BKGD'] = {'samplerate':25,\n",
        "                   'channels':64,\n",
        "                   'LPF':0,\n",
        "                   'HPF':0,\n",
        "                   'label':'BKGD',\n",
        "                   'transducertype':'OPT101',\n",
        "                   'units':'raw',\n",
        "                   'physmin':-32768,\n",
        "                   'physmax':32767,\n",
        "                   'digmin':-32768,\n",
        "                   'digmax':32767\n",
        "                   }\n",
        "\n",
        "DEFAULTsensors['EstG'] = {'samplerate':250,\n",
        "                   'channels':8,\n",
        "                   'LPF':[0,0,0,0,0,0,0,0],     # must be a list (of 1 or 8 numbers)\n",
        "                   'HPF':[0,0,0,0,0,0,0,0],\n",
        "                   'label':'ExG',\n",
        "                   'transducertype':'Ag/AgCl',\n",
        "                   'units':'microV',\n",
        "                   'physmin':-10000,\n",
        "                   'physmax':10000,\n",
        "                   'digmin':0,\n",
        "                   'digmax':32767\n",
        "                   }\n",
        "\n",
        "DEFAULTsensors['ACCE'] = {'samplerate':250,\n",
        "                   'channels':3,\n",
        "                   'LPF':0,\n",
        "                   'HPF':0,\n",
        "                   'label':'ACC',\n",
        "                   'transducertype':'piezo',\n",
        "                   'units':'g',\n",
        "                   'physmin':-16,\n",
        "                   'physmax':16,\n",
        "                   'digmin':0,\n",
        "                   'digmax':32767\n",
        "                   }\n",
        "\n",
        "DEFAULTsensors['GYRO'] = {'samplerate':250,\n",
        "                   'channels':3,\n",
        "                   'LPF':0,\n",
        "                   'HPF':0,\n",
        "                   'label':'GYRO',\n",
        "                   'transducertype':'piezo',\n",
        "                   'units':'deg/sec',\n",
        "                   'physmin':-200,\n",
        "                   'physmax':200,\n",
        "                   'digmin':0,\n",
        "                   'digmax':32767\n",
        "                   }\n",
        "\n",
        "DEFAULTsensors['TEMP'] = {'samplerate':25,\n",
        "                   'channels':1,\n",
        "                   'LPF':0,\n",
        "                   'HPF':0,\n",
        "                   'label':'TEMP',\n",
        "                   'transducertype':'thermistor',\n",
        "                   'units':'deg C',\n",
        "                   'physmin':0,\n",
        "                   'physmax':100,\n",
        "                   'digmin':0,\n",
        "                   'digmax':32767\n",
        "                   }\n",
        "\n",
        "DEFAULTsensors['FORC'] = {'samplerate':25,\n",
        "                   'channels':1,\n",
        "                   'LPF':0,\n",
        "                   'HPF':0,\n",
        "                   'label':'FORC',\n",
        "                   'transducertype':'ink',\n",
        "                   'units':'kg',\n",
        "                   'physmin':0,\n",
        "                   'physmax':2000,\n",
        "                   'digmin':0,\n",
        "                   'digmax':32767,\n",
        "                   }\n",
        "\n",
        "DEFAULTsensors['RESP'] = {'samplerate':25,\n",
        "                   'channels':1,\n",
        "                   'LPF':0,\n",
        "                   'HPF':0,\n",
        "                   'label':'RESP',\n",
        "                   'transducertype':'RIP sensor',\n",
        "                   'units':'H',\n",
        "                   'physmin':0,\n",
        "                   'physmax':2000,\n",
        "                   'digmin':0,\n",
        "                   'digmax':32767,\n",
        "                   }\n",
        "\n",
        "\n",
        "###################### FILTERING FUNCTIONS ########################\n",
        "\n",
        "def findonset(a,val):\n",
        "    \"\"\"\n",
        "\n",
        "Returns index of first value of sosrted list 'a' greater than or equal to val\n",
        "\n",
        "RETURNS: identified index\n",
        "\"\"\"\n",
        "    tmp = a>=val\n",
        "    if len(tmp.nonzero()[0])==0:\n",
        "        return None\n",
        "    else:\n",
        "        return tmp.nonzero()[0][0]\n",
        "\n",
        "\n",
        "def findoffset(a,val):\n",
        "    \"\"\"\n",
        "\n",
        "Returns index of first value of 'a' less than or equal to val\n",
        "\n",
        "RETURNS: identified index\n",
        "\"\"\"\n",
        "    tmp = a<=val\n",
        "    if len(tmp.nonzero()[0])==0:\n",
        "        return None\n",
        "    else:\n",
        "        return tmp.nonzero()[0][0]\n",
        "\n",
        "\n",
        "def findcrossings(a,val,direction=+1,stayput=0):\n",
        "    \"\"\"\n",
        "\n",
        "Returns index of all values of 'a' which cross the threshold in direction specified (pos/neg)\n",
        "\n",
        "RETURNS: identified indices\n",
        "\"\"\"\n",
        "    c = []\n",
        "    for i in range(len(a)-1-stayput):\n",
        "        if direction==1:\n",
        "            if a[i]<val and a[i+1]>val:\n",
        "                if stayput:\n",
        "                    if a[i+1+stayput]>val:  # STILL >val?\n",
        "                        c.append(i)\n",
        "                else:\n",
        "                    c.append(i)\n",
        "        elif direction==-1:\n",
        "            if a[i]>val and a[i+1]<val:\n",
        "                if stayput:\n",
        "                    if a[i+1+stayput]<val:  # STILL <val?\n",
        "                        c.append(i)\n",
        "                else:\n",
        "                    c.append(i)\n",
        "    return np.array(c)\n",
        "\n",
        "\n",
        "def findsteps(a,ystep,xstep=1,refractory=10):\n",
        "    \"\"\"\n",
        "\n",
        "Returns indices of all \"events\" where timeseries in 'a' changes by val=stepsize over a specified\n",
        "x point interval (1=adjacent points, 2=every other point, etc). 'refractory' is how many points\n",
        "to skip after a successful find.\n",
        "\n",
        "RETURNS: list of indices\n",
        "\"\"\"\n",
        "    diffs = a[xstep:]-a[:-xstep]\n",
        "    if ystep>0:\n",
        "        markers = np.nonzero(diffs>ystep)\n",
        "    else:\n",
        "        markers = np.nonzero(diffs<ystep)\n",
        "    markers = np.array(markers)\n",
        "    markers = np.ravel(markers)\n",
        "    try:\n",
        "        pruned = [markers[0]]\n",
        "    except IndexError:\n",
        "        pruned = []\n",
        "    for m in markers[1:]:\n",
        "        if m>pruned[-1]+refractory:\n",
        "            pruned.append(m)\n",
        "    pruned = np.array(pruned)\n",
        "    if xstep>1:\n",
        "        pruned = pruned +int(xstep/2.)\n",
        "    return pruned\n",
        "\n",
        "\n",
        "def find_R_peaks(ekg,t=None,fsekg=250,refract=0.27,propor1hz=0.8,plotit=True,verbose=False):\n",
        "    \"\"\"\n",
        "Detect narrow R-peaks from EKG/ECG signal.\n",
        "    fsekg = Hz, sampling frequency, default=250\n",
        "    refract = sec, refractory period when another spike can't be detected (default=0.27, or 220bpm)\n",
        "    propor1hz = 0-1; if num heartbeats detected < propor1hz*numsec-in-recording, lower threshold\n",
        "\n",
        "Usage:   find_R_peaks(ekg,t=None,fsekg=250,refract=0.27,plotit=False)\n",
        "Returns: prunedR_times, prunedR_indices\n",
        "\"\"\"\n",
        "    # CREATE TIME-BASE\n",
        "    if t is None:\n",
        "        t = np.arange(len(eeg))/float(fseeg)\n",
        "\n",
        "    # FIND TIMES AND INDEXES OF THE ECG R-WAVE PEAKS\n",
        "    ## - Detect R peaks\n",
        "    Q = 5\n",
        "    mov_avg_win = round(0.125*fsekg)\n",
        "\n",
        "    ## - Bandpass\n",
        "    if verbose:\n",
        "        print(\"find_R_peaks() ... bandpass\")\n",
        "    n = 101\n",
        "    fc = 17\n",
        "    BW = fc/float(Q)\n",
        "    band = np.array([(fc-BW/2)*2/fsekg, (fc+BW/2)*2/fsekg])\n",
        "    b = ss.firwin(n,band)\n",
        "    y = filtfilt(b,1,ekg)\n",
        "\n",
        "    ## - Derivative\n",
        "    if verbose:\n",
        "        print(\"find_R_peaks() ... derivative\")\n",
        "    H = [1/5., 1/10., 0. -1/10., -1/5.]\n",
        "    y = filtfilt(H,1,y)\n",
        "\n",
        "    ## - Square to amplify the peak\n",
        "    y = y**2\n",
        "\n",
        "    ## - Moving Average to smooth out noise\n",
        "    if verbose:\n",
        "        print(\"find_R_peaks() ... moving average\", mov_avg_win)\n",
        "    N = int(mov_avg_win)\n",
        "    H = np.ones(N)*1./N\n",
        "    y = filtfilt(H,1,y)\n",
        "    #for h in range(len(y[0,:])):\n",
        "    #    y[:,h] = y[:,h]/np.max(y[:,h])\n",
        "\n",
        "    ## - Hipass the derivative and use 0 as the threshold\n",
        "    # should work as long as the recording isn't /too/ noisy\n",
        "    y = hipass(y,1/8.,250)\n",
        "    thr = 0\n",
        "\n",
        "    # FIND POINTS BRACKETING R-WAVES\n",
        "    s = np.zeros(len(ekg))\n",
        "    s[y > thr] = 1\n",
        "    # compute start & end-of-peak markers\n",
        "    dif = s[1:] - s[:-1]\n",
        "    pos1 = list(np.where(dif==1)[0]+1)\n",
        "    pos2 = list(np.where(dif==-1)[0])\n",
        "    # make sure lists are equal lengths, and delete the half-peak if not\n",
        "    if len(pos1) > len(pos2):\n",
        "        pos1 = pos1[:-1]\n",
        "    elif len(pos1) < len(pos2):\n",
        "        pos2 = pos2[1:]\n",
        "    diffs = np.array(pos2)-np.array(pos1)\n",
        "\n",
        "    # CREATE LIST OF R-TIMES AND VECTOR INDICES (AT MAX VALUE WITHIN EACH PEAK)\n",
        "    if verbose:\n",
        "        print(\"find_R_peaks() ... create R-times list\")\n",
        "    R_t = np.zeros(len(pos1))\n",
        "    R_idx = np.zeros(len(pos1),np.int)\n",
        "    print(\"  pos1:\", pos1[:10])\n",
        "    print(\"  pos2:\", pos2[:10])\n",
        "    comp = (np.array(pos1)<np.array(pos2))\n",
        "    if np.sum(comp)<0.5*len(pos1):\n",
        "        print(\"   Exchanging markers in find_R_peaks()!\")\n",
        "        pos1,pos2 = pos2,pos1\n",
        "    for j in range(len(pos1)):\n",
        "        if pos1[j]==pos2[j]:\n",
        "            R_t[j] = t[pos1[j]]\n",
        "            R_idx[j] = pos1[j]\n",
        "#            print \"ultra-short interval:\",j, pos1[j], t[pos1[j]] #threshold too high?\n",
        "            continue\n",
        "        times = t[pos1[j]:pos2[j]+1]\n",
        "        window = ekg[pos1[j]:pos2[j]]  # abs?? to make sure ECG is upright?\n",
        "        try:\n",
        "            m = np.where(window==np.max(window))[0]\n",
        "        except:\n",
        "            m = int((pos1[j]+pos2[j])/2)\n",
        "#            print \"not OK:\",j, pos1[j], pos2[j], times.shape, window.shape, R_t.shape, m, pos1[j]\n",
        "        try:\n",
        "            R_t[j] = times[m]\n",
        "            R_idx[j] = pos1[j]+m\n",
        "        except:\n",
        "#            print j, m\n",
        "            pass\n",
        "\n",
        "    # keep only R-waves that are outside the refractory period, in SEC\n",
        "    if verbose:\n",
        "        print(\"find_R_peaks() ... prune refractory\")\n",
        "#    print len(R_t)\n",
        "#    print R_t[:40]\n",
        "#    print R_idx[:10]\n",
        "    pR_t = [R_t[0]]\n",
        "    pR_idx = [R_idx[0]]\n",
        "    for i in range(1,len(R_t)):\n",
        "        if R_t[i]-R_t[i-1] > refract:\n",
        "            # add it to list only if greater than refractory period\n",
        "            pR_t.append(R_t[i])\n",
        "            pR_idx.append(R_idx[i])\n",
        "\n",
        "    if plotit:\n",
        "        plot(t,ekg/20.,label='EKG/20')\n",
        "        plot(t,y,label='filt EKG')\n",
        "        plot(t[pos1],y[pos1],'go',label='start')\n",
        "        plot(t[pos2],y[pos2],'kx',label='end')\n",
        "        plot(pR_t,(ekg/20.)[pR_idx],'r+',label='peak')\n",
        "        legend()\n",
        "        show()\n",
        "\n",
        "    return pR_t, pR_idx\n",
        "\n",
        "\n",
        "def filtfilt(b, a, x):\n",
        "    \"\"\"\n",
        "\n",
        "Zero-phase filter signal x, similar to Matlab's filtfilt() function.\n",
        "\n",
        "RETURNS: x filtered according to the b and a filter parameters\n",
        "\"\"\"\n",
        "    if len(x.shape)==1:\n",
        "        x.shape = (x.shape[0],1)\n",
        "\n",
        "    b = np.ravel(b)\n",
        "    a = np.ravel(a)\n",
        "    nb = len(b)\n",
        "    na = len(a)\n",
        "    nfilt = max(nb,na)\n",
        "    n = len(x)\n",
        "\n",
        "    nfact = 3*(nfilt-1)  # length of edge transients\n",
        "    part1 = 2*x[0]-x[(nfact+1):1:-1]\n",
        "    part3 = 2*x[-1]-x[-2:n-nfact-2:-1]\n",
        "    ylongorig = np.concatenate((part1, x, part3))\n",
        "\n",
        "    # filter, reverse data, filter again, and reverse data again\n",
        "    ylong = ss.lfilter(b,a,ylongorig,axis=0)\n",
        "    ylong = ylong[::-1]\n",
        "    ylong = ss.lfilter(b,a,ylong,axis=0)\n",
        "    ylong = ylong[::-1]\n",
        "\n",
        "    # remove extrapolated pieces of y\n",
        "    y = ylong[nfact:-nfact]\n",
        "    return y #, ylong, ylongorig\n",
        "\n",
        "\n",
        "def lowpass(d,flp,samplerate):\n",
        "    \"\"\"\n",
        "\n",
        "Lowpass filter via moving-average, where flp=cutoff frequency in Hz\n",
        "\n",
        "RETURNS: d filtered as requested\n",
        "\"\"\"\n",
        "    if flp == 0:\n",
        "        return d\n",
        "    wwid = np.int(samplerate/float(flp))\n",
        "    b = np.ones((wwid,1))/float(wwid)\n",
        "    a = 1\n",
        "    d = d.astype(np.float)\n",
        "    return np.squeeze(filtfilt(b,a,d))\n",
        "\n",
        "\n",
        "def hipass(d,fhp,samplerate):\n",
        "    \"\"\"\n",
        "\n",
        "Highpass filter by calculating a low-pass moving-average filter and subtracting,\n",
        "where fhp=cutoff frequency in Hz\n",
        "\n",
        "RETURNS: d filtered as requested\n",
        "\"\"\"\n",
        "    # NO HIPASS REQUESTED?\n",
        "    if fhp == 0:\n",
        "        return d\n",
        "    # DATA TOO SHORT FOR THIS HPF CUTOFF?\n",
        "    if len(d)<1./fhp*samplerate:\n",
        "        return d\n",
        "\n",
        "    wwid = np.int(samplerate/float(fhp))\n",
        "    b = np.ones((wwid,1))/float(wwid)\n",
        "    a = 1\n",
        "    return np.squeeze(d-filtfilt(b,a,d))\n",
        "\n",
        "\n",
        "def notch(d,freqlist=[25,50,53.5,75,100,60,120],half_width=2.0,samplerate=250):\n",
        "    \"\"\"\n",
        "\n",
        "Apply a notch filter centered at each freq in 'freqlist', using a band\n",
        "freq +/- half_width. Apply filters in order listed in freqlist.\n",
        "\n",
        "RETURNS: d notch-filtered as requested\n",
        "\"\"\"\n",
        "    # COMPUTE LIST OF b,a BUTTERWORTH COEFFICIENTS FOR EACH NOTCHING FREQUENCY\n",
        "    Bs = []\n",
        "    As = []\n",
        "    for item in freqlist:\n",
        "        bp_stop_Hz = np.array([item-half_width, item+half_width])\n",
        "        tmpb,tmpa = ss.butter(2,bp_stop_Hz/(samplerate/2.0), 'bandstop')\n",
        "        Bs.append(tmpb)\n",
        "        As.append(tmpa)\n",
        "\n",
        "    # APPLY FILTERS IN THE ORDER LISTED\n",
        "    fd = []\n",
        "    if len(d.shape)==1:              # FOR 1D INPUTS\n",
        "        tmp = d\n",
        "        for j in range(len(freqlist)):\n",
        "            tmp = ss.filtfilt(Bs[j],As[j],tmp)\n",
        "        fd.append(tmp)\n",
        "    elif len(d.shape)==2:            # FOR 2D INPUTS\n",
        "        for i in range(d.shape[1]):\n",
        "            tmp = d[:,i]\n",
        "            for j in range(len(freqlist)):\n",
        "                tmp = ss.filtfilt(Bs[j],As[j],tmp)\n",
        "            fd.append(tmp)\n",
        "\n",
        "    return np.array(fd).T\n",
        "\n",
        "\n",
        "def bandpass(d,freq=[0.1, 40],order=4,samplerate=250,verbose=False):\n",
        "    \"\"\"\n",
        "\n",
        "Apply a band-pass filter to dignal 'd', passing lower/upper freq cutoffs.\n",
        "Uses butterworth bandpass..\n",
        "\n",
        "RETURNS: d bandpass filtered according to provided paramters\n",
        "\"\"\"\n",
        "\n",
        "    # COMPUTE b,a BUTTERWORTH COEFFICIENTS\n",
        "    nyq = 0.5*samplerate\n",
        "    low = freq[0]/nyq\n",
        "    high = freq[1]/nyq\n",
        "    b,a = ss.butter(order,[low,high], btype='band')\n",
        "    if verbose:\n",
        "        print(\"a = \",a)\n",
        "        print(\"b = \",b)\n",
        "\n",
        "    # APPLY FILTER\n",
        "    fd = []\n",
        "    if len(d.shape)==1:              # FOR 1D INPUTS\n",
        "        tmp = d\n",
        "        tmp = ss.filtfilt(b,a,tmp)\n",
        "        fd.append(tmp)\n",
        "    elif len(d.shape)==2:            # FOR 2D INPUTS\n",
        "        for i in range(d.shape[1]):\n",
        "            tmp = d[:,i]\n",
        "            tmp = ss.filtfilt(b,a,tmp)\n",
        "            fd.append(tmp)\n",
        "\n",
        "    return np.array(fd).T\n",
        "\n",
        "\n",
        "def SDfilt(d,t,window=5):\n",
        "    if type(t) not in [IntType, FloatType]:\n",
        "        step = t[1]-t[0]\n",
        "    else:\n",
        "        step = t\n",
        "    winwidth = int(window/float(step))\n",
        "\n",
        "    fd = []\n",
        "    for i in range(len(d)):\n",
        "        if len(d.shape)==1:              # FOR 1D INPUTS\n",
        "            tmp = np.std(d[i:i+winwidth])\n",
        "            fd.append(tmp)\n",
        "        elif len(d.shape)==2:            # FOR 2D INPUTS\n",
        "            tmp = np.std(d[i:i+winwidth],0)\n",
        "            fd.append(tmp)\n",
        "    return np.array(fd)\n",
        "\n",
        "\n",
        "def SD_qualtest(sd,thresh=5):\n",
        "    mean_sd = np.mean(sd,0)\n",
        "    test = sd>(mean_sd*thresh)\n",
        "    return test #np.where(test==0,np.nan,test)\n",
        "\n",
        "\n",
        "def SD_badindices(sdtest,dt=1/25.,window=5):\n",
        "    if len(sdtest.shape)==1:              # FOR 1D INPUTS\n",
        "        i = 0\n",
        "        while i<len(sdtest):\n",
        "            if sdtest[i]==1:\n",
        "                pass\n",
        "\n",
        "    elif len(d.shape)==2:            # FOR 2D INPUTS\n",
        "        pass\n",
        "\n",
        "\n",
        "def hbhbo2raw_idx(hbhboidxs):\n",
        "    raw_indices = []\n",
        "    for i in hbhboidxs:\n",
        "        mul = int(i)/8\n",
        "        remain = np.mod(i,8)\n",
        "        raw_indices.append(i+8*mul)\n",
        "    return raw_indices\n",
        "\n",
        "\n",
        "def nin_events2impulses(evlist,length=None,offset=0,skipstart=0,skipend=0):\n",
        "    \"\"\"\n",
        "Convert a list of NIN events=[timestamp,index] pairs to an array of 1s and 0s for use\n",
        "with decon() and nin_deconvolve().\n",
        "\"\"\"\n",
        "    evl = np.array(evlist)\n",
        "    if len(evl.shape)==2:\n",
        "        evl = evlist[:,1]\n",
        "    if length==None:\n",
        "        impulses = np.zeros(evl[-1]/10+1)\n",
        "    else:\n",
        "        impulses = np.zeros(length)\n",
        "    for i in range(skipstart,len(evlist)-skipend):\n",
        "#        print i, evlist[i][1],offset, impulses.shape\n",
        "        impulses[int((evl[i]-offset)/10)] = 1\n",
        "    return impulses\n",
        "\n",
        "\n",
        "def events2impulses(evlist,length=None,offset=0,skipfirst=0,skiplast=0):\n",
        "    \"\"\"\n",
        "Convert a list of NIN events=[timestamp,index] pairs (or just a list of indices),\n",
        "at 250Hz, to an array of 1s and 0s for use with decon() and nin_deconvolve().\n",
        "\"\"\"\n",
        "    evl = np.array(evlist)\n",
        "    if len(evl.shape)==2:\n",
        "        evl = evlist[:,1]\n",
        "    if length==None:\n",
        "        impulses = np.zeros(evl[-1]+1)\n",
        "    else:\n",
        "        impulses = np.zeros(length)\n",
        "    for i in range(skipfirst,len(evlist)-skiplast):\n",
        "#        print i, evlist[i][1],offset, impulses.shape\n",
        "        try:\n",
        "            impulses[int((evl[i]-offset))] = 1\n",
        "        except:\n",
        "            print(\"impulse out of range: \",i,len(impulses))\n",
        "    return impulses\n",
        "\n",
        "\n",
        "def prep4deconv(d,evlists,window=[0,-1],axis=0,presec=0,postsec=10,samplerate=25):\n",
        "    \"\"\"This function will return the cropped version of input data as well as\n",
        "    matched-length list of impulse functions for use with ninDeconvSS().\n",
        "\n",
        "    Input:\n",
        "        d = (SPECIES x TIME x CHAN) or (TIME x CHAN)\n",
        "        evlists = *list* of event-index lists/arrays (250Hz rate)\n",
        "        window = [startidx,endidx] at 250Hz, OR\n",
        "                 'all' (to use full dataset), OR\n",
        "                 'tight' (to use only dataset surrounding the min/max event markers)\n",
        "        axis = time-axis of d, on which to operate\n",
        "        presec = number of sec prior to first event marker to keep\n",
        "        postsec = number of sec following last event-marker to keep\n",
        "        samplerate = sampling rate of d\n",
        "\n",
        "    RETURNS: newx, newd, impulses\n",
        "    \"\"\"\n",
        "    if window=='all':\n",
        "        window = [0,d.shape[axis]]   # 25Hz\n",
        "    elif window=='tight':\n",
        "        minval = min(list(map(min,evlists)))/10.  # convert indices from 250Hz to 25Hz\n",
        "        maxval = max(list(map(max,evlists)))/10.\n",
        "        window = [minval,maxval]     # 25Hz\n",
        "    evlists = list(map(np.array,evlists))  # 250Hz\n",
        "    sidx = int(window[0]-presec*25.)  # convert to 25Hz\n",
        "    eidx = int(window[1]+postsec*25.)\n",
        "#    print window, sidx,eidx, d.shape\n",
        "    if len(evlists)>1:\n",
        "        impulses = []\n",
        "        for evlist in evlists:\n",
        "            tmp = events2impulses((evlist/250.*samplerate).astype(np.int),length=d.shape[axis])\n",
        "            impulses.append(tmp[sidx:eidx])\n",
        "    else:\n",
        "        tmp = events2impulses((evlists[0]/250.*samplerate).astype(np.int),length=d.shape[axis])\n",
        "        impulses = tmp[sidx:eidx]\n",
        "    impulses = np.array(impulses)\n",
        "    if axis==0:\n",
        "        newd = d[sidx:eidx]\n",
        "    elif axis==1:\n",
        "        newd = d[:,sidx:eidx]\n",
        "    elif axis==2:\n",
        "        newd = d[:,:,sidx:eidx]\n",
        "    newx = np.arange(newd.shape[axis])/float(samplerate)+window[0]/float(samplerate)-presec\n",
        "    return newx,newd,impulses\n",
        "\n",
        "\n",
        "def deconv1species(d, paradigms, settings={'preRFsec':5,'postRFsec':15,\n",
        "                                           'sampRate':25,'invMode':'mp','sfProc':0},\n",
        "                               verbose=True):\n",
        "# deconvSS calculates haemodynamic response function for a NIN dataset\n",
        "# Inputs:\n",
        "#       d:          vector (npts x nchan)\n",
        "#       paradigms:  vector (npts x 1) or (npts x npara)\n",
        "#       settings:   structure\n",
        "# output:\n",
        "#       hrf:        vector (nhrf x 1)\n",
        "#       hrfStd:     vector (nhrf x 1)\n",
        "\n",
        "    # IF JUST AN ARRAY, MAKE IT 2D\n",
        "    if len(paradigms.shape)==1:\n",
        "        paradigms.shape = (1,)+paradigms.shape\n",
        "    # DO EACH CHANNEL FOR EACH PARADIGM\n",
        "    resultsd = [[] for i in range(len(paradigms))]\n",
        "    resultssd = [[] for i in range(len(paradigms))]\n",
        "    for p in range(len(paradigms)):\n",
        "        for ch in range(d.shape[1]):\n",
        "            if verbose:\n",
        "                print(\"Calling deconvSS: chan=\",ch,\" d=\",d.shape,\" para=\",paradigms.shape)\n",
        "            nd,nsd = deconvSS(d[:,ch],paradigms[p],settings)\n",
        "            resultsd[p].append(nd)\n",
        "            resultssd[p].append(nsd)\n",
        "#            if verbose:\n",
        "#                print \"   deconvSS output:\",p,ch,nd.shape,nsd.shape\n",
        "    xs = np.arange(len(nd))/float(settings['sampRate'])-settings['preRFsec']\n",
        "    return xs, np.array(resultsd), np.array(resultssd)\n",
        "\n",
        "\n",
        "def nin_deconvSS(d, paradigms, settings={'preRFsec':5,'postRFsec':15,\n",
        "                                         'sampRate':25,'invMode':'mp','sfProc':0},\n",
        "                               verbose=True):\n",
        "# deconvSS calculates haemodynamic response function for a NIN dataset\n",
        "# Inputs:\n",
        "#       d:          vector (hbhbo x npts x nchan)\n",
        "#       paradigms:  vector (npts x 1) or (npts x npara)\n",
        "#       settings:   structure\n",
        "# output:\n",
        "#       hrf:        vector (nhrf x 1)\n",
        "#       hrfStd:     vector (nhrf x 1)\n",
        "\n",
        "    # DATA IS (SPECIES x TIME x CHAN)\n",
        "    resultsd = []\n",
        "    resultssd = []\n",
        "    # DO EACH SPECIES SEPARATELY\n",
        "    for i in range(d.shape[0]):\n",
        "        nx,nd,nsd = deconv1species(d[i],paradigms,settings)\n",
        "        resultsd.append(nd)\n",
        "        resultssd.append(nsd)\n",
        "        print()\n",
        "    resultsd = np.array(resultsd)\n",
        "    resultssd = np.array(resultssd)\n",
        "    return nx, resultsd, resultssd\n",
        "\n",
        "\n",
        "def deconvSS(data, paradigm, settings={'preRFsec':5,'postRFsec':15,\n",
        "                                       'sampRate':25,'invMode':'mp','sfProc':0}):\n",
        "# deconvSS calculates haemodynamic response function for single\n",
        "# channel data under single paradigm condition\n",
        "# Inputs:\n",
        "#       data:       vector (npts x 1)\n",
        "#       paradigm:   vector (npts x 1)\n",
        "#       settings:   structure\n",
        "# output:\n",
        "#       hrf:        vector (nhrf x 1)\n",
        "#       hrfStd:     vector (nhrf x 1)\n",
        "#\n",
        "# modified based on Gary Strangman's code\n",
        "# written by Yi Yang, contact: zjuyangyi@gmail.com\n",
        "#\n",
        "    npts = len(data); # number of data points\n",
        "    preRFtimepoints = int( settings['preRFsec'] * settings['sampRate'] )\n",
        "    postRFtimepoints = int( settings['postRFsec'] * settings['sampRate'] )\n",
        "    nhrf = preRFtimepoints + postRFtimepoints + 1 # number of hrf points\n",
        "\n",
        "    m = data[postRFtimepoints-1:npts-preRFtimepoints-1]   # (ndeconv+nhrf-1:-1:nhrf);\n",
        "\n",
        "    ndeconv = npts - nhrf +1  # number of data points used for deconvolution\n",
        "    if ndeconv < nhrf:\n",
        "        raise ValueError\n",
        "\n",
        "    if settings['sfProc']==0:  # slow or fast processing\n",
        "        # 0: processing relatively short timeseries and speed is relativey fast\n",
        "        S = np.zeros((ndeconv,nhrf))\n",
        "        for ii in range(nhrf):\n",
        "#            print ii, nhrf, ndeconv, nhrf-ii, nhrf+ndeconv-ii-1, S.shape, paradigm.shape, nhrf-ii -(nhrf+ndeconv-ii-1)\n",
        "            S[:,ii] = paradigm[nhrf-ii-1:nhrf+ndeconv-ii-1]\n",
        "        StS = np.dot(S.T, S)\n",
        "#        print S.shape, StS.shape, m.shape\n",
        "        tmp = np.dot(S.T, m)\n",
        "\n",
        "    elif settings['sfProc']==1:  # slow or fast processing\n",
        "        # 1: processing relatively long timeseries and speed is relatively slow\n",
        "        StS = np.zeros((nhrf,nhrf))\n",
        "        tmp = np.zeros(nhrf)\n",
        "        for ii in range(nhrf):\n",
        "            a = paradigm[nhrf-ii-1:nhrf+ndeconv-ii-1]\n",
        "            for jj in range(nhrf):\n",
        "                b = paradigm[nhrf-jj-1:nhrf+ndeconv-jj-1]\n",
        "#                print ii, jj, a.shape, b.shape, nhrf, npts\n",
        "                StS[ii,jj] = np.dot(a,b)\n",
        "#            print \"end of ii loop:\",a.shape, m.shape, tmp.shape, tmp[ii].shape\n",
        "            tmp[ii] = np.dot(a,m)\n",
        "\n",
        "    if settings['invMode'] in ['MP','mp','mP','Mp','Moore-Penrose']:\n",
        "        invStS = np.linalg.pinv(StS);\n",
        "\n",
        "    elif settings['invMode'] in ['SVD','svd','Svd']:\n",
        "        [U, SD, V] = np.linalg.svd(StS)\n",
        "        sd = np.diag(SD)\n",
        "        nSD = np.sum(sd > settings['threshold'])\n",
        "        invStS = np.dot(U[:,nSD], np.diag(1./sd[nSD]))\n",
        "        invStS = np.dot(invStS, V[:,:nSD].T ).T\n",
        "    else:\n",
        "        raise ValueError\n",
        "\n",
        "    hrf = np.dot(invStS, tmp)\n",
        "\n",
        "    try:\n",
        "        mhat = np.dot(S,hrf)\n",
        "    except:\n",
        "        mhat = zeros(m.shape)\n",
        "        for ii in range(ndeconv):\n",
        "            subS = np.flipud(paradigm[ii:ii+nhrf-1])\n",
        "            mhat[ii] = np.dot(subS.T, hrf)\n",
        "\n",
        "    r = m - mhat\n",
        "    mse = np.dot(r.T,r) / (ndeconv-nhrf)\n",
        "\n",
        "#    print invStS.shape, mse.shape\n",
        "    hrfStd = np.sqrt(np.dot(np.diag(invStS), mse))\n",
        "\n",
        "    return hrf, hrfStd\n",
        "\n",
        "\n",
        "def filt_regress(d,ref,windowpoints=None,nonneg=False):\n",
        "    \"\"\"\n",
        "Filter by fitting 'ref' signal to data and subtracting. d and ref\n",
        "must be the same shape. If windowpoints is specified, the regression\n",
        "is done piecewise on that many points at a time.\n",
        "\n",
        "RETURNS: d with ref regressed-out\n",
        "\"\"\"\n",
        "#    # MEAN-SUBTRACT ON REFERENCE SO IT ONLY TAKES OUT \"MODULATIONS\" IN THE REFERENCE\n",
        "#    ref = ref - ref.mean()  # not needed because we don't use the intercept below\n",
        "\n",
        "    # FILTER WHOLE DATASET AT ONCE\n",
        "    if windowpoints is None:\n",
        "        # 2D ARRAY TO BE FILTERED\n",
        "        if len(d.shape)==2:\n",
        "            f = []\n",
        "            for i in range(d.shape[1]):\n",
        "                slope, intercept, rval, pval, sterr = stats.linregress(ref,d[:,i])\n",
        "                if nonneg and slope<0:\n",
        "                    print(\"########## %i: slope=%1.4f --> 0\" %(i, slope))\n",
        "                    slope = 0\n",
        "                    intercept = 0\n",
        "                est = ref*slope  # +intercept\n",
        "                f.append(d[:,i]-est)\n",
        "\n",
        "        # 1D ARRAY TO BE FILTERED\n",
        "        else:\n",
        "            slope, intercept, rval, pval, sterr = stats.linregress(ref,d)\n",
        "            if nonneg and slope<0:\n",
        "                print(\"########## slope=%1.4f --> 0\" %slope)\n",
        "                slope = 0\n",
        "                intercept = 0\n",
        "            est = ref*slope +intercept\n",
        "            f.append(d-est)\n",
        "\n",
        "    # WINDOWED (PIECEWISE) FILTERING\n",
        "    else:\n",
        "        # 2D ARRAY TO BE FILTERED\n",
        "        if len(d.shape)==2:\n",
        "            f = []\n",
        "            ref.shape = (len(ref),1)\n",
        "            for col in range(d.shape[1]):\n",
        "                g = []\n",
        "                chunk = 0\n",
        "                while chunk<len(d):\n",
        "                    thischunk = d[chunk:chunk+windowpoints,col]\n",
        "                    thisref = ref[chunk:chunk+windowpoints]\n",
        "                    thisref = thisref-thisref.mean()\n",
        "                    slope, intercept, rval, pval, sterr = stats.linregress(thisref,thischunk)\n",
        "                    if nonneg and slope<0:\n",
        "                        print(\"########## %i %i: slope=%1.4f --> 0\" %(col, chunk, slope))\n",
        "                        slope = 0\n",
        "                        intercept = 0\n",
        "                    est = thisref*slope +intercept\n",
        "                    g += (thischunk-est).tolist()\n",
        "                    chunk += windowpoints\n",
        "                f.append(g)\n",
        "\n",
        "        # 1D ARRAY TO BE FILTERED\n",
        "        else:\n",
        "            g = []\n",
        "            chunk = 0\n",
        "            while chunk<len(d):\n",
        "                thischunk = d[chunk:chunk+windowpoints]\n",
        "                thisref = ref[chunk:chunk+windowpoints]\n",
        "                thisref = thisref-thisref.mean()\n",
        "                slope, intercept, rval, pval, sterr = stats.linregress(thisref,thischunk)\n",
        "                if nonneg and slope<0:\n",
        "                    print(\"########## %i: slope=%1.4f --> 0\" %(chunk, slope))\n",
        "                    slope = 0\n",
        "                    intercept = 0\n",
        "                est = thisref*slope +intercept\n",
        "                g += (thischunk-est).tolist()\n",
        "                chunk += windowpoints\n",
        "            f.append(g)\n",
        "\n",
        "    return np.array(f).T\n",
        "\n",
        "\n",
        "def nin_filt_regress(od,near=[4,4]):\n",
        "    \"\"\"\n",
        "Apply regression filter, using the specified \"near\" source-detector pair. Uses src\n",
        "to filter data from srcs 0,2,4,6 and (src+1) to filter data from srcs 1,3,5,7.\n",
        "\n",
        "RETURNS: filteredOD\n",
        "\"\"\"\n",
        "    fodeven = filt_regress(od,od[:,near[0]*8+near[1]])      # filter all chan on near SRC, DET\n",
        "    fododd = filt_regress(od,od[:,(near[0]+1)*8+near[1]])   # filter all chan on near SRC+1, DET\n",
        "    fod = np.zeros(fodeven.shape)             # now interleave the two results\n",
        "    for src in [0,2,4,6]:\n",
        "        fod[:,src*8:(src+1)*8] = fodeven[:,src*8:(src+1)*8]\n",
        "        fod[:,(src+1)*8:(src+2)*8] = fododd[:,(src+1)*8:(src+2)*8]\n",
        "    return fod\n",
        "\n",
        "\n",
        "def AF(y,ref,H):\n",
        "    \"\"\"\n",
        "\n",
        "Adaptive filter, using the LMS algorithm. A reasonable default H is often\n",
        "[1,0,0,0 ...] up to how ever many nodes you wish to use.\n",
        "\n",
        "USAGE:   AF(y,ref,H)  ... y=target, ref=reference, H=pre-set nodes\n",
        "RETURNS: yy, hRec     ... yy=filtered target, hRec=new nodes\n",
        "\"\"\"\n",
        "    n = len(y)  # length of input data\n",
        "    WN = len(H) # nodes (window size)\n",
        "    u = 0.0001  # convergence parameter; 0.0001 gives good results if the initial guess is zeros\n",
        "\n",
        "    # INITIALIZE ALL VARIABLES\n",
        "    hRec = np.zeros((n,WN)) # historical record of all Hs\n",
        "    ww = 0                  # prediction at current point\n",
        "    wwRec = np.zeros((n,1)) # historical record of fits\n",
        "    e = np.zeros((n,1))     # resulting filtered signal\n",
        "    X = np.zeros(WN)        # the reference signal to use for this timepoint\n",
        "    XRec = np.zeros((n,WN)) # historical record of X\n",
        "\n",
        "    # START FILTERING\n",
        "    for ii in range(n):\n",
        "        hRec[ii,:] = H\n",
        "        if ii<WN:\n",
        "            X[:ii+1] = np.ravel(ref[ii::-1])\n",
        "        else:\n",
        "            X = np.ravel(ref[ii:(ii-WN):-1])\n",
        "        ww = np.dot(H[np.newaxis,:],X)\n",
        "        wwRec[ii] = ww\n",
        "        e[ii] = y[ii]-ww\n",
        "        H = H +2*u*e[ii]*X\n",
        "        XRec[ii,:] = e[ii]*X\n",
        "\n",
        "    yy = e\n",
        "    return yy, hRec\n",
        "\n",
        "\n",
        "def nin_filt_AF(y,ref,H):\n",
        "    \"\"\"\n",
        "\n",
        "Adaptive filter a .NIN dataset, using the LMS algorithm. A reasonable default H is\n",
        "[1,0,0,0 ...] up to how ever many nodes you wish to use.\n",
        "\n",
        "USAGE:   nin_filt_AF(y,ref,H)  ... y=target, ref=reference, H=pre-set nodes\n",
        "RETURNS: yy, hRec     ... yy=filtered target, hRec=new nodes\n",
        "\"\"\"\n",
        "    if y.shape==ref.shape:\n",
        "        yy,hRec = AF(ref,y,H)\n",
        "        newy = yy\n",
        "    else:\n",
        "        newy = []\n",
        "        for col in y.T:\n",
        "            yy,hRec = AF(ref,y,H)\n",
        "            newy.append(yy)\n",
        "        newy = np.asarray(newy).T\n",
        "    return newy\n",
        "\n",
        "\n",
        "def ninse_filt_estg(estg,Hlen=10):\n",
        "    \"\"\"\n",
        "\n",
        "@@@NOT DONE!\n",
        "Does filtering suitable specifically for NIN-SE polysomnography E*G data:\n",
        "    Channel 0 (purple) = EOG-left eye\n",
        "    Channel 1 (blue) = EOG-right eye\n",
        "    Channel 2 (orange) = EMG-left cheek\n",
        "    Channel 3 (green) = EMG-right cheek\n",
        "    Channel 4 (grey) = EEG-left forehead\n",
        "    Channel 5 (yellow) = EEG-middle forehead\n",
        "    Channel 6 (red) = EEG-right forehead\n",
        "    Channel 7 (brown) = ECG-left thorax\n",
        "\n",
        "USAGE:   ninse_filt_estg(estg,Hlen=10)\n",
        "RETURNS: filtered estg @@@HOW APPLIED\n",
        "\"\"\"\n",
        "    # NORMALIZE SIGNALS FOR FILTERING\n",
        "    tmp = estg*1.0\n",
        "    tmp[:,:7] = tmp[:,:7]-estg[:,:7].mean(0)\n",
        "    tmp[:,:7] = tmp[:,:7] / np.std(tmp[:,:7],0)\n",
        "    ecg = tmp[:,7]\n",
        "\n",
        "    # ADAPTIVE FILTER EOG AGAINST ECG\n",
        "    print(\"Filtering EOG\")\n",
        "    H = np.array([1]+[0]*Hlen)\n",
        "    print(\"  Chan 0 = EOG-left\")\n",
        "    tmp[:,0] = AF(tmp[:,0],ecg,H)[:,0]        # 3=EOG\n",
        "    H = np.array([1]+[0]*Hlen)\n",
        "    print(\"  Chan 1 = EOG-right\")\n",
        "    tmp[:,1] = AF(tmp[:,1],ecg,H)[:,0]        # 4=EOG\n",
        "\n",
        "    # ADAPTIVE FILTER EMG AGAINST ECG\n",
        "    print(\"Filtering EMG\")\n",
        "    H = np.array([1]+[0]*Hlen)\n",
        "    print(\"  Chan 2\")\n",
        "    tmp[:,2] = AF(tmp[:,2],ecg,H)[:,0]        # 5=EMG\n",
        "    H = np.array([1]+[0]*Hlen)\n",
        "    print(\"  Chan 3\")\n",
        "    tmp[:,3] = AF(tmp[:,3],ecg,H)[:,0]        # 6=EMG\n",
        "\n",
        "    # ADAPTIVE FILTER EEG AGAINST ECG  @@@@AND THEN EOG\n",
        "    print(\"Filtering EEG\")\n",
        "    ecg = tmp[:,7]\n",
        "    H = np.array([1]+[0]*Hlen)\n",
        "    print(\"  Chan 4 = EEG-F3\")\n",
        "    tmp[:,4] = AF(tmp[:,4],ecg,H)[:,0]        # 0=EEG\n",
        "    tmp[:,4] = hipass(tmp[:,4],0.5,250)[:,0]\n",
        "    H = np.array([1]+[0]*Hlen)\n",
        "    print(\"  Chan 5 = EEG-Fz\")\n",
        "    tmp[:,5] = AF(tmp[:,5],ecg,H)[:,0]        # 1=EEG\n",
        "    tmp[:,5] = hipass(tmp[:,5],0.5,250)[:,0]\n",
        "    H = np.array([1]+[0]*Hlen)\n",
        "    print(\"  Chan 6 = EEG-F4\")\n",
        "    tmp[:,6] = AF(tmp[:,6],ecg,H)[:,0]        # 2=EEG\n",
        "    tmp[:,6] = hipass(tmp[:,6],0.5,250)[:,0]\n",
        "\n",
        "    # HIPASS ECG at 0.5 Hz\n",
        "    print(\"Filtering ECG\")\n",
        "    print(\"  Chan 7\")\n",
        "    tmp[:,7] = hipass(tmp[:,7],0.5,250)[:,0]  # 7=ECG\n",
        "\n",
        "    return tmp\n",
        "\n",
        "\n",
        "def envelopes(signal,hpf=0,verbose=False):\n",
        "    # FIND PEAKS & TROUGHS OF SIGNAL\n",
        "    if verbose:\n",
        "        print(\"nt.envelopes(): finding peaks ...\")\n",
        "    px, pxval = o.findpeaks(signal,250,0,hpf,1)  # pos peaks\n",
        "    if verbose:\n",
        "        print(\"nt.envelopes(): finding valleys ...\")\n",
        "    tx, txval = o.findpeaks(signal,250,0,hpf,-1) # neg peaks\n",
        "\n",
        "    # FIX AN OFF-BY-ONE ERROR?\n",
        "    px += 1\n",
        "    tx += 1\n",
        "    pxval = signal[px]\n",
        "    txval = signal[tx]\n",
        "\n",
        "    # COMPUTE INTERPOLATION FUNCTIONS\n",
        "    if verbose:\n",
        "        print(\"Interpolating ...\")\n",
        "        print(\"    \",signal.shape, len(px), pxval.shape, len(tx), txval.shape)\n",
        "        print(\"    \",max(px), max(tx))\n",
        "#        plot(signal)\n",
        "#        plot(px,pxval,'rx')\n",
        "#        plot(tx,txval,'kx')\n",
        "\n",
        "    p = si.InterpolatedUnivariateSpline(px/250.,pxval)\n",
        "    t = si.InterpolatedUnivariateSpline(tx/250.,txval)\n",
        "\n",
        "    # COMPUTE SPLINES\n",
        "    if verbose:\n",
        "        print(\"Computing splines ...\")\n",
        "    totaltime = len(signal)/250.\n",
        "    newxs = np.linspace(0,totaltime,totaltime*250)\n",
        "    ip = np.array(list(map(p,newxs)))\n",
        "    it = np.array(list(map(t,newxs)))\n",
        "\n",
        "    return ip, it\n",
        "\n",
        "\n",
        "def GSRenvelope(gsrdata,band=[45,55],lpf=3,hpf=0,verbose=False):\n",
        "#    # BANDPASS AROUND CLOCK FREQUENCY\n",
        "#    print 'gsr bandpass'\n",
        "#    gsrfilt = bandpass(gsrdata,band)\n",
        "\n",
        "    # FIND PEAKS & TROUGHS OF GSR DATA\n",
        "    print('gsr peak/trough detector')\n",
        "    peakcurve,troughcurve = envelopes(gsrdata,hpf,verbose=verbose)\n",
        "\n",
        "    # ENVELOPE RESULT\n",
        "    print('gsr lowpass')\n",
        "    GSRenv = (peakcurve-troughcurve)/2.\n",
        "    GSRenv = lowpass(GSRenv,lpf,250)\n",
        "\n",
        "    return GSRenv\n",
        "\n",
        "\n",
        "def GSRlockin(gsrdata,gsrclock,band=[45,55],lpf=3,shift=1):\n",
        "    # BANDPASS AROUND CLOCK FREQUENCY\n",
        "    gsrfilt = bandpass(gsrdata,band)\n",
        "    clockfilt = bandpass(gsrclock,band)\n",
        "\n",
        "    # FIGURE OUT CLOCK-TO-DATA SHIFT\n",
        "    cmax = max(gsrclock)\n",
        "    cmin = min(gsrclock)\n",
        "    clockNorm = gsrclock #-cmin)/float(cmax-cmin)*2-1  #(gsrclock-2**23)/2.**23\n",
        "    clockShift = clockNorm[shift:]  # to shift left\n",
        "    clockShift = -clockShift        # invert phase\n",
        "\n",
        "    # DEMODULATE THE CLOCK SIGNAL\n",
        "    demodClock = -1*np.ones(len(clockShift))  # all -1s\n",
        "    demodClock = np.where(clockShift>0,1,-1)   # except where clockShift>0\n",
        "\n",
        "    # DEMODULATE THE GSR SIGNAL\n",
        "    gsrdemod = demodClock*gsrfilt[:-shift,0]  # crop of end to match lengths\n",
        "\n",
        "#    plot(clockNorm)\n",
        "#    plot(demodClock)\n",
        "#    plot(gsrfilt/250.)\n",
        "#    show()\n",
        "    return gsrdemod\n",
        "\n",
        "\n",
        "def GSR_Vlad(gsrdata,lpf=1):\n",
        "    newd = gsrdata\n",
        "#    \"\"\"Quan's method:\n",
        "#    # MEAN-SUBTRACT\n",
        "#    newd = gsrdata-np.mean(gsrdata,0)\n",
        "#    # INVERT\n",
        "#    newd[1::2] = -newd[1::2]\n",
        "    \"\"\"\n",
        "    # MY METHOD\n",
        "    # FIGURE OUT LENGTH (ODD OR EVEN)\n",
        "    if np.mod(len(gsrdata),2)==0:\n",
        "        #even length\n",
        "        n = len(gsrdata)\n",
        "    else:  # odd\n",
        "        n = len(gsrdata)-1\n",
        "    # CALC PEAK-TO-PEAK DIFFERENCES (ABS VALUE)\n",
        "    tmp = np.abs( gsrdata[0:n:2,:]-gsrdata[1:n:2,:] )\n",
        "\n",
        "    # PASTE THEM BACK INTO THE ORIGINAL SHAPE\n",
        "    newd = np.zeros(gsrdata.shape,np.float)\n",
        "    newd[0:n:2,:] = tmp\n",
        "    try:\n",
        "        newd[1:n:2,:] = tmp\n",
        "    except ValueError:\n",
        "        newd[1:n-1:2,:] = tmp\n",
        "    \"\"\"\n",
        "    # LOWPASS\n",
        "    newd = lowpass(newd,lpf,250)\n",
        "\n",
        "    return newd\n",
        "\n",
        "\n",
        "def nin_filt_nirs(d,lpf_hpf=[0,0],samplerate=SLOWRATE):\n",
        "    \"\"\"\n",
        "\n",
        "Apply a lowpass and highpass filter to a TIME x CHANNELS data.\n",
        "filt_param holds [LPF_cutoff, HPF_cutoff]. Uses nt.lowpass/nt.hipass.\n",
        "\n",
        "RETURNS: filtered d\n",
        "\"\"\"\n",
        "    tmp = lowpass(d,lpf_hpf[0],samplerate)\n",
        "    tmp = hipass(tmp,lpf_hpf[1],samplerate)\n",
        "    return tmp\n",
        "\n",
        "\n",
        "def nin_filt_all(a,filt_param=DEFAULTfilt_param,verbose=True):\n",
        "    \"\"\"\n",
        "\n",
        "Apply a lowpass and highpass filter to a TIME x CHANNELS data.\n",
        "filt_param holds a dictionary like this {'ACCE':[LPF_cutoff, HPF_cutoff]}.\n",
        "Uses nt.lowpass/nt.hipass. Works on all channels in 'a' dict.\n",
        "\n",
        "RETURNS: copy of 'a' with all filt_param applied\n",
        "\"\"\"\n",
        "    tmp = {}\n",
        "    for k in a.keys():\n",
        "        if k in ['NIRS','SRC','BKGD']:\n",
        "            RATE = 25\n",
        "        elif k in ['ACCE','GYRO','EstG','NECG']:\n",
        "            RATE = 250\n",
        "        elif k in ['RESP','TEMP','FORC']:\n",
        "            RATE = 25\n",
        "        try:\n",
        "            if verbose:\n",
        "                print(\" \",k,\": LPF=\",filt_param[k][0], \"  HPF=\",filt_param[k][1])\n",
        "            tmp[k] = lowpass(a[k],filt_param[k][0],RATE)\n",
        "            tmp[k] = hipass(tmp[k],filt_param[k][1],RATE)\n",
        "        except:\n",
        "            print(\"      Failed filtering in nin_filt_aux() for\",k)\n",
        "            tmp[k] = a[k]\n",
        "            pass\n",
        "    return tmp\n",
        "\n",
        "\n",
        "def nin_filt_aux(a,filt_param=DEFAULTfilt_param,verbose=True):\n",
        "    \"\"\"\n",
        "\n",
        "Apply a lowpass and highpass filter to a TIME x CHANNELS data.\n",
        "filt_param holds a dictionary like this {'ACCE':[LPF_cutoff, HPF_cutoff]}.\n",
        "Uses nt.lowpass/nt.hipass. Looks for: ACCE, GYRO, EstG, RESP, TEMP, FORC.\n",
        "\n",
        "RETURNS: 'a' with all filt_param applied\n",
        "\"\"\"\n",
        "    tmp = {}\n",
        "    for k in filt_param.keys():\n",
        "        if k in ['NIRS','SRC','BKGD']:\n",
        "            continue  # skip these, of course\n",
        "        if k in ['ACCE','GYRO','EstG','NECG']:\n",
        "            RATE = 250\n",
        "        elif k in ['RESP','TEMP','FORC']:\n",
        "            RATE = 25\n",
        "        try:\n",
        "            if verbose:\n",
        "                print(\" \",k,\": LPF=\",filt_param[k][0], \"  HPF=\",filt_param[k][1])\n",
        "            tmp[k] = lowpass(a[k],filt_param[k][0],RATE)\n",
        "            tmp[k] = hipass(tmp[k],filt_param[k][1],RATE)\n",
        "        except:\n",
        "            print(\"      Failed filtering in nin_filt_aux() for\",k)\n",
        "            tmp[k] = a[k]\n",
        "    return tmp\n",
        "\n",
        "\n",
        "def nin_resample_estg(d,t=None,NEWrate=256,OLDrate=FASTRATE):\n",
        "    \"\"\"\n",
        "\n",
        "Resample the E*G timeseries to a new sample rate (upsampling is possible)\n",
        "using numpy.interp().\n",
        "\n",
        "RETURNS: resampled array d, resampled timebase t\n",
        "\"\"\"\n",
        "    if t is not None:\n",
        "        oldx = t\n",
        "    else:\n",
        "        oldx = np.arange(len(d))/float(OLDrate)  # make up 0-->N, step-by-OLDrate xvals\n",
        "    factor = NEWrate/float(OLDrate)\n",
        "    npts = int(len(oldx)*factor)\n",
        "    newx = np.arange(npts)/float(NEWrate)+oldx[0]  # time offset, if needed\n",
        "    newd = []\n",
        "    for i in range(d.shape[1]):\n",
        "        newd.append(np.interp(newx,oldx,d[:,i]))\n",
        "    d = np.array(newd).T\n",
        "    return d,newx\n",
        "\n",
        "\n",
        "def delta_at_freq1(odcolors,hpf,lpf,wavelengths=[690,790,830,850],rate=25,baselineHb=0,baselineHbO=0,plots=False):\n",
        "    \"\"\"Two-step filter of od to frequency-band [hpf,lpf]\n",
        "    Finds peaks and valleys in this frequency band\n",
        "    Computes peak-to-valley differences in OD for each wavelength\n",
        "    Computes hb_hbo from differences\n",
        "    \"\"\"\n",
        "    # HIPASS FILTER TO EXCLUDE NON-BREATHING\n",
        "    fodcolors = hipass(odcolors,hpf,rate)\n",
        "    # LOWPASS FILTER TO EXCLUDE NON-BREATHING\n",
        "    fodcolors = lowpass(fodcolors,lpf,rate)\n",
        "\n",
        "    # FIND PEAKS FROM MEAN SIGNAL\n",
        "    px,p = o.findpeaks(fodcolors[:,2],rate,0,0,1)\n",
        "\n",
        "    # FIND PEAKS FROM MEAN SIGNAL\n",
        "    vx,v = o.findpeaks(fodcolors[:,2],rate,0,0,-1)\n",
        "\n",
        "    # TRUNCATE TO RIGHT LENGTHS\n",
        "    minlen = min(len(px),len(vx))\n",
        "    px = px[:minlen]\n",
        "    vx = vx[:minlen]\n",
        "\n",
        "    # SMOOTH OUT OD SO THAT HIGHER FREQ OSCILLATIONS DON'T CONTAMINATE\n",
        "    sod = lowpass(fodcolors,lpf,rate)\n",
        "\n",
        "    # GRAB DATA AT PEAKS AND VALLEYS AND COMPUTE DIFFERENCE\n",
        "    dpsod = sod[px,:]\n",
        "    dvsod = sod[vx,:]\n",
        "    deltadata = dpsod-dvsod\n",
        "\n",
        "    # COMPUTE DELTA-HBHBO\n",
        "    deltahbhbo = o.od2hbhbo_bls(deltadata,wavelengths,[6]*len(wavelengths))*1e6\n",
        "\n",
        "    # ADD BASELINE\n",
        "    deltahbhbos = deltahbhbo.T+np.array([baselineHb,baselineHbO])\n",
        "\n",
        "    if plots:\n",
        "        figure()\n",
        "        t = np.arange(len(odcolors))/float(rate)\n",
        "        plot(t,fodcolors[:,0])\n",
        "        plot(t[px],fodcolors[px,0],'rx')\n",
        "        plot(t[vx],fodcolors[vx,0],'kx')\n",
        "\n",
        "    return np.array(deltahbhbos),px\n",
        "\n",
        "\n",
        "def delta_at_freq(od,odchan,hpf,lpf,rate=25,baselineHb=0,baselineHbO=0,plots=False):\n",
        "    \"\"\"Two-step filter of od to frequency-band [hpf,lpf]\n",
        "    Finds peaks and valleys in this frequency band\n",
        "    Computes peak-to-valley differences in OD for each wavelength\n",
        "    Computes hb_hbo from differences\n",
        "    \"\"\"\n",
        "    f780s = []\n",
        "    f830s = []\n",
        "    for idx in odchan:\n",
        "        # GRAB 2 COLORS FOR THIS SD-PAIR\n",
        "        d780 = od[:,idx+8]\n",
        "        d830 = od[:,idx]\n",
        "        # HIGHPASS FILTER TO CAPTURE BREATHING\n",
        "        f780 = hipass(d780,hpf,rate)\n",
        "        f830 = hipass(d830,hpf,rate)\n",
        "        # LOWPASS FILTER TO EXCLUDE NON-BREATHING\n",
        "        f780 = lowpass(f780,lpf,rate)\n",
        "        f780 = lowpass(f780,lpf,rate)\n",
        "        # COMPILE A LIST ACROSS CHANNELS\n",
        "        f780s.append(f780)\n",
        "        f830s.append(f830)\n",
        "    # CONVERT ACCUMULATED LIST TO ARRAY ... CHAN x TIME\n",
        "    f780s = np.array(f780s)\n",
        "    f830s = np.array(f830s)\n",
        "\n",
        "    # COMPUTE MEAN ACROSS CHANNELS ... TIME\n",
        "    f780m = np.mean(f780s,0)\n",
        "    f830m = np.mean(f830s,0)\n",
        "\n",
        "    # FIND PEAKS FROM MEAN SIGNAL\n",
        "    p780x,p780 = o.findpeaks(f780m,rate,0,0,1)\n",
        "    p830x,p830 = o.findpeaks(f830m,rate,0,0,1)\n",
        "\n",
        "    # FIND VALLEYS FROM MEAN SIGNAL\n",
        "    v780x,v780 = o.findpeaks(f780m,rate,0,0,-1)\n",
        "    v830x,v830 = o.findpeaks(f830m,rate,0,0,-1)\n",
        "\n",
        "    # TRUNCATE TO RIGHT LENGTHS\n",
        "    minlen = min(len(p780x),len(p830x),len(v780x),len(v830x))\n",
        "    p780x = p780x[:minlen]\n",
        "    p830x = p830x[:minlen]\n",
        "    v780x = v780x[:minlen]\n",
        "    v830x = v830x[:minlen]\n",
        "\n",
        "    # SMOOTH OUT OD SO THAT HIGHER FREQ OSCILLATIONS DON'T CONTAMINATE\n",
        "    sod = lowpass(od,lpf,rate)\n",
        "\n",
        "    deltahbhbos = []\n",
        "    for idx in odchan:\n",
        "        # GRAB 2 COLORS FOR THIS SD-PAIR AT PEAKS\n",
        "        dp780 = sod[p780x,idx+8]\n",
        "        dp830 = sod[p830x,idx]\n",
        "\n",
        "        # GRAB 2 COLORS FOR THIS SD-PAIR AT VALLEYS\n",
        "        dv780 = sod[v780x,idx+8]\n",
        "        dv830 = sod[v830x,idx]\n",
        "\n",
        "        # GLUE TOGETHER 780 & 830nm DATA FOR EACH CYCLE (RESP/CARDIAC/WHATEVER)\n",
        "        deltadata = list(zip( dp780-dv780, dp830-dv830 ))\n",
        "        deltadata = np.array(deltadata)\n",
        "\n",
        "        # COMPUTE DELTA-HBHBO\n",
        "        deltahbhbo = o.od2hbhbo_bls(deltadata,[780,830],[6,6])*1e6\n",
        "\n",
        "        # ADD BASELINE\n",
        "        deltahbhbos.append(deltahbhbo+np.array([baselineHb,baselineHbO]))\n",
        "\n",
        "    if plots:\n",
        "        figure()\n",
        "        t = np.arange(len(od))/float(rate)\n",
        "        plot(t,f780m[:])\n",
        "        plot(t[p780x],f780m[p780x],'rx')\n",
        "        plot(t[v780x],f780m[v780x],'kx')\n",
        "\n",
        "    return np.array(deltahbhbos),p780x\n",
        "\n",
        "\n",
        "def signalpower(d,freqranges,idxrange='all',NFFT=512,samplerate=250):\n",
        "    \"\"\"\n",
        "\n",
        "Calculate power in a set of frequency bands. freqranges is a dict of name:[low,high] pairs.\n",
        "\n",
        "RETURNS: dictionary of average instantaneous power in given ranges using specgram\n",
        "\"\"\"\n",
        "    # CROP TIMESERIES IF REQUESTED\n",
        "    if idxrange!='all':\n",
        "       d = d[idxrange[0]:idxrange[1]]\n",
        "    d = np.squeeze(d)\n",
        "\n",
        "    # COMPUTE SPECTROGRAM\n",
        "    Pxx, freqs, bins, im = specgram(d, NFFT=NFFT, Fs=samplerate, noverlap=128,cmap=plt.cm.gist_heat)\n",
        "    close()  # get rid of figure; only want numbers\n",
        "\n",
        "    # COMPUTE AVERAGE POWERS\n",
        "    p = {}\n",
        "    for k in freqranges.keys():\n",
        "        mn = findonset(freqs,freqranges[k][0])\n",
        "        mx = findonset(freqs,freqranges[k][1])\n",
        "        p[k] = np.mean(Pxx[mn:mx,:])\n",
        "\n",
        "    return p\n",
        "\n",
        "\n",
        "def EEGpower(d,idxrange='all',freqranges=default_EEG_ranges,NFFT=512,samplerate=250,overlap=128):\n",
        "    \"\"\"\n",
        "\n",
        "Calculate power in a set of frequency bands. A default set bands is provided\n",
        "for EEG data. Those defaults can be edited in this file (nintools_v5.py?).\n",
        "\n",
        "RETURNS: dictionary of average instantaneous power in given ranges using specgram\n",
        "\"\"\"\n",
        "    # CROP TIMESERIES IF REQUESTED\n",
        "    if idxrange!='all':\n",
        "       d = d[idxrange[0]:idxrange[1]]\n",
        "    d = np.squeeze(d)\n",
        "\n",
        "    # COMPUTE SPECTROGRAM\n",
        "    Pxx, freqs, bins, im = specgram(d, NFFT=NFFT, Fs=samplerate, noverlap=overlap,\n",
        "                                cmap=plt.cm.gist_heat)\n",
        "    close()  # get rid of figure; only want numbers\n",
        "\n",
        "    # COMPUTE AVERAGE POWERS\n",
        "    p = {}\n",
        "    for k in freqranges.keys():\n",
        "        mn = findonset(freqs,freqranges[k][0])\n",
        "        mx = findonset(freqs,freqranges[k][1])\n",
        "        p[k] = np.mean(Pxx[mn:mx,:])\n",
        "\n",
        "    return p\n",
        "\n",
        "\n",
        "def EEGpower_welch(d,idxrange='all',freqbands=default_EEG_ranges,NFFT=512,samplerate=250):\n",
        "    f, psd = ss.welch(d, fs=samplerate)  # psd units = V^2/Hz\n",
        "    powers = {band: np.mean(psd[np.where((f >= lf) & (f <= hf))]) for band, (lf, hf) in freqbands.items()}\n",
        "    return powers\n",
        "\n",
        "\n",
        "def power_welch(d,sampfreq,minfreq_of_interest=0.01):\n",
        "    win = int(2/minfreq_of_interest*sampfreq)\n",
        "    f,psd = ss.welch(d, sampfreq, nperseg=win)\n",
        "    return f,psd\n",
        "\n",
        "\n",
        "def avg_band_power(d,band=[0.01,100],samplerate=250):\n",
        "    # COMPUTE THE PSD\n",
        "    f,psd = power_welch(d,samplerate,band[0])\n",
        "\n",
        "    # DEFINE DELTA LOWER AND UPPER LIMITS\n",
        "    low, high = band\n",
        "    # FIND INTERSECTING VALUES IN FREQUENCY VECTOR\n",
        "    idx_delta = np.logical_and(f>=low, f<=high)\n",
        "    # FREQUENCY RESOLUTION\n",
        "    freq_res = f[1] - f[0]\n",
        "    # COMPUTE ABSOLUTE POWER BY APPROXIMATING THE AREA UNDER THE CURVE\n",
        "    delta_power = simps(psd[idx_delta], dx=freq_res)\n",
        "\n",
        "    # RELATIVE DELTA POWER (EXPRESSED AS A PERCENTAGE OF TOTAL POWER)\n",
        "    total_power = simps(psd, dx=freq_res)\n",
        "    delta_rel_power = delta_power / total_power\n",
        "\n",
        "    return delta_power, delta_rel_power\n",
        "\n",
        "\n",
        "def bandpower(data, sf, band, method='welch', window_sec=None, relative=False):\n",
        "    \"\"\"Compute the average power of the signal x in a specific frequency band.\n",
        "    from: https://raphaelvallat.com/bandpower.html\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    data : 1d-array\n",
        "      Input signal in the time-domain.\n",
        "    sf : float\n",
        "      Sampling frequency of the data.\n",
        "    band : list\n",
        "      Lower and upper frequencies of the band of interest.\n",
        "    method : string\n",
        "      Periodogram method: 'welch' or 'multitaper'\n",
        "    window_sec : float\n",
        "      Length of each window in seconds. Useful only if method == 'welch'.\n",
        "      If None, window_sec = (1 / min(band)) * 2.\n",
        "    relative : boolean\n",
        "      If True, return the relative power (= divided by the total power of the signal).\n",
        "      If False (default), return the absolute power.\n",
        "\n",
        "    Return\n",
        "    ------\n",
        "    bp : float\n",
        "      Absolute or relative band power.\n",
        "    \"\"\"\n",
        "    from scipy.signal import welch\n",
        "    from scipy.integrate import simps\n",
        "    try:\n",
        "        from mne.time_frequency import psd_array_multitaper\n",
        "    except:\n",
        "#        print(\"multitaper unavailable in nt.bandpower()\")\n",
        "        pass\n",
        "\n",
        "    band = np.asarray(band)\n",
        "    low, high = band\n",
        "\n",
        "    # Compute the modified periodogram (Welch)\n",
        "    if method == 'welch':\n",
        "        if window_sec is not None:\n",
        "            nperseg = window_sec * sf\n",
        "        else:\n",
        "            nperseg = (2 / low) * sf\n",
        "\n",
        "        freqs, psd = welch(data, sf, nperseg=nperseg)\n",
        "\n",
        "    elif method == 'multitaper':\n",
        "        psd, freqs = multitaper.psd_array_multitaper(data, sf, adaptive=True,\n",
        "                                          normalization='full', verbose=0)\n",
        "\n",
        "    # Frequency resolution\n",
        "    freq_res = freqs[1] - freqs[0]\n",
        "\n",
        "    # Find index of band in frequency vector\n",
        "    idx_band = np.logical_and(freqs >= low, freqs <= high)\n",
        "\n",
        "    # Integral approximation of the spectrum using parabola (Simpson's rule)\n",
        "    bp = simps(psd[idx_band], dx=freq_res)\n",
        "\n",
        "    if relative:\n",
        "        bp /= simps(psd, dx=freq_res)\n",
        "    return bp\n",
        "\n",
        "\n",
        "def EEGpower2(d,freqbands=default_EEG_ranges,samplerate=250):\n",
        "    \"\"\"Uses nt.bandpower() to compute *relative* power in each EEG band\"\"\"\n",
        "    powers = {}\n",
        "    for band, lowhigh in freqbands.items():\n",
        "        try:\n",
        "            p = bandpower(d, samplerate, lowhigh, window_sec=None, relative=True)\n",
        "            powers[band] = p\n",
        "        except:\n",
        "            powers[band] = np.nan\n",
        "    return powers\n",
        "\n",
        "\n",
        "def nin_zero2timepoint(d,t,timept):\n",
        "    \"\"\"Zero-correct NIN data to time=t\"\"\"\n",
        "    if type(timept) in [type(list),type(tuple)]:\n",
        "        idx1 = int(timept[0]*25)\n",
        "        idx2 = int(timept[1]*25)\n",
        "        refd = np.mean(d[idx1:idx2,:],0)\n",
        "    else:\n",
        "        idx = int(timept*25)\n",
        "        refd = d[idx,:]\n",
        "    return d-refd\n",
        "\n",
        "\n",
        "def EOG_norm(eogdata):\n",
        "    \"\"\"normalize to mean=0, std=1\"\"\"\n",
        "    Neog = eogdata-np.mean(eogdata,0)\n",
        "    Neog = Neog / np.std(eogdata,0)\n",
        "    return Neog\n",
        "\n",
        "\n",
        "def EOG_movements(eogdata,threshold=+0.5,width=12,refractory=40):\n",
        "    \"\"\"EOG_movements(eogdata,threshold=+0.5,width=12,refractory=40):\n",
        "\n",
        "    Identify saccades ... returns a vector of +1s (movement \"up\") and -1s (movement \"down\")\n",
        "    @@@HACK; NEEDS FURTHER WORK\n",
        "    \"\"\"\n",
        "    Neog = EOG_norm(eogdata)\n",
        "    # SCAN THROUGH FOR \"STEPS\" IN\n",
        "    EOGindexesPLUS = findsteps(Neog,threshold,xstep=width,refractory=refractory)\n",
        "    EOGindexesMINUS = findsteps(Neog,-threshold,xstep=width,refractory=refractory)\n",
        "    # CREATE VECTOR OF EYE-MOVEMENT (1) OR NONE (0)\n",
        "    EOGvec = np.zeros(eogdata.shape)\n",
        "    try:\n",
        "        EOGvec[EOGindexesPLUS] = 1\n",
        "    except:\n",
        "        pass\n",
        "    try:\n",
        "        EOGvec[EOGindexesMINUS] = -1\n",
        "    except:\n",
        "        pass\n",
        "    return EOGvec\n",
        "\n",
        "\n",
        "def ECGsuppress(eeg,ekg,fseeg=250,fsekg=250,refract=0.27,offset=0,propor1hz=0.8,plotit=False,verbose=False):\n",
        "    \"\"\"\n",
        "Removes EKG signal artifacts from EEG (or other biopotential signal) using a peak-to-peak\n",
        "templating approach. Requires same-length EEG & EKG.\n",
        "\n",
        "Returns:  cleaneeg, noise\n",
        "\"\"\"\n",
        "    # DETREND TO REDUCE EDGE-OF-WINDOW GLITCHING\n",
        "    if verbose:\n",
        "        print(\"ECGsuppress() ... Detrending EEG/EKG\")\n",
        "    eeg = ss.detrend(eeg)\n",
        "    ekg = ss.detrend(ekg)\n",
        "\n",
        "    # CREATE TIME-BASE\n",
        "    time = np.arange(len(eeg))/float(fseeg)\n",
        "\n",
        "    # FIND TIMES AND INDEXES OF THE ECG R-WAVE PEAKS\n",
        "    if verbose:\n",
        "        print(\"ECGsuppress() ... Finding R peaks\")\n",
        "    R_t, R_idx = find_R_peaks(ekg,t=time,fsekg=fsekg,refract=refract,propor1hz=0.8,plotit=False,verbose=verbose)\n",
        "\n",
        "    # GRAB WINDOWS OF DATA AROUND EACH HEARTBEAT\n",
        "    # start 200 ms before trigger and end 200 ms before the next trigger\n",
        "    rr = np.diff(R_idx)             # list of R-R intervals, in samples (not sec)\n",
        "    sz = min(np.max(rr),2*fseeg)    # maximum size of window (up to 2 sec)\n",
        "    lim = int(0.2*fseeg)            # 200 ms in samples\n",
        "    ##B = ss.firwin(301, [15./fseeg*2, 19./fseeg*2])  ## makes spike a mess and ends up\n",
        "    ##e = filtfilt(B,1,eeg)                           ## rounding-off the peak\n",
        "\n",
        "    # LOOK IN A 40MS WINDOW AROUND r-PEAK AND GET THE PEAK-TO-PEAK RANGE (AMPLI)\n",
        "    winpts = int(fseeg*0.05)  # 50 ms window for finding peak amp (may not be at EKG peak)\n",
        "    ampli = np.zeros(len(R_idx))\n",
        "    for i in range(len(R_idx)):\n",
        "        mxe = np.max(eeg[R_idx[i]-winpts:R_idx[i]+winpts])\n",
        "        mne = np.min(eeg[R_idx[i]-winpts:R_idx[i]+winpts])\n",
        "        ampli[i] = mxe-mne\n",
        "\n",
        "    # START LOOP TO GRAB EACH WINDOW\n",
        "    if verbose:\n",
        "        print(\"ECGsuppress() ... Grab windows around each peak\")\n",
        "    eegmat = np.zeros((len(R_idx),sz))+np.NaN\n",
        "#    ekgmat = []\n",
        "    for j in range(1,len(R_idx)-2):  # skip first spike so you can go leftward by 'lim'\n",
        "        # check if distance is > 2s\n",
        "        if R_idx[j+1]-R_idx[j]<(2*fseeg) and R_idx[j+1]-R_idx[j]>lim:\n",
        "            eegwin = eeg[R_idx[j]-lim:R_idx[j+1]-lim]\n",
        "#            ekgwin = ekg[R_idx[j]-lim:R_idx[j+1]-lim]\n",
        "        else:\n",
        "            try:\n",
        "                eegwin = eeg[R_idx[j]-lim:R_idx[j]+lim]\n",
        "#                ekgwin = ekg[R_idx[j]-lim:R_idx[j]+lim]\n",
        "            except:\n",
        "                eegwin = eeg[R_idx[j]-lim:]\n",
        "#                ekgwin = ekg[R_idx[j]-lim:]\n",
        "#            ekgmat.append(ekgwin[:,0])\n",
        "        eegmat[j,:len(eegwin)] = eegwin\n",
        "\n",
        "    ##    # resample to longest window interval so they can be averaged together cleanly\n",
        "    ##    # widens R-peak, not good\n",
        "    ####    eegmat.append(ss.resample(eegwin,sz))\n",
        "\n",
        "    # CONCATENATE ARTIFACT WINDOWS TO PRODUCE NOISE SIGNAL\n",
        "    if verbose:\n",
        "        print(\"ECGsuppress() ... Build artifact timeseries ...\", end=' ')\n",
        "    num2avg = 80\n",
        "    noise = np.zeros(eeg.shape[0])\n",
        "    for j in range(1,len(R_idx)-2):   # skip first so you can go -lim safely\n",
        "        if verbose:\n",
        "            if j%1000==0:\n",
        "                print(j, end=' ')\n",
        "        # COMPUTE LOCAL ARTIFACT (from num2avg prior heartbeats)\n",
        "        minidx = max(0,j-num2avg)\n",
        "        n = np.sum(~np.isnan(eegmat[minidx:j,:]),0)\n",
        "        art = np.nanmean(eegmat[minidx:j,:],0)*n/float(num2avg) #Shaun's modification: this way I only weight points that are actually there\n",
        "        art[np.isnan(art)] = 0  # zero out any NaNs\n",
        "        # FIND REGION AROUND PEAK\n",
        "        winstart = R_idx[j]-lim+offset\n",
        "        winend = R_idx[j+1]-lim+offset\n",
        "        # do subtraction, unless there's a gap between beats >2 sec\n",
        "        try:\n",
        "            # figure out the peak-to-peak scaling on this artifact\n",
        "            tmp = art[:winend-winstart]\n",
        "            mxa = np.max(tmp)\n",
        "            mna = np.min(tmp)\n",
        "            # subtract, rescaling based on eeg and this-artifact peak-to-peak ranges\n",
        "            noise[winstart:winend] = tmp*ampli[j]/(mxa-mna)\n",
        "        except:\n",
        "            pass\n",
        "    if verbose:\n",
        "        print()\n",
        "\n",
        "    if plotit:\n",
        "        #plot(ekg/20.,'k')\n",
        "        plot(eeg,'b',label='EEG')\n",
        "        plot(noise,'g',label='noise')\n",
        "        plot(cleaneeg,'r',label='cleanEEG')\n",
        "        legend()\n",
        "        show()\n",
        "\n",
        "    return eeg-noise, noise\n",
        "\n",
        "\n",
        "###################### DATA FILE READING FUNCTIONS ########################\n",
        "\n",
        "def get_nin_header(fname):\n",
        "    \"\"\"\n",
        "\n",
        "Return info from NIN-M header as a dictionary. Currently only date, time & deviceID.\n",
        "\n",
        "RETURNS:  dictionary of header info\n",
        "\"\"\"\n",
        "    if fname[-4:] in ['.edf','.bdf','.mat']:\n",
        "        fname = fname[:-4]+'.nin'\n",
        "    f = open(fname,'rb')\n",
        "    data = str(f.read(512))\n",
        "    s = data.replace('[','')\n",
        "    lst = s.split(']')\n",
        "\n",
        "    y = lst[0][0:4]\n",
        "    m = lst[0][5:7]\n",
        "    d = lst[0][7:9]\n",
        "    dt = d +'.' +m +'.' +y   # using dots for EDF\n",
        "    H = lst[0][10:12]\n",
        "    M = lst[0][12:14]\n",
        "    S = lst[0][14:16]\n",
        "    tm = H +'.' +M +'.' +S   # using dots for EDF\n",
        "    dct = {'date':dt, 'time':tm}\n",
        "\n",
        "    dev = lst[1].split(':')\n",
        "    dct[dev[0]] = dev[1]\n",
        "\n",
        "    return dct\n",
        "\n",
        "\n",
        "def get_nin_config(fname):\n",
        "    \"\"\"\n",
        "\n",
        "Return info from NIN-M -Config.txt file as a dictionary.\n",
        "\n",
        "RETURNS: dictionary of config-file info\n",
        "\"\"\"\n",
        "    if fname[-4:] in ['.edf','.bdf','.mat']:\n",
        "        fname = fname[:-4]+'.nin'\n",
        "    if 'Config' not in fname:\n",
        "        if '.nin' in fname:\n",
        "            fname = fname[:-4]+'-Config.txt'\n",
        "        else:\n",
        "            fname = fname+'-Config.txt'\n",
        "\n",
        "    PROBEgain = []\n",
        "    BOARDgain = []\n",
        "    f = open(fname,'r')\n",
        "    x = f.readline()\n",
        "    while x != \"\":\n",
        "        if \"Probe Gain\" in x:\n",
        "            for i in range(8):\n",
        "                x = f.readline()\n",
        "                PROBEgain += [list(map(int,x.strip()))]\n",
        "        elif \"Board Gain\" in x:\n",
        "            for i in range(8):\n",
        "                x = f.readline()\n",
        "                BOARDgain += [list(map(int,x.split()))]\n",
        "        elif \"Source Power\" in x:\n",
        "            x = f.readline()\n",
        "            SRCpower = list(map(int,x.split()))\n",
        "        elif \"E*G Setting\" in x:\n",
        "            x = f.readline()\n",
        "            EstGgain = list(map(int,str.split(x)))\n",
        "        elif \"Accel Setting\" in x:\n",
        "            x = f.readline()\n",
        "            ACC = int(str.strip(x))\n",
        "        elif \"Force Gain\" in x:\n",
        "            x = f.readline()\n",
        "            FORCE = int(str.strip(x))\n",
        "        elif \"TTL Trigger Out\" in x:\n",
        "            x = f.readline()\n",
        "            try:\n",
        "                TTLout = int(str.strip(x))\n",
        "            except:\n",
        "                TTLout = 0\n",
        "        elif \"TTL Trigger In\" in x:\n",
        "            x = f.readline()\n",
        "            try:\n",
        "                TTLin = int(str.strip(x))\n",
        "            except:\n",
        "                TTLin = 0\n",
        "        elif \"Digital In\" in x:\n",
        "            x = f.readline()\n",
        "            try:\n",
        "                Digital = int(str.strip(x))\n",
        "            except:\n",
        "                Digital = 0\n",
        "        elif \"Bluetooth\" in x:\n",
        "            x = f.readline()\n",
        "            try:\n",
        "                BT = int(str.strip(x))\n",
        "            except:\n",
        "                BT = 1\n",
        "        x = f.readline()\n",
        "\n",
        "    dct = {'PROBEgain':np.array(PROBEgain),\n",
        "            'BOARDgain':np.array(BOARDgain),\n",
        "            'SRCpower':SRCpower,\n",
        "            'EstGgain':EstGgain,\n",
        "            'ACCgain':ACC,\n",
        "            'FORCEgain':FORCE,\n",
        "            'TTLout':TTLout,\n",
        "            'TTLin':TTLin,\n",
        "            'DIGITALin':Digital,\n",
        "            'BT':BT}\n",
        "    return dct\n",
        "\n",
        "\n",
        "def get_nin_events(fname):\n",
        "    \"\"\"\n",
        "\n",
        "Read in all events from a NIN-M/SE -Event.txt file.\n",
        "\n",
        "RETURNS: 4 lists (ea,eb,ec,ed) of [timestamp, 250Hz_data_index] pairs\n",
        "\"\"\"\n",
        "    if fname[-4:] in ['.edf','.bdf','.mat']:\n",
        "        fname = fname[:-4]+'.nin'\n",
        "    idx = fname.find('.nin')\n",
        "    prefix = fname[:idx]\n",
        "    f = open(prefix+'.nin','rb')\n",
        "    starttime = f.read(16)[1:-1]  # datetime is first 16 characters as [2015-0821-1553]\n",
        "    f.close()\n",
        "    #try:\n",
        "    f = open(\"Event-\"+prefix.split(\"-\")[-1]+'.txt','r')\n",
        "    #except:\n",
        "        #return [],[],[],[]\n",
        "\n",
        "    ea = []\n",
        "    eb = []\n",
        "    ec = []\n",
        "    ed = []\n",
        "    l = f.readlines()\n",
        "    if l:\n",
        "        for row in l[1:]:\n",
        "            try:\n",
        "                x = row.split()\n",
        "                dt = datetime.datetime(int(x[0][:4]),int(x[0][5:7]),int(x[0][7:9]),int(x[0][10:12]),int(x[0][13:15]),int(x[0][16:18]))\n",
        "                pt = int(str.lstrip(x[1],'0'))\n",
        "                button = x[2]\n",
        "                if button=='A':\n",
        "                    ea.append([time.mktime(dt.timetuple()),pt,])\n",
        "                elif button=='B':\n",
        "                    eb.append([time.mktime(dt.timetuple()),pt])\n",
        "                elif button=='C':\n",
        "                    ec.append([time.mktime(dt.timetuple()),pt])\n",
        "                elif button=='D':\n",
        "                    ed.append([time.mktime(dt.timetuple()),pt])\n",
        "            except:\n",
        "                pass\n",
        "        return ea,eb,ec,ed\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "\n",
        "def get_nin_data(fname, varstring, segstart=0, segend=-1, data={}):\n",
        "    \"\"\"\n",
        "\n",
        "Read in a time-segment of data from NIN-M compatible (.nin) file. Use varstring=\n",
        "        'SRC' to get laser-on data,\n",
        "        'BKG' to get laser-off data,\n",
        "        'ACCE' for accelerometery data\n",
        "        'FORC' for force sensor\n",
        "        'TEMP' for temperature sensor\n",
        "        'EstG' for analog (8 channels of E*G) sensors\n",
        "        'NECG' for analog new-style (separate-ground) ECG\n",
        "segstart/segend are in seconds (-1=whole file)\n",
        "\n",
        "RETURNS: dictionary (can supply as input to append dictionary), timebase\n",
        "\"\"\"\n",
        "    # HANDLE EITHER .MAT OR .NIN FILES\n",
        "    if fname[-4:] in ['.edf','.bdf','.mat']:\n",
        "        fname = fname[:-4]+'.nin'\n",
        "\n",
        "    # OPEN FILE AND INITIALIZE DATA DICTIONARIES AS NEEDED\n",
        "    f = open(fname,'rb')\n",
        "    if 'SRC' in varstring or 'BKG' in varstring:\n",
        "        data = {}  # absolutely critical initialization, despite d={} in fcn\n",
        "        for src in range(NUMSRC):\n",
        "            data['src'+str(src)] = []\n",
        "    elif 'EstG' in varstring and len(varstring)==5:\n",
        "        data['EstG'] = []\n",
        "    else:\n",
        "        data[varstring] = []\n",
        "\n",
        "    # SET PROPER END-TIME DEFAULT, IF NEEDED\n",
        "    if segend==-1:\n",
        "        segend = 1000000  # 1 million seconds (plenty to cover whole file)\n",
        "\n",
        "    # START THE MAIN FILE-READING LOOP\n",
        "    s = b''         # holds raw BYTES data from file\n",
        "    pointer = 0     # tracks the \"current time in file\", in points (not sec)\n",
        "    targetlen = 0   # make sure this is pre-defined to avoid potential crash\n",
        "    while True:\n",
        "        # GET CHUNK OF BYTES FROM THE FILE\n",
        "        raw = f.read(CHUNKSIZE)\n",
        "\n",
        "        # END OF THE FILE YET?\n",
        "        if not raw:\n",
        "            break  # exit loop\n",
        "\n",
        "        # ADD CHUNK TO s FOR PROCESSING\n",
        "        s = s+raw\n",
        "\n",
        "        # IF PROCESSED 10000 BYTES AND STILL NO varstring, PARAMETER IS MISSING-->BAIL\n",
        "        if s.find(bytes(varstring,'utf-8'))==-1 and len(s)>10000:\n",
        "            # must not have this parameter in this datafile\n",
        "            break\n",
        "\n",
        "        # LOOP OVER BYTES IN s\n",
        "        while s:\n",
        "            # TRY TO FIND varstring IN s\n",
        "            if 'EstG' in varstring and len(varstring)==5:\n",
        "                idx = s.find(bytes(varstring[:-1],'utf-8'))\n",
        "                if idx==-1:\n",
        "                    break # no 'varstring' in this one, get a new chunk\n",
        "            else:\n",
        "                idx = s.find(bytes(varstring,'utf-8'))\n",
        "                if idx==-1:\n",
        "                    break # no 'varstring' in this one, get a new chunk\n",
        "\n",
        "            # START EXTRACTING DATA, DEPENDING ON varstring REQUESTED\n",
        "            if varstring in ['SRC0','SRC1','SRC2','SRC3','SRC4','SRC5','SRC6','SRC7',\n",
        "                             'BKG0','BKG1','BKG2','BKG3','BKG4','BKG5','BKG6','BKG7']:\n",
        "                if idx+4+8*2>len(s):\n",
        "                    break # not enough data to parse this one, get a new chunk\n",
        "                newdata = struct.unpack('<HHHHHHHH',s[idx+4:idx+4+8*2])\n",
        "                if (pointer/25.)>=segstart and (pointer/25.)<segend:\n",
        "                    sn = varstring[-1]\n",
        "                    data['src'+sn].append(newdata)\n",
        "                    pointer += 1\n",
        "                s = s[idx+4+8*2:]\n",
        "\n",
        "            elif varstring in ['SRC','BKG']:  # will be one or the other for the whole loop\n",
        "                if idx+4+8*2>len(s):\n",
        "                    break # not enough data to parse this one, get a new chunk\n",
        "                newdata = struct.unpack('<HHHHHHHH',s[idx+4:idx+4+8*2])\n",
        "                srcnum = chr(s[idx+3])\n",
        "                if (pointer/25.)>=segstart and (pointer/25.)<segend:\n",
        "                    try:\n",
        "                        data['src'+str(srcnum)].append(newdata)\n",
        "                    except:\n",
        "                        pass\n",
        "                if srcnum=='7': # is it SRC7?? (last one in a timeslice-->THEN increment)\n",
        "                    pointer += 1\n",
        "                s = s[idx+4+8*2:]\n",
        "\n",
        "            elif varstring=='ACCE':\n",
        "                if idx+4+3*2>len(s):\n",
        "                    break # not enough data to parse this one, get a new chunk\n",
        "                newdata = struct.unpack('<hhh',s[idx+4:idx+4+3*2])\n",
        "                #@@@ NOTE: need >hhh for other accel, but fix_accel() can byteswap\n",
        "                if pointer/250.>=segstart and pointer/250.<segend:\n",
        "                    data[varstring].append(newdata)\n",
        "                pointer += 1\n",
        "                s = s[idx+4+3*2:]\n",
        "\n",
        "            elif varstring=='GYRO':\n",
        "                if idx+4+3*2>len(s):\n",
        "                    break # not enough data to parse this one, get a new chunk\n",
        "                newdata = struct.unpack('<hhh',s[idx+4:idx+4+3*2])\n",
        "                if pointer/250.>=segstart and pointer/250.<segend:\n",
        "                    data[varstring].append(newdata)\n",
        "                pointer += 1\n",
        "                s = s[idx+4+3*2:]\n",
        "\n",
        "            elif varstring=='TEMP':\n",
        "                if idx+4+1*2>len(s):\n",
        "                    break # not enough data to parse this one, get a new chunk\n",
        "                newdata = struct.unpack('<H',s[idx+4:idx+4+1*2])\n",
        "                if pointer/25.>=segstart and pointer/25.<segend:\n",
        "                    data[varstring].append(newdata)\n",
        "                pointer += 1\n",
        "                s = s[idx+4+1*2:]\n",
        "\n",
        "            elif varstring=='FORC':\n",
        "                if idx+4+1*2>len(s):\n",
        "                    break # not enough data to parse this one, get a new chunk\n",
        "                newdata = struct.unpack('<H',s[idx+4:idx+4+1*2])\n",
        "                if pointer/25.>=segstart and pointer/25.<segend:\n",
        "                    data[varstring].append(newdata)\n",
        "                pointer += 1\n",
        "                s = s[idx+4+1*2:]\n",
        "\n",
        "            elif varstring=='RESP':\n",
        "                if idx+4+1*2>len(s):\n",
        "                    break # not enough data to parse this one, get a new chunk\n",
        "                newdata = struct.unpack('<H',s[idx+4:idx+4+1*2])\n",
        "                if pointer/25.>=segstart and pointer/25.<segend:\n",
        "                    data[varstring].append(newdata)\n",
        "                pointer += 1\n",
        "                s = s[idx+4+1*2:]\n",
        "\n",
        "            elif varstring=='NECG':\n",
        "                if idx+4+1*2>len(s):\n",
        "                    break # not enough data to parse this one, get a new chunk\n",
        "                newdata = struct.unpack('<H',s[idx+4:idx+4+1*2])\n",
        "                if pointer/25.>=segstart and pointer/25.<segend:\n",
        "                    data[varstring].append(newdata)\n",
        "                pointer += 1\n",
        "                s = s[idx+4+1*2:]\n",
        "\n",
        "            elif varstring=='AUXC':\n",
        "                if idx+4+8*2>len(s):\n",
        "                    break # not enough data to parse this one, get a new chunk\n",
        "                newdata = struct.unpack('<hhhhhhhh',s[idx+4:idx+4+8*2])\n",
        "                if pointer/250.>=segstart and pointer/250.<segend:\n",
        "                    data[varstring].append(newdata)\n",
        "                pointer += 1\n",
        "                s = s[idx+4+8*2:]\n",
        "\n",
        "            elif varstring=='EstG':\n",
        "                if idx+4+8*4>len(s):\n",
        "                    break # not enough data to parse this one, get a new chunk\n",
        "                tmp = []\n",
        "                # grab groups of 3 bytes (after 'EstG') and add on 00 or 80 byte at end (sign)\n",
        "                for i in range(8):\n",
        "                    tmp += struct.unpack('<i', s[idx+4+(i*3):idx+4+(i*3+3)] +(b'\\x00' if s[idx+4+(i*3+2)]<128 else b'\\xff'))\n",
        "                if pointer/250.>=segstart and pointer/250.<segend:\n",
        "                    data[varstring].append(tmp) #newdata)\n",
        "                pointer += 1\n",
        "                s = s[idx+4+8*4:]\n",
        "\n",
        "            elif varstring in ['EstG0','EstG1','EstG2','EstG3','EstG4','EstG5','EstG6','EstG7']:\n",
        "                if idx+4+8*4>len(s):\n",
        "                    break # not enough data to parse this one, get a new chunk\n",
        "                # grab groups of 3 bytes (after 'EstG') and add on 00 or 80 byte at end (sign)\n",
        "                i = int(varstring[-1])  # figure out which channel they want\n",
        "                tmp = struct.unpack('<i', s[idx+4+(i*3):idx+4+(i*3+3)] +(b'\\x00' if s[idx+4+(i*3+2)]<128 else b'\\xff'))\n",
        "                if pointer/250.>=segstart and pointer/250.<segend:\n",
        "                    data[varstring[:-1]].append(tmp)\n",
        "                pointer += 1\n",
        "                s = s[idx+4+8*4:]\n",
        "\n",
        "            # DETERMINE IF NEED TO READ IN MORE OR NOT\n",
        "            if varstring in ['SRC','BKG'] or 'SRC' in varstring or 'BKG' in varstring:\n",
        "                targetlen = pointer/25./8.\n",
        "            elif varstring in ['FORC','TEMP','RESP']:\n",
        "                targetlen = pointer/25.\n",
        "            elif varstring in ['EstG','ACCE','GYRO','NECG'] or 'EstG' in varstring:\n",
        "                targetlen = pointer/250.\n",
        "            if targetlen>=segend:\n",
        "                break\n",
        "\n",
        "        # CRASH OUT IF NO NEED TO READ THE FILE FURTHER\n",
        "        if targetlen>=segend:\n",
        "            break\n",
        "\n",
        "#    print \"On exit:\",data.keys()\n",
        "    # CONVERT ALL DATA TO ARRAYS BEFORE RETURNING\n",
        "    for key in list(data.keys()):\n",
        "        data[key] = np.array(data[key])\n",
        "#    print \"On return:\",data.keys()\n",
        "\n",
        "    # BUILD AN APPROPRIATE TIME-BASE\n",
        "    td = None\n",
        "    ta = None\n",
        "    if varstring in ['FORC','RESP','TEMP']:\n",
        "        td = np.arange(len(data[varstring]))/25.+segstart\n",
        "    elif varstring in ['SRC','BKG']:\n",
        "        td = np.arange(len(data['src0']))/25.+segstart\n",
        "    elif varstring in ['SRC0','SRC1','SRC2','SRC3','SRC4','SRC5','SRC6','SRC7',\n",
        "                       'BKG0','BKG1','BKG2','BKG3','BKG4','BKG5','BKG6','BKG7']:\n",
        "        td = np.arange(len(data['src'+varstring[-1]]))/25.+segstart\n",
        "    elif varstring in ['ACCE','GYRO','EstG','NECG']:\n",
        "        ta = np.arange(len(data[varstring]))/250.+segstart\n",
        "    elif 'EstG' in varstring:\n",
        "        ta = np.arange(len(data[varstring[:-1]]))/250.+segstart\n",
        "\n",
        "    if td is not None:\n",
        "        return data, td\n",
        "    elif ta is not None:\n",
        "        return data, ta\n",
        "    else:\n",
        "        return data, None\n",
        "\n",
        "\n",
        "def get_nin_nirs(fname,segstart=0,segend=-1,unwrapgain=1,trim=1,filt_param={},verbose=True):\n",
        "    \"\"\"\n",
        "\n",
        "Read in a time-segment of NIRS (only) data from a .NIN file.\n",
        "segstart/segend are in seconds (-1=whole file)\n",
        "\n",
        "RETURNS: td, diff, events, config, raw, bkgd\n",
        "\"\"\"\n",
        "    if segend==-1:\n",
        "        segend = 1000000  # 1 million seconds (plenty to cover whole file)\n",
        "\n",
        "    if fname[-4:] in ['.edf','.bdf','.mat']:\n",
        "        fname = fname[:-4]+'.nin'\n",
        "    if verbose: print(fname)\n",
        "\n",
        "    ### LOAD DATASETS\n",
        "    if verbose: print(\"  Getting header\")\n",
        "    h = get_nin_header(fname)\n",
        "    if verbose: print(\"  Getting events\")\n",
        "    events = get_nin_events(fname)\n",
        "    if verbose: print(\"  Getting config\")\n",
        "    config = get_nin_config(fname)\n",
        "    if verbose: print(\"  Getting SRC\")\n",
        "    raw,td = get_nin_data(fname,'SRC',segstart,segend)\n",
        "    if verbose: print(\"  Getting BKG\")\n",
        "    bkgd,jnk = get_nin_data(fname,'BKG',segstart,segend)\n",
        "    raw,bkgd = nin_nirsarray(raw,bkgd)\n",
        "\n",
        "    ### TRUNCATE ALL DATASETS TO CLEAN UP RIGHT EDGES\n",
        "    if trim:\n",
        "        if verbose: print(\"  Truncating to equal lengths\")\n",
        "        minlen = min([len(raw),len(bkgd)])\n",
        "        raw = raw[:minlen]\n",
        "        bkgd = bkgd[:minlen]\n",
        "    diff = raw-bkgd\n",
        "\n",
        "    ### UNWRAP GAINS IF REQUESTED\n",
        "    if unwrapgain:\n",
        "        diff = unwrap_gains(diff,config)\n",
        "\n",
        "    ### CLIP ANY NEG VALUES\n",
        "    diff = np.where(diff<10,10,diff)\n",
        "\n",
        "    ### FILTER IF REQUESTED\n",
        "    if filt_param:\n",
        "        if verbose:\n",
        "            print(\"  Filtering NIRS 'diff' data\")\n",
        "            print(\"    NIRS:\",filt_param['NIRS'])\n",
        "        diff = nin_filt_nirs(diff,filt_param['NIRS'],SLOWRATE)\n",
        "\n",
        "    # PUT FLAGS & FILT INTO INTO 'config'\n",
        "    config.update(h)\n",
        "    config['gainunwrapped'] = unwrapgain\n",
        "    config['filt_param'] = filt_param\n",
        "\n",
        "    return td, diff, events, config, raw, bkgd\n",
        "\n",
        "\n",
        "def get_nin_aux(fname,segstart=0,segend=-1,verbose=True):\n",
        "    \"\"\"\n",
        "\n",
        "Read in a time-segment of auxiliary data from a .NIN file.\n",
        "segstart/segend are in seconds (-1=whole file)\n",
        "\n",
        "RETURNS: dictionary with ACCE, TEMP, FORC, EstG, GYRO and/or RESP components, td, ta\n",
        "\"\"\"\n",
        "    if segend==-1:\n",
        "        segend = 1000000  # 1 million seconds (plenty to cover whole file)\n",
        "\n",
        "    if fname[-4:] in ['.edf','.bdf','.mat']:\n",
        "        fname = fname[:-4]+'.nin'\n",
        "\n",
        "    a = {}\n",
        "    for s in AUX_SIGNALS:\n",
        "        if s in ['BKGD','SRC','NIRS']:\n",
        "            continue\n",
        "        if verbose:\n",
        "            print(\"    Getting \",s)\n",
        "        if s in FAST_RAW_SIGNALS:\n",
        "            a,ta = get_nin_data(fname,s,segstart,segend,a)\n",
        "        else:\n",
        "            a,td = get_nin_data(fname,s,segstart,segend,a)\n",
        "    return a, ta, td\n",
        "\n",
        "\n",
        "def get (namepatterns,verbose=1):\n",
        "    \"\"\"\n",
        "Loads a list of lists from text files (specified by a UNIX-style\n",
        "wildcard filename pattern) and converts all numeric values to floats.\n",
        "Uses the glob module for filename pattern conversion.  Loaded filename\n",
        "is printed if verbose=1.\n",
        "\n",
        "Usage:   get (namepatterns,verbose=1)\n",
        "Returns: a 1D or 2D list of lists from whitespace delimited text files\n",
        "         specified by namepatterns; numbers that can be converted to floats\n",
        "         are so converted\n",
        "\"\"\"\n",
        "    fnames = []\n",
        "    if type(namepatterns) in [type(list),type(tuple)]:\n",
        "        for item in namepatterns:\n",
        "            fnames = fnames + glob.glob(item)\n",
        "    else:\n",
        "        fnames = glob.glob(namepatterns)\n",
        "\n",
        "    if len(fnames) == 0:\n",
        "        if verbose:\n",
        "            print('NO FILENAMES MATCH ('+namepatterns+') !!')\n",
        "        return None\n",
        "\n",
        "    if verbose:\n",
        "        print(fnames)             # so user knows what has been loaded\n",
        "    elements = []\n",
        "    for i in range(len(fnames)):\n",
        "        file = open(fnames[i])\n",
        "        newelements = list(map(str.split,file.readlines()))\n",
        "        for i in range(len(newelements)):\n",
        "            for j in range(len(newelements[i])):\n",
        "                try:\n",
        "                    newelements[i][j] = str.atoi(newelements[i][j])\n",
        "                except ValueError:\n",
        "                    try:\n",
        "                        newelements[i][j] = str.atof(newelements[i][j])\n",
        "                    except:\n",
        "                        pass\n",
        "        elements = elements + newelements\n",
        "    if len(elements)==1:  elements = elements[0]\n",
        "    return elements\n",
        "\n",
        "\n",
        "def load_iss_log(fname):\n",
        "    \"\"\"\n",
        "    Load data from ISS Imagent .log file\n",
        "    \"\"\"\n",
        "    d = get(fname)\n",
        "    h = d[0]\n",
        "    d = np.array(d[2:])\n",
        "    return h,d\n",
        "\n",
        "\n",
        "def load_iss(fname):\n",
        "    \"\"\"\n",
        "    Load data from ISS Imagent\n",
        "    \"\"\"\n",
        "    d = get(fname)\n",
        "\n",
        "    for i in range(len(d)):\n",
        "        if 'time' in d[i]:\n",
        "            break\n",
        "    h = d[i]\n",
        "    dd = []\n",
        "    for j in range(i+2,len(d)):\n",
        "        if len(d[j])>3:\n",
        "            dd.append(d[j])\n",
        "    dd = np.array(dd)\n",
        "    return h,dd\n",
        "\n",
        "\n",
        "def load_optiplex(fname):\n",
        "    \"\"\"\n",
        "    Load data from ISS OptiplexTS .txt file\n",
        "    \"\"\"\n",
        "    d = get(fname,verbose=False)\n",
        "\n",
        "    for i in range(len(d)):\n",
        "        if 'Time' in d[i][:2]:\n",
        "            break\n",
        "    h = d[:i]\n",
        "    cols = ['timestamp','elapsedtime',\n",
        "            'AC1_A','AC2_A','AC3_A','AC4_A','AC5_A','AC6_A','AC7_A','AC8_A',\n",
        "            'DC1_A','DC2_A','DC3_A','DC4_A','DC5_A','DC6_A','DC7_A','DC8_A',\n",
        "            'PH1_A','PH2_A','PH3_A','PH4_A','PH5_A','PH6_A','PH7_A','PH8_A',\n",
        "            'aux1','aux2','aux3','aux4','marker',\n",
        "            'AC1_B','AC2_B','AC3_B','AC4_B','AC5_B','AC6_B','AC7_B','AC8_B',\n",
        "            'DC1_B','DC2_B','DC3_B','DC4_B','DC5_B','DC6_B','DC7_B','DC8_B',\n",
        "            'PH1_B','PH2_B','PH3_B','PH4_B','PH5_B','PH6_B','PH7_B','PH8_B',\n",
        "           ]\n",
        "    dd = []\n",
        "    for j in range(i+1,len(d)):\n",
        "        if len(d[j])>3:\n",
        "            dd.append(d[j])\n",
        "    dd = np.array(dd)\n",
        "    df = pd.DataFrame(dd,columns=cols)\n",
        "    return h, df\n",
        "\n",
        "\n",
        "def plot_oxi_markers(t,m,color='k'):\n",
        "    # Plot markers from optiplex data format (column of time and column of 0s with non-zero markers\n",
        "    for i in range(len(t)):\n",
        "        if m[i]>0:\n",
        "            axvline(x=t[i],color=color)\n",
        "    return\n",
        "\n",
        "def plot_oxi(inp,figsize=(12,8),titletxt=''):\n",
        "    if type(inp)==type('string'):\n",
        "        h,dd = load_optiplex(inp)\n",
        "    else:\n",
        "        # assume it's a dataframe already\n",
        "        h,dd = inp\n",
        "    t = dd.elapsedtime\n",
        "    m = dd.marker\n",
        "    figure(figsize=figsize)\n",
        "    for i in range(1,9):\n",
        "        plot(dd.elapsedtime, dd['PH%i_A' %i],label=i)\n",
        "    plot_oxi_markers(t,m)\n",
        "    title('PHASE - '+titletxt)\n",
        "    legend()\n",
        "    figure(figsize=figsize)\n",
        "    for i in range(1,9):\n",
        "        plot(dd.elapsedtime, dd['AC%i_A' %i],label=i)\n",
        "    plot_oxi_markers(t,m)\n",
        "    title('AC - '+titletxt)\n",
        "    legend()\n",
        "    figure(figsize=figsize)\n",
        "    for i in range(1,9):\n",
        "        plot(dd.elapsedtime, dd['DC%i_A' %i],label=i)\n",
        "    plot_oxi_markers(t,m)\n",
        "    title('DC - '+titletxt)\n",
        "    legend()\n",
        "    return h,dd\n",
        "\n",
        "\n",
        "def load_nin(fname,segstart=0,segend=-1,trim=1,keepraw=1,unwrapgain=1,verbose=False):\n",
        "    \"\"\"\n",
        "\n",
        "Load in a time-segment of ALL data from a NIN-M recording.\n",
        "\n",
        "RETURNS: a, td, ta, events, config\n",
        "\"\"\"\n",
        "    if fname[-4:] in ['.edf','.bdf','.mat']:\n",
        "        fname = fname[:-4]+'.nin'\n",
        "    if verbose: print(fname)\n",
        "\n",
        "    ### LOAD DATASETS\n",
        "    if verbose: print(\"  Getting header\")\n",
        "    h = get_nin_header(fname)\n",
        "    if verbose: print(\"  Getting events\")\n",
        "    events = get_nin_events(fname)\n",
        "    if verbose: print(\"  Getting config\")\n",
        "    config = get_nin_config(fname)\n",
        "    if verbose: print(\"  Getting SRC\")\n",
        "    n,td = get_nin_data(fname,'SRC',segstart,segend)\n",
        "    if verbose: print(\"  Getting BKG\")\n",
        "    b,jnk = get_nin_data(fname,'BKG',segstart,segend)\n",
        "    n,b = nin_nirsarray(n,b)\n",
        "    if verbose: print(\"  Getting auxiliary\")\n",
        "    a,ta,jnk = get_nin_aux(fname,segstart,segend,verbose=verbose)\n",
        "    for k in list(a.keys()):\n",
        "        if len(a[k])==0:\n",
        "            a.pop(k)\n",
        "\n",
        "    ### TACK NIRS DATA ONTO DICTIONARY\n",
        "    a['SRC'] = n\n",
        "    a['BKGD'] = b\n",
        "\n",
        "    ### TRUNCATE ALL DATASETS TO CLEAN UP RIGHT EDGES\n",
        "    if trim:\n",
        "        if verbose: print(\"  Truncating to equal lengths\")\n",
        "        a, td, ta = trim_data(a,segstart=segstart,verbose=verbose)\n",
        "    else:\n",
        "        a['NIRS'] = n-b\n",
        "\n",
        "    ### REMOVE RAW DATA IF REQUESTED\n",
        "    config['keepraw'] = keepraw\n",
        "    if not keepraw:\n",
        "        a.pop('SRC')\n",
        "        a.pop('BKGD')\n",
        "\n",
        "    ### CLIP ANY NEG/SMALL VALUES; DO THIS //BEFORE// UNWRAP GAINS\n",
        "    a['NIRS'] = np.where(a['NIRS']<10,10,a['NIRS'])\n",
        "\n",
        "    ### PUT HEADER INTO INTO CONFIG\n",
        "    config.update(h)\n",
        "    config['gainunwrapped'] = 0\n",
        "\n",
        "    return a, td, ta, events, config\n",
        "\n",
        "\n",
        "def load_aux(fname,segstart=0,segend=-1,unwrapgain=1,filt_param={},trim=1,verbose=0):\n",
        "    \"\"\"\n",
        "\n",
        "Load in a time-segment of ALL data from a NIN-M recording.\n",
        "\n",
        "RETURNS: ta, aux, eventsA_D, config\n",
        "\"\"\"\n",
        "    if fname[-4:] in ['.edf','.bdf','.mat']:\n",
        "        fname = fname[:-4]+'.nin'\n",
        "    if verbose: print(fname)\n",
        "\n",
        "    ### LOAD DATASETS\n",
        "    if verbose: print(\"  Getting header\")\n",
        "    h = get_nin_header(fname)\n",
        "    if verbose: print(\"  Getting events\")\n",
        "    events = get_nin_events(fname)\n",
        "    if verbose: print(\"  Getting config\")\n",
        "    config = get_nin_config(fname)\n",
        "    if verbose: print(\"  Getting auxiliary\")\n",
        "    a,ta,jnk = get_nin_aux(fname,segstart,segend)\n",
        "    for k in a.keys():\n",
        "        if len(a[k])==0:\n",
        "            a.pop(k)\n",
        "\n",
        "    ### TRUNCATE ALL DATASETS TO CLEAN UP RIGHT EDGES\n",
        "    if trim:\n",
        "        if verbose: print(\"  Truncating to equal lengths\")\n",
        "        a, ta = trim_aux(None,None,a,segstart=segstart)\n",
        "\n",
        "    # PUT FLAGS & FILT INTO INTO 'config'\n",
        "    config.update(h)  # stick header info into config dict\n",
        "    config['trim'] = trim\n",
        "    config['gainunwrapped'] = unwrapgain\n",
        "    config['filt_param'] = filt_param\n",
        "\n",
        "    return a, ta, events, config\n",
        "\n",
        "\n",
        "def load_estg(fname,segstart=0,segend=-1,unwrapgain=1,filt_param={},trim=1,verbose=0):\n",
        "    \"\"\"\n",
        "\n",
        "Load in a time-segment of ALL E*G data from a NIN-M recording.\n",
        "\n",
        "RETURNS: ta, aux, eventsA_D, config\n",
        "\"\"\"\n",
        "    if fname[-4:] in ['.edf','.bdf','.mat']:\n",
        "        fname = fname[:-4]+'.nin'\n",
        "    if verbose: print(fname)\n",
        "\n",
        "    ### LOAD DATASETS\n",
        "    if verbose: print(\"  Getting header\")\n",
        "    h = get_nin_header(fname)\n",
        "    if verbose: print(\"  Getting events\")\n",
        "    events = get_nin_events(fname)\n",
        "    if verbose: print(\"  Getting config\")\n",
        "    config = get_nin_config(fname)\n",
        "    if verbose: print(\"  Getting auxiliary\")\n",
        "    a,ta = get_nin_data(fname,'EstG',segstart,segend)\n",
        "    for k in a.keys():\n",
        "        if len(a[k])==0:\n",
        "            a.pop(k)\n",
        "\n",
        "    ### TRUNCATE ALL DATASETS TO CLEAN UP RIGHT EDGES\n",
        "    if trim:\n",
        "        if verbose: print(\"  Truncating to equal lengths\")\n",
        "        a, ta = trim_aux(a,segstart,ta)\n",
        "\n",
        "    # PUT FLAGS & FILT INTO INTO 'config'\n",
        "    config.update(h)  # stick header info into config dict\n",
        "    config['trim'] = trim\n",
        "    config['gainunwrapped'] = unwrapgain\n",
        "    config['filt_param'] = filt_param\n",
        "\n",
        "    return a, ta, events, config\n",
        "\n",
        "\n",
        "def load_ecg(fname,segstart=0,segend=-1,unwrapgain=1,filt_param={},trim=1,verbose=0):\n",
        "    \"\"\"\n",
        "\n",
        "Load in a time-segment of ECG data from a NIN-v4 recording.\n",
        "\n",
        "RETURNS: ta, ecg, eventsA_D, config\n",
        "\"\"\"\n",
        "    if fname[-4:] in ['.edf','.bdf','.mat']:\n",
        "        fname = fname[:-4]+'.nin'\n",
        "    if verbose: print(fname)\n",
        "\n",
        "    ### LOAD DATASETS\n",
        "    if verbose: print(\"  Getting header\")\n",
        "    h = get_nin_header(fname)\n",
        "    if verbose: print(\"  Getting events\")\n",
        "    events = get_nin_events(fname)\n",
        "    if verbose: print(\"  Getting config\")\n",
        "    config = get_nin_config(fname)\n",
        "    if verbose: print(\"  Getting auxiliary\")\n",
        "    a,ta = get_nin_data(fname,'ECG',segstart,segend)\n",
        "    for k in a.keys():\n",
        "        if len(a[k])==0:\n",
        "            a.pop(k)\n",
        "\n",
        "    ### TRUNCATE ALL DATASETS TO CLEAN UP RIGHT EDGES\n",
        "    if trim:\n",
        "        if verbose: print(\"  Truncating to equal lengths\")\n",
        "        a, ta = trim_aux(a,segstart,ta)\n",
        "\n",
        "    # PUT FLAGS & FILT INTO INTO 'config'\n",
        "    config.update(h)  # stick header info into config dict\n",
        "    config['trim'] = trim\n",
        "    config['gainunwrapped'] = unwrapgain\n",
        "    config['filt_param'] = filt_param\n",
        "\n",
        "    return a, ta, events, config\n",
        "\n",
        "\n",
        "###################### CONVERSION FUNCTIONS ########################\n",
        "\n",
        "def nin_nirsarray(n,b):\n",
        "    \"\"\"\n",
        "\n",
        "Convert raw-read NIRS data (SRC or BKG) from dictionaries to two 8x8 arrays.\n",
        "\n",
        "RETURNS: raw, bkgd (numpy arrays, TIME x 64 CHANNELS)\n",
        "\"\"\"\n",
        "    ### CONVERT NIRS FROM DICTIONARIES TO TWO 8X8 ARRAYS\n",
        "    lngn = []\n",
        "    lngb = []\n",
        "    for k in list(b.keys()): # find the length of the shortest (probably src7, but could be another)\n",
        "        lngn.append(n[k].shape[0])\n",
        "        lngb.append(b[k].shape[0])\n",
        "    lng = min(lngn+lngb)\n",
        "    raw = np.concatenate((n['src0'][:lng],n['src1'][:lng]),1)\n",
        "    bkgd = np.concatenate((b['src0'][:lng],b['src1'][:lng]),1)\n",
        "    for i in range(2,8):\n",
        "        raw = np.concatenate((raw,n['src'+str(i)][:lng]),1)\n",
        "        bkgd = np.concatenate((bkgd,b['src'+str(i)][:lng]),1)\n",
        "    return raw, bkgd\n",
        "\n",
        "\n",
        "def trim_data(a,td=None,ta=None,segstart=0,verbose=False):\n",
        "    \"\"\"\n",
        "\n",
        "Trim off tail ends of some data so everything aligns, in 2 clumps:\n",
        "    25Hz signals = raw, bkgd, diff, a['TEMP'], a['FORC'], a['RESP']\n",
        "    250Hz signals = a['EstG'], a['ACCE'], a['GYRO']\n",
        "\n",
        "RETURNS: a, td, ta ... with TIME dimensions truncated to same-length\n",
        "\"\"\"\n",
        "    # DEAL WITH FAST-RATE DATA\n",
        "#    print 'a:', a.keys()\n",
        "    all_len = []\n",
        "    if verbose: print(\"  BEFORE ...\")\n",
        "#    print a.keys()\n",
        "    for key in FAST_RAW_SIGNALS:\n",
        "        if key not in a:\n",
        "            continue\n",
        "        if verbose: print(\"    \",key,len(a[key]))\n",
        "        ln = len(a[key])\n",
        "        if ln>10:\n",
        "            all_len.append(len(a[key]))\n",
        "        else:\n",
        "            if verbose: print(\"    REMOVING ...\",key)\n",
        "            a.pop(key,None)\n",
        "    minlen = min(all_len)\n",
        "    if verbose: print(\"  AFTER ...\")\n",
        "    for key in FAST_RAW_SIGNALS:\n",
        "        if key not in a:\n",
        "            continue\n",
        "        a[key] = a[key][:minlen]\n",
        "        if verbose: print(\"    \",key,len(a[key]))\n",
        "    if ta is None:\n",
        "        ta = np.arange(minlen)/float(FASTRATE)+segstart\n",
        "    else:\n",
        "        ta = ta[:minlen]\n",
        "\n",
        "    # SECOND DEAL WITH SLOW-RATE DATA\n",
        "    if verbose: print(\"  BEFORE ...\")\n",
        "    for key in SLOW_RAW_SIGNALS:\n",
        "#        print key,a.has_key(key)\n",
        "        if key not in a:\n",
        "            continue\n",
        "        if verbose: print(\"    \",key,len(a[key]))\n",
        "        if ln>10:\n",
        "            all_len.append(len(a[key]))\n",
        "        else:\n",
        "            if verbose: print(\"    REMOVING ...\",key)\n",
        "            a.pop(key,None)\n",
        "    minlen = min(all_len)\n",
        "    if verbose: print(\"  AFTER ...\")\n",
        "    for key in SLOW_RAW_SIGNALS:\n",
        "        if a is not None:\n",
        "            if key not in a:\n",
        "                continue\n",
        "            a[key] = a[key][:minlen]\n",
        "            if verbose: print(\"    \",key,len(a[key]))\n",
        "\n",
        "    if 'SRC' in a and 'BKGD' in a:\n",
        "        a['NIRS'] = a['SRC']-a['BKGD']\n",
        "\n",
        "    if td is None:\n",
        "        td = np.arange(minlen)/float(SLOWRATE)+segstart\n",
        "    else:\n",
        "        td = td[:minlen]\n",
        "\n",
        "    return a, td, ta\n",
        "\n",
        "\n",
        "def trim_aux(a,ta=None,segstart=0,verbose=True):\n",
        "    \"\"\"\n",
        "\n",
        "Clean up tail end of AUXILIARY data so everything aligns:\n",
        "    25Hz signals = a['TEMP'], a['FORC'], a['RESP']\n",
        "    250Hz signals = a['EstG'], a['ACCE'], a['GYRO']\n",
        "\n",
        "RETURNS: a, td, ta ... with TIME dimension truncated to same-length\n",
        "\"\"\"\n",
        "    print(\"pre-trim_aux():\", list(a.keys()))\n",
        "    # FIRST DEAL WITH FAST-RATE DATA\n",
        "    all_len = []\n",
        "    if verbose: print(\"  BEFORE ...\")\n",
        "    for key in FAST_RAW_SIGNALS:\n",
        "        if key not in a:\n",
        "            continue\n",
        "        if verbose: print(\"    \",key,len(a[key]))\n",
        "        ln = len(a[key])\n",
        "        if ln>10:\n",
        "            all_len.append(len(a[key]))\n",
        "        else:\n",
        "            if verbose: print(\"    REMOVING ...\",key)\n",
        "            a.pop(key,None)\n",
        "    minlen = min(all_len)\n",
        "    if verbose: print(\"  AFTER ...\")\n",
        "    for key in FAST_RAW_SIGNALS:\n",
        "        if key not in a:\n",
        "            continue\n",
        "        a[key] = a[key][:minlen]\n",
        "        if verbose: print(\"    \",key,len(a[key]))\n",
        "    if ta is None:\n",
        "        ta = np.arange(minlen)/float(FASTRATE)+segstart\n",
        "    else:\n",
        "        ta = ta[:minlen]\n",
        "\n",
        "    # SECOND DEAL WITH SLOW-RATE DATA\n",
        "    slowtocheck = ['FORC','TEMP']\n",
        "    all_len = []\n",
        "    if verbose: print(\"  BEFORE ...\")\n",
        "    for key in SLOW_RAW_SIGNALS:\n",
        "        if key not in a:\n",
        "            continue\n",
        "        if verbose: print(\"    \",key,len(a[key]))\n",
        "        if ln>10:\n",
        "            all_len.append(len(a[key]))\n",
        "        else:\n",
        "            if verbose: print(\"    REMOVING ...\",key)\n",
        "            a.pop(key,None)\n",
        "    print(all_len)\n",
        "    if len(all_len)>0:\n",
        "        minlen = min(all_len)\n",
        "        if verbose: print(\"  AFTER ...\")\n",
        "        for key in slowtocheck:\n",
        "            if key not in a:\n",
        "                continue\n",
        "            a[key] = a[key][:minlen]\n",
        "            if verbose: print(\"    \",key,len(a[key]))\n",
        "\n",
        "    print(\"post-trim_aux():\", list(a.keys()))\n",
        "    return a, ta\n",
        "\n",
        "\n",
        "def unwrap_gains(d,config):\n",
        "    \"\"\"\n",
        "\n",
        "Unwrap gain settings from array 'd', given ProbeGains and BoardGains in 'config'..\n",
        "\n",
        "RETURNS: d (TIME x 64 CHANNELS, with signals adjusted for gains)\n",
        "\"\"\"\n",
        "    d = d.astype('float')\n",
        "    for src in range(8):\n",
        "        for det in range(8):\n",
        "            d[:,src*8+det] = d[:,src*8+det] / (ProbeGains[config['PROBEgain'][src,det]] *\n",
        "                                               BoardGains[config['BOARDgain'][src,det]])\n",
        "    config['gainunwrapped'] = 1\n",
        "    return d, config\n",
        "\n",
        "\n",
        "def nin_unwrap_gains(a,config):\n",
        "    \"\"\"\n",
        "\n",
        "Unwrap gain settings from NIRS 'diff' (raw-bkgd) data.\n",
        "\n",
        "RETURNS: d (TIME x 64 CHANNELS, with signals adjusted for gains)\n",
        "\"\"\"\n",
        "    keys = ['NIRS']\n",
        "    if config['keepraw']==True:\n",
        "        keys = keys + ['SRC','BKGD']\n",
        "\n",
        "    for k in keys:\n",
        "        d = a[k].astype('float')\n",
        "        for src in range(8):\n",
        "            for det in range(8):\n",
        "                d[:,src*8+det] = d[:,src*8+det] / (ProbeGains[config['PROBEgain'][src,det]] *\n",
        "                                                   BoardGains[config['BOARDgain'][src,det]])\n",
        "    config['gainunwrapped'] = 1\n",
        "    return a, config\n",
        "\n",
        "\n",
        "def fix_accel(a):\n",
        "    \"\"\"\n",
        "\n",
        "Swaps byte-order for a['ACCE']. IN-PLACE operation (no return value)\n",
        "\n",
        "RETURNS: nothing (fixes a['ACCE'] in-place)\n",
        "\"\"\"\n",
        "    a['ACCE'] = a['ACCE'].newbyteorder()\n",
        "    # no need to return, as it fixes in-place (given there's no copy here)\n",
        "\n",
        "\n",
        "def nin_convert_aux(a,EstGgains=[],acc=200,force='forc'):\n",
        "    \"\"\"\n",
        "\n",
        "Apply unit-conversions to raw auxiliary data.\n",
        "\n",
        "USAGE:   a = auxiliary data dict (from get_nin_aux)\n",
        "         gains comes from config['EstGgain']\n",
        "         acc={16,200} for the +/-16g or +/-200g accel\n",
        "         force={'forc','resp'} for which one is attached\n",
        "RETURNS: ac (new dictionary with converted-units data)\n",
        "\"\"\"\n",
        "    ac = {}\n",
        "    if acc==0:\n",
        "        # DON'T CONVERT ANYTHING!!\n",
        "        ac = a\n",
        "    else:\n",
        "        for k in a.keys():\n",
        "            if k=='ACCE':\n",
        "    #            ac[k] = np.where(a[k]<4095,a[k]*0.0039,0)\n",
        "    #            ac[k] = np.where(a[k]>4095,(a[k]-8192)*0.0039,ac[k])\n",
        "                if acc==16:\n",
        "                    ac[k] = a[k].astype(np.float) *49/ 25. /256. /1.9  # 49 mg/bit; @@@1.9=fudge\n",
        "                elif acc==200:\n",
        "                    #@@@gotta reverse this one\n",
        "                    fix_accel(a) #tmp = a[k].newbyteorder()\n",
        "                    ac[k] = a[k].astype(np.float) *3.9/1000. /256.  # 3.9 mg/bit\n",
        "            elif k==\"FORC\":\n",
        "                ac[k] = a[k].astype(np.float) *0.00061   # mV; 0.61 mV/bit\n",
        "                ac[k] = ac[k] *2.0/0.055   # empirically (2015-0914-115727.txt), 2kg-->0.055mV signal\n",
        "            elif k=='GYRO':\n",
        "                ac[k] = a[k].astype(np.float) *70 /1000.   # 70 mdeg/digit --> conv. to degrees\n",
        "            elif k==\"RESP\":\n",
        "                ac[k] = a[k].astype(np.float) #@@@ no conversion for now\n",
        "            elif k==\"TEMP\":\n",
        "                ac[k] = a[k].astype(np.float) /256.      # deg C; 0.25 deg C/bit\n",
        "            elif k==\"EstG\":\n",
        "                ac[k] = a[k]*1.0\n",
        "                if len(EstGgains):\n",
        "                    for i in range(8):\n",
        "                        ac[k][:,i] = ac[k][:,i] *0.53644/EstGgains[i]  # uV\n",
        "            else:  # @@@i.e., RESP or NECG or anything else\n",
        "                ac[k] = a[k].astype(np.float) #@@@ no conversion for now\n",
        "    return ac\n",
        "\n",
        "\n",
        "def nin_convert(a,config,unwrapgain=False,acceltype=200,force='forc',notchfilt=[],filt_param=DEFAULTfilt_param,verbose=True):\n",
        "    \"\"\"\n",
        "\n",
        "Function to unwrap gain, convert aux to SI units, and/or filter, as requested.\n",
        "\n",
        "USAGE:   a = data dict\n",
        "         config = configuration info, updated by this function\n",
        "         unwrapgain = correct for gain settings or not?\n",
        "         acc = {16,200} for the +/-16g or +/-200g accel; ignores any other values\n",
        "         force = {'forc','resp'} for which one is attached\n",
        "         notch = ['NIRS','EstG'] ... dict keys where 60&120Hz notch filters should be applied\n",
        "         filt_param = dictionary entries like {'NIRS':[lpf,hpf]}\n",
        "RETURNS: updated a, updated config\n",
        "\"\"\"\n",
        "    ac = {}\n",
        "\n",
        "    ### UNWRAP GAINS IF REQUESTED /and/ NEEDED\n",
        "    if unwrapgain:\n",
        "        if config['gainunwrapped']==False:\n",
        "            ac,config = nin_unwrap_gains(a,config)\n",
        "    else:  # otherwise, just copy over the source data\n",
        "        ac['NIRS'] = a['NIRS']\n",
        "        if config['keepraw']==True:\n",
        "            ac['SRC'] = a['SRC']\n",
        "            ac['BKGD'] = a['BKGD']\n",
        "\n",
        "    ### CONVERT AUX CHANNELS TO SI-ish UNITS, IF REQUESTED\n",
        "    auxc = nin_convert_aux(a,acc=acceltype,force=force)\n",
        "    ac.update(auxc)\n",
        "\n",
        "    ### NOTCH-FILTER IF REQUESTED\n",
        "    if len(notchfilt):\n",
        "        for k in notchfilt:\n",
        "            if verbose:\n",
        "                print(\"NOTCH-FILTERING ...\",k)\n",
        "            ac[k] = notch(ac[k])\n",
        "\n",
        "    ### FILTER IF REQUESTED\n",
        "    if filt_param:\n",
        "        if verbose:\n",
        "            print(\"FILTERING DATA ...\")\n",
        "        ac = nin_filt_all(ac,filt_param,verbose)\n",
        "\n",
        "    ### UPDATE FLAGS & FILT IN 'config'\n",
        "    config['gainunwrapped'] = unwrapgain\n",
        "    config['filt_param'] = filt_param\n",
        "    config['acceltype'] = acceltype\n",
        "    config['notch'] = notchfilt\n",
        "\n",
        "    return ac, config\n",
        "\n",
        "\n",
        "def nin_makeOD(data,baseline=None):\n",
        "    \"\"\"\n",
        "\n",
        "Compute optical density using baseline period ...where data = (TIME x CHAN)\n",
        "and baseline = None (use entire dataset); DEFAULT\n",
        "             = integer (number-of-points to use from start-of-recording)\n",
        "             = 1D list of indices into data to use\n",
        "             = 2D array of data used to calc mean for each channel\n",
        "\n",
        "RETURNS: ODdata\n",
        "\"\"\"\n",
        "    if baseline == None:\n",
        "        baseline = np.mean(data,0)\n",
        "    elif type(baseline)==IntType:\n",
        "        baseline = np.mean(data[:baseline],0)\n",
        "    elif type(baseline)==type(list):  # must be indices\n",
        "        baseline = np.mean(data[baseline],0)\n",
        "    elif len(baseline.shape) == 2:  # must be data\n",
        "        baseline = np.mean(baseline,0)\n",
        "    else:\n",
        "        print(\"Not appropriate size/shape for baseline in makeOD\")\n",
        "        return\n",
        "\n",
        "    # now calculate OD\n",
        "    normalized_fluence = (1./baseline)*data\n",
        "    ODdata = -np.log(normalized_fluence)\n",
        "\n",
        "    return ODdata\n",
        "\n",
        "\n",
        "def nin_od2hbhbo(od, wavelengths=DEFAULTwavelengths, BLs=[6,6]):\n",
        "    \"\"\"\n",
        "\n",
        "Convert NIN optical-density data to deoxy/oxy-hemoglobin concentrations.\n",
        "\n",
        "RETURNS: hbhbos, hbhboml ... hbhbos=TIMEx[HHb,O2Hb], hbhboml=measurement list for hbhbos\n",
        "\"\"\"\n",
        "    hbhbos = []\n",
        "    hbhboml = []\n",
        "    for src in [0,2,4,6]:\n",
        "        for det in range(8):\n",
        "            # next line steps by 8 to get src*8+det and (src+1)*8+det only\n",
        "            hbhbos.append(od2hbhbo_bls(od[:,src*8+det:(src+2)*8+det:8],wavelengths, BLs))\n",
        "            hbhboml.append([src,det])\n",
        "    hbhbos = np.array(hbhbos)\n",
        "    hbhbos = np.transpose(hbhbos,[2,1,0])\n",
        "    hbhboml = np.array(hbhboml)\n",
        "    return hbhbos, hbhboml\n",
        "\n",
        "\n",
        "\n",
        "###################### ANALYSIS TOOLS ########################\n",
        "\n",
        "def easyavg(d,t,onsets,preseconds=-5,postseconds=25):\n",
        "    \"\"\"\n",
        "Chops up d into chunks based on onset times and the size of\n",
        "the chunk (pre- and post-onset time) you request. Flattens the onset\n",
        "list, if it is 2D(!!).\n",
        "\n",
        "Usage:   easyavg(d,t,onsets,preseconds=-5,postseconds=25)\n",
        "Returns: avgd, avgt\n",
        "\"\"\"\n",
        "    rate = 1./(t[1]-t[0])\n",
        "\n",
        "    ravelonsets = []\n",
        "    for item in onsets:\n",
        "        if type(item) in [type(list),type(tuple)]:\n",
        "            ravelonsets += item\n",
        "        else:\n",
        "            ravelonsets += [item]\n",
        "    onsets = np.array(ravelonsets)-t[0]\n",
        "    onsetindices = np.round(onsets*rate).astype(np.int)  # convert to points\n",
        "\n",
        "    prepoints = np.int(abs(preseconds)*rate)\n",
        "    postpoints = np.int(postseconds*rate)\n",
        "    totalpoints = prepoints+postpoints\n",
        "    outdata = []     #np.zeros(totalpoints,d.shape[1]);\n",
        "    for i in range(len(onsetindices)):\n",
        "        if (onsetindices[i]-prepoints>0) and (onsetindices[i]+postpoints<d.shape[0]):\n",
        "            cut = d[onsetindices[i]-prepoints:onsetindices[i]+postpoints,:]\n",
        "            outdata.append(cut)\n",
        "    N = len(outdata)\n",
        "    outdata = np.array(outdata)\n",
        "    outt = np.arange(totalpoints)/float(rate) -abs(preseconds)\n",
        "\n",
        "    return outt, outdata\n",
        "\n",
        "\n",
        "def pulsatility(d,rate=250,hpf=0,refractory=0.33,plotit=False):\n",
        "    \"\"\"\n",
        "\n",
        "Compute simple pulsatility index = (peak-trough). Refractory param is the\n",
        "minimum number of seconds between final-output peaks (and troughs).\n",
        "\n",
        "RETURNS: peak-minus-trough-pulsatility,px,pxval,tx,txval (where p=peaks, t=troughs)\n",
        "\"\"\"\n",
        "    # FIND PEAKS & TROUGHS OF HEARTBEATS\n",
        "    print(\"Finding peaks ...\")\n",
        "    px, pxval = o.findpeaks(d,rate,fhp=hpf,flp=0,posneg=1)  # pos peaks\n",
        "    tx, txval = o.findpeaks(d,rate,fhp=hpf,flp=0,posneg=-1) # neg peaks\n",
        "\n",
        "    # IDENTIFY EXTRA-SHORT PEAK/TROUGH INTERVALS\n",
        "    delpidx = []\n",
        "    for i in range(len(px)-1,0,-1):\n",
        "#        print px[i], px[i-1]\n",
        "        if (px[i]-px[i-1])<refractory*rate:\n",
        "            delpidx.append(i)\n",
        "    deltidx = []\n",
        "    for i in range(len(tx)-1,0,-1):\n",
        "        if (tx[i]-tx[i-1])<refractory*rate:\n",
        "            deltidx.append(i)\n",
        "\n",
        "    # PRUNE-OUT EXTRA-SHORT PEAK/TROUGH INTERVALS\n",
        "    px = px.tolist()\n",
        "    pxval = pxval.tolist()\n",
        "    for item in delpidx:\n",
        "        del px[item]\n",
        "        del pxval[item]\n",
        "    tx = tx.tolist()\n",
        "    txval = txval.tolist()\n",
        "    for item in deltidx:\n",
        "        del tx[item]\n",
        "        del txval[item]\n",
        "\n",
        "    # TRIM FINAL LIST OF PEAKS/TROUGHS TO SHORTEST LENGTH\n",
        "    minp = min(len(px),len(tx))\n",
        "    px = px[:minp]\n",
        "    pxval = pxval[:minp]\n",
        "    tx = tx[:minp]\n",
        "    txval = txval[:minp]\n",
        "\n",
        "    px = np.array(px)\n",
        "    tx = np.array(tx)\n",
        "    pxval = np.array(pxval)\n",
        "    txval = np.array(txval)\n",
        "\n",
        "    # COMPUTE SIMPLE PULSATILITY\n",
        "    P = pxval-txval\n",
        "\n",
        "    if plotit:\n",
        "        figure()\n",
        "        denom = float(rate)\n",
        "        t = np.arange(len(d))/denom\n",
        "        plot(t,hipass(d,hpf,rate))\n",
        "        plot(px/denom,pxval,'rx')\n",
        "        plot(tx/denom,txval,'bx')\n",
        "\n",
        "    return P,px,pxval,tx,txval\n",
        "\n",
        "\n",
        "def pulsatility2(d,rate=250,period_sec=[0.33,2.0],extrafilt=0,plotit=False):\n",
        "    \"\"\"\n",
        "NOT FUNCTIONAL YET\n",
        "Compute simple pulsatility index = (peak-trough). Refractory param is the\n",
        "minimum number of seconds between final-output peaks (and troughs).\n",
        "Extrafilt = integer number of *extra* times to apply the bandpass filter (more smoothing)\n",
        "\n",
        "RETURNS: peak-minus-trough-pulsatility,px,pxval,tx,txval (where p=peaks, t=troughs)\n",
        "\"\"\"\n",
        "    rate = float(rate)\n",
        "    # BANDPASS SIGNAL TO APPROPRIATE RANGE\n",
        "    freq = [1.0/period_sec[1], 1.0/period_sec[0]]\n",
        "    df = bandpass(d,freq=freq,order=4,samplerate=rate,verbose=False)\n",
        "    for i in range(extrafilt):\n",
        "        df = bandpass(df,freq=freq,order=4,samplerate=rate,verbose=False)\n",
        "\n",
        "    plot(df)\n",
        "    # FIND PEAKS & TROUGHS IN REQUESTED BAND\n",
        "    print(\"Finding peaks ...\")\n",
        "    px, pxval = o.findpeaks(df,rate,fhp=0,flp=0,posneg=1)  # pos peaks\n",
        "    tx, txval = o.findpeaks(df,rate,fhp=0,flp=0,posneg=-1) # neg peaks\n",
        "\n",
        "    if len(px)==0 or len(tx)==0:\n",
        "        print(len(px), len(tx))\n",
        "        return [],[],[],[],[]\n",
        "\n",
        "    # MAKE SURE YOU'RE STARTING WITH A PEAK (CHOP OFF ANY EXTRA LEADING TROUGHS\n",
        "    while px[0]>tx[0]:\n",
        "        tx = tx[1:]\n",
        "        txval = txval[1:]\n",
        "\n",
        "    # TRIM FINAL LIST OF PEAKS/TROUGHS TO SHORTEST LENGTH\n",
        "    minp = min(len(px),len(tx))\n",
        "    px = px[:minp]\n",
        "    pxval = pxval[:minp]\n",
        "    tx = tx[:minp]\n",
        "    txval = txval[:minp]\n",
        "\n",
        "    # COMPUTE SIMPLE PULSATILITY\n",
        "    P = pxval-txval\n",
        "\n",
        "    if plotit:\n",
        "        figure()\n",
        "        title(plotit)\n",
        "        rate = float(rate)\n",
        "        t = np.arange(len(d))/rate\n",
        "        plot(t,df)\n",
        "        plot(px/rate,pxval,'rx')\n",
        "        plot(tx/rate,txval,'bx')\n",
        "\n",
        "    return P,px,pxval,tx,txval\n",
        "\n",
        "\n",
        "def cardiac_pulsatility(rawd,rate=25,period_sec=[0.38,2.0],plotit=False):\n",
        "    return pulsatility2(d,rate,period_sec=period_sec,plotit=plotit)\n",
        "\n",
        "\n",
        "def mayer_pulsatility(rawd,t,rate=25,period_sec=[7,13],plotit=False):\n",
        "    return pulsatility2(d,rate,period_sec=period_sec,plotit=plotit)\n",
        "\n",
        "\n",
        "def GPI(d,rate=250):\n",
        "    \"\"\"\n",
        "\n",
        "Compute Gosling pulsatility index = (peak-trough)/((peak+trough)/2)\n",
        "\n",
        "RETURNS: Gosling_PI value\n",
        "\"\"\"\n",
        "    # FIND PEAKS & TROUGHS OF HEARTBEATS\n",
        "    print(\"Finding peaks ...\")\n",
        "    px, pxval = o.findpeaks(d,rate,0,0,1)  # no filtering, pos peaks\n",
        "    tx, txval = o.findpeaks(d,rate,0,0,-1) # no filtering, neg peaks\n",
        "\n",
        "    # TRIM LIST OF PEAKS/TROUGHS TO SHORTEST LENGTH\n",
        "    minp = min(len(px),len(tx))\n",
        "    px = px[:minp]\n",
        "    pxval = pxval[:minp]\n",
        "    tx = tx[:minp]\n",
        "    txval = txval[:minp]\n",
        "\n",
        "    # COMPUTE GOSLING PULSATILITY INDEX\n",
        "#    print \"Interpolating ...\"\n",
        "    p = si.InterpolatedUnivariateSpline(d[px],pxval[:,0])\n",
        "    t = si.InterpolatedUnivariateSpline(d[tx],txval[:,0])\n",
        "\n",
        "#    print \"Regridding ...\"\n",
        "    ip = np.array(list(map(p,d[::10])))\n",
        "    it = np.array(list(map(t,d[::10])))\n",
        "\n",
        "#    print \"Computing Gosling Pulsatility Index (GPI) ...\"\n",
        "    GPI = (ip-it)/((ip+it)/2.)\n",
        "\n",
        "#    print \"Median-lowpass smoothing ...\"\n",
        "    GPI = o.lowpass(snd.median_filter(GPI,int(rate/2)),0.2,25)\n",
        "\n",
        "    return GPI[:,0]\n",
        "\n",
        "\n",
        "def functional_connectivity(d):\n",
        "    return\n",
        "\n",
        "\n",
        "def freq_component(d,peak,width,samplerate,bin=2**12):\n",
        "    \"\"\"\n",
        "\n",
        "Compute PSD of 1 signal and sum-up values from peak-width/2 to peak+width/2\n",
        "\n",
        "RETURNS: float (sum over specified interval)\n",
        "\"\"\"\n",
        "    f,fx = psd(np.squeeze(d),bin,samplerate)\n",
        "\n",
        "    lowidx = findonset(fx,peak-width/2.)\n",
        "    hiidx = findonset(fx,peak+width/2.)\n",
        "\n",
        "    return np.sum(f[lowidx:hiidx])\n",
        "\n",
        "\n",
        "def nin_freq_component(d,peak,width,rate,bin=2**12):\n",
        "    \"\"\"\n",
        "Compute the PSD amplitude of a frequency component across all channels in dataset 'd'.\n",
        "\n",
        "RETURNS: list of len(d.shape[1])\n",
        "\"\"\"\n",
        "    fc = []\n",
        "    for i in range(d.shape[1]):\n",
        "        fc.append(freq_component(d[:,i],peak,width,rate,bin))\n",
        "    return fc\n",
        "\n",
        "\n",
        "def freq_component_specgram(d,peak,width,rate,NFFT=2**12,overlap=128):\n",
        "    \"\"\"\n",
        "\n",
        "Integrate power spectral density from the spectrogram in a freq-range\n",
        "\n",
        "RETURNS:  sum of powers in frequencies between peak-width/2 to peak+width/2\n",
        "\"\"\"\n",
        "    spec, tspec, freq = convertToFreqDomain(d,rate,NFFT,overlap)\n",
        "    mean_spec = np.mean(spec,1)\n",
        "\n",
        "    lowidx = findonset(freq,peak-width/2.)\n",
        "    hiidx = findonset(freq,peak+width/2.)\n",
        "#    print rate, width, rate-width/2, rate+width/2\n",
        "#    print freq\n",
        "#    print lowidx, hiidx\n",
        "    return np.sum(mean_spec[lowidx:hiidx])\n",
        "\n",
        "\n",
        "def convertToFreqDomain(f_eeg_data_uV, fs_Hz, NFFT=512, overlap=128):\n",
        "    \"\"\"\n",
        "\n",
        "From https://github.com/chipaudette/EEGHacker/blob/master/Data/2014-10-03%20V3%20Alpha/helperFunctions.py\n",
        "\n",
        "RETURNS: spec_PSDperBin, t_spec, freqs\n",
        "\"\"\"\n",
        "    # COMPUTE SPECTROGRAM\n",
        "    spec_PSDperHz, freqs, t_spec, im = specgram(np.squeeze(f_eeg_data_uV),\n",
        "                                            NFFT=NFFT,\n",
        "                                            window=window_hanning,\n",
        "                                            Fs=fs_Hz,\n",
        "                                            noverlap=overlap\n",
        "                                            ) # returns PSD power per Hz\n",
        "#    close()  # get rid of spectrogram plot\n",
        "    del im   # make sure it's gone\n",
        "\n",
        "    # CONVERT THE UNITS OF THE SPECTRAL DATA\n",
        "    spec_PSDperBin = spec_PSDperHz * fs_Hz / float(NFFT)  # convert to \"per bin\"\n",
        "\n",
        "    return spec_PSDperBin, t_spec, freqs\n",
        "\n",
        "\n",
        "def nearfar_phase(dnear,dfar,threshold=0.6,samplerate=250,bandfilt=[0.2,6],peaktype=1):\n",
        "    \"\"\"\n",
        "\n",
        "Determine the phase-shift in cardiac cycle between near-detector data, and\n",
        "far-detector data.\n",
        "\n",
        "RETURNS: pNx-pFx, paired\n",
        "\"\"\"\n",
        "    # BAND-PASS FILTER TO KEEP CARDIAC ONLY-ISH\n",
        "    dnearf = bandpass(dnear,bandfilt,order=4,samplerate=samplerate)\n",
        "    dfarf = bandpass(dfar,bandfilt,order=4,samplerate=samplerate)\n",
        "\n",
        "    # FIND REQUESTED PEAKS (POS OR NEG)\n",
        "    pNx, pNxval = o.findpeaks(dnearf,rate,0,0,peaktype)\n",
        "    pFx, pFxval = o.findpeaks(dfarf,rate,0,0,peaktype)\n",
        "\n",
        "    paired = []\n",
        "    for i in range(len(pNx)):\n",
        "        test = (pFx>(pNx[i]-0.2*samplerate)) & (pFx<(pNx[i]+0.2*samplerate))\n",
        "        if np.sum(test)==1:\n",
        "            paired.append([pNx[i],pNxval[i],pFx[test],pFxval[test]])\n",
        "            print(\"stored\",i)\n",
        "\n",
        "    paired = np.array(paired)\n",
        "    return pNx-pFx, paired\n",
        "\n",
        "\n",
        "###################### PLOTTING FUCNTIONS ########################\n",
        "\n",
        "def plot_bysource(d,t=None,ev=[],LPF=5,RAWRATE=25,DOWNSAMPLE=1,figsize=figsize,fignum=None,titletxt=''):\n",
        "    \"\"\"\n",
        "\n",
        "Plot NIRS data with 1 panel per source (8 detectors per panel, always colored b/g/r/c/m/y/k/brown).\n",
        "Pass in a list of event-marker lists (as ev) to plot events too.\n",
        "\n",
        "RETURNS: fighandle\n",
        "\"\"\"\n",
        "    f = figure(fignum,figsize=figsize)\n",
        "    if t is None:\n",
        "        t = np.arange(len(d))/25.\n",
        "\n",
        "    for src in range(0,4):\n",
        "        ax = subplot(4,1,src+1)\n",
        "        x = lowpass(d,LPF,RAWRATE)  # a do-nothing of LPF=0\n",
        "        x = x[::DOWNSAMPLE]\n",
        "        plot_events(t,ev)\n",
        "        for det in range(8):\n",
        "            plot(t,x[:,src*8+det],DEFAULTcolors[det],label='D'+str(det))\n",
        "        title('SRC'+str(src))\n",
        "        legend(bbox_to_anchor=(1,1))\n",
        "    subplot(4,1,1)\n",
        "    title(titletxt+'SRC0')\n",
        "\n",
        "    if fignum is not None:\n",
        "        figure(fignum+1,figsize=figsize)\n",
        "    else:\n",
        "        figure(None,figsize=figsize)\n",
        "    for src in range(4,8):\n",
        "        subplot(4,1,src-3)\n",
        "        x = lowpass(d,LPF,RAWRATE)  # a do-nothing of LPF=0\n",
        "        x = x[::DOWNSAMPLE]\n",
        "        plot_events(t,ev)\n",
        "        for det in range(8):\n",
        "            plot(t,x[:,src*8+det],DEFAULTcolors[det],label='D'+str(det))\n",
        "        title('SRC'+str(src))\n",
        "        legend(bbox_to_anchor=(1,1))\n",
        "    subplot(4,1,1)\n",
        "    title(titletxt+'SRC4')\n",
        "    return f\n",
        "\n",
        "\n",
        "def plot_bycolor(d,t=None,ev=[],ml=[],offsetstep=-100,initialoffset=0,figsize=figsize,fignum=None,titletxt=''):\n",
        "    \"\"\"\n",
        "\n",
        "Plot NIRS data in 2 figures, one for the even sources (color0=830) and one for the odd sources\n",
        "(color1=780).\n",
        "\n",
        "RETURNS: fighandles (color0, color1)\n",
        "\"\"\"\n",
        "    if t is None:\n",
        "        t = np.arange(len(d))/float(SLOWRATE)\n",
        "\n",
        "    f1 = figure(fignum,figsize=figsize)\n",
        "    plot_events(t,ev)\n",
        "\n",
        "    for i in range(len(ml)):\n",
        "        src,det = ml[i]\n",
        "        if src not in [0,2,4,6]:\n",
        "            continue\n",
        "        plot(t,d[:,src*8+det]-offsetstep*i+initialoffset,DEFAULTcolors[det],label=\"S%iD%i\" %(src,det))\n",
        "    title(titletxt+' %snm' %DEFAULTwavelengths[0])\n",
        "    legend(bbox_to_anchor=(1,1))\n",
        "\n",
        "    if fignum is not None:\n",
        "        f2 = figure(fignum+1,figsize=figsize)\n",
        "    else:\n",
        "        f2 = figure(None,figsize=figsize)\n",
        "    plot_events(t,ev)\n",
        "    for i in range(len(ml)):\n",
        "        src,det = ml[i]\n",
        "        if src not in [0,2,4,6]:\n",
        "            continue\n",
        "        src += 1  # get the OTHER color\n",
        "        plot(t,d[:,src*8+det]-offsetstep*i+initialoffset,DEFAULTcolors[det],label=\"S%iD%i\" %(src,det))\n",
        "    title(titletxt+' %snm' %DEFAULTwavelengths[1])\n",
        "    legend(bbox_to_anchor=(1,1))\n",
        "    return f1,f2\n",
        "\n",
        "\n",
        "def plot_EstG(d,t=None,ev=[],labels=None,remove_mean=True,EstGoffset=500,RAWRATE=250,DOWNSAMPLE=1,figsize=figsize,fignum=None,filt60hz=True,titletxt='E*G'):\n",
        "    \"\"\"\n",
        "\n",
        "Plot E*G data. Labels can be: {\"ECG','EOG','muscle', or defaults to S1-S8}.\n",
        "\n",
        "RETURNS: fighandle\n",
        "\"\"\"\n",
        "    f = figure(fignum,figsize=figsize)\n",
        "    if labels=='ECG':\n",
        "        labels = ['V1','V2','V3','V4','V5','V6','V7','V8']\n",
        "    elif labels=='EOG':\n",
        "        labels = ['fCR','B-mid','T-mid','V4','EOG-L','EOG-R','RA']\n",
        "    elif labels=='muscle':\n",
        "        labels = ['fCR','B-dist','B-prox','T-dist','T-prox','V6','RA']\n",
        "    elif labels=='PSG':\n",
        "        labels = ['L-EOG','R-EOG','L-EMG','R-EMG','F3','Fz','F4']\n",
        "    else:\n",
        "        labels = ['S1','S2','S3','S4','S5','S6','S7','S8']\n",
        "\n",
        "    if t is None:\n",
        "        t = np.arange(len(d))/250.\n",
        "    plot_events(t,ev)\n",
        "    for i in range(8):\n",
        "        x = d[:,i]\n",
        "        if remove_mean:\n",
        "            x = x - x.mean()\n",
        "        if filt60hz:\n",
        "            plot(t,notch(x)-EstGoffset*i,DEFAULTcolors[i],label=labels[i])\n",
        "        else:\n",
        "            plot(t,x-EstGoffset*i,DEFAULTcolors[i],label=labels[i])\n",
        "    title(titletxt)\n",
        "    xlabel('Time (sec)')\n",
        "    ylabel('uV')\n",
        "    legend()\n",
        "    return f\n",
        "\n",
        "\n",
        "def plot_allin1(dd,figsize=figsize,fignum=None,titletxt=''):\n",
        "    \"\"\"\n",
        "\n",
        "Plot NIRS data with 1 panel per source (8 detectors per panel, always colored b/g/r/c/m/y/k/brown).\n",
        "Pass in a list of event-marker lists (as ev) to plot events too.\n",
        "\n",
        "RETURNS: fighandle\n",
        "\"\"\"\n",
        "    # CONVERT DICTIONARY TO USEFUL VARIABLES\n",
        "    ev = dd['events']\n",
        "    a = dd['a']\n",
        "    config = dd['config']\n",
        "    td = dd['td']\n",
        "    ta = dd['ta']\n",
        "    raw = a['SRC']\n",
        "    bkgd = a['BKGD']\n",
        "    d = raw-bkgd\n",
        "    print(list(dd.keys()))\n",
        "    estg = a['EstG']\n",
        "    acc = a['ACCE']\n",
        "\n",
        "    f = figure(fignum,figsize=figsize)\n",
        "\n",
        "    #  PLOT ACCEL\n",
        "    subplot(3,1,1)\n",
        "    addplot_accel(acc,ta,ev,total=True,RAWRATE=250,timeshift=0)\n",
        "    title(titletxt+\": ACCEL\")\n",
        "\n",
        "    # PLOT E*G\n",
        "    subplot(3,1,2)\n",
        "    labels = ['V1','V2','V3','V4','V5','V6','V7','V8']\n",
        "    plot_events(ta,ev)\n",
        "    for i in range(3):\n",
        "        x = estg[:,i]\n",
        "        x = x - x.mean()\n",
        "        plot(ta,x,DEFAULTcolors[i],label=labels[i])\n",
        "    title(titletxt+\": E*G\")\n",
        "    ylim([-100000,100000])\n",
        "    xlabel('Time (sec)')\n",
        "    ylabel('uV')\n",
        "    legend()\n",
        "\n",
        "    # PLOT NIRS\n",
        "    pairs = [[0,0],[1,0],\n",
        "             [1,2],\n",
        "             [2,4],\n",
        "             [3,6]]\n",
        "    subplot(3,1,3)\n",
        "    plot_events(ta,ev)\n",
        "    for src,det in pairs:\n",
        "            plot(td,d[:,src*8+det],DEFAULTcolors[det],label='S%iD%i'%(src,det))\n",
        "\n",
        "    return f\n",
        "\n",
        "\n",
        "def accel2orient(acc):\n",
        "    \"\"\"\n",
        "\n",
        "Converts accelerometer data to head-orientation angles). @@@NOT VALIDATED\n",
        "\n",
        "RETURNS: TIME x 3 (roll, pitch, yaw/heading)\n",
        "\"\"\"\n",
        "    miu = 0.001\n",
        "    X = acc[:,0]/8192.\n",
        "    Y = acc[:,1]/8192.\n",
        "    Z = acc[:,2]/8192.\n",
        "    sign = np.where(Z>0,1,-1)\n",
        "    #Roll = np.atan2(Y, Z) * 180/M_PI;  # technically right, but prone to error with noise\n",
        "    Roll = np.arctan2(Y, sign* sqrt(Z*Z+ miu*X*X))*180/np.pi  # only 2-3% error this way\n",
        "    Pitch = np.arctan2(-X, np.sqrt(Y*Y + Z*Z)) *180/np.pi;\n",
        "    Roll = np.where(abs(Roll)>135,180-abs(Roll),Roll)\n",
        "    return np.array([Roll, Pitch]).T\n",
        "\n",
        "\n",
        "def addplot_accel(d,t=None,ev=[],total=True,RAWRATE=250,timeshift=0):\n",
        "    \"\"\"\n",
        "\n",
        "Add plot of accelerometer data on current axes, potentially with events\n",
        "and an option to compute and plot total acceleration.\n",
        "\n",
        "RETURNS: None\n",
        "\"\"\"\n",
        "    if total:\n",
        "        labels = ['x','y','z','Total']\n",
        "    else:\n",
        "        labels = ['x','y','z']\n",
        "\n",
        "    if t is None:\n",
        "        t = np.arange(len(d))/250.\n",
        "    plot_events(t,ev,timeshift=timeshift)\n",
        "    plot(t+timeshift,d[:,0],DEFAULTcolors[0])\n",
        "    plot(t+timeshift,d[:,1],DEFAULTcolors[1])\n",
        "    plot(t+timeshift,d[:,2],DEFAULTcolors[2])\n",
        "    if total:\n",
        "        acc_tot = np.sqrt(np.sum(d**2,1))\n",
        "        plot(t+timeshift,acc_tot,'k')\n",
        "    title('Accelerometer')\n",
        "    xlabel('Time (sec)')\n",
        "    ylabel('G')\n",
        "    legend()\n",
        "\n",
        "\n",
        "def addplot_orient(acc,t=None,ev=[],timeshift=0):\n",
        "    \"\"\"\n",
        "\n",
        "Add head-orientation to current plot from RAW accelerometer data.\n",
        "\n",
        "RETURNS: None\n",
        "\"\"\"\n",
        "    if t is None:\n",
        "        t = np.arange(len(d))/float(FASTRATE)\n",
        "\n",
        "    rp = accel2orient(acc)\n",
        "    rp = lowpass(rp,55,FASTRATE)\n",
        "    plot_events(t,ev,timeshift=timeshift)\n",
        "    plot(t+timeshift,rp[:,0],'b',label='Roll')\n",
        "    plot(t+timeshift,rp[:,1],'g',label='Pitch')\n",
        "    xlabel('Time')\n",
        "    ylabel('degrees')\n",
        "    legend()\n",
        "\n",
        "\n",
        "def plot_accel_orient(a,t=None,ev=[],timeshift=0,fignum=None):\n",
        "    \"\"\"\n",
        "\n",
        "Calculate and plot head-orientation passed-in aux dictionary.\n",
        "\n",
        "RETURNS: fighandle\n",
        "\"\"\"\n",
        "    if t is None:\n",
        "        t = np.arange(len(d))/float(FASTRATE)\n",
        "    f = figure(fignum)\n",
        "    subplot(2,1,1)\n",
        "    addplot_accel(a['ACCE'],t,ev,timeshift=timeshift)\n",
        "    subplot(2,1,2)\n",
        "    addplot_orient(a['ACCE'],t,ev,timeshift=timeshift)\n",
        "    return f\n",
        "\n",
        "\n",
        "def plot_accel(accel, ta=None, ev=[], plotTOTAL=True, timeshift=0):\n",
        "    if ta is None:\n",
        "        ta = np.arange(len(ac))/250.\n",
        "\n",
        "    plot_events(ta,ev,timeshift=timeshift)\n",
        "    plot(ta+timeshift,accel[:,0],DEFAULTcolors[0],label='x')\n",
        "    plot(ta+timeshift,accel[:,1],DEFAULTcolors[1],label='y')\n",
        "    plot(ta+timeshift,accel[:,2],DEFAULTcolors[2],label='z')\n",
        "    if plotTOTAL:\n",
        "        acc_tot = np.sqrt(np.sum(accel**2,1))\n",
        "        plot(ta+timeshift,acc_tot,'k',label='total')\n",
        "    legend(bbox_to_anchor=(1,1))\n",
        "\n",
        "\n",
        "def plot_slow(d, ta=None, ev=[], timeshift=0):\n",
        "    if ta is None:\n",
        "        ta = np.arange(len(ac))/250.\n",
        "    td = ta[::10]  #np.arange(len(ac[k]))/25.\n",
        "    td = td[:len(d)]\n",
        "    plot_events(ta,ev,timeshift=timeshift)\n",
        "    plot(td+timeshift,d)\n",
        "\n",
        "\n",
        "def plot_fast(d, ta=None, ev=[], timeshift=0):\n",
        "    if ta is None:\n",
        "        ta = np.arange(len(ac))/250.\n",
        "    plot_events(ta,ev,timeshift=timeshift)\n",
        "    plot(ta+timeshift,d)\n",
        "\n",
        "\n",
        "def plot_aux(ac,t=None,ev=[],GSR=[],plotTOTAL=True,timeshift=0,GSRcalibwin=[-7,-2],fignum=None,\n",
        "             sharex=True):\n",
        "    \"\"\"\n",
        "\n",
        "Plot auxiliary data in dict 'ac', excluding EstG.\n",
        "\n",
        "RETURNS: fighandle\n",
        "\"\"\"\n",
        "    if t is None:\n",
        "        ta = np.arange(len(ac))/250.\n",
        "    else:\n",
        "        ta = t\n",
        "\n",
        "    f = figure(fignum,figsize=figsize)\n",
        "\n",
        "    ks = list(ac.keys())\n",
        "    ks.sort()\n",
        "    if 'SRC' in ks:\n",
        "        ks.remove('SRC')\n",
        "    if 'BKGD' in ks:\n",
        "        ks.remove('BKGD')\n",
        "    if 'NIRS' in ks:\n",
        "        ks.remove('NIRS')\n",
        "    if 'EstG' in ks:\n",
        "        ks.remove('EstG')\n",
        "    if GSR:\n",
        "        gsrcount = 1\n",
        "    else:\n",
        "        gsrcount = 0\n",
        "    pltnum = 1  # initialize counter\n",
        "    for k in ks:\n",
        "        if pltnum==1:\n",
        "            ax1 = subplot(len(ks)+gsrcount,1,pltnum)\n",
        "        else:\n",
        "            if sharex==True:\n",
        "                ax = subplot(len(ks)+gsrcount,1,pltnum,sharex=ax1)\n",
        "            else:\n",
        "                ax = subplot(len(ks)+gsrcount,1,pltnum)\n",
        "        if k in ['ACCE','GYRO']:\n",
        "            plot_accel(ac[k],ta,ev,plotTOTAL,timeshift=timeshift)\n",
        "            if k=='ACCE':\n",
        "                title('Accelerometer')\n",
        "                ylabel('g')\n",
        "            elif k=='GYRO':\n",
        "                title('Gyroscope')\n",
        "                ylabel('deg/sec')\n",
        "            legend(bbox_to_anchor=(1,1))\n",
        "            pltnum += 1\n",
        "        elif k in ['FORC','RESP','TEMP']:\n",
        "            plot_slow(ac[k],ta,ev,timeshift=timeshift)\n",
        "            if k=='FORC':\n",
        "                title('Force')\n",
        "                ylabel('Force (kg)')\n",
        "            elif k=='GYRO':\n",
        "                title('Gyroscope')\n",
        "                ylabel('deg/sec')\n",
        "            elif k=='TEMP':\n",
        "                title('Temperature')\n",
        "                ylabel('deg C')\n",
        "            pltnum += 1\n",
        "        elif k in ['NECG']:\n",
        "            plot_fast(ac[k],ta,ev,timeshift=timeshift)\n",
        "            title('ECG')\n",
        "            ylabel('(a.u.)')\n",
        "            pltnum += 1\n",
        "    if GSR:\n",
        "        if sharex==True:\n",
        "            subplot(len(ks)+gsrcount,1,pltnum,sharex=ax1)\n",
        "        else:\n",
        "            subplot(len(ks)+gsrcount,1,pltnum)\n",
        "        plot_events(ta,ev,timeshift=timeshift)\n",
        "#        GSRenv = GSRenvelope(ac['EstG'][:,GSR[0]])\n",
        "#        GSRenvfilt = lowpass(GSRenv,3,250.)  # hard-coded 3Hz bandwidth\n",
        "#        plot(ta[:len(GSRenv)],GSRenvfilt)\n",
        "        if len(GSR)==1:  # ORIGINAL GSR\n",
        "            GSR = ac['EstG'][:,GSR[0]]           # grab GSR data from ac dict\n",
        "            GSRfilt = lowpass(GSR,1,250)    # lowpass out spikes etc.\n",
        "            GSR = np.mean(GSR[GSRcalibwin[0]*250:GSRcalibwin[1]*250])/(GSRfilt*50)*1000  # 50=ohms; convert to milliSiemens\n",
        "            plot(ta[:len(GSR)],GSR)\n",
        "        else:\n",
        "            GSRdata = ac['EstG'][:,GSR]\n",
        "            GSR = GSR_Vlad(GSRdata,lpf=2)\n",
        "            plot(ta[:len(GSR)],GSR)\n",
        "        title('GSR')\n",
        "        ylabel('Rel. Ampl.')\n",
        "    xlabel('Time (sec)')\n",
        "\n",
        "    return f\n",
        "\n",
        "\n",
        "def plot_splayed(d,t=None,ev=[],ml=[],offsetstep=-10,initialoffset=0,figsize=figsize,fignum=None):\n",
        "    \"\"\"\n",
        "\n",
        "Plots signals in 'd' each with offsets y-units (e.g., for OD plotting of many traces)\n",
        "\n",
        "RETURNS: fighandle\n",
        "\"\"\"\n",
        "    f = figure(fignum,figsize=figsize)\n",
        "    if t is None:\n",
        "        t = np.arange(len(d))\n",
        "    plot_events(t,ev)\n",
        "    if len(ml)>0:\n",
        "        for i in range(len(ml)):\n",
        "            src,det = ml[i]\n",
        "            x = d[:,src*8+det]\n",
        "            x = x -offsetstep*i +initialoffset\n",
        "            plot(t,x,DEFAULTcolors[det],label=\"S%iD%i\" %(src,det))\n",
        "    else:\n",
        "        for i in range(d.shape[1]):\n",
        "            plot(t,d[:,i]-offsetstep*i+initialoffset,DEFAULTcolors[i%8])\n",
        "    xlabel('Time (sec)')\n",
        "    legend(bbox_to_anchor=(1,1))\n",
        "    return f\n",
        "\n",
        "\n",
        "def plot_hbhbosplayed(d,t=None,ev=[],ml=[],offsetstep=-10,initialoffset=0,figsize=figsize,fignum=None):\n",
        "    \"\"\"\n",
        "\n",
        "Plots signals in 'd' each with offsets y-units (e.g., for OD plotting of many traces)\n",
        "\n",
        "RETURNS: fighandle\n",
        "\"\"\"\n",
        "    f = figure(fignum,figsize=figsize)\n",
        "    if t is None:\n",
        "        t = np.arange(len(d))\n",
        "    plot_events(t,ev)\n",
        "    if len(ml)>0:\n",
        "        for i in range(len(ml)):\n",
        "            src,det = ml[i]\n",
        "            if src not in [0,2,4,6]:\n",
        "                continue\n",
        "            x = d[:,i]\n",
        "            x = x -offsetstep*i +initialoffset\n",
        "            plot(t,x,DEFAULTcolors[det],label=\"S%iD%i\" %(src,det))\n",
        "    else:\n",
        "        for i in range(d.shape[1]):\n",
        "            plot(t,d[:,i]-offsetstep*i+initialoffset,DEFAULTcolors[i%8])\n",
        "    xlabel('Time (sec)')\n",
        "    legend(bbox_to_anchor=(1,1))\n",
        "    return f\n",
        "\n",
        "\n",
        "def plot_map(d,clim=None,cmap='jet_r',interpolation='none',figsize=figsize,figstart=None,titletxt=''):\n",
        "    \"\"\"\n",
        "\n",
        "Plots a colormap of data in 'd' (e.g., SNR or gains, etc). Use jet_r for SNRmaps and jet for others.\n",
        "\n",
        "RETURNS: fighandle\n",
        "\"\"\"\n",
        "    f = figure(figstart,figsize=figsize)\n",
        "    im = imshow(d, interpolation=interpolation)\n",
        "    if titletxt:\n",
        "        title(titletxt)\n",
        "    xlabel('Detector')\n",
        "    ylabel('Source')\n",
        "    if clim is not None:\n",
        "        im.set_clim(clim[0],clim[1])\n",
        "    set_cmap(cmap)\n",
        "    colorbar()\n",
        "    return f\n",
        "\n",
        "\n",
        "def plot_events(t, ev, ymin=0, ymax=65536, linewidth=1.5,colors=DEFAULTcolors,timeshift=0,plot_event_text=False,):\n",
        "    \"\"\"\n",
        "\n",
        "Plot event markers on the current graph. Requires a time-base plus 'ev'=a\n",
        "list of lists of [timestamp,index] pairs, as from ev=get_nin_events().\n",
        "SKIPS LINES when events extend beyond the right-edge of the data\n",
        "\n",
        "RETURNS: None\n",
        "\"\"\"\n",
        "    if len(t)<2:\n",
        "        return\n",
        "    if 1.0/(t[1]-t[0])<50:\n",
        "        slow = 1\n",
        "    else:\n",
        "        slow = 0\n",
        "    flag = 0\n",
        "    for i in range(len(ev)):\n",
        "        trig = ev[i]  # get all events for a single button\n",
        "        for row in trig:\n",
        "            try:\n",
        "                if len(t)>0:\n",
        "                    trigtime = row[1]/250.  # in sec\n",
        "                    tline = findonset(t,trigtime)\n",
        "                    if tline is not None and (abs(t[tline]-trigtime)<0.5):\n",
        "                        axvline(t[tline]+timeshift,ymin,ymax,color=colors[i],linewidth=linewidth)\n",
        "#                        print trigtime, tline, t[tline], t[0], t[-1], timeshift,t[tline]+timeshift\n",
        "                    else:\n",
        "                        print(\"plot_events() FAILED:\",trigtime, tline, t[tline], t[0], t[-1], timeshift,t[tline]+timeshift)\n",
        "                        flag = 1\n",
        "                        pass\n",
        "                else:\n",
        "                    axvline(row[1]+timeshift,ymin,ymax,color=colors[i],linewidth=linewidth)\n",
        "            except: # may be plotting short dataset\n",
        "                print('plot_events() crapped out; short dataset?')\n",
        "                flag = 1\n",
        "                pass\n",
        "    if flag==1:\n",
        "        print(\"Dataset & events match? Couldn't plot all event markers.\")\n",
        "    return\n",
        "\n",
        "\n",
        "def plot_timeline(dct,minmax=None,xlbl=None,ylbl=None,ax=None,extralength=0,jitter=0.05):\n",
        "    \"\"\"dct needs to be {'label':[[xvals],color], etc}\n",
        "    extralength is how far the arrow line should extend prior to and beyond the end of the data\"\"\"\n",
        "    if ax is None:\n",
        "        figure(figsize=(12,3))\n",
        "        ax = gca()\n",
        "    if minmax is None:\n",
        "        allvals = []\n",
        "        for l,c in dct.values():\n",
        "            allvals += l\n",
        "        minmax = [min(allvals), max(allvals)]\n",
        "    uniquex = np.unique(allvals)\n",
        "    uniquex = uniquex.tolist()\n",
        "    uniquex.sort()\n",
        "    arrow(minmax[0]-extralength, 0, minmax[1]+extralength, 0, shape='full', linewidth=3, width=0.007, color='k', length_includes_head=True)\n",
        "    ks = list(dct.keys())\n",
        "    ks.sort()\n",
        "    for i in range(len(ks)):\n",
        "        k = ks[i]\n",
        "        times,color = dct[k]\n",
        "        shift = i*jitter-(len(ks)*jitter/2.)\n",
        "        vlines(x=np.array(times)+shift,ymin=-0.4,ymax=1,color=color,linewidth=3,label=k)\n",
        "    legend()\n",
        "    ax.set_yticklabels([])\n",
        "    if xlbl:\n",
        "        xlabel(xlbl)\n",
        "    if ylbl:\n",
        "        ylabel(ylbl)\n",
        "    tight_layout()\n",
        "    ax.set_xticks(uniquex)\n",
        "    return ax\n",
        "\n",
        "def plot_spectrogram(f_eeg_data_uV, fs_Hz=250, NFFT=512, overlap=128, fignum=None, figsize=figsize):\n",
        "    \"\"\"\n",
        "\n",
        "From https://github.com/chipaudette/EEGHacker/blob/master/Data/2014-10-03%20V3%20Alpha/helperFunctions.py\n",
        "\n",
        "RETURNS:  fighandle\n",
        "\"\"\"\n",
        "    # COMPUTE SPECTROGRAM\n",
        "    f = figure(fignum,figsize=figsize)\n",
        "    x = np.squeeze(f_eeg_data_uV)\n",
        "    spec_PSDperHz, freqs, t_spec, im = specgram(x,\n",
        "                                            NFFT=NFFT,\n",
        "                                            window=window_hanning,\n",
        "                                            Fs=fs_Hz,\n",
        "                                            noverlap=overlap\n",
        "                                            ) # returns PSD power per Hz\n",
        "    xlabel('Time')\n",
        "    ylabel('Freq (Hz)')\n",
        "    return f\n",
        "\n",
        "\n",
        "def plot_spectrum(d, fs_Hz=250, NFFT=512, overlap=128, filt60hz=True, color='b',fignum=None):\n",
        "    \"\"\"\n",
        "\n",
        "Plot spectrogram of single time-series data in 'd'.\n",
        "\n",
        "RETURNS: fighandle\n",
        "\"\"\"\n",
        "    if filt60hz:\n",
        "        d = notch(d)\n",
        "    f = figure(fignum,figsize=figsize)\n",
        "    spec, tspec, freq = convertToFreqDomain(d,fs_Hz,NFFT,overlap)\n",
        "    close()  # get rid of spectrogram plot (only done to get return-values)\n",
        "    mean_spec = np.mean(spec,1)\n",
        "    f = figure(fignum,figsize=figsize)\n",
        "    plot(freq,np.log(mean_spec),color)  #@@@added log() so plot is visible\n",
        "    xlabel('Frequency (Hz)')\n",
        "    ylabel('log(RMS Amplitude\\n(uV/ Bin^-1/2))')\n",
        "    return f\n",
        "\n",
        "\n",
        "def nin_plotconcentrations(hbspecies,t=None,ev=[],fignum=None,figsize=figsize):\n",
        "    \"\"\"\n",
        "\n",
        "Plots oxy/deoxy/total Hb data\n",
        "\n",
        "RETURNS:  fighandle\n",
        "\"\"\"\n",
        "    f = figure(fignum,figsize=figsize)\n",
        "    if events:\n",
        "        t = np.arange(len(hbspecies[0]))/25.\n",
        "        plot_events(t,ev)\n",
        "\n",
        "    offset = 0\n",
        "    numplots = len(hbhboindices)\n",
        "    for j in range(numplots):\n",
        "        subplot(numplots,1,j+1)\n",
        "        plot_events(t,ev)\n",
        "        offset = 0\n",
        "        for i in hbhboindices[j]:\n",
        "            hbhbo = hbhbos[i]\n",
        "            if species=='hb':\n",
        "                y = hbhbo[::DOWNSAMPLE,0]\n",
        "                titlestr = 'Deoxy-Hb: '+fname\n",
        "            elif species=='hbo2':\n",
        "                y = hbhbo[::DOWNSAMPLE,1]\n",
        "                titlestr = 'Oxy-Hb: '+fname\n",
        "            elif species=='hbt':\n",
        "                y = np.sum(hbhbo,1)[::DOWNSAMPLE]\n",
        "                titlestr = 'Total-Hb: '+fname\n",
        "            y = y +offset   # add an offset to each trace\n",
        "            y = y*1e6\n",
        "    #            offset -= CONCoffsetstep\n",
        "            if i%2==0:\n",
        "                l = \"Scalp HbT\"\n",
        "            else:\n",
        "                l = \"Brain HbT\"\n",
        "            src,det = hbhboml[i]\n",
        "            plot(t,y-np.mean(y[:200]),DEFAULTcolors[det],label=l)\n",
        "            ylabel('$\\Delta$Conc. (uM)')\n",
        "            legend(bbox_to_anchor=(1,1))\n",
        "\n",
        "        subplot(numplots,1,1)\n",
        "        title(titlestr)\n",
        "        subplot(numplots,1,numplots)\n",
        "        xlabel('Time (sec)')\n",
        "    return f\n",
        "\n",
        "\n",
        "def plot_in_panels(d,indiceslist,fig=None,fignum=None,startpanel=0,t=None,ev=[],species=None,titlestr='',\n",
        "                  xlimits=[],ylimits=[],linestyle='-',matlabchan=False,sharex=True):\n",
        "    \"\"\"\n",
        "\n",
        "Plot a figure with subplots, one subplot per list in indiceslist.\n",
        "fig = figure to add-to\n",
        "\n",
        "RETURNS: fighandle\n",
        "\"\"\"\n",
        "    numplots = len(indiceslist)\n",
        "    if fig is None:\n",
        "        startpanel = 0\n",
        "        if fignum:  # create specific figure number\n",
        "            fig,ax = subplots(nrows=numplots,ncols=1,sharex=sharex,figsize=figsize,num=fignum)\n",
        "        else:       # just create a new figure\n",
        "            fig,ax = subplots(nrows=numplots,ncols=1,sharex=sharex,figsize=figsize)\n",
        "    axs = fig.axes\n",
        "    if len(axs)==0: # got an empty figure here\n",
        "        startpanel = 0\n",
        "        fignum = gcf().number\n",
        "        fig,ax = subplots(nrows=numplots,ncols=1,sharex=sharex,figsize=figsize,num=fignum)\n",
        "        axs = fig.axes\n",
        "\n",
        "    if t is None:\n",
        "        t = np.arange(len(d))/float(SLOWRATE)\n",
        "\n",
        "    for j in range(numplots):\n",
        "        fig.sca(axs[startpanel+j])   # set this subplot\n",
        "        if j==0:\n",
        "            title(titlestr)\n",
        "        plot_events(t,ev)\n",
        "        for idx in range(len(indiceslist[j])):\n",
        "            i = indiceslist[j][idx]\n",
        "            if matlabchan:\n",
        "                lbls = [x+1 for x in indiceslist[j]]\n",
        "                legendtitle = 'MatlabCh'\n",
        "            else:\n",
        "                lbls = indiceslist[j]\n",
        "                legendtitle = 'PythonCh'\n",
        "            lbls = list(map(str,lbls))\n",
        "            y = d[:,i]\n",
        "            plot(t,y,color=DEFAULTcolors[i%8],linestyle=linestyle,label=lbls[idx]) #\"Ch\"+str(i))\n",
        "            legend(title=legendtitle,bbox_to_anchor=(1,1))\n",
        "            if len(xlimits)==2:\n",
        "                xlim(xlimits[0],xlimits[1])\n",
        "            if len(ylimits)==2:\n",
        "                ylim(ylimits[0],ylimits[1])\n",
        "        xlabel('Time (sec)')\n",
        "    return f\n",
        "\n",
        "\n",
        "def plot_panels(d,indiceslist,t=None,ev=[],species=None,titlestr='',\n",
        "                  xlimits=[],ylimits=[],fignum=None,figsize=figsize,matlabchan=False,sharex=True):\n",
        "    \"\"\"\n",
        "KEPT FOR BACKWARD COMPATIBILITY ... USE plot_in_panels(), above\n",
        "Plot a figure with subplots, one subplot per list in indiceslist.\n",
        "\n",
        "RETURNS: fighandle\n",
        "\"\"\"\n",
        "    f = figure(fignum,figsize)\n",
        "\n",
        "    if t is None:\n",
        "        t = np.arange(len(d))/float(SLOWRATE)\n",
        "\n",
        "    numplots = len(indiceslist)\n",
        "    for j in range(numplots):\n",
        "        if j==0:\n",
        "            ax1 = subplot(numplots,1,j+1)\n",
        "            title(titlestr)\n",
        "        else:\n",
        "            if sharex==True:\n",
        "                subplot(numplots,1,j+1,sharex=ax1)\n",
        "            else:\n",
        "                subplot(numplots,1,j+1)\n",
        "        plot_events(t,ev)\n",
        "        for idx in range(len(indiceslist[j])):\n",
        "            i = indiceslist[j][idx]\n",
        "            if matlabchan:\n",
        "                lbls = [x+1 for x in indiceslist[j]]\n",
        "                legendtitle = 'MatlabCh'\n",
        "            else:\n",
        "                lbls = indiceslist[j]\n",
        "                legendtitle = 'PythonCh'\n",
        "            lbls = list(map(str,lbls))\n",
        "            y = d[:,i]\n",
        "            plot(t,y,DEFAULTcolors[i%8],label=lbls[idx]) #\"Ch\"+str(i))\n",
        "            legend(title=legendtitle,bbox_to_anchor=(1,1))\n",
        "            if len(xlimits)==2:\n",
        "                xlim(xlimits[0],xlimits[1])\n",
        "            if len(ylimits)==2:\n",
        "                ylim(ylimits[0],ylimits[1])\n",
        "        xlabel('Time (sec)')\n",
        "    return f\n",
        "\n",
        "\n",
        "def plot_specgram(hbhbo,species=1,plotchan=[10,11],\n",
        "                   fignum=None):\n",
        "    \"\"\"\n",
        "\n",
        "Plot one figure per plot channel.\n",
        "    species=0 for Deoxy\n",
        "    species=1 for Oxy\n",
        "    species=2 for Total\n",
        "\n",
        "RETURNS: None\n",
        "\"\"\"\n",
        "    figlist = []\n",
        "    for ch in plotchan:\n",
        "        figure(fignum,figsize)\n",
        "        if species<2:\n",
        "            f = psd(hbhbo[species,:,ch],NFFT=2**10,Fs=25)\n",
        "        else:\n",
        "            f = psd(np.sum(hbhbo,0)[:,ch],NFFT=2**10,Fs=25)\n",
        "        if species==0:\n",
        "            titlestr = 'Deoxy-Hb: '\n",
        "        if species==1:\n",
        "            titlestr = 'Oxy-Hb: '\n",
        "        if species==2:\n",
        "            titlestr = 'Total-Hb: '\n",
        "        titlestr += 'Chan=%s' %str(ch)\n",
        "        title(titlestr)\n",
        "        figlist.append(f)\n",
        "    return figlist\n",
        "\n",
        "\n",
        "def plot_quadconc(hbhbo,t=None,ev=[],plotchan=[[0,1],[10,11],[20,21],[30,31]],\n",
        "                        xlimits=[],ylimits=[],fignum=None,titletxt=''):\n",
        "    \"\"\"\n",
        "Use plot_in_panels() to plot 4 panels of each Hb species.\n",
        "plotchan holds channel-pairs (column indices, out of 64 for NIN-M data) that\n",
        "should be plotted together.\n",
        "\n",
        "RETURNS: 3 fighandles to deoxy/oxy/total data\n",
        "\"\"\"\n",
        "    # channels to put on each subplot\n",
        "\n",
        "    # PLOT HHb\n",
        "    titlestr = 'Deoxy-Hb: '+titletxt\n",
        "    f1 = plot_in_panels(hbhbo[0],plotchan,t=t,ev=ev,fignum=fignum,titlestr=titlestr,xlimits=xlimits,ylimits=ylimits)\n",
        "\n",
        "    # PLOT O2Hb\n",
        "    if fignum is not None:\n",
        "        fignum += 1\n",
        "    titlestr = 'Oxy-Hb: '+titletxt\n",
        "    f2 = plot_in_panels(hbhbo[1],plotchan,t=t,ev=ev,fignum=fignum,titlestr=titlestr,xlimits=xlimits,ylimits=ylimits)\n",
        "\n",
        "    # PLOT HbT\n",
        "    if fignum is not None:\n",
        "        fignum += 1\n",
        "    titlestr = 'Total-Hb: '+titletxt\n",
        "    f3 = plot_in_panels(np.sum(hbhbo,0),plotchan,t=t,ev=ev,fignum=fignum,titlestr=titlestr,xlimits=xlimits,ylimits=ylimits)\n",
        "    return f1, f2, f3\n",
        "\n",
        "\n",
        "def plot_SEstripconc(hbhbo,t=None,ev=[],plotchan=[[0,20],[10,20],[21,20],[31,20]],\n",
        "                        xlimits=[],ylimits=[],fignum=None):\n",
        "    \"\"\"\n",
        "\n",
        "Use plot_in_panels() to plot 4 panels of each Hb species.\n",
        "plotchan holds channel-pairs (column indices, out of 64 for NIN-M data) that\n",
        "should be plotted together.\n",
        "\n",
        "RETURNS: 3 fighandles to deoxy/oxy/total data\n",
        "\"\"\"\n",
        "    # channels to put on each subplot\n",
        "\n",
        "    # PLOT HHb\n",
        "    titlestr = 'Deoxy-Hb'\n",
        "    f1 = plot_in_panels(hbhbo[0],plotchan,t=t,ev=ev,fignum=fignum,titlestr=titlestr,xlimits=xlimits,ylimits=ylimits)\n",
        "\n",
        "    # PLOT O2Hb\n",
        "    if fignum is not None:\n",
        "        fignum += 1\n",
        "    titlestr = 'Oxy-Hb'\n",
        "    f2 = plot_in_panels(hbhbo[1],plotchan,t=t,ev=ev,fignum=fignum,titlestr=titlestr,xlimits=xlimits,ylimits=ylimits)\n",
        "\n",
        "    # PLOT HbT\n",
        "    if fignum is not None:\n",
        "        fignum += 1\n",
        "    titlestr = 'Total-Hb'\n",
        "    f3 = plot_in_panels(np.sum(hbhbo,0),plotchan,t=t,ev=ev,fignum=fignum,titlestr=titlestr,xlimits=xlimits,ylimits=ylimits)\n",
        "    return f1, f2, f3\n",
        "\n",
        "\n",
        "def plot_channels(data,chan,t=None,ev=[],titlestr='',\n",
        "                  xlimits=[],ylimits=[],fignum=None,matlabchan=False):\n",
        "    \"\"\"\n",
        "\n",
        "Use plot_in_panels() to plot 4 panels of each Hb species.\n",
        "plotchan holds channel-pairs (column indices, out of 64 for NIN-M data) that\n",
        "should be plotted together.\n",
        "\n",
        "RETURNS: 3 fighandles to deoxy/oxy/total data\n",
        "\"\"\"\n",
        "    # channels to put on each subplot\n",
        "\n",
        "    if chan=='quad':\n",
        "        chan = [[0,20],[10,20],[21,20],[31,20]]\n",
        "    elif chan=='SEstrip':\n",
        "        chan = [[0,1,2],[9,10,11,12],[18,19,20,21,22],[29,30,31]]\n",
        "    elif chan=='bysrc':\n",
        "        chan = [list(range(8)),list(range(8,16)),list(range(16,24)),list(range(24,32))]\n",
        "\n",
        "    f1 = plot_in_panels(data,chan,t=t,ev=ev,fignum=fignum,titlestr=titlestr,xlimits=xlimits,ylimits=ylimits,matlabchan=matlabchan)\n",
        "\n",
        "    return f1, chan\n",
        "\n",
        "\n",
        "def plot_signalVseparation(d,geometry,config=None,fignum=None,figsize=figsize):\n",
        "    \"\"\"\n",
        "\n",
        "Plot a scatterplot of signal level vs. separation.\n",
        "If 'config' is not None, it unwraps gains first.\n",
        "\n",
        "RETURNS: fighandle\n",
        "\"\"\"\n",
        "    # UNWRAP GAINS IF NEEDED\n",
        "    if config is not None:\n",
        "        if config['gainunwrapped']==0:\n",
        "            ungained,config = unwrap_gains(d,config)\n",
        "    else:\n",
        "        ungained = d\n",
        "\n",
        "    # FLATTEN IF NEEDED\n",
        "    if len(ungained.shape)==2:\n",
        "        ungained = np.mean(ungained,0)\n",
        "\n",
        "    # GET GEOMETRY INFO\n",
        "    pSrc,pDet = get_geometry(geometry)\n",
        "\n",
        "    # BUILD PLOTTING VALUES\n",
        "    xs = []\n",
        "    ys = []\n",
        "    lbls = []\n",
        "    all = []\n",
        "    idx = 1\n",
        "    for src in range(8):\n",
        "        for det in range(8):\n",
        "            dst = dist(pSrc[src],pDet[det])\n",
        "            xs.append(dst)\n",
        "            ys.append(ungained[src*8+det])\n",
        "            lbls.append('S'+str(src)+'D'+str(det))\n",
        "            all.append([idx,src+1,det+1,dst/10.])\n",
        "            idx += 1\n",
        "\n",
        "    f = figure(fignum,figsize)\n",
        "    semilogy(xs,ys,'o')\n",
        "    for i in range(len(lbls)):\n",
        "        text(xs[i]+0.05, ys[i], lbls[i])\n",
        "    xlabel(\"Separation (mm)\")\n",
        "    ylabel('Signal')\n",
        "    return ungained\n",
        "\n",
        "\n",
        "###################### CONVERSION TOOLS ########################\n",
        "\n",
        "def edf_filt(a,sensors=DEFAULTsensors):\n",
        "    \"\"\"\n",
        "\n",
        "Filters all datasets attached to dictionary 'a' according to parameters in\n",
        "'sensors' (which defaults to this file's sensors values.\n",
        "\n",
        "RETURNS: filtered version of a\n",
        "\"\"\"\n",
        "\n",
        "    ### FILTER AS REQUESTED IN DICTIONARIES UP-TOP\n",
        "    print(\"  Filtering per sensors dict (at top, or passed in) ...\")\n",
        "\n",
        "    # START WITH NOTCH FILTERING\n",
        "    for k in sensors.keys():\n",
        "        if k not in list(a.keys()):\n",
        "            continue\n",
        "        print(\"    Notching\",k)\n",
        "\n",
        "\n",
        "    # START WITH LOWPASS\n",
        "    print(\"    LOWPASS:\")\n",
        "    for k in sensors.keys():\n",
        "        if k not in list(a.keys()):\n",
        "            continue\n",
        "        print(\"      \",k, \"cutoff=\",sensors[k]['LPF'])\n",
        "        print(\"  \",sensors[k]['LPF'], sensors[k]['samplerate'], sensors[k]['LPF'] in [type(list),type(tuple)])\n",
        "        if type(sensors[k]['LPF']) in [type(list),type(tuple)]:\n",
        "            for idx in range(len(sensors[k]['LPF'])):\n",
        "                lpf = sensors[k]['LPF'][idx]\n",
        "                a[k][:,idx] = lowpass(a[k][:,idx],lpf,sensors[k]['samplerate'])\n",
        "        else:\n",
        "            a[k] = lowpass(a[k],sensors[k]['LPF'],sensors[k]['samplerate'])\n",
        "\n",
        "    # THEN DO HIPASS\n",
        "    print(\"    HIPASS:\")\n",
        "    for k in sensors.keys():\n",
        "        if k not in list(a.keys()):\n",
        "            continue\n",
        "        print(\"      \",k, \"cutoff=\",sensors[k]['HPF'])\n",
        "        if type(sensors[k]['HPF']) in [type(list),type(tuple)]:\n",
        "            for idx in range(len(sensors[k]['HPF'])):\n",
        "                hpf = sensors[k]['HPF'][idx]\n",
        "                a[k][:,idx] = hipass(a[k][:,idx],hpf,sensors[k]['samplerate'])\n",
        "        else:\n",
        "            a[k] = hipass(a[k],sensors[k]['HPF'],sensors[k]['samplerate'])\n",
        "    print()\n",
        "    return a\n",
        "\n",
        "\n",
        "def nin2edf(fname,seglength=-1,sensors=DEFAULTsensors,notchfilt=[],outname=None):\n",
        "    \"\"\"\n",
        "\n",
        "Converts a .nin file to one or more .EDF files. 'seglength' determines the\n",
        "lenth of time included in each .edf file (in sec; -1=whole file).\n",
        "Does NOT unwrapgain (generates floats) or trim.\n",
        "\n",
        "RETURNS: None, but saves files with fname[:-4]+starttime-endtime.edf\n",
        "\"\"\"\n",
        "    print(\"\\nnin2edf(): Starting main loop ...\")\n",
        "    ### STORE THIS FOR LATER\n",
        "    if outname is None:\n",
        "        outprefix = fname[:-4]\n",
        "    else:\n",
        "        idx = outname.rfind('.')\n",
        "        if idx>=0:\n",
        "            outprefix = outname[:idx]\n",
        "        else:\n",
        "            outprefix = outname\n",
        "\n",
        "    segnum = 0\n",
        "    while True:\n",
        "        if seglength==-1:\n",
        "            segstart = 0\n",
        "            segend = 1000000\n",
        "        else:\n",
        "            segstart = segnum*seglength\n",
        "            segend = (segnum+1)*seglength\n",
        "        print(\"  Loading data from %s\" %fname)\n",
        "        print(\"  for time chunk [%i, %i] sec.\"%(segstart, segend))\n",
        "        a, td, ta, events, config = load_nin(fname,segstart,segend,trim=0,verbose=True)\n",
        "        diff = a['NIRS']\n",
        "        segnum += 1\n",
        "\n",
        "        ### DO CONVERSIONS, BUT ONLY NOTCH FILTERING\n",
        "        a, config = nin_convert(a,config,unwrapgain=1,acceltype=16,force='forc',\n",
        "                                  notchfilt=notchfilt,filt_param={},verbose=True)\n",
        "\n",
        "        ### FILTER AS REQUESTED IN DICTIONARIES UP-TOP\n",
        "        print(\"  Filtering per sensors dict (at top, or passed in) ...\")\n",
        "        a = edf_filt(a,sensors)\n",
        "\n",
        "        ### TRUNCATE ALL DATASETS TO A MULTIPLE OF recdur\n",
        "        # NIRS TRUNCATION\n",
        "        print(\"  Truncating to a multiple of record-duration ...\")\n",
        "        print(\"    NIRS orig:\",diff.shape)\n",
        "        samplerate = sensors['NIRS']['samplerate']\n",
        "        totaltime = len(a['NIRS'])/float(samplerate)  # sec\n",
        "        numrec = int(totaltime/recdur)      # N\n",
        "        truncidx = numrec*recdur*samplerate\n",
        "        a['NIRS'] = a['NIRS'][:truncidx]\n",
        "        a['SRC'] = a['SRC'][:truncidx]\n",
        "        a['BKGD'] = a['BKGD'][:truncidx]\n",
        "        print(\"    NIRS trunc:\",a['NIRS'].shape)\n",
        "\n",
        "        # AUX TRUNCATION\n",
        "        for key in a.keys():\n",
        "            print(\"    %s orig:\" %key, a[key].shape)\n",
        "            samplerate = sensors[key]['samplerate']\n",
        "            totaltime = len(a[key])/float(samplerate)  # sec\n",
        "            numrec = int(totaltime/recdur)      # N\n",
        "            truncidx = numrec*recdur*samplerate\n",
        "            a[key] = a[key][:truncidx]\n",
        "            print(\"    %s trunc:\" %key, a[key].shape)\n",
        "\n",
        "        ### STORE DATASETS\n",
        "        print(\"  Storing data segment ...\")\n",
        "        write_edf(outprefix,a,config,sensors=sensors,segstart=segstart,segend=segend)\n",
        "\n",
        "        # CHECK IF DONE\n",
        "        if len(a['SRC'])<((segend-segstart)*25-5):\n",
        "            break\n",
        "    ##DONE WITH ALL EDF SEGMENTS\n",
        "    return\n",
        "\n",
        "\n",
        "def write_edf(outprefix,a,config,sensors=DEFAULTsensors,segstart=0,segend=1000000):\n",
        "\n",
        "    seglength = segend-segstart\n",
        "\n",
        "    ### STORE DATASETS\n",
        "    print(\"  Storing data segments ...\")\n",
        "    for k in a.keys():\n",
        "        x = np.array(a[k],np.float)\n",
        "        x[np.isnan(x)] = 0      # get rid of any NaNs which mess up the while condition below\n",
        "        if len(x):\n",
        "            # divide amplitudes by 2 until they fit into int16\n",
        "            while 2*np.std(np.abs(x))>32767:\n",
        "                x = x/2.  # divide as float to avoid quantization\n",
        "            x = np.array(x,np.int16)\n",
        "        #    sensors[k]['physmin'] = round(np.min(x))\n",
        "        #    sensors[k]['physmax'] = round(np.max(x))\n",
        "#            print k, np.min(x), np.max(x)\n",
        "            sensors[k]['data'] = x\n",
        "            print(\"    \",k,sensors[k]['data'].shape, np.min(x), np.max(x))\n",
        "        else:\n",
        "            print(\"PROBLEM: popping\",k)\n",
        "            a.pop(k)\n",
        "\n",
        "    ### BUILD EDF VARIABLES BASED ON sensors DICTIONARY\n",
        "    Nsignals = 0\n",
        "    labels = []\n",
        "    transducertypes = []\n",
        "    units = []\n",
        "    physmin = []\n",
        "    physmax = []\n",
        "    digmin = []\n",
        "    digmax = []\n",
        "    prefilter = []\n",
        "    samplesperrecord = []\n",
        "\n",
        "    # REORDER KEYS SO NIRS STUFF IS AT THE END (FOR A .EDF FILE)\n",
        "    allkeys = list(a.keys())\n",
        "    atend = []\n",
        "    if 'NIRS' in allkeys:\n",
        "        atend.append('NIRS')\n",
        "        allkeys.remove('NIRS')\n",
        "    if 'SRC' in allkeys:\n",
        "        atend.append('SRC')\n",
        "        allkeys.remove('SRC')\n",
        "    if 'BKGD' in allkeys:\n",
        "        atend.append('BKGD')\n",
        "        allkeys.remove('BKGD')\n",
        "\n",
        "    # START BUILDING HEADER STRINGS\n",
        "    for k in allkeys+atend:\n",
        "        s = sensors[k]\n",
        "        if 'data' not in s:\n",
        "            print(\"---> SKIPPING %s: no 'data' key to store\" %k)\n",
        "            continue\n",
        "        chan = s['channels']\n",
        "        Nsignals += chan\n",
        "        for ch in range(chan):\n",
        "            labels += [s['label']+str(ch)]\n",
        "            samplesperrecord += [s['samplerate']*recdur]\n",
        "            if type(s['HPF'])==type(list):\n",
        "                prefilter += [\"HP:%1.3fHz  LP:%1.3fHz\" %(s['HPF'][ch],s['LPF'][ch])]\n",
        "            else:\n",
        "                prefilter += [\"HP:%1.3fHz  LP:%1.3fHz\" %(s['HPF'],s['LPF'])]\n",
        "        transducertypes += [s['transducertype']]*s['channels']\n",
        "        units += [s['units']]*sensors[k]['channels']\n",
        "        physmin += [s['physmin']]*s['channels']\n",
        "        physmax += [s['physmax']]*s['channels']\n",
        "        digmin += [s['digmin']]*s['channels']\n",
        "        digmax += [s['digmax']]*s['channels']\n",
        "\n",
        "    # DETERMINE DURATION FOR SEGMENTING\n",
        "    if a['NIRS'] is not None:\n",
        "        dur = len(a['NIRS'])/25.  # calc from NIRS data\n",
        "    else:\n",
        "        dur = len(a['EstG'])/float(sensors['EstG']['samplerate'])\n",
        "    Nrec = int(np.floor(dur/float(recdur)))\n",
        "    numrec = int(dur/recdur)      # N\n",
        "\n",
        "    ### REQUEST STUFF NEEDED FOR EDF BUT NOT AVAILABLE IN NIN-M FILE\n",
        "    subjID = 'subjcode' #raw_input(\"Enter subject name/code:\")\n",
        "    subjsex = 'M' #raw_input(\"Enter subject sex (M/F):\")\n",
        "    subjsex = str.upper(subjsex)\n",
        "    subjbday = '01-jan-1950' #raw_input(\"Enter subject birthday (e.g. 01-JAN-1950):\")\n",
        "    hospitalcode = \"MGH\"     # no spaces allowed\n",
        "    patientname = 'X'\n",
        "    device = \"M2015002\"      # no spaces allowed; @@@add to header info\n",
        "    localID = str.join([hospitalcode+device+subjID, subjsex, subjbday, patientname],' ')\n",
        "\n",
        "\n",
        "    ### BUILD EDF(+)-COMPATIBLE HEADER\n",
        "    print(\"\\nStart:\",time.asctime(time.localtime()))\n",
        "    print(\"\\nBuilding EDF header ...\")\n",
        "\n",
        "    # FIRST, GENERIC 256 BYTES\n",
        "    header = ''\n",
        "    header += pad2('0',8)\n",
        "    header += pad2(subjID,80)         # SUBJECT-ID\n",
        "    header += pad2(localID,80)        # LOCAL-SUBJECT-ID\n",
        "    shortdate = config['date'][:6]+config['date'][-2:]  # DATE\n",
        "    header += shortdate               # RECORDING START-DATE, dd.mm.yy\n",
        "    header += config['time']          # RECORDING START-TIME, hh.mm.ss\n",
        "    header += '%s'            # placeholder for numheaderbytes\n",
        "    header += pad2('RESERVED',44)     # RESERVED\n",
        "    header += pad2(str(Nrec),8)       # NUMBER OF RECORDS\n",
        "    header += pad2(str(recdur),8)     # DURATION OF EACH RECORD\n",
        "    header += pad2(str(Nsignals),4)   # NUMBER OF SIGNALS\n",
        "\n",
        "    # SENSOR-SPECIFIC STUFF, 256 BYTES PER SENSOR\n",
        "    header += multipad2(labels,16)    # LABEL\n",
        "    header += multipad2(transducertypes,80)  # TRANSDUCER TYPE\n",
        "    header += multipad2(units,8)      # UNITS\n",
        "    header += multipad2(physmin,8)    # MIN PHYSICAL UNITS\n",
        "    header += multipad2(physmax,8)    # MAX PHYSICAL UNITS\n",
        "    header += multipad2(digmin,8)     # MIN DIGITAL VAL\n",
        "    header += multipad2(digmax,8)     # MAX DIGITAL VAL\n",
        "    header += multipad2(prefilter,80) # PREFILTER STRING\n",
        "    header += multipad2(samplesperrecord,8)  # SAMPLES PER RECORD\n",
        "    header += multipad2(['reserved']*Nsignals,32)  # RESERVED\n",
        "    # NOW THAT IT'S BUILT, INSERT HEADER LENGTH (6 char more than the %s placeholder above)\n",
        "    header = header %(pad2(str(len(header)+6),8))\n",
        "\n",
        "\n",
        "    # BUILD THE DATA RECORDS SECTION\n",
        "    print(\"  Building data records ...\", end=' ')\n",
        "    print(dur, numrec, Nrec, len(a['EstG']))\n",
        "    records_in_this_segment = int( (segend-segstart)/float(recdur) )\n",
        "    # clean up this one\n",
        "\n",
        "    # PREPARE TO WRITE OUT .EDF FILE\n",
        "    print(\"  Writing out EDF file\")\n",
        "    if seglength in [-1,1000000]:\n",
        "        outname = outprefix+'.edf'\n",
        "    else:\n",
        "        outname = outprefix+'-%i-%i.edf' %(segstart,segend)\n",
        "\n",
        "    out = ''\n",
        "    with open(outname,'wb') as f:\n",
        "        # WRITE OUT HEADER\n",
        "        f.write(header)\n",
        "\n",
        "        # LOOP OVER RECORDS\n",
        "        for rec in range(Nrec): #records_in_this_segment):\n",
        "            if rec%1000==0:\n",
        "                f.write(out)\n",
        "                out = ''\n",
        "                print(rec, end=' ')\n",
        "            for k in allkeys+atend:\n",
        "                if 'data' not in sensors[k]:\n",
        "                    continue\n",
        "                s = sensors[k]\n",
        "                recsamp = s['samplerate']*recdur\n",
        "                for chan in range(s['channels']):\n",
        "                    if s['channels']>1:\n",
        "                        x = s['data'][rec*recsamp:(rec+1)*recsamp,chan]\n",
        "                    else:\n",
        "                        x = s['data'][rec*recsamp:(rec+1)*recsamp]\n",
        "                    out += struct.pack('<'+'h'*len(x),*x)\n",
        "        # WRITE OUT ANY LEFTOVERS\n",
        "        f.write(out)\n",
        "    #        if rec%10==0:\n",
        "    #            print \" \",rec,len(out)\n",
        "    #        if rec>segend-segstart:\n",
        "    #            break\n",
        "    print(\"\\nEnd:\",time.asctime(time.localtime()),\"   %s\\n\" %outname)\n",
        "\n",
        "    return\n",
        "\n",
        "\n",
        "def nin2mat(fname,unwrapgain=1,seglength=-1,geometry=None,trim=1,outname=None):\n",
        "    \"\"\"\n",
        "\n",
        "Converts RAW data from .NIN file to one or more .MAT files. 'seglength'\n",
        "determines the lenth of time included in each .MAT file (in sec; -1=whole file).\n",
        "NO filtering is conducted.\n",
        "\n",
        "RETURNS: None, but saves files with fname[:-4]+starttime-endtime.mat\n",
        "\"\"\"\n",
        "    print(\"\\nnin2mat(): Starting main loop ...\")\n",
        "    segnum = 0\n",
        "    while True:\n",
        "        if seglength==-1:\n",
        "            segstart = 0\n",
        "            segend = 1000000\n",
        "        else:\n",
        "            segstart = segnum*seglength\n",
        "            segend = (segnum+1)*seglength\n",
        "        print(\"  Loading data files for ...\",segstart, segend)\n",
        "        a, td, ta, events, config = load_nin(fname,segstart,segend,trim=trim,keepraw=True,verbose=True)\n",
        "        diff = a['NIRS']\n",
        "        raw = a['SRC']\n",
        "        bkgd = a['BKGD']\n",
        "        segnum += 1\n",
        "\n",
        "        # WRITE OUT .MAT FILE\n",
        "        if outname is None:\n",
        "            outprefix = fname[:-4]\n",
        "        else:\n",
        "            outprefix = outname*1\n",
        "\n",
        "        if seglength==-1:\n",
        "            savename = outprefix+'-raw.mat'\n",
        "        else:\n",
        "            savename = outprefix+'-raw-%i-%i.mat' %(segstart,segend)\n",
        "\n",
        "        print(\"Saving .MAT file ...\",savename)\n",
        "        if 'filt_param' in config:\n",
        "            if config['filt_param']=={}:\n",
        "                config.pop('filt_param')\n",
        "        outdict = {\n",
        "                   'raw':raw,\n",
        "                   'bkgd':bkgd,\n",
        "                   'd':diff,\n",
        "                   'buttonA':events[0],\n",
        "                   'buttonB':events[1],\n",
        "                   'buttonC':events[2],\n",
        "                   'buttonD':events[3],\n",
        "                   'ml':np.array(FULLml),\n",
        "                   'td':td,\n",
        "                   'ta':ta,\n",
        "                   'gainunwrapped':unwrapgain,\n",
        "                   'config':config,\n",
        "                  }\n",
        "        outdict.update(a)\n",
        "        outdict = add_geometry(outdict,geometry)\n",
        "        sio.savemat(savename,outdict)\n",
        "\n",
        "        # CHECK IF DONE\n",
        "        if len(raw)<((segend-segstart)*25-5):\n",
        "            break\n",
        "    ## DONE\n",
        "    return\n",
        "\n",
        "\n",
        "def nin2nirs(fname,unwrapgain=1,seglength=-1,geometry=None,trim=1,outname=None):\n",
        "    \"\"\"\n",
        "\n",
        "Converts RAW data from .NIN file to one or more .nirs (Homer/Matlab) files. 'seglength'\n",
        "determines the lenth of time included in each .nirs file (in sec; -1=whole file).\n",
        "NO filtering is conducted.\n",
        "\n",
        "RETURNS: None, but saves files with fname[:-4]+starttime-endtime.nirs\n",
        "\"\"\"\n",
        "    print(\"\\nnin2nirs(): Starting main loop ...\")\n",
        "    segnum = 0\n",
        "    while True:\n",
        "        if seglength==-1:\n",
        "            segstart = 0\n",
        "            segend = 1000000\n",
        "        else:\n",
        "            segstart = segnum*seglength\n",
        "            segend = (segnum+1)*seglength\n",
        "        print(\"  Loading data files for ...\",segstart, segend)\n",
        "        a, td, ta, events, config = load_nin(fname,segstart,segend,trim=trim,keepraw=True,verbose=True)\n",
        "        diff = a['NIRS']\n",
        "        raw = a['SRC']\n",
        "        bkgd = a['BKGD']\n",
        "        segnum += 1\n",
        "\n",
        "        # WRITE OUT .MAT FILE\n",
        "        if outname is None:\n",
        "            outprefix = fname[:-4]\n",
        "        else:\n",
        "            outprefix = outname*1\n",
        "\n",
        "        if seglength==-1:\n",
        "            savename = outprefix+'-raw.nirs'\n",
        "        else:\n",
        "            savename = outprefix+'-raw-%i-%i.nirs' %(segstart,segend)\n",
        "\n",
        "        # FIX ML TO COUNT FROM 1 and add 2 more columns\n",
        "        ml = []\n",
        "        for i in range(len(FULLml)):\n",
        "            if FULLml[i][0]%2:\n",
        "                wavelen = 2  # 780nm\n",
        "            else:\n",
        "                wavelen = 1  # 830nm\n",
        "            ml.append([FULLml[i][0]+1, FULLml[i][1]+1, 0, wavelen])  # SRC,DET,0=CW,0/1 for wavelengths\n",
        "        ml = np.array(ml)\n",
        "\n",
        "        # CREATE GEOMETRY PIECES\n",
        "        pSrc,pDet = get_geometry(geometry)\n",
        "        SD = {'SrcPos': pSrc,\n",
        "              'DetPos': pDet,\n",
        "              'Lambda': DEFAULTwavelengths,\n",
        "              'nSrcs':8,\n",
        "              'nDets':8,\n",
        "              'MeasList':ml\n",
        "             }\n",
        "\n",
        "        s = np.zeros((len(td),1))\n",
        "        s[0] = 1\n",
        "        # STILL MISSING THE StimDesign PIECE\n",
        "        #StimDesign - this is a structure to denote the stimulus timing\n",
        "        #StimDesign.name - the condition name\n",
        "        #StimDesign.onset - The list of times (in seconds) for the onset of events\n",
        "        #StimDesign.dur - The list of times (in seconds) for the duration of events\n",
        "        #StimDesign.amp - The list of amplitudes of events (used in parametric designs)\n",
        "\n",
        "        print(\"Saving .nirs file ...\",savename)\n",
        "        if 'filt_param' in config:\n",
        "            if config['filt_param']=={}:\n",
        "                config.pop('filt_param')\n",
        "        outdict = {\n",
        "#                   'raw':raw,\n",
        "#                   'bkgd':bkgd,\n",
        "                   'd':diff,\n",
        "                   't':td,\n",
        "                   'ml':ml,\n",
        "                   'SD':SD,\n",
        "                   's':s,\n",
        "                   'buttonA':events[0],\n",
        "                   'buttonB':events[1],\n",
        "                   'buttonC':events[2],\n",
        "                   'buttonD':events[3],\n",
        "                   'gainunwrapped':unwrapgain,\n",
        "                   'config':config,\n",
        "                  }\n",
        "        outdict.update(a)\n",
        "        sio.savemat(savename,outdict)\n",
        "\n",
        "        # CHECK IF DONE\n",
        "        if len(raw)<((segend-segstart)*25-5):\n",
        "            break\n",
        "    ## DONE\n",
        "    return\n",
        "\n",
        "\n",
        "def clump_bycolor64(d,axis=0):\n",
        "    \"\"\"\n",
        "\n",
        "Take a standard N x 64-channel data structure and reorder it so\n",
        "that instead of all detectors for S0/1/2/3/4/5/6/7\n",
        "you get all detectors for S0/2/4/6/1/3/5/7  (i.e., grouped by wavelength).\n",
        "You can reorder either axis=0 (measurement lists) or axis=1 (data)\n",
        "\n",
        "RETURNS:  reordered version of d\n",
        "\"\"\"\n",
        "    out = np.concatenate([d[0:8],\n",
        "                          d[16:24],\n",
        "                          d[32:40],\n",
        "                          d[48:56],\n",
        "                          d[8:16],\n",
        "                          d[24:32],\n",
        "                          d[40:48],\n",
        "                          d[56:64]],axis)\n",
        "    return out\n",
        "\n",
        "\n",
        "def nin_reorg_byml(d,ml):\n",
        "    \"\"\"\n",
        "\n",
        "Select channels from 'd' pointed to by ml's SD-pairs. Requires\n",
        "a python-compatible ml (src/det #s 0-7).\n",
        "\n",
        "RETURNS: Time x len(ml)\n",
        "\"\"\"\n",
        "    outd = []\n",
        "    for row in ml:\n",
        "        outd.append(d[:,row[0]*8+row[1]])\n",
        "    return np.array(outd)\n",
        "\n",
        "\n",
        "def nin_reorg_byPMIml(d,PMIml):\n",
        "    \"\"\"\n",
        "\n",
        "Select channels from 'd' pointed to by ml's SD-pairs. Requires\n",
        "a python-compatible ml (src/det #s 0-7).\n",
        "\n",
        "RETURNS: Time x len(ml)\n",
        "\"\"\"\n",
        "    outd = []\n",
        "    for row in PMIml:\n",
        "        outd.append(d[:,int(row[4])])\n",
        "    return np.array(outd)\n",
        "\n",
        "\n",
        "def nin_ml2PMIml(ml):\n",
        "    \"\"\"\n",
        "\n",
        "Takes a ml (list of [src,det] pairs) and reorganizes it so that all even\n",
        "sources (830nm) are at the top and all odd sources (780nm) are at the\n",
        "bottom. Adds the column of 1s and wavelength number too.\n",
        "\n",
        "RETURNS:  PMI-compatible ml ordering\n",
        "\"\"\"\n",
        "    # FIRST, SORT ACCORDING TO WAVELENGTH\n",
        "    PMIml1 = []\n",
        "    PMIml2 = []\n",
        "\n",
        "    for row in ml:\n",
        "        if row[0] in [0,2,4,6]:\n",
        "            PMIml1.append(list(row)+[1,1,row[0]*8+row[1]])\n",
        "        elif row[0] in [1,3,5,7]:\n",
        "            PMIml2.append(list(row)+[1,2,row[0]*8+row[1]])\n",
        "    newml = np.array(PMIml1+PMIml2)\n",
        "    # THEN MAKE CORRECTIONS FOR PMI REQUIREMENTS\n",
        "    newml[:,0] = np.floor(newml[:,0]/2.)  # src0/1-->0, src2/3-->1, etc.\n",
        "#    newml = np.array(newml, np.float)     # convert to ints\n",
        "    newml[:,:2] = newml[:,:2] +1          # adjust for counting from 0\n",
        "    return newml\n",
        "\n",
        "\n",
        "def get_pmistruct(geometry, wavelengths=DEFAULTwavelengths, **kwargs):\n",
        "    \"\"\"\n",
        "\n",
        "Returns a default PMI structure into which data2pmistruct() loads in the data\n",
        "that is to be imaged.\n",
        "\n",
        "RETURNS: ds structure (minus ds['data']['Raw'] and MeasList elements)\n",
        "\"\"\"\n",
        "    pSrc,pDet = get_geometry(geometry)\n",
        "\n",
        "    ### FORWARD MODEL STRUCTURE\n",
        "    ds = {}\n",
        "    ds['Fwd']={}\n",
        "    ds['Debug'] = 0\n",
        "    ds['Fwd']['ModFreq'] = 0.\n",
        "    ds['Fwd']['Lambda'] = np.array(wavelengths,np.float)\n",
        "    ds['Fwd']['idxRefr'] = np.array([1.37,1.37])\n",
        "    ds['Fwd']['Mu_a'] = np.array([0.02, 0.02])  # cm-1\n",
        "    ds['Fwd']['Mu_s'] = np.array([50., 50.])  # cm-1\n",
        "    ds['Fwd']['g'] = np.array([0.9, 0.9])\n",
        "    ds['Fwd']['Mu_sp'] = ds['Fwd']['Mu_s']*(1-ds['Fwd']['g'])\n",
        "    ds['Fwd']['v'] = 2.99e10/ds['Fwd']['idxRefr']\n",
        "    ds['Fwd']['Det'] = {}\n",
        "    ds['Fwd']['Det']['Type'] = 'list'\n",
        "    ds['Fwd']['Det']['Pos'] = np.array(pDet)/10.\n",
        "    ds['Fwd']['Det']['Amplitude'] = np.ones((ds['Fwd']['Det']['Pos'].shape[0],2))*1.\n",
        "    ds['Fwd']['Src'] = {}\n",
        "    ds['Fwd']['Src']['Type'] = 'list'\n",
        "    ds['Fwd']['Src']['Pos'] = np.array(pSrc[0::2])/10.  # USE EVEN ONES ONLY (EVEN/ODD IN SAME PLACES)\n",
        "    ds['Fwd']['Src']['Amplitude'] = np.ones((ds['Fwd']['Src']['Pos'].shape[0],2))*1.\n",
        "    ds['Fwd']['Boundary'] = {}\n",
        "    ds['Fwd']['Boundary']['Geometry'] = 'semi-infinite'\n",
        "    ds['Fwd']['Boundary']['Thickness'] = 3.5\n",
        "    ds['Fwd']['Method'] = {}\n",
        "    ds['Fwd']['Method']['Type'] = 'Rytov'\n",
        "\n",
        "    # DATA STRUCTURE\n",
        "    ds['data'] = {}\n",
        "    ds['data']['Lambda'] = np.array(wavelengths,np.float)\n",
        "    ds['data']['nWavelengths'] = len(ds['data']['Lambda'])\n",
        "    ds['data']['idxRefr'] = np.array([1.37,1.37])\n",
        "    ds['data']['v'] = 2.99e10/ds['data']['idxRefr']\n",
        "    ds['data']['ModFreq'] = 0.\n",
        "\n",
        "    # INVERSE MODEL STRUCTURE\n",
        "    ds['Inv'] = {}\n",
        "    ds['Inv']['Lambda'] = np.array(wavelengths)\n",
        "    ds['Inv']['idxRefr'] = np.array([1.37,1.37])\n",
        "    ds['Inv']['v'] = 2.99e10/ds['Fwd']['idxRefr']\n",
        "    ds['Inv']['ModFreq'] = 0.\n",
        "    ds['Inv']['Det'] = {}\n",
        "    ds['Inv']['Det']['Type'] = 'list'\n",
        "    ds['Inv']['Det']['Pos'] = np.array(pDet)/10.\n",
        "    ds['Inv']['Det']['Amplitude'] = np.ones((ds['Fwd']['Det']['Pos'].shape[0],2))*1.\n",
        "    ds['Inv']['Src'] = {}\n",
        "    ds['Inv']['Src']['Type'] = 'list'\n",
        "    ds['Inv']['Src']['Pos'] = np.array(pSrc[0::2])/10.\n",
        "    ds['Inv']['Src']['Amplitude'] = np.ones((ds['Fwd']['Src']['Pos'].shape[0],2))*1.\n",
        "    ds['Inv']['Mu_a'] = np.array([0.02, 0.02])\n",
        "    ds['Inv']['Mu_s'] = np.array([50., 50.])  # cm-1\n",
        "    ds['Inv']['g'] = np.array([0.9, 0.9])\n",
        "    ds['Inv']['Mu_sp'] = ds['Fwd']['Mu_s']*(1-ds['Fwd']['g'])\n",
        "    ds['Inv']['Boundary'] = {}\n",
        "    ds['Inv']['Boundary']['Geometry'] = 'semi-infinite'\n",
        "    ds['Inv']['Boundary']['Thickness'] = 3.5\n",
        "    ds['Inv']['Method'] = {}\n",
        "    ds['Inv']['Method']['Type'] = 'Rytov'\n",
        "    ds['Inv']['Method']['ObjVec_mua'] = 1.\n",
        "    ds['Inv']['Method']['ObjVec_musp'] = 0.\n",
        "    ds['Inv']['Method']['ObjVec_sd'] = 0.\n",
        "    ds['Inv']['CompVol'] = {}\n",
        "    ds['Inv']['CompVol']['Type'] = 'uniform'\n",
        "    ds['Inv']['CompVol']['XStep'] = 1.\n",
        "    ds['Inv']['CompVol']['YStep'] = 1.\n",
        "    ds['Inv']['CompVol']['ZStep'] = 1.\n",
        "    ds['Inv']['CompVol']['X'] = np.arange(12)*1.\n",
        "    ds['Inv']['CompVol']['Y'] = np.arange(5)*1.\n",
        "    ds['Inv']['CompVol']['Z'] = [0.01, 1.01, 2.01, 3.01]\n",
        "    ds['Inv']['nSrcs'] = float(len(ds['Inv']['Src']['Pos']))\n",
        "    ds['Inv']['nDets'] = float(len(ds['Inv']['Det']['Pos']))\n",
        "    ds['Inv']['nLambda'] = float(len(ds['Inv']['Lambda']))\n",
        "\n",
        "    ds['Recon'] = {}\n",
        "    ds['Recon']['ReconAlg'] = 'TSVD'\n",
        "    ds['Recon']['TSVD_nSV'] = 10.\n",
        "    ds['Recon']['TSVD_Lsq'] = 0.\n",
        "    ds['Recon']['TSVD_FullSVS'] = 1.\n",
        "    ds['Recon']['TSVD_CalcSVD'] = 1.\n",
        "    ds['Recon']['Whiten'] = 0.\n",
        "\n",
        "    # THESE ARE ESSENTIAL BUT ADDED TO THE BASIC ds STRUCTURE LATER\n",
        "    #ds['Fwd']['MeasList'] = reorg_ml\n",
        "    #ds['data']['Nframes'] = len(diff)\n",
        "    #ds['data']['Raw'] = clump_bycolor(diff,1)\n",
        "    #ds['data']['Raw_std'] = 100.e-6*np.ones(ds['data']['Raw'].shape)\n",
        "    #ds['data']['MeasList'] = reorg_ml\n",
        "    #ds['Inv']['nMeas'] = len(ds['Inv']['MeasList'])\n",
        "    #ds['Inv']['MeasList'] = reorg_ml\n",
        "\n",
        "    return ds\n",
        "\n",
        "\n",
        "def data2pmistruct(d,ds,ml=FULLml):\n",
        "    \"\"\"\n",
        "\n",
        "Adds the data in d (possibly with a non-standard ml) to the existing\n",
        "PMI structure ds (from get_pmistruct()). Pass in the FULL d (Time x 64)\n",
        "and the PRUNED ml (so the function grabs the right channels from d).\n",
        "\n",
        "RETURNS: new ds with Fwd/Inv/data.Raw and MeasList components added\n",
        "\"\"\"\n",
        "    # RENUMBER & REORGANIZE NIN ml INTO PMI MeasList FORMAT\n",
        "    print(\"\\nStarting data2pmistruct()\")\n",
        "    reorg_ml = nin_ml2PMIml(np.array(ml,np.float))   # put 830s first, 780s second\n",
        "    ds['Fwd']['MeasList'] = reorg_ml\n",
        "\n",
        "    ds['data']['Nframes'] = len(d)\n",
        "    d = np.where(d<1e-6,1e-6,d)\n",
        "    ds['data']['Raw'] = nin_reorg_byPMIml(d,reorg_ml)   # put 830s first, 780s second\n",
        "    ds['data']['Raw_std'] = 100.e-6*np.ones(ds['data']['Raw'].shape)\n",
        "    ds['data']['MeasList'] = reorg_ml\n",
        "\n",
        "    # INVERSE MODEL\n",
        "    ds['Inv']['MeasList'] = reorg_ml\n",
        "    ds['Inv']['nMeas'] = len(ds['Inv']['MeasList'])\n",
        "\n",
        "    return ds\n",
        "\n",
        "\n",
        "def nin2pmi(fname,filt_param=DEFAULTfilt_param,seglength=-1,ml=FULLml,goodml_nin=None,geometry=None,outname=None):\n",
        "    \"\"\"\n",
        "\n",
        "Converts a .nin file to one or more PMI-style .MAT files.\n",
        "'filt_param' is a dictionary like {'NIRS':[LPF,HPF]}\n",
        "'seglength' determines the lenth of time included in each .MAT file\n",
        "   (in sec; -1=whole file)\n",
        "Always does unwrapgain and trim.\n",
        "\n",
        "RETURNS: None, but saves files with fname[:-4]+starttime-endtime.mat\n",
        "\"\"\"\n",
        "    print(\"\\nnin2pmi(): Starting main loop ...\")\n",
        "\n",
        "    base_ds = get_pmistruct(geometry,unwrapgain=1)\n",
        "\n",
        "    segnum = 0\n",
        "    while True:\n",
        "        if seglength==-1:\n",
        "            segstart = 0\n",
        "            segend = 1000000\n",
        "        else:\n",
        "            segstart = segnum*seglength\n",
        "            segend = (segnum+1)*seglength\n",
        "\n",
        "        ### LOAD IN DATA FILE (SEGMENT), DROPPING RAW NIRS DATA\n",
        "        print(\"  Loading data files for ...\",segstart, segend)\n",
        "        a, td, ta, events, config = load_nin(fname,segstart,segend,trim=1,verbose=True,keepraw=False)\n",
        "        segnum += 1  # prepare for next cycle\n",
        "\n",
        "        # UNWRAP GAIN, AUX-CONVERT & FILTER\n",
        "        a, config = nin_convert(a,config,unwrapgain=1,filt_param=filt_param)\n",
        "        diff = a['NIRS']\n",
        "\n",
        "        ### ATTACH FULL RAW DATA TO PMI STRUCTURE\n",
        "        ds = data2pmistruct(diff,base_ds,FULLml)\n",
        "\n",
        "        ### DO TENTATIVE PRUNING\n",
        "        # goodml_nin counts from S0-7, D0-7\n",
        "        if goodml_nin is None:\n",
        "            goodml_nin = nin_ML(diff,config['BOARDgain'],GAINthresh=16,SNRwindow=[0,30],SNRthresh=2,geometry=geometry,DISTthresh=65)\n",
        "\n",
        "        # stick on CURRENT Matlab data-index (780s first, counting from 1)\n",
        "        idxs = []\n",
        "        for row in goodml_nin:\n",
        "            if row[0] in [0,2,4,6]:\n",
        "                idxs.append(int(row[0]/2*8+row[1]+1))\n",
        "            elif row[0] in [1,3,5,7]:\n",
        "                idxs.append(int(np.floor(row[0]/2)*8+row[1]+33))\n",
        "        goodml_nin = np.hstack((goodml_nin, np.array(idxs)[:,None]))\n",
        "        # goodml_pmi counts from S1-4, D1-7\n",
        "        goodml_pmi = nin_ml2PMIml(goodml_nin)\n",
        "        print(\"goodml_pmi =\")\n",
        "        print(goodml_pmi)\n",
        "\n",
        "        if not geometry:\n",
        "            print(\"NOTE!!!! You did not specify a geometry!\")\n",
        "        else:\n",
        "            print(\"geometry =\",geometry)\n",
        "\n",
        "        # WRITE OUT .MAT FILE\n",
        "        if outname is None:\n",
        "            outprefix = fname[:-4]\n",
        "        else:\n",
        "            outprefix = outname\n",
        "\n",
        "        if seglength==-1:\n",
        "            outname = outprefix+'-PMI.mat'\n",
        "        else:\n",
        "            outname = outprefix+'-PMI-%i-%i.mat' %(segstart,segend)\n",
        "\n",
        "        print(\"Saving .MAT file ...\",outname)\n",
        "        outdict = {\n",
        "                   'td':td,\n",
        "                   'gainunwrapped':1,\n",
        "                   'filt_param':filt_param,\n",
        "                   'config':config,\n",
        "                   'ds':ds,\n",
        "                   'goodml':goodml_nin,\n",
        "#                   'goodml_pmi':goodml_pmi,\n",
        "                  }\n",
        "        outdict = add_geometry(outdict,geometry)\n",
        "        sio.savemat(outname,outdict)\n",
        "\n",
        "        # CHECK IF DONE\n",
        "        if len(diff)<((segend-segstart)*25-5):\n",
        "            break\n",
        "    ## DONE\n",
        "    return\n",
        "\n",
        "\n",
        "def nin2filtmat(fname,filt_param=DEFAULTfilt_param,unwrapgain=1,seglength=-1,geometry=None,outname=None):\n",
        "    \"\"\"\n",
        "\n",
        "Converts a .NIN file to one or more .MAT files, saving out the data in\n",
        "standard variables but with a 'filt_param' structure explining what was\n",
        "filtered how. If unwrapgain=1, gains are unwrapped.\n",
        "\n",
        "'seglength' determines the length of time included in each .MAT file\n",
        "(in sec; -1=whole file)\n",
        "\n",
        "RETURNS: None, but saves files with fname[:-4]-filt-starttime-endtime.mat\n",
        "\"\"\"\n",
        "    print(\"\\nnin2filtmat(): Starting main loop ...\")\n",
        "    segnum = 0\n",
        "    while True:\n",
        "        if seglength==-1:\n",
        "            segstart = 0\n",
        "            segend = 1000000\n",
        "        else:\n",
        "            segstart = segnum*seglength\n",
        "            segend = (segnum+1)*seglength\n",
        "        print(\"  Loading data files for ...\",segstart, segend)\n",
        "        a, td, ta, events, config = load_nin(fname,segstart,segend,trim=1,verbose=True,keepraw=True)\n",
        "        diff = a['NIRS']\n",
        "        raw = a['SRC']\n",
        "        bkgd = a['BKGD']\n",
        "        segnum += 1\n",
        "\n",
        "        # UNWRAP GAIN, AUX-CONVERT & FILTER\n",
        "        a, config = nin_convert(a,config,unwrapgain=unwrapgain,filt_param=filt_param)\n",
        "\n",
        "        # WRITE OUT .MAT FILE\n",
        "        if outname is None:\n",
        "            outprefix = fname[:-4]\n",
        "        else:\n",
        "            outprefix = outname\n",
        "\n",
        "        if seglength==-1:\n",
        "            outname = outprefix+'-filt.mat'\n",
        "        else:\n",
        "            outname = outprefix+'-filt-%i-%i.mat' %(segstart,segend)\n",
        "\n",
        "        print(\"Saving .MAT file ...\",outname)\n",
        "        outdict = {\n",
        "                   'raw':raw,\n",
        "                   'bkgd':bkgd,\n",
        "                   'd':diff,\n",
        "                   'buttonA':events[0],\n",
        "                   'buttonB':events[1],\n",
        "                   'buttonC':events[2],\n",
        "                   'buttonD':events[3],\n",
        "                   'ml':FULLml,\n",
        "                   'td':td,\n",
        "                   'ta':ta,\n",
        "                   'filt_param':filt_param,\n",
        "                   'gainunwrapped':unwrapgain,\n",
        "                   'config':config,\n",
        "                  }\n",
        "        outdict.update(a)\n",
        "        outdict = add_geometry(outdict,geometry)\n",
        "        sio.savemat(outname,outdict)\n",
        "\n",
        "        # CHECK IF DONE\n",
        "        if len(raw)<((segend-segstart)*25-5):\n",
        "            break\n",
        "    ## DONE\n",
        "    return\n",
        "\n",
        "\n",
        "def nin2filtconvertmat(fname,filt_param=DEFAULTfilt_param,unwrapgain=1,seglength=-1,geometry=None,outname=None,SNRthresh=SNRthresh,DISTthresh=DISTthresh):\n",
        "    \"\"\"\n",
        "\n",
        "Converts a .NIN file to one or more .MAT files, saving out the data in\n",
        "standard variables but with a 'filt_param' structure explining what was\n",
        "filtered how. If unwrapgain=1, gains are unwrapped. OD and HHb/O2Hb data is\n",
        "included as well.\n",
        "\n",
        "'seglength' determines the length of time included in each .MAT file\n",
        "(in sec; -1=whole file)\n",
        "\n",
        "RETURNS: None, but saves files with fname[:-4]-filt-starttime-endtime.mat\n",
        "\"\"\"\n",
        "    print(\"\\nnin2filtconvertmat(): Starting main loop ...\")\n",
        "    segnum = 0\n",
        "    while True:\n",
        "        if seglength==-1:\n",
        "            segstart = 0\n",
        "            segend = 1000000\n",
        "        else:\n",
        "            segstart = segnum*seglength\n",
        "            segend = (segnum+1)*seglength\n",
        "\n",
        "        ### LOAD IN THIS CHUNK OF DATA\n",
        "        print(\"  Loading data files for ...\",segstart, segend)\n",
        "        a, td, ta, events, config = load_nin(fname,segstart,segend,trim=1,verbose=True,keepraw=True)\n",
        "        diff = a['NIRS']\n",
        "        raw = a['SRC']\n",
        "        bkgd = a['BKGD']\n",
        "        segnum += 1\n",
        "\n",
        "        # UNWRAP GAIN, AUX-CONVERT & FILTER\n",
        "        a, config = nin_convert(a,config,unwrapgain=unwrapgain,filt_param=filt_param)\n",
        "\n",
        "        ### COMPUTE \"GOOD\" MEASUREMENT LIST\n",
        "        ml = nin_ML(diff,config['BOARDgain'],GAINthresh=15,SNRwindow=[0,30],SNRthresh=SNRthresh,DISTthresh=75,verbose=False,geometry=geometry)\n",
        "\n",
        "        ### CONVERT TO OD\n",
        "        od = nin_makeOD(diff,baseline=None)\n",
        "\n",
        "        ### CONVERT TO CONCENTRATIONS\n",
        "        hbhbo,hbhboml = nin_od2hbhbo(od, wavelengths=DEFAULTwavelengths, BLs=[6,6])\n",
        "\n",
        "        ### PRUNE DATA TO KEEP ONLY GOOD MEASUREMENTS\n",
        "        pdiff = prune_data(diff,ml,bothwavelengths=False)\n",
        "        pod = prune_data(od,ml,bothwavelengths=False)\n",
        "        phbhbo = prune_hbdata(hbhbo,ml)\n",
        "\n",
        "        # WRITE OUT .MAT FILE\n",
        "        if outname is None:\n",
        "            outprefix = fname[:-4]\n",
        "        else:\n",
        "            outprefix = outname\n",
        "\n",
        "        if seglength==-1:\n",
        "            outname = outprefix+'-filt-convert.mat'\n",
        "        else:\n",
        "            outname = outprefix+'-filt-convert-%i-%i.mat' %(segstart,segend)\n",
        "\n",
        "        print(\"Saving .MAT file ...\",outname)\n",
        "        outdict = {\n",
        "                   'raw':raw,\n",
        "                   'bkgd':bkgd,\n",
        "                   'd':diff,\n",
        "                   'buttonA':events[0],\n",
        "                   'buttonB':events[1],\n",
        "                   'buttonC':events[2],\n",
        "                   'buttonD':events[3],\n",
        "                   'ml':FULLml,\n",
        "                   'td':td,\n",
        "                   'ta':ta,\n",
        "                   'filt_param':filt_param,\n",
        "                   'gainunwrapped':unwrapgain,\n",
        "                   'config':config,\n",
        "                   'ml':ml,\n",
        "                   'od':od,\n",
        "                   'hbhbo':hbhbo,\n",
        "                   'hbhboml':hbhboml,\n",
        "                   'pdiff':pdiff,\n",
        "                   'pod':pod,\n",
        "                   'phbhbo':phbhbo,\n",
        "                  }\n",
        "        outdict.update(a)\n",
        "        outdict = add_geometry(outdict,geometry)\n",
        "        sio.savemat(outname,outdict)\n",
        "\n",
        "        # CHECK IF DONE\n",
        "        if len(raw)<((segend-segstart)*25-5):\n",
        "            break\n",
        "    ## DONE\n",
        "    return\n",
        "\n",
        "\n",
        "def nin2mat_aux(fname,seglength=-1,sensors=DEFAULTsensors,verbose=False,outname=None):\n",
        "    \"\"\"\n",
        "Converts a .nin file to one or more .MAT files contining the aux data.\n",
        "'seglength' determines the lenth of time included in each .MAT file (in sec),\n",
        "where -1=whole file.\n",
        "\n",
        "RETURNS: None, but saves files with fname[:-4]-aux-starttime-endtime.mat\n",
        "\"\"\"\n",
        "    if verbose:  print(\"\\nnin2mat_aux(): Starting main loop ...\")\n",
        "    ta = None\n",
        "    td = None\n",
        "    segnum = 0\n",
        "    while True:\n",
        "        if seglength==-1:\n",
        "            segstart = 0\n",
        "            segend = 1000000\n",
        "        else:\n",
        "            segstart = segnum*seglength\n",
        "            segend = (segnum+1)*seglength\n",
        "        print(\"  Loading data files for ...\",segstart, segend)\n",
        "\n",
        "        ### LOAD DATASETS\n",
        "        print(\"  Getting small files\")\n",
        "        header = get_nin_header(fname)\n",
        "        config = get_nin_config(fname)\n",
        "        ev = get_nin_events(fname)\n",
        "        ea,eb,ec,ed = ev\n",
        "        print(\"  Getting auxiliaries\")\n",
        "        a = {}\n",
        "        for s in sensors:\n",
        "            if s in ['aux','']:\n",
        "                # DEFAULT TO GETTING ALL AUX SENSORS\n",
        "                a,td,ta = get_nin_aux(fname,s,segstart,segend)\n",
        "            else:\n",
        "                # OTHERWISE, GET REQUESTED ONE\n",
        "                a,td = get_nin_data(fname,s,segstart,segend,a)\n",
        "            segnum += 1\n",
        "#        print \"RIGHT after read:\",a\n",
        "\n",
        "        # MAKE SURE THEY'RE ALL THE SAME LENGTH\n",
        "        a,ta = trim_aux(a,segstart=segstart)\n",
        "\n",
        "        # WRITE OUT .MAT FILE\n",
        "        if outname is None:\n",
        "            outprefix = fname[:-4]\n",
        "        else:\n",
        "            outprefix = outname\n",
        "\n",
        "        if seglength==-1:\n",
        "            outname = outprefix+'-aux.mat'\n",
        "        else:\n",
        "            outname = outprefix+'-aux-%i-%i.mat' %(segstart,segend)\n",
        "\n",
        "        print(\"Saving .MAT file ...\",outname)\n",
        "#        print \"Before save:\",a\n",
        "        config.update(header)\n",
        "        outdict = {\n",
        "                   'ta':ta,\n",
        "                   'td':td,\n",
        "                   'buttonA':ea,\n",
        "                   'buttonB':eb,\n",
        "                   'buttonC':ec,\n",
        "                   'buttonD':ed,\n",
        "                   'config':config,\n",
        "                  }\n",
        "        outdict.update(a)\n",
        "        sio.savemat(outname,outdict)\n",
        "\n",
        "        # CHECK IF DONE\n",
        "        if ta is not None:\n",
        "            if len(ta)<((segend-segstart)*250-5):\n",
        "                break\n",
        "        if td is not None:\n",
        "            if len(td)<((segend-segstart)*25-5):\n",
        "                break\n",
        "    return\n",
        "\n",
        "\n",
        "def nin2mat_estg(fname,seglength=-1,verbose=False,outname=None):\n",
        "    \"\"\"\n",
        "\n",
        "Converts a .nin file to one or more .MAT files contining the E*G data (only).\n",
        "'seglength' determines the lenth of time included in each .MAT file (in sec;\n",
        "where -1=whole file).\n",
        "\n",
        "RETURNS: None, but saves files with fname[:-4]-estg-starttime-endtime.mat\n",
        "\"\"\"\n",
        "    if verbose:  print(\"\\nnin2mat_estg(): Starting main loop ...\")\n",
        "    segnum = 0\n",
        "    while True:\n",
        "        if seglength==-1:\n",
        "            segstart = 0\n",
        "            segend = 1000000\n",
        "        else:\n",
        "            segstart = segnum*seglength\n",
        "            segend = (segnum+1)*seglength\n",
        "        if verbose:  print(\"  Loading data files for ...\",segstart, segend)\n",
        "\n",
        "        ### LOAD DATASETS\n",
        "        if verbose: print(\"  Getting small files\")\n",
        "        header = get_nin_header(fname)\n",
        "        config = get_nin_config(fname)\n",
        "        ev = get_nin_events(fname)\n",
        "        ea,eb,ec,ed = ev\n",
        "\n",
        "        if verbose: print(\"  Getting E*G\")\n",
        "        a,ta = get_nin_data(fname,'EstG',segstart,segend)\n",
        "        estg = a['EstG']\n",
        "        segnum += 1\n",
        "\n",
        "        # WRITE OUT .MAT FILE\n",
        "        if outname is None:\n",
        "            outprefix = fname[:-4]\n",
        "        else:\n",
        "            outprefix = outname\n",
        "\n",
        "        if seglength==-1:\n",
        "            outname = outprefix+'-estg.mat'\n",
        "        else:\n",
        "            outname = outprefix+'-estg-%i-%i.mat' %(segstart,segend)\n",
        "\n",
        "        print(\"Saving .MAT file ...\",outname)\n",
        "        config.update(header)\n",
        "        outdict = {\n",
        "                   'ta':ta,\n",
        "                   'estg':estg,\n",
        "                   'buttonA':ea,\n",
        "                   'buttonB':eb,\n",
        "                   'buttonC':ec,\n",
        "                   'buttonD':ed,\n",
        "                   'config':config,\n",
        "                  }\n",
        "        sio.savemat(outname,outdict)\n",
        "\n",
        "        # CHECK IF DONE\n",
        "        if len(estg)<((segend-segstart)*250-5):\n",
        "            break\n",
        "    ##DONE\n",
        "    return\n",
        "\n",
        "\n",
        "def nin2parammats(fname,unwrapgain=1,AUXconvert=True,seglength=-1,outname=None):\n",
        "    \"\"\"\n",
        "\n",
        "Converts a .nin file to one or more .MAT files, each file being the\n",
        "entire timeseries from a single variable.\n",
        "\n",
        "RETURNS: None, but saves files with fname[:-4]+ 'aux.mat','estg.mat',etc.\n",
        "\"\"\"\n",
        "    print(\"\\nnin2parammats(): Starting main loop ...\")\n",
        "    segnum = 0\n",
        "    while True:\n",
        "        if seglength==-1:\n",
        "            segstart = 0\n",
        "            segend = 1000000\n",
        "        else:\n",
        "            segstart = segnum*seglength\n",
        "            segend = (segnum+1)*seglength\n",
        "        print(\"Processing small files ... for %i - %i\" %(segstart,segend))\n",
        "        ### LOAD SMALL FILES\n",
        "        header = get_nin_header(fname)\n",
        "        config = get_nin_config(fname)\n",
        "        ev = get_nin_events(fname)\n",
        "        ea,eb,ec,ed = ev\n",
        "\n",
        "        ### GET FILENAME PREFIX\n",
        "        if outname is None:\n",
        "            outprefix = fname[:-4]\n",
        "        else:\n",
        "            outprefix = outname\n",
        "\n",
        "        ### LOAD AND CONVERT NIRS DATA TO .MAT FILES\n",
        "        print(\"Processing NIRS data\")\n",
        "        for src in range(8):\n",
        "            print(\"  Loading SOURCE\",src)\n",
        "            n,td = get_nin_data(fname,'SRC'+str(src),segstart=segstart,segend=segend)\n",
        "            b,jnk = get_nin_data(fname,'BKG'+str(src),segstart=segstart,segend=segend)\n",
        "            ky = 'src'+str(src)\n",
        "            n = n[ky]\n",
        "            b = b[ky]\n",
        "\n",
        "            ### CLIP raw & bkgd TO SAME LENGTH\n",
        "            ln = min(len(n),len(b))\n",
        "            n = n[:ln]\n",
        "            b = b[:ln]\n",
        "            td = td[:ln]\n",
        "\n",
        "            ### UNWRAP GAIN FROM RAW DATA\n",
        "            if unwrapgain:\n",
        "                diff = (n-b).astype('float')\n",
        "                for det in range(8):\n",
        "                    diff[:,det] = diff[:,det] / (ProbeGains[config['PROBEgain'][src,det]] *\n",
        "                                                 BoardGains[config['BOARDgain'][src,det]])\n",
        "            else:\n",
        "                diff = n-b\n",
        "\n",
        "            ### SAVE .MAT FILE\n",
        "            print(\"   Saving SOURCE\",src)\n",
        "            if seglength==-1:\n",
        "                outname = outprefix+'-'+ky+'.mat'\n",
        "            else:\n",
        "                outname = outprefix+'-'+ky+'-%i-%i.mat' %(segstart,segend)\n",
        "            config.update(header)\n",
        "            outdict = {\n",
        "                       'raw':n,\n",
        "                       'bkgd':b,\n",
        "                       'd':diff,\n",
        "                       'td':td,\n",
        "                       'buttonA':ea,\n",
        "                       'buttonB':eb,\n",
        "                       'buttonC':ec,\n",
        "                       'buttonD':ed,\n",
        "                       'config':config,\n",
        "                      }\n",
        "            sio.savemat(outname,outdict)\n",
        "\n",
        "        ### LOAD AND CONVERT E*G DATA TO .MAT FILES\n",
        "        print(\"Processing E*G data\")\n",
        "        for eg in range(8):\n",
        "            print(\"  Loading E*G\",eg)\n",
        "            ky = 'EstG'+str(eg)\n",
        "            a,ta = get_nin_data(fname,ky,segstart=segstart,segend=segend)\n",
        "\n",
        "            ### SAVE .MAT FILE\n",
        "            print(\"   Saving E*G\",eg)\n",
        "            ky = ky.lower()\n",
        "            if seglength==-1:\n",
        "                outname = outprefix+'-'+ky+'.mat'\n",
        "            else:\n",
        "                outname = outprefix+'-'+ky+'-%i-%i.mat' %(segstart,segend)\n",
        "            config.update(header)\n",
        "            outdict = {\n",
        "                       ky:a['EstG'],\n",
        "                       'ta':ta,\n",
        "                       'buttonA':ea,\n",
        "                       'buttonB':eb,\n",
        "                       'buttonC':ec,\n",
        "                       'buttonD':ed,\n",
        "                       'config':config,\n",
        "                      }\n",
        "            sio.savemat(outname,outdict)\n",
        "\n",
        "        print(\"Processing ACCEL\")\n",
        "        aa,ta = get_nin_data(fname,'ACCE',segstart=segstart,segend=segend)\n",
        "        ### CONVERT AUX TO REAL UNITS\n",
        "        if AUXconvert:\n",
        "            aa = nin_convert_aux(aa)\n",
        "        ky = 'acc'\n",
        "        if seglength==-1:\n",
        "            outname = outprefix+'-'+ky+'.mat'\n",
        "        else:\n",
        "            outname = outprefix+'-'+ky+'-%i-%i.mat' %(segstart,segend)\n",
        "        if len(ta)>10:\n",
        "            config.update(header)\n",
        "            outdict = {\n",
        "                       ky:aa['ACCE'],\n",
        "                       'ta':ta,\n",
        "                       'buttonA':ea,\n",
        "                       'buttonB':eb,\n",
        "                       'buttonC':ec,\n",
        "                       'buttonD':ed,\n",
        "                       'config':config,\n",
        "                      }\n",
        "            sio.savemat(outname,outdict)\n",
        "\n",
        "        print(\"Processing GYRO\")\n",
        "        ag,ta = get_nin_data(fname,'GYRO',segstart=0,segend=-1)\n",
        "        ### CONVERT AUX TO REAL UNITS\n",
        "        if AUXconvert:\n",
        "            ag = nin_convert_aux(ag)\n",
        "        ky = 'gyro'\n",
        "        if seglength==-1:\n",
        "            outname = outprefix+'-'+ky+'.mat'\n",
        "        else:\n",
        "            outname = outprefix+'-'+ky+'-%i-%i.mat' %(segstart,segend)\n",
        "        if len(ta)>10:\n",
        "            config.update(header)\n",
        "            outdict = {\n",
        "                      ky:ag['GYRO'],\n",
        "                      'ta':ta,\n",
        "                      'buttonA':ea,\n",
        "                      'buttonB':eb,\n",
        "                      'buttonC':ec,\n",
        "                      'buttonD':ed,\n",
        "                      'config':config,\n",
        "                     }\n",
        "            sio.savemat(outname,outdict)\n",
        "\n",
        "        print(\"Processing TEMP\")\n",
        "        at,td = get_nin_data(fname,'TEMP',segstart=segstart,segend=segend)\n",
        "        ### CONVERT AUX TO REAL UNITS\n",
        "        if AUXconvert:\n",
        "            at = nin_convert_aux(at)\n",
        "        ky = 'temp'\n",
        "        if seglength==-1:\n",
        "            outname = outprefix+'-'+ky+'.mat'\n",
        "        else:\n",
        "            outname = outprefix+'-'+ky+'-%i-%i.mat' %(segstart,segend)\n",
        "        if len(td)>10:\n",
        "            config.update(header)\n",
        "            outdict = {\n",
        "                       ky:at['TEMP'],\n",
        "                       'td':td,\n",
        "                       'buttonA':ea,\n",
        "                       'buttonB':eb,\n",
        "                       'buttonC':ec,\n",
        "                       'buttonD':ed,\n",
        "                       'config':config,\n",
        "                      }\n",
        "            sio.savemat(outname,outdict)\n",
        "\n",
        "        print(\"Processing RESP\")\n",
        "        af,td = get_nin_data(fname,'FORC',segstart=segstart,segend=segend)\n",
        "        ### CONVERT AUX TO REAL UNITS\n",
        "        if AUXconvert:\n",
        "            af = nin_convert_aux(af)\n",
        "        ky = 'resp'\n",
        "        if seglength==-1:\n",
        "            outname = outprefix+'-'+ky+'.mat'\n",
        "        else:\n",
        "            outname = outprefix+'-'+ky+'-%i-%i.mat' %(segstart,segend)\n",
        "        if len(td)>10:\n",
        "            config.update(header)\n",
        "            outdict = {\n",
        "                       ky:af['FORC'],\n",
        "                       'td':td,\n",
        "                       'buttonA':ea,\n",
        "                       'buttonB':eb,\n",
        "                       'buttonC':ec,\n",
        "                       'buttonD':ed,\n",
        "                       'config':config,\n",
        "                      }\n",
        "            sio.savemat(outname,outdict)\n",
        "\n",
        "        # CHECK IF DONE\n",
        "        if ta is None:\n",
        "            ta = []\n",
        "        if td is None:\n",
        "            td = []\n",
        "        if len(ta)<((segend-segstart)*250-5) and len(td)<((segend-segstart)*25-5):\n",
        "            break\n",
        "\n",
        "        # IF NOT DONE, GO TO NEXT SEGMENT\n",
        "        segnum += 1\n",
        "\n",
        "    ## DONE\n",
        "    return\n",
        "\n",
        "\n",
        "\n",
        "################ MISC/CONVENIENCE FUNCTIONS ###############\n",
        "def fixstr(i,n):\n",
        "    s = str(i)\n",
        "    s = '0'*(n-len(s))+s\n",
        "    return s\n",
        "\n",
        "\n",
        "def pad2(s,n):\n",
        "    return s+(n-len(s))*' '\n",
        "\n",
        "\n",
        "def multipad2(lst,pad):\n",
        "    s = ''\n",
        "    for item in lst:\n",
        "        s += pad2(str(item),pad)\n",
        "    return s\n",
        "\n",
        "\n",
        "def dist(x,y):\n",
        "    d = np.array(x,np.float)-np.array(y,np.float)\n",
        "    return np.sqrt(np.sum(d**2))\n",
        "\n",
        "\n",
        "def calc_SNR(d,axis=0,window=None):\n",
        "    \"\"\"\n",
        "\n",
        "Calculate SNR over a time-window (in sec) from data in d (TIME x CHANNELS).\n",
        "\n",
        "RETURNS: 1D array of SNRs\n",
        "\"\"\"\n",
        "    ### CALCULATE SNR\n",
        "    if window is None:\n",
        "        windowstart = 0\n",
        "        windowend = len(d)\n",
        "    else:\n",
        "        windowstart = window[0]*SLOWRATE\n",
        "        windowend = window[1]*SLOWRATE\n",
        "    if axis==0:\n",
        "        SNR = np.mean(d[windowstart:windowend,:],axis)/np.std(d[windowstart:windowend,:],axis)\n",
        "    elif axis==1:\n",
        "        SNR = np.mean(d[:,windowstart:windowend],axis)/np.std(d[:,windowstart:windowend],axis)\n",
        "    return SNR\n",
        "\n",
        "\n",
        "def nin_SNR(d,window=None):\n",
        "    \"\"\"\n",
        "\n",
        "Calculate SNR over a time-window (in sec) from data in d (TIME x CHANNELS).\n",
        "If no window (in sec from recording-start), calculate SNR over whole recording.\n",
        "\n",
        "RETURNS: 8x8 array of SNRs\n",
        "\"\"\"\n",
        "    ### CALCULATE SNR\n",
        "    if window is None:\n",
        "        windowstart = 0\n",
        "        windowend = len(d)\n",
        "    else:\n",
        "        windowstart = int(window[0]*SLOWRATE)\n",
        "        windowend = int(window[1]*SLOWRATE)\n",
        "    SNR = np.mean(d[windowstart:windowend,:],0)/np.std(d[windowstart:windowend,:],0)\n",
        "    SNRmap = np.reshape(np.array(SNR),(8,8))\n",
        "    return SNRmap\n",
        "\n",
        "\n",
        "def nin_ML(d,boardgain,GAINthresh=16,SNRwindow=[0,60],SNRthresh=2,pSrc=None,pDet=None,geometry=None,DISTthresh=75,verbose=False):\n",
        "    \"\"\"\n",
        "\n",
        "Determine a \"good measurement\" list based on <GAINthresh, >SNRthresh, <DISTthresh\n",
        "\n",
        "RETURNS: list of [src,det] pairs that are \"good\" measurements\n",
        "\"\"\"\n",
        "\n",
        "    if geometry is not None:\n",
        "        pSrc,pDet = get_geometry(geometry)\n",
        "    else:\n",
        "        pSrc = None\n",
        "        pDet = None\n",
        "    SNR = nin_SNR(d,SNRwindow)\n",
        "    ml1 = []\n",
        "    ml2 = []\n",
        "    for item in FULLml:\n",
        "        src,det = item\n",
        "        if src not in [0,2,4,6]:  # doing pairs, so start with evens only\n",
        "            continue\n",
        "        if not boardgain[src,det]<GAINthresh:       # check 830nm gain\n",
        "#            print \"bad 830 board gain:\",boardgain[src,det]\n",
        "            continue\n",
        "        if not boardgain[src+1,det]<GAINthresh:     # see if 780nm gain is ALSO good\n",
        "#            print \"bad 780 board gain:\",boardgain[src,det]\n",
        "            continue\n",
        "        if not SNR[src,det]>SNRthresh:              # check SNR threshold 830\n",
        "#            print \"bad 830 SNR:\",SNR[src,det]\n",
        "            continue\n",
        "        if not SNR[src+1,det]>SNRthresh:            # check SNR threshold 780\n",
        "#            print \"bad 780 SNR:\",SNR[src,det]\n",
        "            continue\n",
        "        if pSrc is not None and pDet is not None:\n",
        "            if dist(pSrc[src/2],pDet[det])<DISTthresh:    # check distance is <threshold\n",
        "                ml1.append([src,det])\n",
        "                ml2.append([src+1,det])\n",
        "                if verbose:\n",
        "                    print(\"S\",src,\" D\",det,\": gain=\",boardgain[src,det])\n",
        "                    print(\"Matlab good-SD listing:\")\n",
        "                    print(\"   \",src+1,det+1)\n",
        "                    print(\"   \",src+2,det+1)\n",
        "        else:\n",
        "            # no distance info available; save it as-is\n",
        "            ml1.append([src,det])\n",
        "            ml2.append([src+1,det])\n",
        "    return np.array(ml1+ml2)\n",
        "\n",
        "\n",
        "def prune_data(d,ml,bothwavelengths=False):\n",
        "    \"\"\"\n",
        "\n",
        "Prune data in 'd' to only those measurements in ml. If\n",
        "'bothwavelengths' is True, keep both wavelengths together.\n",
        "\n",
        "RETURNS: pruned version of 'd'\n",
        "\"\"\"\n",
        "    newd = []\n",
        "    for src,det in ml:\n",
        "        newd.append(d[:,src*8+det])\n",
        "        if bothwavelengths:\n",
        "            if src in [0,2,4,6]:\n",
        "                newd.append(d[:,(src+1)*8+det])\n",
        "    return np.array(newd).T\n",
        "\n",
        "\n",
        "def prune_hbdata(hbd,ml):\n",
        "    \"\"\"\n",
        "\n",
        "Prune hbhbo data in 'hbd' to only those measurements in ml.\n",
        "\n",
        "RETURNS: pruned version of 'hbd'\n",
        "\"\"\"\n",
        "    newd0 = []\n",
        "    newd1 = []\n",
        "    for src,det in ml:\n",
        "        # skip odd ones because we have separate hb & hbo lists\n",
        "        if src in [1,3,5,7]:\n",
        "            continue\n",
        "        newsrc = int(src/2)  # INTEGER division!\n",
        "        newd0.append(hbd[0,:,newsrc*8+det])\n",
        "        newd1.append(hbd[1,:,newsrc*8+det])\n",
        "    newd0 = np.array([newd0,newd1])\n",
        "    print(newd0.shape)\n",
        "    print(len(newd1))\n",
        "    return np.transpose(newd0,[0,2,1])\n",
        "\n",
        "\n",
        "def get_geometry(geometry):\n",
        "    \"\"\"\n",
        "\n",
        "Returns pSrc and pDet variables for the requested probe geometry\n",
        "'geometry' can be: {'quad','SEstrip','rect','alt','2pad','2fan',hex'} so far.\n",
        "\n",
        "RETURNS:  pSrc, pDet ... each a list of x,y,z coords\n",
        "\"\"\"\n",
        "    if geometry is not None:\n",
        "        if geometry=='quad':\n",
        "            pSrc = ningeometries.pSrcQuad\n",
        "            pDet = ningeometries.pDetQuad\n",
        "        elif geometry=='SEstrip':\n",
        "            pSrc = ningeometries.pSrcSEstrip\n",
        "            pDet = ningeometries.pDetSEstrip\n",
        "        elif geometry=='bilat':\n",
        "            pSrc = ningeometries.pSrcBilat\n",
        "            pDet = ningeometries.pDetBilat\n",
        "        elif geometry=='rect':\n",
        "            pSrc = ningeometries.pSrcRect\n",
        "            pDet = ningeometries.pDetRect\n",
        "        elif geometry=='alt':\n",
        "            pSrc = ningeometries.pSrcAlt\n",
        "            pDet = ningeometries.pDetAlt\n",
        "        elif geometry=='2pad':\n",
        "            pSrc = ningeometries.pSrc2pad\n",
        "            pDet = ningeometries.pDet2pad\n",
        "        elif geometry=='2fan':\n",
        "            pSrc = ningeometries.pSrc2fan\n",
        "            pDet = ningeometries.pDet2fan\n",
        "        elif geometry=='hex':\n",
        "            pSrc = ningeometries.pSrcHex\n",
        "            pDet = ningeometries.pDetHex\n",
        "    else:\n",
        "        pSrc = []\n",
        "        pDet = []\n",
        "    return pSrc,pDet\n",
        "\n",
        "\n",
        "def add_geometry(dct,geometry):\n",
        "    \"\"\"\n",
        "\n",
        "Adds pSrc and pDet variables to the 'dct' dictionary, as requested.\n",
        "'geometry' can be: {'quad','SEstrip','hex'} and others in ningeomtries.py.\n",
        "\n",
        "RETURNS:  'dct' with pSrc and pDet variables (each a list of x,y,z coords)\n",
        "\"\"\"\n",
        "    pSrc,pDet = get_geometry(geometry)\n",
        "    dct['pSrc'] = pSrc\n",
        "    dct['pDet'] = pDet\n",
        "    return dct\n",
        "\n",
        "\n",
        "########################## COMBO FUNCTIONS ##########################\n",
        "\n",
        "def nin2plotdata(fname,segstart=0,segend=-1,trim=1,unwrapgain=1,keepraw=1,\n",
        "                 force='forc',acceltype=200,GSR=[],GSRcalibwin=[],\n",
        "                 basiconly=False,SNRwindow=[0,20],BLs=[6,6],ODoffsetstep=0.3,CONCoffsetstep=10,geometry=None,SNRthresh=5,\n",
        "                 NINbaseline=None,notchfilt=[],filt_param=DEFAULTfilt_param,savePNG=False,verbose=True):\n",
        "    \"\"\"\n",
        "\n",
        "Generate \"standard\" plots from NIN-M data (but don't \"show\" them):\n",
        "    1&2 = RAW data, NIRS\n",
        "    3&4 = BKG data, NIRS\n",
        "\n",
        "    8 = Total-Hb\n",
        "    9 = O2Hb\n",
        "    10 = HHb\n",
        "    11 = OD data for 830nm\n",
        "    12 = OD data for 780nm\n",
        "    13 = E*G\n",
        "    14 = AUX\n",
        "    15&16 = DIFF data, NIRS\n",
        "    17 = SNR\n",
        "    18 = Probe gain\n",
        "    19 = Box gain\n",
        "\n",
        "RETURNS:  None\n",
        "\"\"\"\n",
        "    ### LOAD IN ALL DATA\n",
        "    print(\"Loading %s as NIN-M file\" %fname)\n",
        "    tmp, td, ta, events, config = load_nin(fname,segstart,segend,trim=1,keepraw=1,verbose=verbose)\n",
        "    ea,eb,ec,ed = events\n",
        "\n",
        "    print(\"BEFORE CONVERSION:\", list(tmp.keys()))\n",
        "\n",
        "    ### CONVERT AUXILIARY UNITS, IF REQUESTED\n",
        "    if acceltype==0:  # don't convert anything\n",
        "        a = {}\n",
        "        for k in tmp.keys():\n",
        "            a[k] = tmp[k]\n",
        "    else:\n",
        "        a,config = nin_convert(tmp,config,unwrapgain=unwrapgain,acceltype=acceltype,force='forc',\n",
        "                             notchfilt=notchfilt,filt_param=filt_param,verbose=verbose)\n",
        "\n",
        "    print(\"AFTER CONVERSION:\", list(a.keys()))\n",
        "\n",
        "    del tmp  # save some memory, this is big\n",
        "    raw = a['SRC']\n",
        "    bkgd = a['BKGD']\n",
        "    diff = raw-bkgd\n",
        "\n",
        "    ### COMPUTE \"GOOD\" MEASUREMENT LIST\n",
        "    ml = nin_ML(diff,config['BOARDgain'],GAINthresh=16,SNRwindow=SNRwindow,SNRthresh=SNRthresh,DISTthresh=75,verbose=False,geometry=geometry)\n",
        "\n",
        "    ### CONVERT TO OD\n",
        "    od = nin_makeOD(diff,baseline=NINbaseline)\n",
        "\n",
        "    ### CONVERT TO CONCENTRATIONS\n",
        "    if not basiconly:\n",
        "        hbhbo,hbhboml = nin_od2hbhbo(od, wavelengths=DEFAULTwavelengths, BLs=BLs)\n",
        "\n",
        "    ### PRUNE DATA TO KEEP ONLY GOOD MEASUREMENTS\n",
        "    if not basiconly:\n",
        "        pdiff = prune_data(diff,ml,bothwavelengths=False)\n",
        "        pod = prune_data(od,ml,bothwavelengths=False)\n",
        "        phbhbo = prune_hbdata(hbhbo,hbhboml)\n",
        "\n",
        "    ### RETURN DATA\n",
        "    if basiconly:\n",
        "        return {'a':a, 'td':td, 'ta':ta, 'events':events, 'config':config, 'ml':ml, 'od':od}\n",
        "    else:\n",
        "        return {'a':a, 'td':td, 'ta':ta, 'events':events, 'config':config, 'ml':ml, 'od':od,\n",
        "                'hbhbo':hbhbo, 'hbhboml':hbhboml, 'pdiff':pdiff, 'pod':pod, 'phbhbo':phbhbo}\n",
        "\n",
        "\n",
        "def nin2plots(fname,segstart=0,segend=-1,unwrapgain=1,acceltype=200,GSR=[],GSRcalibwin=[],basiconly=False,\n",
        "              SNRwindow=[0,20],ODoffsetstep=0.3,CONCoffsetstep=10,geometry=None,SNRthresh=5,\n",
        "              NINbaseline=None,notchfilt=[],AUX8offset=250,filt_param=DEFAULTfilt_param,savePNG=False,verbose=True):\n",
        "    \"\"\"\n",
        "\n",
        "Generate \"standard\" plots from NIN-M data (but don't \"show\" them):\n",
        "    1&2 = RAW data, NIRS\n",
        "    3&4 = BKG data, NIRS\n",
        "\n",
        "    8 = Total-Hb\n",
        "    9 = O2Hb\n",
        "    10 = HHb\n",
        "    11 = OD data for 830nm\n",
        "    12 = OD data for 780nm\n",
        "    13 = E*G\n",
        "    14 = AUX\n",
        "    15&16 = DIFF data, NIRS\n",
        "    17 = SNR\n",
        "    18 = Probe gain\n",
        "    19 = Box gain\n",
        "\n",
        "RETURNS:  None\n",
        "\"\"\"\n",
        "    if savePNG:\n",
        "        figsize = (18,10)\n",
        "\n",
        "    # GET STANDARDLY-CONVERTED DATA DICTIONARY\n",
        "    dd = nin2plotdata(fname,segstart,segend,trim=1,keepraw=1,unwrapgain=unwrapgain,\n",
        "                      acceltype=acceltype,force='forc',\n",
        "                      basiconly=basiconly, NINbaseline=NINbaseline,SNRwindow=SNRwindow,\n",
        "                      notchfilt=notchfilt,filt_param=filt_param,verbose=True)\n",
        "\n",
        "    # CONVERT DICTIONARY TO USEFUL VARIABLES\n",
        "    events = dd['events']\n",
        "    ea,eb,ec,ed = dd['events']\n",
        "    a = dd['a']\n",
        "    config = dd['config']\n",
        "    td = dd['td']\n",
        "    ta = dd['ta']\n",
        "    raw = a['SRC']\n",
        "    bkgd = a['BKGD']\n",
        "    diff = raw-bkgd\n",
        "    ml = dd['ml']\n",
        "    od = dd['od']\n",
        "    try:\n",
        "        aux8 = a['AUXC']\n",
        "    except:\n",
        "        aux8 = None\n",
        "    if not basiconly:\n",
        "        hbhbo = dd['hbhbo']\n",
        "        hbhboml = dd['hbhboml']\n",
        "\n",
        "    ### PLOT SRC DATA\n",
        "    plot_bysource(raw,t=td,ev=events,LPF=0,titletxt='Lasers ON: ',fignum=1)\n",
        "    ### PLOT BKGD DATA\n",
        "    plot_bysource(bkgd,t=td,ev=events,LPF=0,titletxt='Lasers OFF (BKGD): ',fignum=3)\n",
        "\n",
        "    ### PLOT HB/HBO/HBT DATA IN QUAD FORMAT\n",
        "    if not basiconly:\n",
        "        if geometry in [None,'quad']:\n",
        "            plot_quadconc(hbhbo*1e6,t=td,ev=[ea,eb,ec,ed],fignum=5,titletxt=fname)\n",
        "        elif geometry in ['SEstrip']:\n",
        "            plot_SEstripconc(hbhbo*1e6,t=td,ev=[ea,eb,ec,ed],fignum=5,titletxt=fname)\n",
        "\n",
        "    ### PLOT HB/HBO/HBT DATA\n",
        "    if not basiconly:\n",
        "        plot_hbhbosplayed(hbhbo[0]*1e6,td,ev=events,ml=ml,offsetstep=CONCoffsetstep,fignum=10)  # HHb\n",
        "        title(\"Deoxy-Hb: \"+fname)\n",
        "\n",
        "        plot_hbhbosplayed(hbhbo[1]*1e6,td,ev=events,ml=ml,offsetstep=CONCoffsetstep,fignum=9)  # O2Hb\n",
        "        title(\"Oxy-Hb: \"+fname)\n",
        "\n",
        "        plot_hbhbosplayed((hbhbo[0]+hbhbo[1])*1e6,td,ev=events,ml=ml,offsetstep=CONCoffsetstep,fignum=8)  # HbT\n",
        "        title(\"Total-Hb: \"+fname)\n",
        "\n",
        "\n",
        "    ### PLOT OD DATA\n",
        "    if not basiconly:\n",
        "        plot_bycolor(od,t=td,ev=[ea,eb,ec,ed],ml=ml,offsetstep=ODoffsetstep,fignum=11,titletxt='OD data: '+fname)\n",
        "\n",
        "    ### PLOT E*G\n",
        "    plot_EstG(a['EstG'],t=ta,ev=[ea,eb,ec,ed],labels='ECG: '+fname,filt60hz=True,fignum=13,titletxt='E*G: '+fname)\n",
        "\n",
        "    ### PLOT AUXILIARIES (EXCEPT E*G)\n",
        "    plot_aux(a,t=ta,ev=events,GSR=GSR,GSRcalibwin=GSRcalibwin,fignum=14)\n",
        "    suptitle('AUX1: '+fname)\n",
        "\n",
        "    ### PLOT DIFF DATA\n",
        "    plot_bysource(diff,t=td,ev=[ea,eb,ec,ed],LPF=0,titletxt='NIRS DIFFERENCE: '+fname,fignum=15)\n",
        "\n",
        "    ### COMPUTE AND PLOT MAP OF SNR\n",
        "    snr = nin_SNR(diff,window=SNRwindow)  # SNR of whole timecourse\n",
        "    plot_map(snr,clim=[0,20],cmap='jet_r',interpolation='none',titletxt='SNR: '+fname)\n",
        "    ### PLOT MAP OF PROBEgain\n",
        "    plot_map(config['PROBEgain'],clim=[0,1],cmap='jet',interpolation='none',titletxt='Probe Gains: '+fname)\n",
        "    ### PLOT MAP OF BOARDgain\n",
        "    plot_map(config['BOARDgain'],clim=[0,17],cmap='jet',interpolation='none',titletxt='Board Gains: '+fname)\n",
        "\n",
        "    if aux8 is not None:\n",
        "        plot_EstG(aux8,t=ta,ev=[ea,eb,ec,ed],labels=None,EstGoffset=AUX8offset,filt60hz=False,fignum=20)\n",
        "\n",
        "    if savePNG:\n",
        "        parts = os.path.split(fname)\n",
        "        idx = parts[1].rfind('.')\n",
        "        prefix = parts[1][:idx]\n",
        "        for i in range(1,20):\n",
        "            figure(i)\n",
        "            savefig(prefix+'-fig%s.png' %fixstr(i,2))\n",
        "\n",
        "\n",
        "    ### DISPLAY ALL FIGURES\n",
        "#    show()\n",
        "    return dd\n",
        "\n",
        "\n",
        "def nin2singleplot(fname,segstart=0,segend=-1,unwrapgain=1,acceltype=200,GSR=[],basiconly=False,\n",
        "              SNRwindow=[0,20],ODoffsetstep=0.3,CONCoffsetstep=10,geometry=None,SNRthresh=5,\n",
        "              NINbaseline=None,notchfilt=[],filt_param=DEFAULTfilt_param,savePNG=False,verbose=True,\n",
        "              titletxt='',figsize=(12,9)):\n",
        "    \"\"\"\n",
        "\n",
        "Generate \"standard\" plots from NIN-M data (but don't \"show\" them):\n",
        "    1&2 = RAW data, NIRS\n",
        "    3&4 = BKG data, NIRS\n",
        "\n",
        "    8 = Total-Hb\n",
        "    9 = O2Hb\n",
        "    10 = HHb\n",
        "    11 = OD data for 830nm\n",
        "    12 = OD data for 780nm\n",
        "    13 = E*G\n",
        "    14 = AUX\n",
        "    15&16 = DIFF data, NIRS\n",
        "    17 = SNR\n",
        "    18 = Probe gain\n",
        "    19 = Box gain\n",
        "\n",
        "RETURNS:  None\n",
        "\"\"\"\n",
        "    if savePNG:\n",
        "        figsize = (18,10)\n",
        "\n",
        "    # GET STANDARDLY-CONVERTED DATA DICTIONARY\n",
        "    dd = nin2plotdata(fname,segstart,segend,trim=1,keepraw=1,unwrapgain=unwrapgain,\n",
        "                      acceltype=acceltype,force='forc',\n",
        "                      basiconly=basiconly, NINbaseline=NINbaseline,SNRwindow=SNRwindow,\n",
        "                      notchfilt=notchfilt,filt_param=filt_param,verbose=True)\n",
        "\n",
        "    ### PLOT EVERYTHING\n",
        "    plot_allin1(dd,titletxt=titletxt,figsize=figsize)\n",
        "\n",
        "    if savePNG:\n",
        "        parts = os.path.split(fname)\n",
        "        idx = parts[1].rfind('.')\n",
        "        prefix = parts[1][:idx]\n",
        "        savefig('allin1-%s.png' %prefix)\n",
        "\n",
        "    ### DISPLAY ALL FIGURES\n",
        "#    show()\n",
        "    return dd\n",
        "\n",
        "\n",
        "def savePNGs(prefix,figs='all'):\n",
        "    if figs=='all':\n",
        "        for i in get_fignums():\n",
        "            figure(i)\n",
        "            savefig(prefix+'-fig%s.png' %fixstr(i,2))\n",
        "    else:\n",
        "        for i in figs:\n",
        "            figure(i)\n",
        "            savefig(prefix+'-fig%s.png' %fixstr(i,2))\n",
        "    return"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sX0xuVhzU3U2",
        "outputId": "9079396f-dfeb-445a-db2b-97f0d0d508ea"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No optical26 module; continuing.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def nin2plotdata(fname,segstart=0,segend=-1,trim=1,unwrapgain=1,keepraw=1,\n",
        "                 force='forc',acceltype=200,GSR=[],GSRcalibwin=[],\n",
        "                 basiconly=False,SNRwindow=[0,20],BLs=[6,6],ODoffsetstep=0.3,CONCoffsetstep=10,geometry=None,SNRthresh=5,\n",
        "                 NINbaseline=None,notchfilt=[],filt_param=DEFAULTfilt_param,savePNG=False,verbose=True):\n",
        "    \"\"\"\n",
        "\n",
        "Generate \"standard\" plots from NIN-M data (but don't \"show\" them):\n",
        "    1&2 = RAW data, NIRS\n",
        "    3&4 = BKG data, NIRS\n",
        "\n",
        "    8 = Total-Hb\n",
        "    9 = O2Hb\n",
        "    10 = HHb\n",
        "    11 = OD data for 830nm\n",
        "    12 = OD data for 780nm\n",
        "    13 = E*G\n",
        "    14 = AUX\n",
        "    15&16 = DIFF data, NIRS\n",
        "    17 = SNR\n",
        "    18 = Probe gain\n",
        "    19 = Box gain\n",
        "\n",
        "RETURNS:  None\n",
        "\"\"\"\n",
        "    ### LOAD IN ALL DATA\n",
        "    print(\"Loading %s as NIN-M file\" %fname)\n",
        "    tmp, td, ta, events, config = load_nin(fname,segstart,segend,trim=1,keepraw=1,verbose=verbose)\n",
        "    ea,eb,ec,ed = events\n",
        "\n",
        "    print(\"BEFORE CONVERSION:\", list(tmp.keys()))\n",
        "\n",
        "    ### CONVERT AUXILIARY UNITS, IF REQUESTED\n",
        "    if acceltype==0:  # don't convert anything\n",
        "        a = {}\n",
        "        for k in tmp.keys():\n",
        "            a[k] = tmp[k]\n",
        "    else:\n",
        "        a,config = nin_convert(tmp,config,unwrapgain=unwrapgain,acceltype=acceltype,force='forc',\n",
        "                             notchfilt=notchfilt,filt_param=filt_param,verbose=verbose)\n",
        "\n",
        "    print(\"AFTER CONVERSION:\", list(a.keys()))\n",
        "\n",
        "    del tmp  # save some memory, this is big\n",
        "    raw = a['SRC']\n",
        "    bkgd = a['BKGD']\n",
        "    diff = raw-bkgd\n",
        "\n",
        "    ### COMPUTE \"GOOD\" MEASUREMENT LIST\n",
        "    ml = nin_ML(diff,config['BOARDgain'],GAINthresh=16,SNRwindow=SNRwindow,SNRthresh=SNRthresh,DISTthresh=75,verbose=False,geometry=geometry)\n",
        "\n",
        "    ### CONVERT TO OD\n",
        "    od = nin_makeOD(diff,baseline=NINbaseline)\n",
        "\n",
        "    ### CONVERT TO CONCENTRATIONS\n",
        "    if not basiconly:\n",
        "        hbhbo,hbhboml = nin_od2hbhbo(od, wavelengths=DEFAULTwavelengths, BLs=BLs)\n",
        "\n",
        "    ### PRUNE DATA TO KEEP ONLY GOOD MEASUREMENTS\n",
        "    if not basiconly:\n",
        "        pdiff = prune_data(diff,ml,bothwavelengths=False)\n",
        "        pod = prune_data(od,ml,bothwavelengths=False)\n",
        "        phbhbo = prune_hbdata(hbhbo,hbhboml)\n",
        "\n",
        "    ### RETURN DATA\n",
        "    if basiconly:\n",
        "        return {'a':a, 'td':td, 'ta':ta, 'events':events, 'config':config, 'ml':ml, 'od':od}\n",
        "    else:\n",
        "        return {'a':a, 'td':td, 'ta':ta, 'events':events, 'config':config, 'ml':ml, 'od':od,\n",
        "                'hbhbo':hbhbo, 'hbhboml':hbhboml, 'pdiff':pdiff, 'pod':pod, 'phbhbo':phbhbo}\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LS9-EEmKaZO1"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "q9Y3LV-OTqjE",
        "outputId": "28bf3cff-354b-499c-80a4-6ec46e677198"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading /content/2022-0318-115200-50227.nin as NIN-M file\n",
            "/content/2022-0318-115200-50227.nin\n",
            "  Getting header\n",
            "  Getting events\n",
            "  Getting config\n",
            "  Getting SRC\n",
            "  Getting BKG\n",
            "  Getting auxiliary\n",
            "    Getting  GYRO\n",
            "    Getting  ACCE\n",
            "    Getting  EstG\n",
            "    Getting  NECG\n",
            "    Getting  AUXC\n",
            "    Getting  FORC\n",
            "    Getting  TEMP\n",
            "  Truncating to equal lengths\n",
            "  BEFORE ...\n",
            "     ACCE 42458\n",
            "     EstG 42458\n",
            "     AUXC 42458\n",
            "  AFTER ...\n",
            "     ACCE 42458\n",
            "     EstG 42458\n",
            "     AUXC 42458\n",
            "  BEFORE ...\n",
            "     SRC 4246\n",
            "     BKGD 4246\n",
            "     FORC 4245\n",
            "     TEMP 4245\n",
            "  AFTER ...\n",
            "     SRC 4245\n",
            "     BKGD 4245\n",
            "     FORC 4245\n",
            "     TEMP 4245\n",
            "BEFORE CONVERSION: ['ACCE', 'EstG', 'AUXC', 'FORC', 'TEMP', 'SRC', 'BKGD', 'NIRS']\n",
            "FILTERING DATA ...\n",
            "  ACCE : LPF= 100   HPF= 0\n",
            "  EstG : LPF= 0   HPF= 0\n",
            "      Failed filtering in nin_filt_aux() for AUXC\n",
            "  FORC : LPF= 1   HPF= 0\n",
            "  TEMP : LPF= 0.1   HPF= 0\n",
            "  SRC : LPF= 5   HPF= 0\n",
            "  BKGD : LPF= 5   HPF= 0\n",
            "  NIRS : LPF= 5   HPF= 0\n",
            "AFTER CONVERSION: ['ACCE', 'EstG', 'AUXC', 'FORC', 'TEMP', 'SRC', 'BKGD', 'NIRS']\n",
            "(2, 32, 4245)\n",
            "32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-64557777ebcb>:2679: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  ac[k] = a[k].astype(np.float) *3.9/1000. /256.  # 3.9 mg/bit\n",
            "<ipython-input-38-64557777ebcb>:2695: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  ac[k] = a[k].astype(np.float) #@@@ no conversion for now\n",
            "<ipython-input-38-64557777ebcb>:2681: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  ac[k] = a[k].astype(np.float) *0.00061   # mV; 0.61 mV/bit\n",
            "<ipython-input-38-64557777ebcb>:2688: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  ac[k] = a[k].astype(np.float) /256.      # deg C; 0.25 deg C/bit\n",
            "<ipython-input-38-64557777ebcb>:468: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  wwid = np.int(samplerate/float(flp))\n",
            "<ipython-input-38-64557777ebcb>:471: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  d = d.astype(np.float)\n",
            "<ipython-input-38-64557777ebcb>:2776: RuntimeWarning: divide by zero encountered in log\n",
            "  ODdata = -np.log(normalized_fluence)\n",
            "<ipython-input-38-64557777ebcb>:2776: RuntimeWarning: invalid value encountered in log\n",
            "  ODdata = -np.log(normalized_fluence)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-3cf8047a3e4b>\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0macce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ACCE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mgyro\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'GYRO'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0mestg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'EstG'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TEMP'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'GYRO'"
          ]
        }
      ],
      "source": [
        "### Copyright Gary Strangman & Massachusetts General Hospital 2022; All rights reserved.\n",
        "\n",
        "from __future__ import absolute_import\n",
        "#import nintools_v34 as nt\n",
        "\n",
        "import sys\n",
        "import numpy as np\n",
        "from pylab import *\n",
        "from six.moves import range\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "fname = sys.argv[1]\n",
        "\n",
        "# LOAD IN ALL DATA\n",
        "d = nin2plotdata(\"/content/2022-0318-115200-50227.nin\")\n",
        "\n",
        "# ASSIGNMENTS TO MAKE REFERENCING EASIER\n",
        "td = d['td']\n",
        "ta = d['ta']\n",
        "a = d['a']\n",
        "\n",
        "acce = a['ACCE']\n",
        "gyro = a['GYRO']\n",
        "estg = a['EstG']\n",
        "temp = a['TEMP']\n",
        "forc = a['FORC']\n",
        "\n",
        "hb = d['hbhbo'][0]*1e6\n",
        "hbo = d['hbhbo'][1]*1e6\n",
        "hbt = (hb+hbo)*1e6\n",
        "\n",
        "# RESHAPE FOR STACKING\n",
        "td.shape = (len(td),1)\n",
        "ta.shape = (len(ta),1)\n",
        "temp.shape = (len(temp),1)\n",
        "forc.shape = (len(forc),1)\n",
        "\n",
        "# BUILD NEW ARRAYS\n",
        "estg = np.hstack([ta,estg])\n",
        "fast = np.hstack([ta,acce,gyro])\n",
        "hbt  = np.hstack([td,temp,hbt])\n",
        "hhb  = np.hstack([td,temp,hb])\n",
        "hbo2 = np.hstack([td,temp,hbo])\n",
        "\n",
        "# SAVE OUT NEW ARRAYS\n",
        "np.savetxt(fname[:-4]+\"-estg.csv\", estg, delimiter=\",\",header=\"sec, v1, v2, v3, v4, v5, v6, v7, v8\")\n",
        "np.savetxt(fname[:-4]+\"-fast.csv\", fast, delimiter=\",\",header=\"sec, accX, accY, accZ, gyroX, gyroY, gyroZ\")\n",
        "np.savetxt(fname[:-4]+\"-hbt.csv\", hbt, delimiter=\",\",header=\"sec, temp,\" + \"Ch%i, \"*32 %tuple(range(32)))\n",
        "np.savetxt(fname[:-4]+\"-hhb.csv\", hhb, delimiter=\",\",header=\"sec, temp,\" + \"Ch%i, \"*32 %tuple(range(32)))\n",
        "np.savetxt(fname[:-4]+\"-hbo2.csv\", hbo2, delimiter=\",\",header=\"sec, temp,\" + \"Ch%i, \"*32 %tuple(range(32)))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKvgkYk2VuJ1",
        "outputId": "61c623c4-36de-468e-ea9d-b367de763b99"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['a', 'td', 'ta', 'events', 'config', 'ml', 'od', 'hbhbo', 'hbhboml', 'pdiff', 'pod', 'phbhbo'])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d[\"events\"][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rb632tUAYXA-",
        "outputId": "82282d90-a4ab-4fac-99aa-9cf9089dbdca"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1647604450.0, 31718],\n",
              " [1647604457.0, 33372],\n",
              " [1647604457.0, 33474],\n",
              " [1647604458.0, 33604]]"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d[\"events\"][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWJg0PoXnR2E",
        "outputId": "f613cc36-42e3-4bda-a9dc-bf94c0ea8da1"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1647604461.0, 34524], [1647604463.0, 34838], [1647604477.0, 38385]]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for i in range(10):\n",
        "  print(d[\"ta\"][i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqfSKOs1ZR9O",
        "outputId": "75526347-35c8-4b5c-bff8-2df9037af350"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n",
            "0.004\n",
            "0.008\n",
            "0.012\n",
            "0.016\n",
            "0.02\n",
            "0.024\n",
            "0.028\n",
            "0.032\n",
            "0.036\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4eoClQlha18",
        "outputId": "5719506b-d3c0-4336-86d5-e1d6f0313a75"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a': {'ACCE': array([[-4.22677558e+13, -4.91244203e+13,  5.48876205e+12],\n",
              "         [-4.52865750e+13, -4.83011060e+13,  6.03763825e+12],\n",
              "         [-4.85798322e+13, -4.93988584e+13,  8.50758117e+12],\n",
              "         ...,\n",
              "         [-7.35536995e+13,  0.00000000e+00,  0.00000000e+00],\n",
              "         [-7.35536995e+13,  0.00000000e+00,  2.74438102e+11],\n",
              "         [-7.35536995e+13,  0.00000000e+00,  1.09775241e+12]]),\n",
              "  'EstG': array([[ 378383.,  311160.,  379578., ...,  262194.,  299286.,  295044.],\n",
              "         [ 378502.,  311709.,  380091., ...,  262576.,  299281.,  295369.],\n",
              "         [ 378582.,  312313.,  380511., ...,  263264.,  299776.,  296168.],\n",
              "         ...,\n",
              "         [4434223., 4446338., 4450647., ..., 4447916., 4452371., 4450377.],\n",
              "         [4434096., 4446276., 4450442., ..., 4448414., 4452628., 4450861.],\n",
              "         [4433824., 4446318., 4450196., ..., 4448386., 4452591., 4450946.]]),\n",
              "  'AUXC': array([[   0.,    0.,  537., ...,    0.,    0.,    0.],\n",
              "         [   0.,    0.,  548., ...,    0.,    0.,    0.],\n",
              "         [   0.,    0.,  550., ...,    0.,    0.,    0.],\n",
              "         ...,\n",
              "         [3200., 1802., 1638., ...,  791.,  868., 1249.],\n",
              "         [2853., 1799., 1636., ...,  792.,  865., 1249.],\n",
              "         [2266., 1795., 1638., ...,  792.,  869., 1250.]]),\n",
              "  'FORC': array([1167.89490909, 1167.89490909, 1167.89490909, ..., 1167.89490909,\n",
              "         1167.89490909, 1167.89490909]),\n",
              "  'TEMP': array([28.625164, 28.624836, 28.624508, ..., 30.62424 , 30.62462 ,\n",
              "         30.625   ]),\n",
              "  'SRC': array([[23482.8 , 21245.8 , 27579.44, ..., 23137.52, 23717.24, 21551.28],\n",
              "         [23516.12, 21289.6 , 27321.2 , ..., 23037.  , 23636.04, 21593.04],\n",
              "         [23559.84, 21343.  , 27136.08, ..., 22989.28, 23561.64, 21621.68],\n",
              "         ...,\n",
              "         [21409.4 , 20993.2 , 27065.  , ..., 21415.  , 17451.76, 16334.  ],\n",
              "         [21306.96, 20927.92, 27037.12, ..., 21260.92, 17311.88, 16297.36],\n",
              "         [21203.  , 20850.  , 27028.  , ..., 21064.  , 17161.  , 16270.  ]]),\n",
              "  'BKGD': array([[17328.88, 11699.24, 25210.32, ..., 16132.72,  7614.04,  6997.8 ],\n",
              "         [17174.48, 11643.28, 25271.08, ..., 16086.32,  7635.48,  6995.72],\n",
              "         [17093.04, 11605.16, 25286.72, ..., 16043.68,  7639.2 ,  6993.24],\n",
              "         ...,\n",
              "         [17600.12, 12222.52, 25386.28, ..., 15997.24,  7824.  ,  7191.2 ],\n",
              "         [17691.6 , 12070.76, 25362.24, ..., 15809.76,  7786.24,  7133.96],\n",
              "         [17821.  , 11960.  , 25273.  , ..., 15566.  ,  7724.  ,  7043.  ]]),\n",
              "  'NIRS': array([[ 6153.92,  9546.56,  2369.12, ...,  7004.8 , 16103.2 , 14553.48],\n",
              "         [ 6341.64,  9646.32,  2050.12, ...,  6950.68, 16000.56, 14597.32],\n",
              "         [ 6466.8 ,  9737.84,  1849.36, ...,  6945.6 , 15922.44, 14628.44],\n",
              "         ...,\n",
              "         [ 3809.28,  8770.68,  1678.72, ...,  5417.76,  9627.76,  9142.8 ],\n",
              "         [ 3615.36,  8857.16,  1674.88, ...,  5451.16,  9525.64,  9163.4 ],\n",
              "         [ 3382.  ,  8890.  ,  1755.  , ...,  5498.  ,  9437.  ,  9227.  ]])},\n",
              " 'td': array([0.0000e+00, 4.0000e-02, 8.0000e-02, ..., 1.6968e+02, 1.6972e+02,\n",
              "        1.6976e+02]),\n",
              " 'ta': array([0.00000e+00, 4.00000e-03, 8.00000e-03, ..., 1.69820e+02,\n",
              "        1.69824e+02, 1.69828e+02]),\n",
              " 'events': ([[1647604450.0, 31718],\n",
              "   [1647604457.0, 33372],\n",
              "   [1647604457.0, 33474],\n",
              "   [1647604458.0, 33604]],\n",
              "  [[1647604461.0, 34524], [1647604463.0, 34838], [1647604477.0, 38385]],\n",
              "  [[1647604468.0, 36102], [1647604469.0, 36333]],\n",
              "  [[1647604476.0, 38115], [1647604477.0, 38389], [1647604484.0, 40265]]),\n",
              " 'config': {'PROBEgain': array([[1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 0, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 0, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 0, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 0, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 0, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 0, 1, 1, 1]]),\n",
              "  'BOARDgain': array([[12, 11, 14,  2,  3, 14, 14, 14],\n",
              "         [12, 10, 12,  6,  3, 14, 14, 14],\n",
              "         [11, 10, 12,  6,  2, 14, 14, 14],\n",
              "         [12, 11, 13,  7,  2, 14, 14, 14],\n",
              "         [14, 14, 14,  7,  1, 14, 11, 12],\n",
              "         [14, 14, 14,  5,  5, 12, 10, 12],\n",
              "         [14, 14, 14,  3,  3, 12,  8,  9],\n",
              "         [14, 14, 14,  5,  5, 12,  9,  9]]),\n",
              "  'SRCpower': [108, 36, 156, 89, 119, 212, 104, 98],\n",
              "  'EstGgain': [101, 101, 101, 101, 101, 101, 101, 101],\n",
              "  'ACCgain': 16,\n",
              "  'FORCEgain': 10,\n",
              "  'TTLout': 1,\n",
              "  'TTLin': 0,\n",
              "  'DIGITALin': 0,\n",
              "  'BT': 1,\n",
              "  'keepraw': 1,\n",
              "  'date': \"03.2-.b'20\",\n",
              "  'time': '8-.11.52',\n",
              "  'Device-ID': '0003538997',\n",
              "  'gainunwrapped': 1,\n",
              "  'filt_param': {'NIRS': [5, 0],\n",
              "   'SRC': [5, 0],\n",
              "   'BKGD': [5, 0],\n",
              "   'ACCE': [100, 0],\n",
              "   'EstG': [0, 0],\n",
              "   'FORC': [1, 0],\n",
              "   'GYRO': [100, 0],\n",
              "   'RESP': [5, 0],\n",
              "   'TEMP': [0.1, 0],\n",
              "   'NECG': [0, 0]},\n",
              "  'acceltype': 200,\n",
              "  'notch': []},\n",
              " 'ml': array([[0, 0],\n",
              "        [0, 1],\n",
              "        [0, 2],\n",
              "        [0, 3],\n",
              "        [2, 0],\n",
              "        [2, 1],\n",
              "        [2, 2],\n",
              "        [2, 3],\n",
              "        [2, 4],\n",
              "        [4, 4],\n",
              "        [4, 6],\n",
              "        [4, 7],\n",
              "        [6, 0],\n",
              "        [6, 2],\n",
              "        [6, 4],\n",
              "        [6, 5],\n",
              "        [6, 6],\n",
              "        [6, 7],\n",
              "        [1, 0],\n",
              "        [1, 1],\n",
              "        [1, 2],\n",
              "        [1, 3],\n",
              "        [3, 0],\n",
              "        [3, 1],\n",
              "        [3, 2],\n",
              "        [3, 3],\n",
              "        [3, 4],\n",
              "        [5, 4],\n",
              "        [5, 6],\n",
              "        [5, 7],\n",
              "        [7, 0],\n",
              "        [7, 2],\n",
              "        [7, 4],\n",
              "        [7, 5],\n",
              "        [7, 6],\n",
              "        [7, 7]]),\n",
              " 'od': array([[-0.13193766, -0.01401567, -0.3367846 , ..., -0.02911912,\n",
              "         -0.21655129, -0.16963252],\n",
              "        [-0.1619858 , -0.02441129, -0.19216435, ..., -0.02136299,\n",
              "         -0.210157  , -0.17264033],\n",
              "        [-0.18152978, -0.03385412, -0.08910565, ..., -0.02063186,\n",
              "         -0.20526272, -0.17476995],\n",
              "        ...,\n",
              "        [ 0.34771142,  0.07075087,  0.00770238, ...,  0.22779406,\n",
              "          0.29781612,  0.29523094],\n",
              "        [ 0.39996018,  0.06093904,  0.00999246, ...,  0.22164807,\n",
              "          0.30847961,  0.29298034],\n",
              "        [ 0.46668436,  0.05723816, -0.03673487, ...,  0.21309211,\n",
              "          0.31782858,  0.28606366]]),\n",
              " 'hbhbo': array([[[-4.63653096e-05, -3.04808486e-05, -5.28045385e-06, ...,\n",
              "          -6.19532264e-06, -1.47645281e-05, -1.02302031e-05],\n",
              "         [-3.81371167e-05, -2.85909417e-05, -1.83448699e-05, ...,\n",
              "          -4.84893986e-06, -1.27058194e-05, -9.94111209e-06],\n",
              "         [-3.18804562e-05, -2.69163004e-05, -2.81367448e-05, ...,\n",
              "          -4.11042580e-06, -1.11920520e-05, -9.64920984e-06],\n",
              "         ...,\n",
              "         [ 9.45052846e-05,  3.99311496e-05,  5.60347904e-05, ...,\n",
              "           1.43744727e-05,  1.23753023e-05,  1.05430520e-05],\n",
              "         [ 9.47382065e-05,  4.13057057e-05,  5.45202973e-05, ...,\n",
              "           1.53379625e-05,  1.36384286e-05,  9.05998828e-06],\n",
              "         [ 9.92236829e-05,  4.19116936e-05,  5.68762807e-05, ...,\n",
              "           1.57737410e-05,  1.47938650e-05,  6.45574813e-06]],\n",
              " \n",
              "        [[ 2.31858805e-05,  2.06467752e-05, -2.12707559e-05, ...,\n",
              "           6.41547226e-06,  2.87125023e-07, -1.79780459e-06],\n",
              "         [ 1.50981770e-05,  1.85294848e-05, -1.22750570e-06, ...,\n",
              "           5.16681541e-06, -2.17933081e-06, -2.54232942e-06],\n",
              "         [ 9.19390919e-06,  1.66361703e-05,  1.33985704e-05, ...,\n",
              "           4.12272171e-06, -3.97328244e-06, -3.20158441e-06],\n",
              "         ...,\n",
              "         [-4.14042616e-05, -2.31547900e-05, -3.92985976e-05, ...,\n",
              "           1.44986027e-06,  1.16165561e-05,  1.41283213e-05],\n",
              "         [-3.76871495e-05, -2.48620039e-05, -3.80507889e-05, ...,\n",
              "          -6.36106703e-07,  1.07904040e-05,  1.61452818e-05],\n",
              "         [-3.59201649e-05, -2.55682178e-05, -4.31996884e-05, ...,\n",
              "          -2.16843716e-06,  9.99336036e-06,  1.93848001e-05]]]),\n",
              " 'hbhboml': array([[0, 0],\n",
              "        [0, 1],\n",
              "        [0, 2],\n",
              "        [0, 3],\n",
              "        [0, 4],\n",
              "        [0, 5],\n",
              "        [0, 6],\n",
              "        [0, 7],\n",
              "        [2, 0],\n",
              "        [2, 1],\n",
              "        [2, 2],\n",
              "        [2, 3],\n",
              "        [2, 4],\n",
              "        [2, 5],\n",
              "        [2, 6],\n",
              "        [2, 7],\n",
              "        [4, 0],\n",
              "        [4, 1],\n",
              "        [4, 2],\n",
              "        [4, 3],\n",
              "        [4, 4],\n",
              "        [4, 5],\n",
              "        [4, 6],\n",
              "        [4, 7],\n",
              "        [6, 0],\n",
              "        [6, 1],\n",
              "        [6, 2],\n",
              "        [6, 3],\n",
              "        [6, 4],\n",
              "        [6, 5],\n",
              "        [6, 6],\n",
              "        [6, 7]]),\n",
              " 'pdiff': array([[ 6153.92,  9546.56,  2369.12, ...,  7004.8 , 16103.2 , 14553.48],\n",
              "        [ 6341.64,  9646.32,  2050.12, ...,  6950.68, 16000.56, 14597.32],\n",
              "        [ 6466.8 ,  9737.84,  1849.36, ...,  6945.6 , 15922.44, 14628.44],\n",
              "        ...,\n",
              "        [ 3809.28,  8770.68,  1678.72, ...,  5417.76,  9627.76,  9142.8 ],\n",
              "        [ 3615.36,  8857.16,  1674.88, ...,  5451.16,  9525.64,  9163.4 ],\n",
              "        [ 3382.  ,  8890.  ,  1755.  , ...,  5498.  ,  9437.  ,  9227.  ]]),\n",
              " 'pod': array([[-0.13193766, -0.01401567, -0.3367846 , ..., -0.02911912,\n",
              "         -0.21655129, -0.16963252],\n",
              "        [-0.1619858 , -0.02441129, -0.19216435, ..., -0.02136299,\n",
              "         -0.210157  , -0.17264033],\n",
              "        [-0.18152978, -0.03385412, -0.08910565, ..., -0.02063186,\n",
              "         -0.20526272, -0.17476995],\n",
              "        ...,\n",
              "        [ 0.34771142,  0.07075087,  0.00770238, ...,  0.22779406,\n",
              "          0.29781612,  0.29523094],\n",
              "        [ 0.39996018,  0.06093904,  0.00999246, ...,  0.22164807,\n",
              "          0.30847961,  0.29298034],\n",
              "        [ 0.46668436,  0.05723816, -0.03673487, ...,  0.21309211,\n",
              "          0.31782858,  0.28606366]]),\n",
              " 'phbhbo': array([[[-4.63653096e-05, -3.04808486e-05, -5.28045385e-06, ...,\n",
              "          -6.19532264e-06, -1.47645281e-05, -1.02302031e-05],\n",
              "         [-3.81371167e-05, -2.85909417e-05, -1.83448699e-05, ...,\n",
              "          -4.84893986e-06, -1.27058194e-05, -9.94111209e-06],\n",
              "         [-3.18804562e-05, -2.69163004e-05, -2.81367448e-05, ...,\n",
              "          -4.11042580e-06, -1.11920520e-05, -9.64920984e-06],\n",
              "         ...,\n",
              "         [ 9.45052846e-05,  3.99311496e-05,  5.60347904e-05, ...,\n",
              "           1.43744727e-05,  1.23753023e-05,  1.05430520e-05],\n",
              "         [ 9.47382065e-05,  4.13057057e-05,  5.45202973e-05, ...,\n",
              "           1.53379625e-05,  1.36384286e-05,  9.05998828e-06],\n",
              "         [ 9.92236829e-05,  4.19116936e-05,  5.68762807e-05, ...,\n",
              "           1.57737410e-05,  1.47938650e-05,  6.45574813e-06]],\n",
              " \n",
              "        [[ 2.31858805e-05,  2.06467752e-05, -2.12707559e-05, ...,\n",
              "           6.41547226e-06,  2.87125023e-07, -1.79780459e-06],\n",
              "         [ 1.50981770e-05,  1.85294848e-05, -1.22750570e-06, ...,\n",
              "           5.16681541e-06, -2.17933081e-06, -2.54232942e-06],\n",
              "         [ 9.19390919e-06,  1.66361703e-05,  1.33985704e-05, ...,\n",
              "           4.12272171e-06, -3.97328244e-06, -3.20158441e-06],\n",
              "         ...,\n",
              "         [-4.14042616e-05, -2.31547900e-05, -3.92985976e-05, ...,\n",
              "           1.44986027e-06,  1.16165561e-05,  1.41283213e-05],\n",
              "         [-3.76871495e-05, -2.48620039e-05, -3.80507889e-05, ...,\n",
              "          -6.36106703e-07,  1.07904040e-05,  1.61452818e-05],\n",
              "         [-3.59201649e-05, -2.55682178e-05, -4.31996884e-05, ...,\n",
              "          -2.16843716e-06,  9.99336036e-06,  1.93848001e-05]]])}"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-6a8dgzoqXI3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
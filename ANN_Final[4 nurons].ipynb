{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RafsanJany-44/ACM/blob/master/ANN_Final%5B4%20nurons%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KPnkjM0D7riO"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0-PI1t5nCB4",
        "outputId": "065c553b-577f-43db-d2cd-7fc1b05e8593"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading Dataset\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/Thesis_Data/EEG_HMC_underscore.csv\")"
      ],
      "metadata": {
        "id": "dBa0SHNFndqo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.iloc[:, 1:76].values\n",
        "Y = data.iloc[:, 0].values"
      ],
      "metadata": {
        "id": "6q5hpx-3nHIs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Encoding Categorical the sleep_stage\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "LE1 = LabelEncoder()\n",
        "Y = np.array(LE1.fit_transform(Y))"
      ],
      "metadata": {
        "id": "-IUhl3tRnMCu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Encoding Categorical variable Geography\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ct =ColumnTransformer(transformers=[('encoder',OneHotEncoder(),[1])],remainder=\"passthrough\")\n",
        "X = np.array(ct.fit_transform(X))"
      ],
      "metadata": {
        "id": "exC-gMyanMfH"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting dataset into training and testing dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,Y,test_size=0.2,random_state=0)"
      ],
      "metadata": {
        "id": "X3Gotf3InPYz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCYh6eOu7rif",
        "outputId": "ae63b364-3eb3-4709-91ff-8ea85b105ff4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "86760"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "len(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwal07Pi7rik",
        "outputId": "bdc3fa29-1375-4b51-d5df-302ba36d36cc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21691"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "len(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mdsvw9Bc7rim",
        "outputId": "c72d6b06-9409-4d42-81cb-5d925c0fb1c3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(86760, 215)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "X_train.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(250, input_shape=(215,), activation='relu'), # input layer\n",
        "    keras.layers.Dense(150, activation='sigmoid'),\n",
        "    keras.layers.Dense(100, activation='sigmoid'),\n",
        "    #keras.layers.Dense(150, activation='sigmoid'),\n",
        "    keras.layers.Dense(75, activation='softmax')                    # output layer\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7m1Ujz34ZvPh",
        "outputId": "4a0156a2-fa6b-4b9f-f65e-44c65ac8fe65"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "2712/2712 [==============================] - 18s 6ms/step - loss: 1.1759 - accuracy: 0.5188\n",
            "Epoch 2/1000\n",
            "2712/2712 [==============================] - 14s 5ms/step - loss: 0.9509 - accuracy: 0.6147\n",
            "Epoch 3/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.8955 - accuracy: 0.6412\n",
            "Epoch 4/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.8637 - accuracy: 0.6561\n",
            "Epoch 5/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.8364 - accuracy: 0.6675\n",
            "Epoch 6/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.8211 - accuracy: 0.6732\n",
            "Epoch 7/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.8090 - accuracy: 0.6786\n",
            "Epoch 8/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.7932 - accuracy: 0.6841\n",
            "Epoch 9/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.7839 - accuracy: 0.6873\n",
            "Epoch 10/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.7723 - accuracy: 0.6939\n",
            "Epoch 11/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.7644 - accuracy: 0.6981\n",
            "Epoch 12/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.7535 - accuracy: 0.7010\n",
            "Epoch 13/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.7468 - accuracy: 0.7031\n",
            "Epoch 14/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.7417 - accuracy: 0.7062\n",
            "Epoch 15/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.7352 - accuracy: 0.7084\n",
            "Epoch 16/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.7314 - accuracy: 0.7103\n",
            "Epoch 17/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.7271 - accuracy: 0.7108\n",
            "Epoch 18/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.7250 - accuracy: 0.7142\n",
            "Epoch 19/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.7189 - accuracy: 0.7149\n",
            "Epoch 20/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.7161 - accuracy: 0.7154\n",
            "Epoch 21/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.7100 - accuracy: 0.7170\n",
            "Epoch 22/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.7074 - accuracy: 0.7195\n",
            "Epoch 23/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.7043 - accuracy: 0.7209\n",
            "Epoch 24/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.7002 - accuracy: 0.7234\n",
            "Epoch 25/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6953 - accuracy: 0.7243\n",
            "Epoch 26/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6945 - accuracy: 0.7250\n",
            "Epoch 27/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6914 - accuracy: 0.7244\n",
            "Epoch 28/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6897 - accuracy: 0.7272\n",
            "Epoch 29/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6854 - accuracy: 0.7297\n",
            "Epoch 30/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6841 - accuracy: 0.7291\n",
            "Epoch 31/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6818 - accuracy: 0.7302\n",
            "Epoch 32/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.6795 - accuracy: 0.7301\n",
            "Epoch 33/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6755 - accuracy: 0.7308\n",
            "Epoch 34/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.6733 - accuracy: 0.7328\n",
            "Epoch 35/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6707 - accuracy: 0.7332\n",
            "Epoch 36/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6712 - accuracy: 0.7347\n",
            "Epoch 37/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6652 - accuracy: 0.7357\n",
            "Epoch 38/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6626 - accuracy: 0.7372\n",
            "Epoch 39/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6659 - accuracy: 0.7353\n",
            "Epoch 40/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6620 - accuracy: 0.7365\n",
            "Epoch 41/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6630 - accuracy: 0.7376\n",
            "Epoch 42/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6562 - accuracy: 0.7400\n",
            "Epoch 43/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6559 - accuracy: 0.7384\n",
            "Epoch 44/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.6554 - accuracy: 0.7399\n",
            "Epoch 45/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.6522 - accuracy: 0.7411\n",
            "Epoch 46/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.6510 - accuracy: 0.7426\n",
            "Epoch 47/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.6496 - accuracy: 0.7438\n",
            "Epoch 48/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6469 - accuracy: 0.7431\n",
            "Epoch 49/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.6451 - accuracy: 0.7446\n",
            "Epoch 50/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6442 - accuracy: 0.7446\n",
            "Epoch 51/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6421 - accuracy: 0.7452\n",
            "Epoch 52/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6436 - accuracy: 0.7442\n",
            "Epoch 53/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6421 - accuracy: 0.7447\n",
            "Epoch 54/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.6401 - accuracy: 0.7448\n",
            "Epoch 55/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.6402 - accuracy: 0.7463\n",
            "Epoch 56/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.6397 - accuracy: 0.7464\n",
            "Epoch 57/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.6368 - accuracy: 0.7468\n",
            "Epoch 58/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6362 - accuracy: 0.7473\n",
            "Epoch 59/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6362 - accuracy: 0.7487\n",
            "Epoch 60/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6349 - accuracy: 0.7460\n",
            "Epoch 61/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6326 - accuracy: 0.7488\n",
            "Epoch 62/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6300 - accuracy: 0.7507\n",
            "Epoch 63/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.6316 - accuracy: 0.7507\n",
            "Epoch 64/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.6311 - accuracy: 0.7496\n",
            "Epoch 65/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.6275 - accuracy: 0.7507\n",
            "Epoch 66/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.6292 - accuracy: 0.7500\n",
            "Epoch 67/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6308 - accuracy: 0.7502\n",
            "Epoch 68/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6317 - accuracy: 0.7493\n",
            "Epoch 69/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6269 - accuracy: 0.7501\n",
            "Epoch 70/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6241 - accuracy: 0.7509\n",
            "Epoch 71/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6236 - accuracy: 0.7513\n",
            "Epoch 72/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6254 - accuracy: 0.7530\n",
            "Epoch 73/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.6237 - accuracy: 0.7524\n",
            "Epoch 74/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.6227 - accuracy: 0.7529\n",
            "Epoch 75/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.6204 - accuracy: 0.7545\n",
            "Epoch 76/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.6206 - accuracy: 0.7538\n",
            "Epoch 77/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6217 - accuracy: 0.7535\n",
            "Epoch 78/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6217 - accuracy: 0.7527\n",
            "Epoch 79/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6164 - accuracy: 0.7540\n",
            "Epoch 80/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6179 - accuracy: 0.7548\n",
            "Epoch 81/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6167 - accuracy: 0.7558\n",
            "Epoch 82/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6159 - accuracy: 0.7561\n",
            "Epoch 83/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.6168 - accuracy: 0.7558\n",
            "Epoch 84/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.6148 - accuracy: 0.7571\n",
            "Epoch 85/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.6137 - accuracy: 0.7569\n",
            "Epoch 86/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6152 - accuracy: 0.7567\n",
            "Epoch 87/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6122 - accuracy: 0.7559\n",
            "Epoch 88/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6169 - accuracy: 0.7542\n",
            "Epoch 89/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6141 - accuracy: 0.7561\n",
            "Epoch 90/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6144 - accuracy: 0.7562\n",
            "Epoch 91/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6095 - accuracy: 0.7581\n",
            "Epoch 92/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.6097 - accuracy: 0.7580\n",
            "Epoch 93/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.6122 - accuracy: 0.7583\n",
            "Epoch 94/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.6069 - accuracy: 0.7587\n",
            "Epoch 95/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6107 - accuracy: 0.7575\n",
            "Epoch 96/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6130 - accuracy: 0.7575\n",
            "Epoch 97/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6102 - accuracy: 0.7578\n",
            "Epoch 98/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6084 - accuracy: 0.7604\n",
            "Epoch 99/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6092 - accuracy: 0.7585\n",
            "Epoch 100/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6080 - accuracy: 0.7583\n",
            "Epoch 101/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6104 - accuracy: 0.7578\n",
            "Epoch 102/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6080 - accuracy: 0.7582\n",
            "Epoch 103/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6077 - accuracy: 0.7600\n",
            "Epoch 104/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6027 - accuracy: 0.7611\n",
            "Epoch 105/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6038 - accuracy: 0.7600\n",
            "Epoch 106/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6061 - accuracy: 0.7596\n",
            "Epoch 107/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6106 - accuracy: 0.7578\n",
            "Epoch 108/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6040 - accuracy: 0.7610\n",
            "Epoch 109/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6112 - accuracy: 0.7577\n",
            "Epoch 110/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6088 - accuracy: 0.7596\n",
            "Epoch 111/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.6052 - accuracy: 0.7597\n",
            "Epoch 112/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.6067 - accuracy: 0.7593\n",
            "Epoch 113/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.6035 - accuracy: 0.7593\n",
            "Epoch 114/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.6043 - accuracy: 0.7605\n",
            "Epoch 115/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6042 - accuracy: 0.7608\n",
            "Epoch 116/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.6026 - accuracy: 0.7608\n",
            "Epoch 117/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.6046 - accuracy: 0.7609\n",
            "Epoch 118/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5990 - accuracy: 0.7612\n",
            "Epoch 119/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.6020 - accuracy: 0.7610\n",
            "Epoch 120/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.5990 - accuracy: 0.7632\n",
            "Epoch 121/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.6014 - accuracy: 0.7606\n",
            "Epoch 122/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.5989 - accuracy: 0.7637\n",
            "Epoch 123/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.5991 - accuracy: 0.7629\n",
            "Epoch 124/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.5997 - accuracy: 0.7630\n",
            "Epoch 125/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5944 - accuracy: 0.7644\n",
            "Epoch 126/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5999 - accuracy: 0.7620\n",
            "Epoch 127/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5916 - accuracy: 0.7659\n",
            "Epoch 128/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.5966 - accuracy: 0.7632\n",
            "Epoch 129/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5933 - accuracy: 0.7650\n",
            "Epoch 130/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.5964 - accuracy: 0.7646\n",
            "Epoch 131/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6009 - accuracy: 0.7622\n",
            "Epoch 132/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5987 - accuracy: 0.7607\n",
            "Epoch 133/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5960 - accuracy: 0.7638\n",
            "Epoch 134/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6016 - accuracy: 0.7620\n",
            "Epoch 135/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5973 - accuracy: 0.7640\n",
            "Epoch 136/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5986 - accuracy: 0.7634\n",
            "Epoch 137/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5977 - accuracy: 0.7640\n",
            "Epoch 138/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.6016 - accuracy: 0.7618\n",
            "Epoch 139/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5949 - accuracy: 0.7645\n",
            "Epoch 140/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5959 - accuracy: 0.7638\n",
            "Epoch 141/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5958 - accuracy: 0.7636\n",
            "Epoch 142/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5977 - accuracy: 0.7632\n",
            "Epoch 143/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5948 - accuracy: 0.7642\n",
            "Epoch 144/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5955 - accuracy: 0.7638\n",
            "Epoch 145/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5974 - accuracy: 0.7636\n",
            "Epoch 146/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5924 - accuracy: 0.7649\n",
            "Epoch 147/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5945 - accuracy: 0.7653\n",
            "Epoch 148/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5890 - accuracy: 0.7664\n",
            "Epoch 149/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5993 - accuracy: 0.7637\n",
            "Epoch 150/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5943 - accuracy: 0.7640\n",
            "Epoch 151/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5981 - accuracy: 0.7623\n",
            "Epoch 152/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5935 - accuracy: 0.7643\n",
            "Epoch 153/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5963 - accuracy: 0.7637\n",
            "Epoch 154/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5930 - accuracy: 0.7653\n",
            "Epoch 155/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5993 - accuracy: 0.7615\n",
            "Epoch 156/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5991 - accuracy: 0.7630\n",
            "Epoch 157/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5934 - accuracy: 0.7637\n",
            "Epoch 158/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5939 - accuracy: 0.7643\n",
            "Epoch 159/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5901 - accuracy: 0.7660\n",
            "Epoch 160/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5969 - accuracy: 0.7636\n",
            "Epoch 161/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5941 - accuracy: 0.7652\n",
            "Epoch 162/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5896 - accuracy: 0.7659\n",
            "Epoch 163/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5961 - accuracy: 0.7639\n",
            "Epoch 164/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5961 - accuracy: 0.7634\n",
            "Epoch 165/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5907 - accuracy: 0.7653\n",
            "Epoch 166/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5935 - accuracy: 0.7642\n",
            "Epoch 167/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.5967 - accuracy: 0.7647\n",
            "Epoch 168/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.5910 - accuracy: 0.7671\n",
            "Epoch 169/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5937 - accuracy: 0.7654\n",
            "Epoch 170/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5957 - accuracy: 0.7630\n",
            "Epoch 171/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5918 - accuracy: 0.7656\n",
            "Epoch 172/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5919 - accuracy: 0.7648\n",
            "Epoch 173/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5936 - accuracy: 0.7650\n",
            "Epoch 174/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.5889 - accuracy: 0.7662\n",
            "Epoch 175/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5895 - accuracy: 0.7674\n",
            "Epoch 176/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5994 - accuracy: 0.7614\n",
            "Epoch 177/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.5933 - accuracy: 0.7651\n",
            "Epoch 178/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5924 - accuracy: 0.7657\n",
            "Epoch 179/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5968 - accuracy: 0.7632\n",
            "Epoch 180/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5895 - accuracy: 0.7651\n",
            "Epoch 181/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.5854 - accuracy: 0.7688\n",
            "Epoch 182/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.5918 - accuracy: 0.7652\n",
            "Epoch 183/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5960 - accuracy: 0.7634\n",
            "Epoch 184/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5900 - accuracy: 0.7673\n",
            "Epoch 185/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5921 - accuracy: 0.7665\n",
            "Epoch 186/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5935 - accuracy: 0.7644\n",
            "Epoch 187/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5896 - accuracy: 0.7674\n",
            "Epoch 188/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5910 - accuracy: 0.7653\n",
            "Epoch 189/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.5897 - accuracy: 0.7656\n",
            "Epoch 190/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.5902 - accuracy: 0.7652\n",
            "Epoch 191/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5883 - accuracy: 0.7668\n",
            "Epoch 192/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5943 - accuracy: 0.7644\n",
            "Epoch 193/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5858 - accuracy: 0.7670\n",
            "Epoch 194/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5913 - accuracy: 0.7638\n",
            "Epoch 195/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5936 - accuracy: 0.7647\n",
            "Epoch 196/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5912 - accuracy: 0.7655\n",
            "Epoch 197/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5887 - accuracy: 0.7654\n",
            "Epoch 198/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5891 - accuracy: 0.7669\n",
            "Epoch 199/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5911 - accuracy: 0.7656\n",
            "Epoch 200/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5933 - accuracy: 0.7649\n",
            "Epoch 201/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5880 - accuracy: 0.7681\n",
            "Epoch 202/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5912 - accuracy: 0.7665\n",
            "Epoch 203/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5857 - accuracy: 0.7676\n",
            "Epoch 204/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5819 - accuracy: 0.7704\n",
            "Epoch 205/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.5845 - accuracy: 0.7692\n",
            "Epoch 206/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.5866 - accuracy: 0.7676\n",
            "Epoch 207/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5883 - accuracy: 0.7672\n",
            "Epoch 208/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5906 - accuracy: 0.7650\n",
            "Epoch 209/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.5933 - accuracy: 0.7652\n",
            "Epoch 210/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.5909 - accuracy: 0.7663\n",
            "Epoch 211/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5915 - accuracy: 0.7657\n",
            "Epoch 212/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.5873 - accuracy: 0.7680\n",
            "Epoch 213/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.5838 - accuracy: 0.7688\n",
            "Epoch 214/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.5901 - accuracy: 0.7677\n",
            "Epoch 215/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.5872 - accuracy: 0.7667\n",
            "Epoch 216/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.5940 - accuracy: 0.7650\n",
            "Epoch 217/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5913 - accuracy: 0.7659\n",
            "Epoch 218/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5924 - accuracy: 0.7646\n",
            "Epoch 219/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5893 - accuracy: 0.7653\n",
            "Epoch 220/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5907 - accuracy: 0.7670\n",
            "Epoch 221/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.5880 - accuracy: 0.7678\n",
            "Epoch 222/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.5884 - accuracy: 0.7669\n",
            "Epoch 223/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.5903 - accuracy: 0.7673\n",
            "Epoch 224/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.5804 - accuracy: 0.7719\n",
            "Epoch 225/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5878 - accuracy: 0.7675\n",
            "Epoch 226/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5855 - accuracy: 0.7676\n",
            "Epoch 227/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5908 - accuracy: 0.7665\n",
            "Epoch 228/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5893 - accuracy: 0.7672\n",
            "Epoch 229/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.5872 - accuracy: 0.7681\n",
            "Epoch 230/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5888 - accuracy: 0.7682\n",
            "Epoch 231/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5863 - accuracy: 0.7674\n",
            "Epoch 232/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5864 - accuracy: 0.7669\n",
            "Epoch 233/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.5833 - accuracy: 0.7688\n",
            "Epoch 234/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5868 - accuracy: 0.7680\n",
            "Epoch 235/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5832 - accuracy: 0.7677\n",
            "Epoch 236/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5811 - accuracy: 0.7703\n",
            "Epoch 237/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.5931 - accuracy: 0.7649\n",
            "Epoch 238/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5922 - accuracy: 0.7655\n",
            "Epoch 239/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5871 - accuracy: 0.7669\n",
            "Epoch 240/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5904 - accuracy: 0.7671\n",
            "Epoch 241/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5903 - accuracy: 0.7671\n",
            "Epoch 242/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5895 - accuracy: 0.7676\n",
            "Epoch 243/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5859 - accuracy: 0.7694\n",
            "Epoch 244/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5861 - accuracy: 0.7676\n",
            "Epoch 245/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5909 - accuracy: 0.7647\n",
            "Epoch 246/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5849 - accuracy: 0.7683\n",
            "Epoch 247/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5881 - accuracy: 0.7656\n",
            "Epoch 248/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5853 - accuracy: 0.7699\n",
            "Epoch 249/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5861 - accuracy: 0.7675\n",
            "Epoch 250/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5906 - accuracy: 0.7652\n",
            "Epoch 251/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5883 - accuracy: 0.7672\n",
            "Epoch 252/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5961 - accuracy: 0.7635\n",
            "Epoch 253/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5929 - accuracy: 0.7662\n",
            "Epoch 254/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.5846 - accuracy: 0.7695\n",
            "Epoch 255/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.5867 - accuracy: 0.7669\n",
            "Epoch 256/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5818 - accuracy: 0.7709\n",
            "Epoch 257/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5917 - accuracy: 0.7659\n",
            "Epoch 258/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5840 - accuracy: 0.7695\n",
            "Epoch 259/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.5885 - accuracy: 0.7671\n",
            "Epoch 260/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5860 - accuracy: 0.7666\n",
            "Epoch 261/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.5894 - accuracy: 0.7671\n",
            "Epoch 262/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.5850 - accuracy: 0.7678\n",
            "Epoch 263/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.5935 - accuracy: 0.7650\n",
            "Epoch 264/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.5929 - accuracy: 0.7641\n",
            "Epoch 265/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5938 - accuracy: 0.7657\n",
            "Epoch 266/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5911 - accuracy: 0.7663\n",
            "Epoch 267/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5856 - accuracy: 0.7675\n",
            "Epoch 268/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5875 - accuracy: 0.7664\n",
            "Epoch 269/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5926 - accuracy: 0.7658\n",
            "Epoch 270/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5886 - accuracy: 0.7675\n",
            "Epoch 271/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5866 - accuracy: 0.7673\n",
            "Epoch 272/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5836 - accuracy: 0.7686\n",
            "Epoch 273/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5829 - accuracy: 0.7692\n",
            "Epoch 274/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5849 - accuracy: 0.7679\n",
            "Epoch 275/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5833 - accuracy: 0.7691\n",
            "Epoch 276/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5803 - accuracy: 0.7702\n",
            "Epoch 277/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5844 - accuracy: 0.7677\n",
            "Epoch 278/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5853 - accuracy: 0.7699\n",
            "Epoch 279/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5930 - accuracy: 0.7651\n",
            "Epoch 280/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5917 - accuracy: 0.7659\n",
            "Epoch 281/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5847 - accuracy: 0.7680\n",
            "Epoch 282/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5863 - accuracy: 0.7692\n",
            "Epoch 283/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5847 - accuracy: 0.7675\n",
            "Epoch 284/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.5887 - accuracy: 0.7665\n",
            "Epoch 285/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.5885 - accuracy: 0.7671\n",
            "Epoch 286/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.5848 - accuracy: 0.7682\n",
            "Epoch 287/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5893 - accuracy: 0.7667\n",
            "Epoch 288/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5875 - accuracy: 0.7667\n",
            "Epoch 289/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5815 - accuracy: 0.7698\n",
            "Epoch 290/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5873 - accuracy: 0.7679\n",
            "Epoch 291/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5890 - accuracy: 0.7664\n",
            "Epoch 292/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5914 - accuracy: 0.7660\n",
            "Epoch 293/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.5876 - accuracy: 0.7678\n",
            "Epoch 294/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.5832 - accuracy: 0.7695\n",
            "Epoch 295/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.5881 - accuracy: 0.7676\n",
            "Epoch 296/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.5852 - accuracy: 0.7697\n",
            "Epoch 297/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5939 - accuracy: 0.7635\n",
            "Epoch 298/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5878 - accuracy: 0.7676\n",
            "Epoch 299/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5789 - accuracy: 0.7699\n",
            "Epoch 300/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5822 - accuracy: 0.7695\n",
            "Epoch 301/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5867 - accuracy: 0.7683\n",
            "Epoch 302/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5806 - accuracy: 0.7693\n",
            "Epoch 303/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5837 - accuracy: 0.7689\n",
            "Epoch 304/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5867 - accuracy: 0.7666\n",
            "Epoch 305/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5896 - accuracy: 0.7674\n",
            "Epoch 306/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5865 - accuracy: 0.7680\n",
            "Epoch 307/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5880 - accuracy: 0.7678\n",
            "Epoch 308/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5850 - accuracy: 0.7696\n",
            "Epoch 309/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5940 - accuracy: 0.7643\n",
            "Epoch 310/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5859 - accuracy: 0.7682\n",
            "Epoch 311/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5841 - accuracy: 0.7691\n",
            "Epoch 312/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5893 - accuracy: 0.7673\n",
            "Epoch 313/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5895 - accuracy: 0.7671\n",
            "Epoch 314/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5899 - accuracy: 0.7662\n",
            "Epoch 315/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.5808 - accuracy: 0.7709\n",
            "Epoch 316/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.5908 - accuracy: 0.7660\n",
            "Epoch 317/1000\n",
            "2712/2712 [==============================] - 8s 3ms/step - loss: 0.5868 - accuracy: 0.7687\n",
            "Epoch 318/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5832 - accuracy: 0.7704\n",
            "Epoch 319/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5896 - accuracy: 0.7680\n",
            "Epoch 320/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5961 - accuracy: 0.7650\n",
            "Epoch 321/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5897 - accuracy: 0.7658\n",
            "Epoch 322/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5841 - accuracy: 0.7701\n",
            "Epoch 323/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5830 - accuracy: 0.7697\n",
            "Epoch 324/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5868 - accuracy: 0.7688\n",
            "Epoch 325/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5837 - accuracy: 0.7685\n",
            "Epoch 326/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5866 - accuracy: 0.7683\n",
            "Epoch 327/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5921 - accuracy: 0.7654\n",
            "Epoch 328/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5854 - accuracy: 0.7686\n",
            "Epoch 329/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5869 - accuracy: 0.7681\n",
            "Epoch 330/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5870 - accuracy: 0.7668\n",
            "Epoch 331/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5934 - accuracy: 0.7654\n",
            "Epoch 332/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5874 - accuracy: 0.7674\n",
            "Epoch 333/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5870 - accuracy: 0.7675\n",
            "Epoch 334/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5847 - accuracy: 0.7678\n",
            "Epoch 335/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5804 - accuracy: 0.7710\n",
            "Epoch 336/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5860 - accuracy: 0.7666\n",
            "Epoch 337/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5801 - accuracy: 0.7698\n",
            "Epoch 338/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5868 - accuracy: 0.7671\n",
            "Epoch 339/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5909 - accuracy: 0.7683\n",
            "Epoch 340/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5838 - accuracy: 0.7698\n",
            "Epoch 341/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5898 - accuracy: 0.7661\n",
            "Epoch 342/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5858 - accuracy: 0.7686\n",
            "Epoch 343/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5851 - accuracy: 0.7685\n",
            "Epoch 344/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5792 - accuracy: 0.7716\n",
            "Epoch 345/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5807 - accuracy: 0.7701\n",
            "Epoch 346/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5848 - accuracy: 0.7677\n",
            "Epoch 347/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5883 - accuracy: 0.7672\n",
            "Epoch 348/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5934 - accuracy: 0.7653\n",
            "Epoch 349/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5952 - accuracy: 0.7650\n",
            "Epoch 350/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5846 - accuracy: 0.7677\n",
            "Epoch 351/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5878 - accuracy: 0.7666\n",
            "Epoch 352/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5841 - accuracy: 0.7691\n",
            "Epoch 353/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5835 - accuracy: 0.7685\n",
            "Epoch 354/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5832 - accuracy: 0.7703\n",
            "Epoch 355/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5861 - accuracy: 0.7685\n",
            "Epoch 356/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5816 - accuracy: 0.7702\n",
            "Epoch 357/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5837 - accuracy: 0.7680\n",
            "Epoch 358/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5874 - accuracy: 0.7688\n",
            "Epoch 359/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5886 - accuracy: 0.7666\n",
            "Epoch 360/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5814 - accuracy: 0.7697\n",
            "Epoch 361/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5865 - accuracy: 0.7676\n",
            "Epoch 362/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5881 - accuracy: 0.7676\n",
            "Epoch 363/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5817 - accuracy: 0.7706\n",
            "Epoch 364/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5857 - accuracy: 0.7679\n",
            "Epoch 365/1000\n",
            "2712/2712 [==============================] - 11s 4ms/step - loss: 0.5808 - accuracy: 0.7699\n",
            "Epoch 366/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5869 - accuracy: 0.7675\n",
            "Epoch 367/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5885 - accuracy: 0.7671\n",
            "Epoch 368/1000\n",
            "2712/2712 [==============================] - 11s 4ms/step - loss: 0.5855 - accuracy: 0.7684\n",
            "Epoch 369/1000\n",
            "2712/2712 [==============================] - 11s 4ms/step - loss: 0.5807 - accuracy: 0.7711\n",
            "Epoch 370/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5867 - accuracy: 0.7694\n",
            "Epoch 371/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.6003 - accuracy: 0.7618\n",
            "Epoch 372/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5846 - accuracy: 0.7686\n",
            "Epoch 373/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5866 - accuracy: 0.7680\n",
            "Epoch 374/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5826 - accuracy: 0.7689\n",
            "Epoch 375/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5967 - accuracy: 0.7642\n",
            "Epoch 376/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5907 - accuracy: 0.7661\n",
            "Epoch 377/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5866 - accuracy: 0.7665\n",
            "Epoch 378/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5883 - accuracy: 0.7669\n",
            "Epoch 379/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5908 - accuracy: 0.7657\n",
            "Epoch 380/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5862 - accuracy: 0.7676\n",
            "Epoch 381/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5872 - accuracy: 0.7674\n",
            "Epoch 382/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5822 - accuracy: 0.7692\n",
            "Epoch 383/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5859 - accuracy: 0.7680\n",
            "Epoch 384/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5910 - accuracy: 0.7651\n",
            "Epoch 385/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5905 - accuracy: 0.7665\n",
            "Epoch 386/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5932 - accuracy: 0.7655\n",
            "Epoch 387/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5881 - accuracy: 0.7683\n",
            "Epoch 388/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5922 - accuracy: 0.7651\n",
            "Epoch 389/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5860 - accuracy: 0.7679\n",
            "Epoch 390/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5893 - accuracy: 0.7677\n",
            "Epoch 391/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5851 - accuracy: 0.7680\n",
            "Epoch 392/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5937 - accuracy: 0.7642\n",
            "Epoch 393/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5864 - accuracy: 0.7683\n",
            "Epoch 394/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5891 - accuracy: 0.7673\n",
            "Epoch 395/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5912 - accuracy: 0.7652\n",
            "Epoch 396/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5826 - accuracy: 0.7695\n",
            "Epoch 397/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5884 - accuracy: 0.7666\n",
            "Epoch 398/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5899 - accuracy: 0.7669\n",
            "Epoch 399/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5938 - accuracy: 0.7646\n",
            "Epoch 400/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5894 - accuracy: 0.7665\n",
            "Epoch 401/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5917 - accuracy: 0.7663\n",
            "Epoch 402/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5891 - accuracy: 0.7670\n",
            "Epoch 403/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5820 - accuracy: 0.7697\n",
            "Epoch 404/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5932 - accuracy: 0.7649\n",
            "Epoch 405/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5851 - accuracy: 0.7686\n",
            "Epoch 406/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5842 - accuracy: 0.7689\n",
            "Epoch 407/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5914 - accuracy: 0.7654\n",
            "Epoch 408/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5865 - accuracy: 0.7679\n",
            "Epoch 409/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5974 - accuracy: 0.7632\n",
            "Epoch 410/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5858 - accuracy: 0.7679\n",
            "Epoch 411/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5843 - accuracy: 0.7689\n",
            "Epoch 412/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5854 - accuracy: 0.7684\n",
            "Epoch 413/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5937 - accuracy: 0.7632\n",
            "Epoch 414/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5958 - accuracy: 0.7637\n",
            "Epoch 415/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5899 - accuracy: 0.7660\n",
            "Epoch 416/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5914 - accuracy: 0.7657\n",
            "Epoch 417/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5917 - accuracy: 0.7665\n",
            "Epoch 418/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5870 - accuracy: 0.7669\n",
            "Epoch 419/1000\n",
            "2712/2712 [==============================] - 9s 3ms/step - loss: 0.5831 - accuracy: 0.7710\n",
            "Epoch 420/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5863 - accuracy: 0.7679\n",
            "Epoch 421/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5843 - accuracy: 0.7690\n",
            "Epoch 422/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5944 - accuracy: 0.7651\n",
            "Epoch 423/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5924 - accuracy: 0.7649\n",
            "Epoch 424/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5771 - accuracy: 0.7712\n",
            "Epoch 425/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5849 - accuracy: 0.7683\n",
            "Epoch 426/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5913 - accuracy: 0.7656\n",
            "Epoch 427/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5895 - accuracy: 0.7664\n",
            "Epoch 428/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5899 - accuracy: 0.7663\n",
            "Epoch 429/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5849 - accuracy: 0.7680\n",
            "Epoch 430/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5903 - accuracy: 0.7647\n",
            "Epoch 431/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5861 - accuracy: 0.7674\n",
            "Epoch 432/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5836 - accuracy: 0.7680\n",
            "Epoch 433/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5812 - accuracy: 0.7706\n",
            "Epoch 434/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5821 - accuracy: 0.7695\n",
            "Epoch 435/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5870 - accuracy: 0.7669\n",
            "Epoch 436/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5846 - accuracy: 0.7697\n",
            "Epoch 437/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5832 - accuracy: 0.7684\n",
            "Epoch 438/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5818 - accuracy: 0.7683\n",
            "Epoch 439/1000\n",
            "2712/2712 [==============================] - 10s 3ms/step - loss: 0.5895 - accuracy: 0.7678\n",
            "Epoch 440/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5895 - accuracy: 0.7658\n",
            "Epoch 441/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.6026 - accuracy: 0.7618\n",
            "Epoch 442/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5966 - accuracy: 0.7632\n",
            "Epoch 443/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5923 - accuracy: 0.7658\n",
            "Epoch 444/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5879 - accuracy: 0.7688\n",
            "Epoch 445/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5801 - accuracy: 0.7706\n",
            "Epoch 446/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5774 - accuracy: 0.7707\n",
            "Epoch 447/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5874 - accuracy: 0.7666\n",
            "Epoch 448/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5837 - accuracy: 0.7677\n",
            "Epoch 449/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5810 - accuracy: 0.7698\n",
            "Epoch 450/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5861 - accuracy: 0.7673\n",
            "Epoch 451/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5853 - accuracy: 0.7677\n",
            "Epoch 452/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5806 - accuracy: 0.7694\n",
            "Epoch 453/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5909 - accuracy: 0.7663\n",
            "Epoch 454/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5904 - accuracy: 0.7662\n",
            "Epoch 455/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5879 - accuracy: 0.7673\n",
            "Epoch 456/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5836 - accuracy: 0.7704\n",
            "Epoch 457/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5829 - accuracy: 0.7696\n",
            "Epoch 458/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5878 - accuracy: 0.7671\n",
            "Epoch 459/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5882 - accuracy: 0.7669\n",
            "Epoch 460/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5872 - accuracy: 0.7678\n",
            "Epoch 461/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5894 - accuracy: 0.7674\n",
            "Epoch 462/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5896 - accuracy: 0.7656\n",
            "Epoch 463/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5940 - accuracy: 0.7649\n",
            "Epoch 464/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5862 - accuracy: 0.7662\n",
            "Epoch 465/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5877 - accuracy: 0.7683\n",
            "Epoch 466/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5889 - accuracy: 0.7673\n",
            "Epoch 467/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5954 - accuracy: 0.7644\n",
            "Epoch 468/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5928 - accuracy: 0.7655\n",
            "Epoch 469/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5876 - accuracy: 0.7684\n",
            "Epoch 470/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5843 - accuracy: 0.7698\n",
            "Epoch 471/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5869 - accuracy: 0.7675\n",
            "Epoch 472/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5935 - accuracy: 0.7663\n",
            "Epoch 473/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5889 - accuracy: 0.7675\n",
            "Epoch 474/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5921 - accuracy: 0.7667\n",
            "Epoch 475/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5831 - accuracy: 0.7710\n",
            "Epoch 476/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5892 - accuracy: 0.7667\n",
            "Epoch 477/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5885 - accuracy: 0.7684\n",
            "Epoch 478/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5855 - accuracy: 0.7674\n",
            "Epoch 479/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5947 - accuracy: 0.7650\n",
            "Epoch 480/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5900 - accuracy: 0.7671\n",
            "Epoch 481/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5926 - accuracy: 0.7661\n",
            "Epoch 482/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5909 - accuracy: 0.7670\n",
            "Epoch 483/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.6015 - accuracy: 0.7630\n",
            "Epoch 484/1000\n",
            "2712/2712 [==============================] - 11s 4ms/step - loss: 0.5931 - accuracy: 0.7664\n",
            "Epoch 485/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5926 - accuracy: 0.7657\n",
            "Epoch 486/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5864 - accuracy: 0.7681\n",
            "Epoch 487/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5944 - accuracy: 0.7638\n",
            "Epoch 488/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5913 - accuracy: 0.7659\n",
            "Epoch 489/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5874 - accuracy: 0.7671\n",
            "Epoch 490/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5866 - accuracy: 0.7691\n",
            "Epoch 491/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5817 - accuracy: 0.7696\n",
            "Epoch 492/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5946 - accuracy: 0.7652\n",
            "Epoch 493/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5986 - accuracy: 0.7628\n",
            "Epoch 494/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5859 - accuracy: 0.7691\n",
            "Epoch 495/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5956 - accuracy: 0.7653\n",
            "Epoch 496/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5915 - accuracy: 0.7665\n",
            "Epoch 497/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5835 - accuracy: 0.7687\n",
            "Epoch 498/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5874 - accuracy: 0.7686\n",
            "Epoch 499/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5955 - accuracy: 0.7647\n",
            "Epoch 500/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5932 - accuracy: 0.7660\n",
            "Epoch 501/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5918 - accuracy: 0.7660\n",
            "Epoch 502/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5888 - accuracy: 0.7661\n",
            "Epoch 503/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5912 - accuracy: 0.7664\n",
            "Epoch 504/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5861 - accuracy: 0.7682\n",
            "Epoch 505/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5902 - accuracy: 0.7648\n",
            "Epoch 506/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5880 - accuracy: 0.7650\n",
            "Epoch 507/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5814 - accuracy: 0.7690\n",
            "Epoch 508/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5968 - accuracy: 0.7631\n",
            "Epoch 509/1000\n",
            "2712/2712 [==============================] - 11s 4ms/step - loss: 0.5873 - accuracy: 0.7672\n",
            "Epoch 510/1000\n",
            "2712/2712 [==============================] - 11s 4ms/step - loss: 0.5897 - accuracy: 0.7676\n",
            "Epoch 511/1000\n",
            "2712/2712 [==============================] - 11s 4ms/step - loss: 0.5929 - accuracy: 0.7648\n",
            "Epoch 512/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5887 - accuracy: 0.7657\n",
            "Epoch 513/1000\n",
            "2712/2712 [==============================] - 11s 4ms/step - loss: 0.5859 - accuracy: 0.7679\n",
            "Epoch 514/1000\n",
            "2712/2712 [==============================] - 11s 4ms/step - loss: 0.5862 - accuracy: 0.7685\n",
            "Epoch 515/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5891 - accuracy: 0.7673\n",
            "Epoch 516/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5983 - accuracy: 0.7633\n",
            "Epoch 517/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.6017 - accuracy: 0.7614\n",
            "Epoch 518/1000\n",
            "2712/2712 [==============================] - 11s 4ms/step - loss: 0.5973 - accuracy: 0.7638\n",
            "Epoch 519/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5962 - accuracy: 0.7640\n",
            "Epoch 520/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5801 - accuracy: 0.7707\n",
            "Epoch 521/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5846 - accuracy: 0.7677\n",
            "Epoch 522/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5994 - accuracy: 0.7644\n",
            "Epoch 523/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5886 - accuracy: 0.7679\n",
            "Epoch 524/1000\n",
            "2712/2712 [==============================] - 11s 4ms/step - loss: 0.6010 - accuracy: 0.7622\n",
            "Epoch 525/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5915 - accuracy: 0.7650\n",
            "Epoch 526/1000\n",
            "2712/2712 [==============================] - 11s 4ms/step - loss: 0.5914 - accuracy: 0.7658\n",
            "Epoch 527/1000\n",
            "2712/2712 [==============================] - 11s 4ms/step - loss: 0.5923 - accuracy: 0.7662\n",
            "Epoch 528/1000\n",
            "2712/2712 [==============================] - 11s 4ms/step - loss: 0.5867 - accuracy: 0.7677\n",
            "Epoch 529/1000\n",
            "2712/2712 [==============================] - 11s 4ms/step - loss: 0.5909 - accuracy: 0.7674\n",
            "Epoch 530/1000\n",
            "2712/2712 [==============================] - 11s 4ms/step - loss: 0.5912 - accuracy: 0.7656\n",
            "Epoch 531/1000\n",
            "2712/2712 [==============================] - 11s 4ms/step - loss: 0.5870 - accuracy: 0.7681\n",
            "Epoch 532/1000\n",
            "2712/2712 [==============================] - 11s 4ms/step - loss: 0.5880 - accuracy: 0.7673\n",
            "Epoch 533/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5863 - accuracy: 0.7676\n",
            "Epoch 534/1000\n",
            "2712/2712 [==============================] - 11s 4ms/step - loss: 0.5852 - accuracy: 0.7684\n",
            "Epoch 535/1000\n",
            "2712/2712 [==============================] - 11s 4ms/step - loss: 0.5868 - accuracy: 0.7666\n",
            "Epoch 536/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5888 - accuracy: 0.7668\n",
            "Epoch 537/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5922 - accuracy: 0.7665\n",
            "Epoch 538/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5870 - accuracy: 0.7691\n",
            "Epoch 539/1000\n",
            "2712/2712 [==============================] - 11s 4ms/step - loss: 0.5867 - accuracy: 0.7687\n",
            "Epoch 540/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5864 - accuracy: 0.7694\n",
            "Epoch 541/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5825 - accuracy: 0.7688\n",
            "Epoch 542/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5935 - accuracy: 0.7654\n",
            "Epoch 543/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5900 - accuracy: 0.7681\n",
            "Epoch 544/1000\n",
            "2712/2712 [==============================] - 11s 4ms/step - loss: 0.5901 - accuracy: 0.7661\n",
            "Epoch 545/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5914 - accuracy: 0.7659\n",
            "Epoch 546/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5901 - accuracy: 0.7664\n",
            "Epoch 547/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5993 - accuracy: 0.7631\n",
            "Epoch 548/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5922 - accuracy: 0.7659\n",
            "Epoch 549/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5963 - accuracy: 0.7649\n",
            "Epoch 550/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5916 - accuracy: 0.7650\n",
            "Epoch 551/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5931 - accuracy: 0.7649\n",
            "Epoch 552/1000\n",
            "2712/2712 [==============================] - 11s 4ms/step - loss: 0.5951 - accuracy: 0.7656\n",
            "Epoch 553/1000\n",
            "2712/2712 [==============================] - 11s 4ms/step - loss: 0.5991 - accuracy: 0.7639\n",
            "Epoch 554/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5902 - accuracy: 0.7648\n",
            "Epoch 555/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5956 - accuracy: 0.7645\n",
            "Epoch 556/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5877 - accuracy: 0.7669\n",
            "Epoch 557/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5951 - accuracy: 0.7648\n",
            "Epoch 558/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5895 - accuracy: 0.7665\n",
            "Epoch 559/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5924 - accuracy: 0.7655\n",
            "Epoch 560/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5957 - accuracy: 0.7629\n",
            "Epoch 561/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5882 - accuracy: 0.7673\n",
            "Epoch 562/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5890 - accuracy: 0.7661\n",
            "Epoch 563/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5883 - accuracy: 0.7660\n",
            "Epoch 564/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5881 - accuracy: 0.7672\n",
            "Epoch 565/1000\n",
            "2712/2712 [==============================] - 11s 4ms/step - loss: 0.5837 - accuracy: 0.7698\n",
            "Epoch 566/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5837 - accuracy: 0.7703\n",
            "Epoch 567/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5871 - accuracy: 0.7691\n",
            "Epoch 568/1000\n",
            "2712/2712 [==============================] - 11s 4ms/step - loss: 0.5970 - accuracy: 0.7643\n",
            "Epoch 569/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5973 - accuracy: 0.7632\n",
            "Epoch 570/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5981 - accuracy: 0.7626\n",
            "Epoch 571/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5913 - accuracy: 0.7665\n",
            "Epoch 572/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5905 - accuracy: 0.7668\n",
            "Epoch 573/1000\n",
            "2712/2712 [==============================] - 11s 4ms/step - loss: 0.5971 - accuracy: 0.7636\n",
            "Epoch 574/1000\n",
            "2712/2712 [==============================] - 11s 4ms/step - loss: 0.5887 - accuracy: 0.7670\n",
            "Epoch 575/1000\n",
            "2712/2712 [==============================] - 11s 4ms/step - loss: 0.5937 - accuracy: 0.7641\n",
            "Epoch 576/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5814 - accuracy: 0.7717\n",
            "Epoch 577/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5920 - accuracy: 0.7648\n",
            "Epoch 578/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5915 - accuracy: 0.7657\n",
            "Epoch 579/1000\n",
            "2712/2712 [==============================] - 10s 4ms/step - loss: 0.5987 - accuracy: 0.7634\n",
            "Epoch 580/1000\n",
            "2545/2712 [===========================>..] - ETA: 0s - loss: 0.5952 - accuracy: 0.7642"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-fa66c1b31a85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m               metrics=['accuracy'])\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3itZB-Rc7ri7",
        "outputId": "2546ceed-82df-483e-a8e4-daa58bafc3b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "678/678 [==============================] - 2s 3ms/step - loss: 0.7376 - accuracy: 0.7203\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7376335859298706, 0.7203448414802551]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red' size='8'>A msg for RAHAT SIR:</font><br>\n",
        "I did not change any syntex in next sections. It is just like the tensoreflow_NN.ipynb file, that you shared. "
      ],
      "metadata": {
        "id": "iJwQaG3rhFTf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#---------------------------------------------------------------\n",
        "________________________________________________________________"
      ],
      "metadata": {
        "id": "dkR_5W4QEHOi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparing Accuracy with RF and SVM (with different kernels):"
      ],
      "metadata": {
        "id": "91uov3c0fq6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier #ensemble is used if we have to use multiple algorithms \n",
        "model_rf = RandomForestClassifier(n_estimators=30) # n_estimators = number of random dicision trees \n",
        "model_rf.fit(X_train_flattened, y_train)"
      ],
      "metadata": {
        "id": "0VIBlREQfqd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_rf.score(X_test_flattened, y_test)"
      ],
      "metadata": {
        "id": "YasAlvZsfvn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "model_svm = SVC()"
      ],
      "metadata": {
        "id": "O1b8PwnXfyef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_svm.fit(X_train_flattened, y_train)\n",
        "model_svm.score(X_test_flattened, y_test)"
      ],
      "metadata": {
        "id": "h_K9EVrof1QV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_svm_poly = SVC(kernel='poly')\n",
        "model_svm_poly.fit(X_train_flattened, y_train)\n",
        "model_svm_poly.score(X_test_flattened, y_test)"
      ],
      "metadata": {
        "id": "Du75JrsZf3v8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_svm_rbf = SVC(kernel='rbf')\n",
        "model_svm_rbf.fit(X_train_flattened, y_train)\n",
        "model_svm_rbf.score(X_test_flattened, y_test)"
      ],
      "metadata": {
        "id": "EDslxw7yf6U_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AmyEXFp7rjx"
      },
      "source": [
        "<h2>Improve NN with scaling the features</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TcdzWLez7rjy"
      },
      "outputs": [],
      "source": [
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n",
        "X_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_flattened_1 = X_train.reshape(len(X_train), 28*28)\n",
        "X_test_flattened_1 = X_test.reshape(len(X_test), 28*28)\n",
        "model.fit(X_train_flattened_1, y_train, epochs=5)"
      ],
      "metadata": {
        "id": "iHQZ_d8CgGt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_flattened_1, y_train, epochs=15)"
      ],
      "metadata": {
        "id": "V9zoHjyGgJ5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test_flattened_1, y_test)"
      ],
      "metadata": {
        "id": "98DzwRVLgM3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrJUlUpM7rkS"
      },
      "source": [
        "<h3>Now we try to draw the Confusion matrix</h3>\n",
        "<p>Here, the NN will predict the test data considering each of the neurons. So, we need to find out the best neuron which is giving us the highest prediction.\n",
        "    <br> In this case we have to use the argmax() function for those neurons. </p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zW7SM71J7rkT"
      },
      "outputs": [],
      "source": [
        "y_predicted = model.predict(X_test_flattened_1)\n",
        "y_predicted_labels = [np.argmax(i) for i in y_predicted]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfQIjY8f7rkT"
      },
      "source": [
        "**Now we need to draw the confusion matrix to show where our model is doing mistakes**\n",
        "<br>\n",
        "<br>\n",
        "***Tensorflow has its own confusion matrix function where \"labels\" is the truth data and \"predictions\" is the predicted data***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DUneWC5k7rkT"
      },
      "outputs": [],
      "source": [
        "cm = tf.math.confusion_matrix(labels=y_test,predictions=y_predicted_labels)\n",
        "cm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5GbjX6za7rkU",
        "outputId": "69cb63b6-5651-4520-9e24-68e1d46fad1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(69.0, 0.5, 'Truth')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import seaborn as sn\n",
        "plt.figure(figsize = (10,7))\n",
        "sn.heatmap(cm, annot=True, fmt='d') # here, cm is called to be visualized\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Truth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvYkDLFM7rkU"
      },
      "source": [
        "<h3>Add hidden layers in the NN to improve the accuracy</h3>\n",
        "<p>What we will do here: <br>\n",
        "    1. The first layer includes the input layer and hidden layer. The number of neurons in the hidden layer is fixed based on some trail and error <br>\n",
        "    2. The last layer includes the output layer<br>\n",
        "    3. layers are comma (,) separated\n",
        "    \n",
        "<b>Note: When the NN adds hidden layer, it will take more time to be trained</b>\n",
        "\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BqT6dFTF7rkU"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(100, input_shape=(784,), activation='relu'), # input layer\n",
        "    keras.layers.Dense(10, activation='sigmoid') # output layer\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train_flattened, y_train, epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3HxUrZsG7rkV"
      },
      "outputs": [],
      "source": [
        "model.fit(X_train_flattened, y_train, epochs=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJ5a7j1l7rka"
      },
      "outputs": [],
      "source": [
        "model.evaluate(X_test_flattened, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xF69s0v17rka"
      },
      "outputs": [],
      "source": [
        "y_predicted = model.predict(X_test_flattened)\n",
        "y_predicted_labels = [np.argmax(i) for i in y_predicted]\n",
        "cm = tf.math.confusion_matrix(labels=y_test,predictions=y_predicted_labels)\n",
        "\n",
        "plt.figure(figsize = (10,7))\n",
        "sn.heatmap(cm, annot=True, fmt='d')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Truth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQ66xrYE7rkb"
      },
      "source": [
        "<h3>Using Flatten layer so that we don't have to call .reshape function on input dataset</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTflNSFY7rkb"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)), # input layer is reshaped and flattened\n",
        "    keras.layers.Dense(100, activation='relu'), # input layer\n",
        "    keras.layers.Dense(10, activation='sigmoid') # output layer\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1WclpdP7rkb",
        "outputId": "d35cbf4a-26ea-4e28-c85a-7a81329fb8f2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(69.0, 0.5, 'Truth')"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "y_predicted = model.predict(X_test)\n",
        "y_predicted_labels = [np.argmax(i) for i in y_predicted]\n",
        "cm = tf.math.confusion_matrix(labels=y_test,predictions=y_predicted_labels)\n",
        "\n",
        "plt.figure(figsize = (10,7))\n",
        "sn.heatmap(cm, annot=True, fmt='d')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Truth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WU_ix7vZ7rkc"
      },
      "outputs": [],
      "source": [
        "model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AboWdW_87rkc"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "ANN_Final.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
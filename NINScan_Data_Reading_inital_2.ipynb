{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP+cqNBQ1u7ZKPl1x3yxZwi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4b75605c183d4465b490c230fb5bc240": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "/content/2022-0318-115200-50228.nin",
            "description_tooltip": null,
            "disabled": false,
            "indent": false,
            "layout": "IPY_MODEL_94686f89e7cc4d9c8e45042878be0b21",
            "style": "IPY_MODEL_d3b30e5cc8524294a12b81762d1683f8",
            "value": false
          }
        },
        "94686f89e7cc4d9c8e45042878be0b21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3b30e5cc8524294a12b81762d1683f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d61ec988ca6848a2ba5368754b2d0694": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "/content/2022-0318-115200-50227.nin",
            "description_tooltip": null,
            "disabled": false,
            "indent": false,
            "layout": "IPY_MODEL_2dfb2d5b195049149dd9b79eb9541d55",
            "style": "IPY_MODEL_c0b3cf2040184e63b551809eb5cd5205",
            "value": true
          }
        },
        "2dfb2d5b195049149dd9b79eb9541d55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0b3cf2040184e63b551809eb5cd5205": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RafsanJany-44/ARC/blob/master/NINScan_Data_Reading_inital_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "in7a9BKPDw8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import struct\n",
        "\n",
        "\n",
        "\n",
        "hbohb_extinctions = np.array([\n",
        "#Lambda  O2Hb    HHb\n",
        "[250,   106112, 112736],\n",
        "[252,   105552, 112736],\n",
        "[254,   107660, 112736],\n",
        "[256,   109788, 113824],\n",
        "[258,   112944, 115040],\n",
        "[260,   116376, 116296],\n",
        "[262,   120188, 117564],\n",
        "[264,   124412, 118876],\n",
        "[266,   128696, 120208],\n",
        "[268,   133064, 121544],\n",
        "[270,   136068, 122880],\n",
        "[272,   137232, 123096],\n",
        "[274,   138408, 121952],\n",
        "[276,   137424, 120808],\n",
        "[278,   135820, 119840],\n",
        "[280,   131936, 118872],\n",
        "[282,   127720, 117628],\n",
        "[284,   122280, 114820],\n",
        "[286,   116508, 112008],\n",
        "[288,   108484, 107140],\n",
        "[290,   104752, 98364],\n",
        "[292,   98936,  91636],\n",
        "[294,   88136,  85820],\n",
        "[296,   79316,  77100],\n",
        "[298,   70884,  69444],\n",
        "[300,   65972,  64440],\n",
        "[302,   63208,  61300],\n",
        "[304,   61952,  58828],\n",
        "[306,   62352,  56908],\n",
        "[308,   62856,  57620],\n",
        "[310,   63352,  59156],\n",
        "[312,   65972,  62248],\n",
        "[314,   69016,  65344],\n",
        "[316,   72404,  68312],\n",
        "[318,   75536,  71208],\n",
        "[320,   78752,  74508],\n",
        "[322,   82256,  78284],\n",
        "[324,   85972,  82060],\n",
        "[326,   89796,  85592],\n",
        "[328,   93768,  88516],\n",
        "[330,   97512,  90856],\n",
        "[332,   100964, 93192],\n",
        "[334,   103504, 95532],\n",
        "[336,   104968, 99792],\n",
        "[338,   106452, 104476],\n",
        "[340,   107884, 108472],\n",
        "[342,   109060, 110996],\n",
        "[344,   110092, 113524],\n",
        "[346,   109032, 116052],\n",
        "[348,   107984, 118752],\n",
        "[350,   106576, 122092],\n",
        "[352,   105040, 125436],\n",
        "[354,   103696, 128776],\n",
        "[356,   101568, 132120],\n",
        "[358,   97828,  133632],\n",
        "[360,   94744,  134940],\n",
        "[362,   92248,  136044],\n",
        "[364,   89836,  136972],\n",
        "[366,   88484,  137900],\n",
        "[368,   87512,  138856],\n",
        "[370,   88176,  139968],\n",
        "[372,   91592,  141084],\n",
        "[374,   95140,  142196],\n",
        "[376,   98936,  143312],\n",
        "[378,   103432, 144424],\n",
        "[380,   109564, 145232],\n",
        "[382,   116968, 145232],\n",
        "[384,   125420, 148668],\n",
        "[386,   135132, 153908],\n",
        "[388,   148100, 159544],\n",
        "[390,   167748, 167780],\n",
        "[392,   189740, 180004],\n",
        "[394,   212060, 191540],\n",
        "[396,   231612, 202124],\n",
        "[398,   248404, 212712],\n",
        "[400,   266232, 223296],\n",
        "[402,   284224, 236188],\n",
        "[404,   308716, 253368],\n",
        "[406,   354208, 270548],\n",
        "[408,   422320, 287356],\n",
        "[410,   466840, 303956],\n",
        "[412,   500200, 321344],\n",
        "[414,   524280, 342596],\n",
        "[416,   521880, 363848],\n",
        "[418,   515520, 385680],\n",
        "[420,   480360, 407560],\n",
        "[422,   431880, 429880],\n",
        "[424,   376236, 461200],\n",
        "[426,   326032, 481840],\n",
        "[428,   283112, 500840],\n",
        "[430,   246072, 528600],\n",
        "[432,   214120, 552160],\n",
        "[434,   165332, 552160],\n",
        "[436,   132820, 547040],\n",
        "[438,   119140, 501560],\n",
        "[440,   102580, 413280],\n",
        "[442,   92780,  363240],\n",
        "[444,   81444,  282724],\n",
        "[446,   76324,  237224],\n",
        "[448,   67044,  173320],\n",
        "[450,   62816,  103292],\n",
        "[452,   58864,  62640],\n",
        "[454,   53552,  36170],\n",
        "[456,   49496,  30698.8],\n",
        "[458,   47496,  25886.4],\n",
        "[460,   44480,  23388.8],\n",
        "[462,   41320,  20891.2],\n",
        "[464,   39807.2,    19260.8],\n",
        "[466,   37073.2,    18142.4],\n",
        "[468,   34870.8,    17025.6],\n",
        "[470,   33209.2,    16156.4],\n",
        "[472,   31620,  15310],\n",
        "[474,   30113.6,    15048.4],\n",
        "[476,   28850.8,    14792.8],\n",
        "[478,   27718,  14657.2],\n",
        "[480,   26629.2,    14550],\n",
        "[482,   25701.6,    14881.2],\n",
        "[484,   25180.4,    15212.4],\n",
        "[486,   24669.6,    15543.6],\n",
        "[488,   24174.8,    15898],\n",
        "[490,   23684.4,    16684],\n",
        "[492,   23086.8,    17469.6],\n",
        "[494,   22457.6,    18255.6],\n",
        "[496,   21850.4,    19041.2],\n",
        "[498,   21260,  19891.2],\n",
        "[500,   20932.8,    20862],\n",
        "[502,   20596.4,    21832.8],\n",
        "[504,   20418,  22803.6],\n",
        "[506,   19946,  23774.4],\n",
        "[508,   19996,  24745.2],\n",
        "[510,   20035.2,    25773.6],\n",
        "[512,   20150.4,    26936.8],\n",
        "[514,   20429.2,    28100],\n",
        "[516,   21001.6,    29263.2],\n",
        "[518,   22509.6,    30426.4],\n",
        "[520,   24202.4,    31589.6],\n",
        "[522,   26450.4,    32851.2],\n",
        "[524,   29269.2,    34397.6],\n",
        "[526,   32496.4,    35944],\n",
        "[528,   35990,  37490],\n",
        "[530,   39956.8,    39036.4],\n",
        "[532,   43876,  40584],\n",
        "[534,   46924,  42088],\n",
        "[536,   49752,  43592],\n",
        "[538,   51712,  45092],\n",
        "[540,   53236,  46592],\n",
        "[542,   53292,  48148],\n",
        "[544,   52096,  49708],\n",
        "[546,   49868,  51268],\n",
        "[548,   46660,  52496],\n",
        "[550,   43016,  53412],\n",
        "[552,   39675.2,    54080],\n",
        "[554,   36815.2,    54520],\n",
        "[556,   34476.8,    54540],\n",
        "[558,   33456,  54164],\n",
        "[560,   32613.2,    53788],\n",
        "[562,   32620,  52276],\n",
        "[564,   33915.6,    50572],\n",
        "[566,   36495.2,    48828],\n",
        "[568,   40172,  46948],\n",
        "[570,   44496,  45072],\n",
        "[572,   49172,  43340],\n",
        "[574,   53308,  41716],\n",
        "[576,   55540,  40092],\n",
        "[578,   54728,  38467.6],\n",
        "[580,   50104,  37020],\n",
        "[582,   43304,  35676.4],\n",
        "[584,   34639.6,    34332.8],\n",
        "[586,   26600.4,    32851.6],\n",
        "[588,   19763.2,    31075.2],\n",
        "[590,   14400.8,    28324.4],\n",
        "[592,   10468.4,    25470],\n",
        "[594,   7678.8, 22574.8],\n",
        "[596,   5683.6, 19800],\n",
        "[598,   4504.4, 17058.4],\n",
        "[600,   3200,   14677.2],\n",
        "[602,   2664,   13622.4],\n",
        "[604,   2128,   12567.6],\n",
        "[606,   1789.2, 11513.2],\n",
        "[608,   1647.6, 10477.6],\n",
        "[610,   1506,   9443.6],\n",
        "[612,   1364.4, 8591.2],\n",
        "[614,   1222.8, 7762],\n",
        "[616,   1110,   7344.8],\n",
        "[618,   1026,   6927.2],\n",
        "[620,   942,    6509.6],\n",
        "[622,   858,    6193.2],\n",
        "[624,   774,    5906.8],\n",
        "[626,   707.6,  5620],\n",
        "[628,   658.8,  5366.8],\n",
        "[630,   610,    5148.8],\n",
        "[632,   561.2,  4930.8],\n",
        "[634,   512.4,  4730.8],\n",
        "[636,   478.8,  4602.4],\n",
        "[638,   460.4,  4473.6],\n",
        "[640,   442,    4345.2],\n",
        "[642,   423.6,  4216.8],\n",
        "[644,   405.2,  4088.4],\n",
        "[646,   390.4,  3965.08],\n",
        "[648,   379.2,  3857.6],\n",
        "[650,   368,    3750.12],\n",
        "[652,   356.8,  3642.64],\n",
        "[654,   345.6,  3535.16],\n",
        "[656,   335.2,  3427.68],\n",
        "[658,   325.6,  3320.2],\n",
        "[660,   319.6,  3226.56],\n",
        "[662,   314,    3140.28],\n",
        "[664,   308.4,  3053.96],\n",
        "[666,   302.8,  2967.68],\n",
        "[668,   298,    2881.4],\n",
        "[670,   294,    2795.12],\n",
        "[672,   290,    2708.84],\n",
        "[674,   285.6,  2627.64],\n",
        "[676,   282,    2554.4],\n",
        "[678,   279.2,  2481.16],\n",
        "[680,   277.6,  2407.92],\n",
        "[682,   276,    2334.68],\n",
        "[684,   274.4,  2261.48],\n",
        "[686,   272.8,  2188.24],\n",
        "[688,   274.4,  2115],\n",
        "[690,   276,    2051.96],\n",
        "[692,   277.6,  2000.48],\n",
        "[694,   279.2,  1949.04],\n",
        "[696,   282,    1897.56],\n",
        "[698,   286,    1846.08],\n",
        "[700,   290,    1794.28],\n",
        "[702,   294,    1741],\n",
        "[704,   298,    1687.76],\n",
        "[706,   302.8,  1634.48],\n",
        "[708,   308.4,  1583.52],\n",
        "[710,   314,    1540.48],\n",
        "[712,   319.6,  1497.4],\n",
        "[714,   325.2,  1454.36],\n",
        "[716,   332,    1411.32],\n",
        "[718,   340,    1368.28],\n",
        "[720,   348,    1325.88],\n",
        "[722,   356,    1285.16],\n",
        "[724,   364,    1244.44],\n",
        "[726,   372.4,  1203.68],\n",
        "[728,   381.2,  1152.8],\n",
        "[730,   390,    1102.2],\n",
        "[732,   398.8,  1102.2],\n",
        "[734,   407.6,  1102.2],\n",
        "[736,   418.8,  1101.76],\n",
        "[738,   432.4,  1100.48],\n",
        "[740,   446,    1115.88],\n",
        "[742,   459.6,  1161.64],\n",
        "[744,   473.2,  1207.4],\n",
        "[746,   487.6,  1266.04],\n",
        "[748,   502.8,  1333.24],\n",
        "[750,   518,    1405.24],\n",
        "[752,   533.2,  1515.32],\n",
        "[754,   548.4,  1541.76],\n",
        "[756,   562,    1560.48],\n",
        "[758,   574,    1560.48],\n",
        "[760,   586,    1548.52],\n",
        "[762,   598,    1508.44],\n",
        "[764,   610,    1459.56],\n",
        "[766,   622.8,  1410.52],\n",
        "[768,   636.4,  1361.32],\n",
        "[770,   650,    1311.88],\n",
        "[772,   663.6,  1262.44],\n",
        "[774,   677.2,  1213],\n",
        "[776,   689.2,  1163.56],\n",
        "[778,   699.6,  1114.8],\n",
        "[780,   710,    1075.44],\n",
        "[782,   720.4,  1036.08],\n",
        "[784,   730.8,  996.72],\n",
        "[786,   740,    957.36],\n",
        "[788,   748,    921.8],\n",
        "[790,   756,    890.8],\n",
        "[792,   764,    859.8],\n",
        "[794,   772,    828.8],\n",
        "[796,   786.4,  802.96],\n",
        "[798,   807.2,  782.36],\n",
        "[800,   816,    761.72],\n",
        "[802,   828,    743.84],\n",
        "[804,   836,    737.08],\n",
        "[806,   844,    730.28],\n",
        "[808,   856,    723.52],\n",
        "[810,   864,    717.08],\n",
        "[812,   872,    711.84],\n",
        "[814,   880,    706.6],\n",
        "[816,   887.2,  701.32],\n",
        "[818,   901.6,  696.08],\n",
        "[820,   916,    693.76],\n",
        "[822,   930.4,  693.6],\n",
        "[824,   944.8,  693.48],\n",
        "[826,   956.4,  693.32],\n",
        "[828,   965.2,  693.2],\n",
        "[830,   974,    693.04],\n",
        "[832,   982.8,  692.92],\n",
        "[834,   991.6,  692.76],\n",
        "[836,   1001.2, 692.64],\n",
        "[838,   1011.6, 692.48],\n",
        "[840,   1022,   692.36],\n",
        "[842,   1032.4, 692.2],\n",
        "[844,   1042.8, 691.96],\n",
        "[846,   1050,   691.76],\n",
        "[848,   1054,   691.52],\n",
        "[850,   1058,   691.32],\n",
        "[852,   1062,   691.08],\n",
        "[854,   1066,   690.88],\n",
        "[856,   1072.8, 690.64],\n",
        "[858,   1082.4, 692.44],\n",
        "[860,   1092,   694.32],\n",
        "[862,   1101.6, 696.2],\n",
        "[864,   1111.2, 698.04],\n",
        "[866,   1118.4, 699.92],\n",
        "[868,   1123.2, 701.8],\n",
        "[870,   1128,   705.84],\n",
        "[872,   1132.8, 709.96],\n",
        "[874,   1137.6, 714.08],\n",
        "[876,   1142.8, 718.2],\n",
        "[878,   1148.4, 722.32],\n",
        "[880,   1154,   726.44],\n",
        "[882,   1159.6, 729.84],\n",
        "[884,   1165.2, 733.2],\n",
        "[886,   1170,   736.6],\n",
        "[888,   1174,   739.96],\n",
        "[890,   1178,   743.6],\n",
        "[892,   1182,   747.24],\n",
        "[894,   1186,   750.88],\n",
        "[896,   1190,   754.52],\n",
        "[898,   1194,   758.16],\n",
        "[900,   1198,   761.84],\n",
        "[902,   1202,   765.04],\n",
        "[904,   1206,   767.44],\n",
        "[906,   1209.2, 769.8],\n",
        "[908,   1211.6, 772.16],\n",
        "[910,   1214,   774.56],\n",
        "[912,   1216.4, 776.92],\n",
        "[914,   1218.8, 778.4],\n",
        "[916,   1220.8, 778.04],\n",
        "[918,   1222.4, 777.72],\n",
        "[920,   1224,   777.36],\n",
        "[922,   1225.6, 777.04],\n",
        "[924,   1227.2, 776.64],\n",
        "[926,   1226.8, 772.36],\n",
        "[928,   1224.4, 768.08],\n",
        "[930,   1222,   763.84],\n",
        "[932,   1219.6, 752.28],\n",
        "[934,   1217.2, 737.56],\n",
        "[936,   1215.6, 722.88],\n",
        "[938,   1214.8, 708.16],\n",
        "[940,   1214,   693.44],\n",
        "[942,   1213.2, 678.72],\n",
        "[944,   1212.4, 660.52],\n",
        "[946,   1210.4, 641.08],\n",
        "[948,   1207.2, 621.64],\n",
        "[950,   1204,   602.24],\n",
        "[952,   1200.8, 583.4],\n",
        "[954,   1197.6, 568.92],\n",
        "[956,   1194,   554.48],\n",
        "[958,   1190,   540.04],\n",
        "[960,   1186,   525.56],\n",
        "[962,   1182,   511.12],\n",
        "[964,   1178,   495.36],\n",
        "[966,   1173.2, 473.32],\n",
        "[968,   1167.6, 451.32],\n",
        "[970,   1162,   429.32],\n",
        "[972,   1156.4, 415.28],\n",
        "[974,   1150.8, 402.28],\n",
        "[976,   1144,   389.288],\n",
        "[978,   1136,   374.944],\n",
        "[980,   1128,   359.656],\n",
        "[982,   1120,   344.372],\n",
        "[984,   1112,   329.084],\n",
        "[986,   1102.4, 313.796],\n",
        "[988,   1091.2, 298.508],\n",
        "[990,   1080,   283.22],\n",
        "[992,   1068.8, 267.932],\n",
        "[994,   1057.6, 252.648],\n",
        "[996,   1046.4, 237.36],\n",
        "[998,   1035.2, 222.072],\n",
        "[1000,  1024,   206.784]])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "DEFAULTwavelengths = [830,780]\n",
        "DEFAULTfilt_param= {\n",
        "                      'NIRS':[5,0],\n",
        "                      'SRC':[5,0],\n",
        "                      'BKGD':[5,0],\n",
        "                      'ACCE':[100,0],\n",
        "                      'EstG':[0,0],\n",
        "                      'FORC':[1,0],\n",
        "                      'GYRO':[100,0],\n",
        "                      'RESP':[5,0],\n",
        "                      'TEMP':[0.1,0],\n",
        "                      'NECG':[0,0],\n",
        "                     }\n",
        "\n",
        "NUMSRC = 8\n",
        "CHUNKSIZE = 1000\n",
        "FASTRATE = 250\n",
        "SLOWRATE = 25\n",
        "ProbeGains = [30., 1500.]\n",
        "BoardGains = [1., 2., 4., 5., 8., 10., 16., 20., 25., 32.,\n",
        "              40., 50., 64., 80., 100., 128., 160., 256., 320., 512., 1024.]\n",
        "\n",
        "FAST_RAW_SIGNALS = ['GYRO','ACCE','EstG','NECG','AUXC']\n",
        "SLOW_RAW_SIGNALS = ['SRC','BKGD','FORC','TEMP']\n",
        "\n",
        "AUX_SIGNALS = FAST_RAW_SIGNALS + SLOW_RAW_SIGNALS\n",
        "srcs = [0]*8+[1]*8+[2]*8+[3]*8+[4]*8+[5]*8+[6]*8+[7]*8\n",
        "dets = list(range(8))*8\n",
        "FULLml = list(zip(srcs,dets))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def prune_data(d,ml,bothwavelengths=False):\n",
        "    \"\"\"\n",
        "\n",
        "Prune data in 'd' to only those measurements in ml. If\n",
        "'bothwavelengths' is True, keep both wavelengths together.\n",
        "\n",
        "RETURNS: pruned version of 'd'\n",
        "\"\"\"\n",
        "    newd = []\n",
        "    for src,det in ml:\n",
        "        newd.append(d[:,src*8+det])\n",
        "        if bothwavelengths:\n",
        "            if src in [0,2,4,6]:\n",
        "                newd.append(d[:,(src+1)*8+det])\n",
        "    return np.array(newd).T\n",
        "\n",
        "\n",
        "\n",
        "def prune_hbdata(hbd,ml):\n",
        "    \"\"\"\n",
        "\n",
        "Prune hbhbo data in 'hbd' to only those measurements in ml.\n",
        "\n",
        "RETURNS: pruned version of 'hbd'\n",
        "\"\"\"\n",
        "    newd0 = []\n",
        "    newd1 = []\n",
        "    for src,det in ml:\n",
        "        # skip odd ones because we have separate hb & hbo lists\n",
        "        if src in [1,3,5,7]:\n",
        "            continue\n",
        "        newsrc = int(src/2)  # INTEGER division!\n",
        "        newd0.append(hbd[0,:,newsrc*8+det])\n",
        "        newd1.append(hbd[1,:,newsrc*8+det])\n",
        "    newd0 = np.array([newd0,newd1])\n",
        "    print(newd0.shape)\n",
        "    print(len(newd1))\n",
        "    return np.transpose(newd0,[0,2,1])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def getExtinctions(lambdas,molecule='hb'):\n",
        "    \"\"\"Gets the extinction coefficients from data table in this optical.py file.\n",
        "\n",
        "    Usage:   getExtinctions(lambdas,molecule='hb')  moledule='h2o' or 'aa3' or 'lipid'\n",
        "    Returns: returns lists of extinction coefficients for each wavelength (Hb, HbO)\n",
        "    \"\"\"\n",
        "\n",
        "    # extinction matrix holds the lambda,Hb,HbO\n",
        "    A = hbohb_extinctions*1   # data embedded at the end of this file\n",
        "\n",
        "    nLambda = len(lambdas)\n",
        "\n",
        "    if molecule == 'hb':\n",
        "        Hb = np.zeros(nLambda)\n",
        "        HbO = np.zeros(nLambda)\n",
        "\n",
        "        for i in range(nLambda):\n",
        "            # If we have an odd wavelength interpulate the epsilon\n",
        "            if np.mod(lambdas[i],2)==1:\n",
        "                idx      = np.argmax(A[:,0]==lambdas[i]-1)  # -1 because table values are even\n",
        "                Hb[i]    = (A[idx,2]+A[idx+1,2]) / 2.\n",
        "                HbO[i]   = (A[idx,1]+A[idx+1,1]) / 2.\n",
        "#                print idx, Hb[i], HbO[i]\n",
        "            else:\n",
        "                idx      = np.argmax(A[:,0]==lambdas[i])\n",
        "                Hb[i]    = A[idx,2]\n",
        "                HbO[i]   = A[idx,1]\n",
        "#                print idx, Hb[i], HbO[i]\n",
        "\n",
        "        # For humans the fudge factor is 1.15e-4\n",
        "        # If you do this then you get percent of 4% whole blood not molar concentration\n",
        "        #Hb=Hb*1.15e-4\n",
        "        #HbO=HHbo*1.15e-4\n",
        "\n",
        "        # molar weight too small; fix extinction coeff\n",
        "#        Hb = Hb * 4\n",
        "#        HbO = HbO * 4\n",
        "\n",
        "        return Hb, HbO\n",
        "\n",
        "    elif molecule == 'h2o':\n",
        "        h2o = np.zeros(nLambda)\n",
        "\n",
        "        for i in range(nLambda):\n",
        "            # find closest wavelength\n",
        "            idx = 0\n",
        "            while h2o_abscoef[idx,0] < lambdas[i]:\n",
        "                idx += 1\n",
        "            h2o[i] = h2o_abscoef[idx,1]\n",
        "        return h2o\n",
        "\n",
        "    elif molecule == 'aa3':\n",
        "        aa3 = np.zeros(nLambda)\n",
        "\n",
        "        for i in range(nLambda):\n",
        "            # If we have an odd wavelength interpulate the epsilon\n",
        "            if np.mod(lambdas[i],2)==1:\n",
        "                idx    = np.argmax(aa3_abscoef[:,0]==lambdas[i])-1  # -1 because table values are even\n",
        "                aa3[i] = (aa3_abscoef[idx,1]+aa3_abscoef[idx+1,1]) / 2.\n",
        "            else:\n",
        "                idx    = np.argmax(aa3_abscoef[:,0]==lambdas[i])\n",
        "                aa3[i] = aa3_abscoef[idx,1]\n",
        "        return aa3\n",
        "\n",
        "        # round to closest\n",
        "        for i in range(nLambda):\n",
        "            idx = np.floor((lambdas[i]-650)/2)\n",
        "            aa3[i] = aa3_abscoef[idx,1]\n",
        "        return aa3\n",
        "\n",
        "    elif molecule == 'lipid':\n",
        "        lipid = np.zeros(nLambda)\n",
        "\n",
        "        for i in range(nLambda):\n",
        "            # If we have an odd wavelength interpulate the epsilon\n",
        "            if np.mod(lambdas[i],2)==1:\n",
        "                idx      = np.argmax(lipid_abscoef[:,0]==lambdas[i])-1  # -1 because table values are even\n",
        "                lipid[i]    = (lipid_abscoef[idx,1]+lipid_abscoef[idx+1,1]) / 2.\n",
        "            else:\n",
        "                idx      = np.argmax(lipid_abscoef[:,0]==lambdas[i])\n",
        "                lipid[i] = lipid_abscoef[idx,1]\n",
        "        return lipid\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def od2hbhbo_bls(data, wavelengths, BLs):\n",
        "    \"\"\"%\n",
        "  Converts ONE channel's worth of optical data (in OD units) to hb/hbo data,\n",
        "  given appropriate wavelength-dependent scaling factors (BLs)\n",
        "  Assumes: the absorbtion is proportional to the fluence\n",
        "\n",
        "  [hbhbo,A]=od2hbhbo_BLs(\n",
        "    data,         # OD data for these 2+ wavelengths (e.g., [data(:,(830col)), data(:,785col)])\n",
        "    wavelengths,  # 2+ wavelengths used (e.g., [830 785])\n",
        "    BLs)          # k's to be used for this source-detector pair ==> fluence/BL\n",
        "                  # (e.g., [18 18]\n",
        "\n",
        "   hb,hbo,A = Hb and HbO timeseries' in units of [Moles/Liter], A-matrix\n",
        "\"\"\"\n",
        "    nLambda = len(wavelengths)\n",
        "    [hb,hbo] = getExtinctions(wavelengths,'hb')\n",
        "#    print hb\n",
        "#    print hbo\n",
        "    A = np.array([hb,hbo])\n",
        "    wavelengths = np.array(wavelengths)\n",
        "    BLs = np.array(BLs)\n",
        "\n",
        "    # in case it was passed in incorrectly\n",
        "    m,n = data.shape\n",
        "    if m<n:\n",
        "        data = data.T\n",
        "        m,n = data.shape\n",
        "\n",
        "    # Make sure we have enough wavelengths\n",
        "    if nLambda<2 or nLambda<data.shape[1]:\n",
        "        n = max(2,data.shape[1])\n",
        "        print(\"Need %s wavelengths to do [hb,hbo] transform on %s columns.\" %(nLambda,n))\n",
        "        return\n",
        "\n",
        "    data = (1./BLs)*data\n",
        "\n",
        "    # Least squares does not buy you anything if you only have a two by\n",
        "    # two so don't do the processing on it.\n",
        "    if len(np.unique(wavelengths))==2:\n",
        "        hbhbo = np.dot(data,np.linalg.inv(A))\n",
        "    else:  # This means we have an overdetermined case, so do the least squares\n",
        "        print(A)\n",
        "        hbhbo = np.dot(np.linalg.inv(np.dot(A.T,A)),A.T)  # compute (A.T*A)^-1 * A.T\n",
        "        hbhbo = np.dot(hbhbo.T,data.T)\n",
        "#        hbhbo = hbhbo.T\n",
        "\n",
        "    hb=hbhbo[:,0]\n",
        "    hbo=hbhbo[:,1]\n",
        "    return hbhbo/np.log(10)\n",
        "\n",
        "\n",
        "\n",
        "def nin_od2hbhbo(od, wavelengths=DEFAULTwavelengths, BLs=[6,6]):\n",
        "    \"\"\"\n",
        "  Convert NIN optical-density data to deoxy/oxy-hemoglobin concentrations.\n",
        "\n",
        "  RETURNS: hbhbos, hbhboml ... hbhbos=TIMEx[HHb,O2Hb], hbhboml=measurement list for hbhbos\n",
        "  \"\"\"\n",
        "    hbhbos = []\n",
        "    hbhboml = []\n",
        "    for src in [0,2,4,6]:\n",
        "        for det in range(8):\n",
        "            # next line steps by 8 to get src*8+det and (src+1)*8+det only\n",
        "            hbhbos.append(od2hbhbo_bls(od[:,src*8+det:(src+2)*8+det:8],wavelengths, BLs))\n",
        "            hbhboml.append([src,det])\n",
        "    hbhbos = np.array(hbhbos)\n",
        "    hbhbos = np.transpose(hbhbos,[2,1,0])\n",
        "    hbhboml = np.array(hbhboml)\n",
        "    return hbhbos, hbhboml\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def nin_makeOD(data,baseline=None):\n",
        "    \"\"\"\n",
        "    Compute optical density using baseline period ...where data = (TIME x CHAN)\n",
        "    and baseline = None (use entire dataset); DEFAULT\n",
        "                = integer (number-of-points to use from start-of-recording)\n",
        "                = 1D list of indices into data to use\n",
        "                = 2D array of data used to calc mean for each channel\n",
        "\n",
        "    RETURNS: ODdata\n",
        "    \"\"\"\n",
        "    if baseline == None:\n",
        "        baseline = np.mean(data,0)\n",
        "    elif type(baseline)==IntType:\n",
        "        baseline = np.mean(data[:baseline],0)\n",
        "    elif type(baseline)==type(list):  # must be indices\n",
        "        baseline = np.mean(data[baseline],0)\n",
        "    elif len(baseline.shape) == 2:  # must be data\n",
        "        baseline = np.mean(baseline,0)\n",
        "    else:\n",
        "        print(\"Not appropriate size/shape for baseline in makeOD\")\n",
        "        return\n",
        "\n",
        "    # now calculate OD\n",
        "    normalized_fluence = (1./baseline)*data\n",
        "    ODdata = -np.log(normalized_fluence)\n",
        "\n",
        "    return ODdata\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def nin_SNR(d,window=None):\n",
        "    \"\"\"\n",
        "    Calculate SNR over a time-window (in sec) from data in d (TIME x CHANNELS).\n",
        "    If no window (in sec from recording-start), calculate SNR over whole recording.\n",
        "\n",
        "    RETURNS: 8x8 array of SNRs\n",
        "    \"\"\"\n",
        "    ### CALCULATE SNR\n",
        "    if window is None:\n",
        "        windowstart = 0\n",
        "        windowend = len(d)\n",
        "    else:\n",
        "        windowstart = int(window[0]*SLOWRATE)\n",
        "        windowend = int(window[1]*SLOWRATE)\n",
        "    SNR = np.mean(d[windowstart:windowend,:],0)/np.std(d[windowstart:windowend,:],0)\n",
        "    SNRmap = np.reshape(np.array(SNR),(8,8))\n",
        "    return SNRmap\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def nin_ML(d,boardgain,GAINthresh=16,SNRwindow=[0,60],SNRthresh=2,pSrc=None,pDet=None,geometry=None,DISTthresh=75,verbose=False):\n",
        "    \"\"\"\n",
        "    Determine a \"good measurement\" list based on <GAINthresh, >SNRthresh, <DISTthresh\n",
        "    RETURNS: list of [src,det] pairs that are \"good\" measurements\n",
        "    \"\"\"\n",
        "\n",
        "    if geometry is not None:\n",
        "        pSrc,pDet = get_geometry(geometry)\n",
        "    else:\n",
        "        pSrc = None\n",
        "        pDet = None\n",
        "    SNR = nin_SNR(d,SNRwindow)\n",
        "    ml1 = []\n",
        "    ml2 = []\n",
        "    for item in FULLml:\n",
        "        src,det = item\n",
        "        if src not in [0,2,4,6]:  # doing pairs, so start with evens only\n",
        "            continue\n",
        "        if not boardgain[src,det]<GAINthresh:       # check 830nm gain\n",
        "#            print \"bad 830 board gain:\",boardgain[src,det]\n",
        "            continue\n",
        "        if not boardgain[src+1,det]<GAINthresh:     # see if 780nm gain is ALSO good\n",
        "#            print \"bad 780 board gain:\",boardgain[src,det]\n",
        "            continue\n",
        "        if not SNR[src,det]>SNRthresh:              # check SNR threshold 830\n",
        "#            print \"bad 830 SNR:\",SNR[src,det]\n",
        "            continue\n",
        "        if not SNR[src+1,det]>SNRthresh:            # check SNR threshold 780\n",
        "#            print \"bad 780 SNR:\",SNR[src,det]\n",
        "            continue\n",
        "        if pSrc is not None and pDet is not None:\n",
        "            if dist(pSrc[src/2],pDet[det])<DISTthresh:    # check distance is <threshold\n",
        "                ml1.append([src,det])\n",
        "                ml2.append([src+1,det])\n",
        "                if verbose:\n",
        "                    print(\"S\",src,\" D\",det,\": gain=\",boardgain[src,det])\n",
        "                    print(\"Matlab good-SD listing:\")\n",
        "                    print(\"   \",src+1,det+1)\n",
        "                    print(\"   \",src+2,det+1)\n",
        "        else:\n",
        "            # no distance info available; save it as-is\n",
        "            ml1.append([src,det])\n",
        "            ml2.append([src+1,det])\n",
        "    return np.array(ml1+ml2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def nin_filt_all(a,filt_param=DEFAULTfilt_param,verbose=True):\n",
        "    \"\"\"\n",
        "    Apply a lowpass and highpass filter to a TIME x CHANNELS data.\n",
        "    filt_param holds a dictionary like this {'ACCE':[LPF_cutoff, HPF_cutoff]}.\n",
        "    Uses nt.lowpass/nt.hipass. Works on all channels in 'a' dict.\n",
        "\n",
        "    RETURNS: copy of 'a' with all filt_param applied\n",
        "    \"\"\"\n",
        "    tmp = {}\n",
        "    for k in a.keys():\n",
        "        if k in ['NIRS','SRC','BKGD']:\n",
        "            RATE = 25\n",
        "        elif k in ['ACCE','GYRO','EstG','NECG']:\n",
        "            RATE = 250\n",
        "        elif k in ['RESP','TEMP','FORC']:\n",
        "            RATE = 25\n",
        "        try:\n",
        "            if verbose:\n",
        "                print(\" \",k,\": LPF=\",filt_param[k][0], \"  HPF=\",filt_param[k][1])\n",
        "            tmp[k] = lowpass(a[k],filt_param[k][0],RATE)\n",
        "            tmp[k] = hipass(tmp[k],filt_param[k][1],RATE)\n",
        "        except:\n",
        "            print(\"      Failed filtering in nin_filt_aux() for\",k)\n",
        "            tmp[k] = a[k]\n",
        "            pass\n",
        "    return tmp\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def fix_accel(a):\n",
        "    \"\"\"\n",
        "    Swaps byte-order for a['ACCE']. IN-PLACE operation (no return value)\n",
        "\n",
        "    RETURNS: nothing (fixes a['ACCE'] in-place)\n",
        "    \"\"\"\n",
        "    a['ACCE'] = a['ACCE'].newbyteorder()\n",
        "    # no need to return, as it fixes in-place (given there's no copy here)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def nin_convert_aux(a,EstGgains=[],acc=200,force='forc'):\n",
        "    \"\"\"\n",
        "\n",
        "    Apply unit-conversions to raw auxiliary data.\n",
        "\n",
        "    USAGE:   a = auxiliary data dict (from get_nin_aux)\n",
        "            gains comes from config['EstGgain']\n",
        "            acc={16,200} for the +/-16g or +/-200g accel\n",
        "            force={'forc','resp'} for which one is attached\n",
        "    RETURNS: ac (new dictionary with converted-units data)\n",
        "    \"\"\"\n",
        "    ac = {}\n",
        "    if acc==0:\n",
        "        # DON'T CONVERT ANYTHING!!\n",
        "        ac = a\n",
        "    else:\n",
        "        for k in a.keys():\n",
        "            if k=='ACCE':\n",
        "    #            ac[k] = np.where(a[k]<4095,a[k]*0.0039,0)\n",
        "    #            ac[k] = np.where(a[k]>4095,(a[k]-8192)*0.0039,ac[k])\n",
        "                if acc==16:\n",
        "                    ac[k] = a[k].astype(np.float) *49/ 25. /256. /1.9  # 49 mg/bit; @@@1.9=fudge\n",
        "                elif acc==200:\n",
        "                    #@@@gotta reverse this one\n",
        "                    fix_accel(a) #tmp = a[k].newbyteorder()\n",
        "                    ac[k] = a[k].astype(np.float) *3.9/1000. /256.  # 3.9 mg/bit\n",
        "            elif k==\"FORC\":\n",
        "                ac[k] = a[k].astype(np.float) *0.00061   # mV; 0.61 mV/bit\n",
        "                ac[k] = ac[k] *2.0/0.055   # empirically (2015-0914-115727.txt), 2kg-->0.055mV signal\n",
        "            elif k=='GYRO':\n",
        "                ac[k] = a[k].astype(np.float) *70 /1000.   # 70 mdeg/digit --> conv. to degrees\n",
        "            elif k==\"RESP\":\n",
        "                ac[k] = a[k].astype(np.float) #@@@ no conversion for now\n",
        "            elif k==\"TEMP\":\n",
        "                ac[k] = a[k].astype(np.float) /256.      # deg C; 0.25 deg C/bit\n",
        "            elif k==\"EstG\":\n",
        "                ac[k] = a[k]*1.0\n",
        "                if len(EstGgains):\n",
        "                    for i in range(8):\n",
        "                        ac[k][:,i] = ac[k][:,i] *0.53644/EstGgains[i]  # uV\n",
        "            else:  # @@@i.e., RESP or NECG or anything else\n",
        "                ac[k] = a[k].astype(np.float) #@@@ no conversion for now\n",
        "    return ac\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def nin_unwrap_gains(a,config):\n",
        "    \"\"\"\n",
        "    Unwrap gain settings from NIRS 'diff' (raw-bkgd) data.\n",
        "\n",
        "    RETURNS: d (TIME x 64 CHANNELS, with signals adjusted for gains)\n",
        "    \"\"\"\n",
        "    keys = ['NIRS']\n",
        "    if config['keepraw']==True:\n",
        "        keys = keys + ['SRC','BKGD']\n",
        "\n",
        "    for k in keys:\n",
        "        d = a[k].astype('float')\n",
        "        for src in range(8):\n",
        "            for det in range(8):\n",
        "                d[:,src*8+det] = d[:,src*8+det] / (ProbeGains[config['PROBEgain'][src,det]] *\n",
        "                                                   BoardGains[config['BOARDgain'][src,det]])\n",
        "    config['gainunwrapped'] = 1\n",
        "    return a, config\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def nin_convert_aux(a,EstGgains=[],acc=200,force='forc'):\n",
        "    \"\"\"\n",
        "\n",
        "Apply unit-conversions to raw auxiliary data.\n",
        "\n",
        "USAGE:   a = auxiliary data dict (from get_nin_aux)\n",
        "         gains comes from config['EstGgain']\n",
        "         acc={16,200} for the +/-16g or +/-200g accel\n",
        "         force={'forc','resp'} for which one is attached\n",
        "RETURNS: ac (new dictionary with converted-units data)\n",
        "\"\"\"\n",
        "    ac = {}\n",
        "    if acc==0:\n",
        "        # DON'T CONVERT ANYTHING!!\n",
        "        ac = a\n",
        "    else:\n",
        "        for k in a.keys():\n",
        "            if k=='ACCE':\n",
        "    #            ac[k] = np.where(a[k]<4095,a[k]*0.0039,0)\n",
        "    #            ac[k] = np.where(a[k]>4095,(a[k]-8192)*0.0039,ac[k])\n",
        "                if acc==16:\n",
        "                    ac[k] = a[k].astype(np.float) *49/ 25. /256. /1.9  # 49 mg/bit; @@@1.9=fudge\n",
        "                elif acc==200:\n",
        "                    #@@@gotta reverse this one\n",
        "                    fix_accel(a) #tmp = a[k].newbyteorder()\n",
        "                    ac[k] = a[k].astype(np.float) *3.9/1000. /256.  # 3.9 mg/bit\n",
        "            elif k==\"FORC\":\n",
        "                ac[k] = a[k].astype(np.float) *0.00061   # mV; 0.61 mV/bit\n",
        "                ac[k] = ac[k] *2.0/0.055   # empirically (2015-0914-115727.txt), 2kg-->0.055mV signal\n",
        "            elif k=='GYRO':\n",
        "                ac[k] = a[k].astype(np.float) *70 /1000.   # 70 mdeg/digit --> conv. to degrees\n",
        "            elif k==\"RESP\":\n",
        "                ac[k] = a[k].astype(np.float) #@@@ no conversion for now\n",
        "            elif k==\"TEMP\":\n",
        "                ac[k] = a[k].astype(np.float) /256.      # deg C; 0.25 deg C/bit\n",
        "            elif k==\"EstG\":\n",
        "                ac[k] = a[k]*1.0\n",
        "                if len(EstGgains):\n",
        "                    for i in range(8):\n",
        "                        ac[k][:,i] = ac[k][:,i] *0.53644/EstGgains[i]  # uV\n",
        "            else:  # @@@i.e., RESP or NECG or anything else\n",
        "                ac[k] = a[k].astype(np.float) #@@@ no conversion for now\n",
        "    return ac\n",
        "\n",
        "\n",
        "def nin_convert(a,config,unwrapgain=False,acceltype=200,force='forc',notchfilt=[],filt_param=DEFAULTfilt_param,verbose=True):\n",
        "    \"\"\"\n",
        "\n",
        "    Function to unwrap gain, convert aux to SI units, and/or filter, as requested.\n",
        "\n",
        "    USAGE:   a = data dict\n",
        "            config = configuration info, updated by this function\n",
        "            unwrapgain = correct for gain settings or not?\n",
        "            acc = {16,200} for the +/-16g or +/-200g accel; ignores any other values\n",
        "            force = {'forc','resp'} for which one is attached\n",
        "            notch = ['NIRS','EstG'] ... dict keys where 60&120Hz notch filters should be applied\n",
        "            filt_param = dictionary entries like {'NIRS':[lpf,hpf]}\n",
        "    RETURNS: updated a, updated config\n",
        "    \"\"\"\n",
        "    ac = {}\n",
        "\n",
        "    ### UNWRAP GAINS IF REQUESTED /and/ NEEDED\n",
        "    if unwrapgain:\n",
        "        if config['gainunwrapped']==False:\n",
        "            ac,config = nin_unwrap_gains(a,config)\n",
        "    else:  # otherwise, just copy over the source data\n",
        "        ac['NIRS'] = a['NIRS']\n",
        "        if config['keepraw']==True:\n",
        "            ac['SRC'] = a['SRC']\n",
        "            ac['BKGD'] = a['BKGD']\n",
        "\n",
        "    ### CONVERT AUX CHANNELS TO SI-ish UNITS, IF REQUESTED\n",
        "    auxc = nin_convert_aux(a,acc=acceltype,force=force)\n",
        "    ac.update(auxc)\n",
        "\n",
        "    ### NOTCH-FILTER IF REQUESTED\n",
        "    if len(notchfilt):\n",
        "        for k in notchfilt:\n",
        "            if verbose:\n",
        "                print(\"NOTCH-FILTERING ...\",k)\n",
        "            ac[k] = notch(ac[k])\n",
        "\n",
        "    ### FILTER IF REQUESTED\n",
        "    if filt_param:\n",
        "        if verbose:\n",
        "            print(\"FILTERING DATA ...\")\n",
        "        ac = nin_filt_all(ac,filt_param,verbose)\n",
        "\n",
        "    ### UPDATE FLAGS & FILT IN 'config'\n",
        "    config['gainunwrapped'] = unwrapgain\n",
        "    config['filt_param'] = filt_param\n",
        "    config['acceltype'] = acceltype\n",
        "    config['notch'] = notchfilt\n",
        "\n",
        "    return ac, config\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def trim_data(a,td=None,ta=None,segstart=0,verbose=False):\n",
        "    \"\"\"\n",
        "\n",
        "    Trim off tail ends of some data so everything aligns, in 2 clumps:\n",
        "        25Hz signals = raw, bkgd, diff, a['TEMP'], a['FORC'], a['RESP']\n",
        "        250Hz signals = a['EstG'], a['ACCE'], a['GYRO']\n",
        "\n",
        "    RETURNS: a, td, ta ... with TIME dimensions truncated to same-length\n",
        "    \"\"\"\n",
        "    # DEAL WITH FAST-RATE DATA\n",
        "#    print 'a:', a.keys()\n",
        "    all_len = []\n",
        "    if verbose: print(\"  BEFORE ...\")\n",
        "#    print a.keys()\n",
        "    for key in FAST_RAW_SIGNALS:\n",
        "        if key not in a:\n",
        "            continue\n",
        "        if verbose: print(\"    \",key,len(a[key]))\n",
        "        ln = len(a[key])\n",
        "        if ln>10:\n",
        "            all_len.append(len(a[key]))\n",
        "        else:\n",
        "            if verbose: print(\"    REMOVING ...\",key)\n",
        "            a.pop(key,None)\n",
        "    minlen = min(all_len)\n",
        "    if verbose: print(\"  AFTER ...\")\n",
        "    for key in FAST_RAW_SIGNALS:\n",
        "        if key not in a:\n",
        "            continue\n",
        "        a[key] = a[key][:minlen]\n",
        "        if verbose: print(\"    \",key,len(a[key]))\n",
        "    if ta is None:\n",
        "        ta = np.arange(minlen)/float(FASTRATE)+segstart\n",
        "    else:\n",
        "        ta = ta[:minlen]\n",
        "\n",
        "    # SECOND DEAL WITH SLOW-RATE DATA\n",
        "    if verbose: print(\"  BEFORE ...\")\n",
        "    for key in SLOW_RAW_SIGNALS:\n",
        "#        print key,a.has_key(key)\n",
        "        if key not in a:\n",
        "            continue\n",
        "        if verbose: print(\"    \",key,len(a[key]))\n",
        "        if ln>10:\n",
        "            all_len.append(len(a[key]))\n",
        "        else:\n",
        "            if verbose: print(\"    REMOVING ...\",key)\n",
        "            a.pop(key,None)\n",
        "    minlen = min(all_len)\n",
        "    if verbose: print(\"  AFTER ...\")\n",
        "    for key in SLOW_RAW_SIGNALS:\n",
        "        if a is not None:\n",
        "            if key not in a:\n",
        "                continue\n",
        "            a[key] = a[key][:minlen]\n",
        "            if verbose: print(\"    \",key,len(a[key]))\n",
        "\n",
        "    if 'SRC' in a and 'BKGD' in a:\n",
        "        a['NIRS'] = a['SRC']-a['BKGD']\n",
        "\n",
        "    if td is None:\n",
        "        td = np.arange(minlen)/float(SLOWRATE)+segstart\n",
        "    else:\n",
        "        td = td[:minlen]\n",
        "\n",
        "    return a, td, ta\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_nin_aux(fname,segstart=0,segend=-1,verbose=True):\n",
        "    \"\"\"\n",
        "\n",
        "    Read in a time-segment of auxiliary data from a .NIN file.\n",
        "    segstart/segend are in seconds (-1=whole file)\n",
        "\n",
        "    RETURNS: dictionary with ACCE, TEMP, FORC, EstG, GYRO and/or RESP components, td, ta\n",
        "    \"\"\"\n",
        "    if segend==-1:\n",
        "        segend = 1000000  # 1 million seconds (plenty to cover whole file)\n",
        "\n",
        "    if fname[-4:] in ['.edf','.bdf','.mat']:\n",
        "        fname = fname[:-4]+'.nin'\n",
        "\n",
        "    a = {}\n",
        "    for s in AUX_SIGNALS:\n",
        "        if s in ['BKGD','SRC','NIRS']:\n",
        "            continue\n",
        "        if verbose:\n",
        "            print(\"    Getting \",s)\n",
        "        if s in FAST_RAW_SIGNALS:\n",
        "            a,ta = get_nin_data(fname,s,segstart,segend,a)\n",
        "        else:\n",
        "            a,td = get_nin_data(fname,s,segstart,segend,a)\n",
        "    return a, ta, td\n",
        "\n",
        "\n",
        "\n",
        "def nin_nirsarray(n,b):\n",
        "    \"\"\"\n",
        "\n",
        "    Convert raw-read NIRS data (SRC or BKG) from dictionaries to two 8x8 arrays.\n",
        "\n",
        "    RETURNS: raw, bkgd (numpy arrays, TIME x 64 CHANNELS)\n",
        "    \"\"\"\n",
        "    ### CONVERT NIRS FROM DICTIONARIES TO TWO 8X8 ARRAYS\n",
        "    lngn = []\n",
        "    lngb = []\n",
        "    for k in list(b.keys()): # find the length of the shortest (probably src7, but could be another)\n",
        "        lngn.append(n[k].shape[0])\n",
        "        lngb.append(b[k].shape[0])\n",
        "    lng = min(lngn+lngb)\n",
        "    raw = np.concatenate((n['src0'][:lng],n['src1'][:lng]),1)\n",
        "    bkgd = np.concatenate((b['src0'][:lng],b['src1'][:lng]),1)\n",
        "    for i in range(2,8):\n",
        "        raw = np.concatenate((raw,n['src'+str(i)][:lng]),1)\n",
        "        bkgd = np.concatenate((bkgd,b['src'+str(i)][:lng]),1)\n",
        "    return raw, bkgd\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_nin_data(fname, varstring, segstart=0, segend=-1, data={}):\n",
        "    \"\"\"\n",
        "\n",
        "    Read in a time-segment of data from NIN-M compatible (.nin) file. Use varstring=\n",
        "            'SRC' to get laser-on data,\n",
        "            'BKG' to get laser-off data,\n",
        "            'ACCE' for accelerometery data\n",
        "            'FORC' for force sensor\n",
        "            'TEMP' for temperature sensor\n",
        "            'EstG' for analog (8 channels of E*G) sensors\n",
        "            'NECG' for analog new-style (separate-ground) ECG\n",
        "    segstart/segend are in seconds (-1=whole file)\n",
        "\n",
        "    RETURNS: dictionary (can supply as input to append dictionary), timebase\n",
        "    \"\"\"\n",
        "    # HANDLE EITHER .MAT OR .NIN FILES\n",
        "    if fname[-4:] in ['.edf','.bdf','.mat']:\n",
        "        fname = fname[:-4]+'.nin'\n",
        "\n",
        "    # OPEN FILE AND INITIALIZE DATA DICTIONARIES AS NEEDED\n",
        "    f = open(fname,'rb')\n",
        "    if 'SRC' in varstring or 'BKG' in varstring:\n",
        "        data = {}  # absolutely critical initialization, despite d={} in fcn\n",
        "        for src in range(NUMSRC):\n",
        "            data['src'+str(src)] = []\n",
        "    elif 'EstG' in varstring and len(varstring)==5:\n",
        "        data['EstG'] = []\n",
        "    else:\n",
        "        data[varstring] = []\n",
        "\n",
        "    # SET PROPER END-TIME DEFAULT, IF NEEDED\n",
        "    if segend==-1:\n",
        "        segend = 1000000  # 1 million seconds (plenty to cover whole file)\n",
        "\n",
        "    # START THE MAIN FILE-READING LOOP\n",
        "    s = b''         # holds raw BYTES data from file\n",
        "    pointer = 0     # tracks the \"current time in file\", in points (not sec)\n",
        "    targetlen = 0   # make sure this is pre-defined to avoid potential crash\n",
        "    while True:\n",
        "        # GET CHUNK OF BYTES FROM THE FILE\n",
        "        raw = f.read(CHUNKSIZE)\n",
        "\n",
        "        # END OF THE FILE YET?\n",
        "        if not raw:\n",
        "            break  # exit loop\n",
        "\n",
        "        # ADD CHUNK TO s FOR PROCESSING\n",
        "        s = s+raw\n",
        "\n",
        "        # IF PROCESSED 10000 BYTES AND STILL NO varstring, PARAMETER IS MISSING-->BAIL\n",
        "        if s.find(bytes(varstring,'utf-8'))==-1 and len(s)>10000:\n",
        "            # must not have this parameter in this datafile\n",
        "            break\n",
        "\n",
        "        # LOOP OVER BYTES IN s\n",
        "        while s:\n",
        "            # TRY TO FIND varstring IN s\n",
        "            if 'EstG' in varstring and len(varstring)==5:\n",
        "                idx = s.find(bytes(varstring[:-1],'utf-8'))\n",
        "                if idx==-1:\n",
        "                    break # no 'varstring' in this one, get a new chunk\n",
        "            else:\n",
        "                idx = s.find(bytes(varstring,'utf-8'))\n",
        "                if idx==-1:\n",
        "                    break # no 'varstring' in this one, get a new chunk\n",
        "\n",
        "            # START EXTRACTING DATA, DEPENDING ON varstring REQUESTED\n",
        "            if varstring in ['SRC0','SRC1','SRC2','SRC3','SRC4','SRC5','SRC6','SRC7',\n",
        "                             'BKG0','BKG1','BKG2','BKG3','BKG4','BKG5','BKG6','BKG7']:\n",
        "                if idx+4+8*2>len(s):\n",
        "                    break # not enough data to parse this one, get a new chunk\n",
        "                newdata = struct.unpack('<HHHHHHHH',s[idx+4:idx+4+8*2])\n",
        "                if (pointer/25.)>=segstart and (pointer/25.)<segend:\n",
        "                    sn = varstring[-1]\n",
        "                    data['src'+sn].append(newdata)\n",
        "                    pointer += 1\n",
        "                s = s[idx+4+8*2:]\n",
        "\n",
        "            elif varstring in ['SRC','BKG']:  # will be one or the other for the whole loop\n",
        "                if idx+4+8*2>len(s):\n",
        "                    break # not enough data to parse this one, get a new chunk\n",
        "                newdata = struct.unpack('<HHHHHHHH',s[idx+4:idx+4+8*2])\n",
        "                srcnum = chr(s[idx+3])\n",
        "                if (pointer/25.)>=segstart and (pointer/25.)<segend:\n",
        "                    try:\n",
        "                        data['src'+str(srcnum)].append(newdata)\n",
        "                    except:\n",
        "                        pass\n",
        "                if srcnum=='7': # is it SRC7?? (last one in a timeslice-->THEN increment)\n",
        "                    pointer += 1\n",
        "                s = s[idx+4+8*2:]\n",
        "\n",
        "            elif varstring=='ACCE':\n",
        "                if idx+4+3*2>len(s):\n",
        "                    break # not enough data to parse this one, get a new chunk\n",
        "                newdata = struct.unpack('<hhh',s[idx+4:idx+4+3*2])\n",
        "                #@@@ NOTE: need >hhh for other accel, but fix_accel() can byteswap\n",
        "                if pointer/250.>=segstart and pointer/250.<segend:\n",
        "                    data[varstring].append(newdata)\n",
        "                pointer += 1\n",
        "                s = s[idx+4+3*2:]\n",
        "\n",
        "            elif varstring=='GYRO':\n",
        "                if idx+4+3*2>len(s):\n",
        "                    break # not enough data to parse this one, get a new chunk\n",
        "                newdata = struct.unpack('<hhh',s[idx+4:idx+4+3*2])\n",
        "                if pointer/250.>=segstart and pointer/250.<segend:\n",
        "                    data[varstring].append(newdata)\n",
        "                pointer += 1\n",
        "                s = s[idx+4+3*2:]\n",
        "\n",
        "            elif varstring=='TEMP':\n",
        "                if idx+4+1*2>len(s):\n",
        "                    break # not enough data to parse this one, get a new chunk\n",
        "                newdata = struct.unpack('<H',s[idx+4:idx+4+1*2])\n",
        "                if pointer/25.>=segstart and pointer/25.<segend:\n",
        "                    data[varstring].append(newdata)\n",
        "                pointer += 1\n",
        "                s = s[idx+4+1*2:]\n",
        "\n",
        "            elif varstring=='FORC':\n",
        "                if idx+4+1*2>len(s):\n",
        "                    break # not enough data to parse this one, get a new chunk\n",
        "                newdata = struct.unpack('<H',s[idx+4:idx+4+1*2])\n",
        "                if pointer/25.>=segstart and pointer/25.<segend:\n",
        "                    data[varstring].append(newdata)\n",
        "                pointer += 1\n",
        "                s = s[idx+4+1*2:]\n",
        "\n",
        "            elif varstring=='RESP':\n",
        "                if idx+4+1*2>len(s):\n",
        "                    break # not enough data to parse this one, get a new chunk\n",
        "                newdata = struct.unpack('<H',s[idx+4:idx+4+1*2])\n",
        "                if pointer/25.>=segstart and pointer/25.<segend:\n",
        "                    data[varstring].append(newdata)\n",
        "                pointer += 1\n",
        "                s = s[idx+4+1*2:]\n",
        "\n",
        "            elif varstring=='NECG':\n",
        "                if idx+4+1*2>len(s):\n",
        "                    break # not enough data to parse this one, get a new chunk\n",
        "                newdata = struct.unpack('<H',s[idx+4:idx+4+1*2])\n",
        "                if pointer/25.>=segstart and pointer/25.<segend:\n",
        "                    data[varstring].append(newdata)\n",
        "                pointer += 1\n",
        "                s = s[idx+4+1*2:]\n",
        "\n",
        "            elif varstring=='AUXC':\n",
        "                if idx+4+8*2>len(s):\n",
        "                    break # not enough data to parse this one, get a new chunk\n",
        "                newdata = struct.unpack('<hhhhhhhh',s[idx+4:idx+4+8*2])\n",
        "                if pointer/250.>=segstart and pointer/250.<segend:\n",
        "                    data[varstring].append(newdata)\n",
        "                pointer += 1\n",
        "                s = s[idx+4+8*2:]\n",
        "\n",
        "            elif varstring=='EstG':\n",
        "                if idx+4+8*4>len(s):\n",
        "                    break # not enough data to parse this one, get a new chunk\n",
        "                tmp = []\n",
        "                # grab groups of 3 bytes (after 'EstG') and add on 00 or 80 byte at end (sign)\n",
        "                for i in range(8):\n",
        "                    tmp += struct.unpack('<i', s[idx+4+(i*3):idx+4+(i*3+3)] +(b'\\x00' if s[idx+4+(i*3+2)]<128 else b'\\xff'))\n",
        "                if pointer/250.>=segstart and pointer/250.<segend:\n",
        "                    data[varstring].append(tmp) #newdata)\n",
        "                pointer += 1\n",
        "                s = s[idx+4+8*4:]\n",
        "\n",
        "            elif varstring in ['EstG0','EstG1','EstG2','EstG3','EstG4','EstG5','EstG6','EstG7']:\n",
        "                if idx+4+8*4>len(s):\n",
        "                    break # not enough data to parse this one, get a new chunk\n",
        "                # grab groups of 3 bytes (after 'EstG') and add on 00 or 80 byte at end (sign)\n",
        "                i = int(varstring[-1])  # figure out which channel they want\n",
        "                tmp = struct.unpack('<i', s[idx+4+(i*3):idx+4+(i*3+3)] +(b'\\x00' if s[idx+4+(i*3+2)]<128 else b'\\xff'))\n",
        "                if pointer/250.>=segstart and pointer/250.<segend:\n",
        "                    data[varstring[:-1]].append(tmp)\n",
        "                pointer += 1\n",
        "                s = s[idx+4+8*4:]\n",
        "\n",
        "            # DETERMINE IF NEED TO READ IN MORE OR NOT\n",
        "            if varstring in ['SRC','BKG'] or 'SRC' in varstring or 'BKG' in varstring:\n",
        "                targetlen = pointer/25./8.\n",
        "            elif varstring in ['FORC','TEMP','RESP']:\n",
        "                targetlen = pointer/25.\n",
        "            elif varstring in ['EstG','ACCE','GYRO','NECG'] or 'EstG' in varstring:\n",
        "                targetlen = pointer/250.\n",
        "            if targetlen>=segend:\n",
        "                break\n",
        "\n",
        "        # CRASH OUT IF NO NEED TO READ THE FILE FURTHER\n",
        "        if targetlen>=segend:\n",
        "            break\n",
        "\n",
        "#    print \"On exit:\",data.keys()\n",
        "    # CONVERT ALL DATA TO ARRAYS BEFORE RETURNING\n",
        "    for key in list(data.keys()):\n",
        "        data[key] = np.array(data[key])\n",
        "#    print \"On return:\",data.keys()\n",
        "\n",
        "    # BUILD AN APPROPRIATE TIME-BASE\n",
        "    td = None\n",
        "    ta = None\n",
        "    if varstring in ['FORC','RESP','TEMP']:\n",
        "        td = np.arange(len(data[varstring]))/25.+segstart\n",
        "    elif varstring in ['SRC','BKG']:\n",
        "        td = np.arange(len(data['src0']))/25.+segstart\n",
        "    elif varstring in ['SRC0','SRC1','SRC2','SRC3','SRC4','SRC5','SRC6','SRC7',\n",
        "                       'BKG0','BKG1','BKG2','BKG3','BKG4','BKG5','BKG6','BKG7']:\n",
        "        td = np.arange(len(data['src'+varstring[-1]]))/25.+segstart\n",
        "    elif varstring in ['ACCE','GYRO','EstG','NECG']:\n",
        "        ta = np.arange(len(data[varstring]))/250.+segstart\n",
        "    elif 'EstG' in varstring:\n",
        "        ta = np.arange(len(data[varstring[:-1]]))/250.+segstart\n",
        "\n",
        "    if td is not None:\n",
        "        return data, td\n",
        "    elif ta is not None:\n",
        "        return data, ta\n",
        "    else:\n",
        "        return data, None\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_nin_config(fname):\n",
        "    \"\"\"\n",
        "\n",
        "    Return info from NIN-M -Config.txt file as a dictionary.\n",
        "\n",
        "    RETURNS: dictionary of config-file info\n",
        "\"\"\"\n",
        "    if fname[-4:] in ['.edf','.bdf','.mat']:\n",
        "        fname = fname[:-4]+'.nin'\n",
        "    if 'Config' not in fname:\n",
        "        if '.nin' in fname:\n",
        "            fname = fname[:-4]+'-Config.txt'\n",
        "        else:\n",
        "            fname = fname+'-Config.txt'\n",
        "\n",
        "    PROBEgain = []\n",
        "    BOARDgain = []\n",
        "    f = open(fname,'r')\n",
        "    x = f.readline()\n",
        "    while x != \"\":\n",
        "        if \"Probe Gain\" in x:\n",
        "            for i in range(8):\n",
        "                x = f.readline()\n",
        "                PROBEgain += [list(map(int,x.strip()))]\n",
        "        elif \"Board Gain\" in x:\n",
        "            for i in range(8):\n",
        "                x = f.readline()\n",
        "                BOARDgain += [list(map(int,x.split()))]\n",
        "        elif \"Source Power\" in x:\n",
        "            x = f.readline()\n",
        "            SRCpower = list(map(int,x.split()))\n",
        "        elif \"E*G Setting\" in x:\n",
        "            x = f.readline()\n",
        "            EstGgain = list(map(int,str.split(x)))\n",
        "        elif \"Accel Setting\" in x:\n",
        "            x = f.readline()\n",
        "            ACC = int(str.strip(x))\n",
        "        elif \"Force Gain\" in x:\n",
        "            x = f.readline()\n",
        "            FORCE = int(str.strip(x))\n",
        "        elif \"TTL Trigger Out\" in x:\n",
        "            x = f.readline()\n",
        "            try:\n",
        "                TTLout = int(str.strip(x))\n",
        "            except:\n",
        "                TTLout = 0\n",
        "        elif \"TTL Trigger In\" in x:\n",
        "            x = f.readline()\n",
        "            try:\n",
        "                TTLin = int(str.strip(x))\n",
        "            except:\n",
        "                TTLin = 0\n",
        "        elif \"Digital In\" in x:\n",
        "            x = f.readline()\n",
        "            try:\n",
        "                Digital = int(str.strip(x))\n",
        "            except:\n",
        "                Digital = 0\n",
        "        elif \"Bluetooth\" in x:\n",
        "            x = f.readline()\n",
        "            try:\n",
        "                BT = int(str.strip(x))\n",
        "            except:\n",
        "                BT = 1\n",
        "        x = f.readline()\n",
        "\n",
        "    dct = {'PROBEgain':np.array(PROBEgain),\n",
        "            'BOARDgain':np.array(BOARDgain),\n",
        "            'SRCpower':SRCpower,\n",
        "            'EstGgain':EstGgain,\n",
        "            'ACCgain':ACC,\n",
        "            'FORCEgain':FORCE,\n",
        "            'TTLout':TTLout,\n",
        "            'TTLin':TTLin,\n",
        "            'DIGITALin':Digital,\n",
        "            'BT':BT}\n",
        "    return dct\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_nin_events(fname):\n",
        "    \"\"\"\n",
        "\n",
        "    Read in all events from a NIN-M/SE -Event.txt file.\n",
        "\n",
        "    RETURNS: 4 lists (ea,eb,ec,ed) of [timestamp, 250Hz_data_index] pairs\n",
        "    \"\"\"\n",
        "    if fname[-4:] in ['.edf','.bdf','.mat']:\n",
        "        fname = fname[:-4]+'.nin'\n",
        "    idx = fname.find('.nin')\n",
        "    prefix = fname[:idx]\n",
        "    f = open(prefix+'.nin','rb')\n",
        "    starttime = f.read(16)[1:-1]  # datetime is first 16 characters as [2015-0821-1553]\n",
        "    f.close()\n",
        "    #try:\n",
        "    f = open(\"Event-\"+prefix.split(\"-\")[-1]+'.txt','r')\n",
        "    #except:\n",
        "        #return [],[],[],[]\n",
        "\n",
        "    ea = []\n",
        "    eb = []\n",
        "    ec = []\n",
        "    ed = []\n",
        "    l = f.readlines()\n",
        "    if l:\n",
        "        for row in l[1:]:\n",
        "            try:\n",
        "                x = row.split()\n",
        "                dt = datetime.datetime(int(x[0][:4]),int(x[0][5:7]),int(x[0][7:9]),int(x[0][10:12]),int(x[0][13:15]),int(x[0][16:18]))\n",
        "                pt = int(str.lstrip(x[1],'0'))\n",
        "                button = x[2]\n",
        "                if button=='A':\n",
        "                    ea.append([time.mktime(dt.timetuple()),pt,])\n",
        "                elif button=='B':\n",
        "                    eb.append([time.mktime(dt.timetuple()),pt])\n",
        "                elif button=='C':\n",
        "                    ec.append([time.mktime(dt.timetuple()),pt])\n",
        "                elif button=='D':\n",
        "                    ed.append([time.mktime(dt.timetuple()),pt])\n",
        "            except:\n",
        "                pass\n",
        "        return ea,eb,ec,ed\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_nin_header(fname):\n",
        "    \"\"\"\n",
        "\n",
        "    Return info from NIN-M header as a dictionary. Currently only date, time & deviceID.\n",
        "\n",
        "    RETURNS:  dictionary of header info\n",
        "    \"\"\"\n",
        "    if fname[-4:] in ['.edf','.bdf','.mat']:\n",
        "        fname = fname[:-4]+'.nin'\n",
        "    f = open(fname,'rb')\n",
        "    data = str(f.read(512))\n",
        "    s = data.replace('[','')\n",
        "    lst = s.split(']')\n",
        "\n",
        "    y = lst[0][0:4]\n",
        "    m = lst[0][5:7]\n",
        "    d = lst[0][7:9]\n",
        "    dt = d +'.' +m +'.' +y   # using dots for EDF\n",
        "    H = lst[0][10:12]\n",
        "    M = lst[0][12:14]\n",
        "    S = lst[0][14:16]\n",
        "    tm = H +'.' +M +'.' +S   # using dots for EDF\n",
        "    dct = {'date':dt, 'time':tm}\n",
        "\n",
        "    dev = lst[1].split(':')\n",
        "    dct[dev[0]] = dev[1]\n",
        "\n",
        "    return dct\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def load_nin(fname,segstart=0,segend=-1,trim=1,keepraw=1,unwrapgain=1,verbose=False):\n",
        "    \"\"\"\n",
        "\n",
        "    Load in a time-segment of ALL data from a NIN-M recording.\n",
        "\n",
        "    RETURNS: a, td, ta, events, config\n",
        "    \"\"\"\n",
        "    if fname[-4:] in ['.edf','.bdf','.mat']:\n",
        "        fname = fname[:-4]+'.nin'\n",
        "    if verbose: print(fname)\n",
        "\n",
        "    ### LOAD DATASETS\n",
        "    if verbose: print(\"  Getting header\")\n",
        "    h = get_nin_header(fname)\n",
        "    if verbose: print(\"  Getting events\")\n",
        "    events = get_nin_events(fname)\n",
        "    if verbose: print(\"  Getting config\")\n",
        "    config = get_nin_config(fname)\n",
        "    if verbose: print(\"  Getting SRC\")\n",
        "    n,td = get_nin_data(fname,'SRC',segstart,segend)\n",
        "    if verbose: print(\"  Getting BKG\")\n",
        "    b,jnk = get_nin_data(fname,'BKG',segstart,segend)\n",
        "    n,b = nin_nirsarray(n,b)\n",
        "    if verbose: print(\"  Getting auxiliary\")\n",
        "    a,ta,jnk = get_nin_aux(fname,segstart,segend,verbose=verbose)\n",
        "    for k in list(a.keys()):\n",
        "        if len(a[k])==0:\n",
        "            a.pop(k)\n",
        "\n",
        "    ### TACK NIRS DATA ONTO DICTIONARY\n",
        "    a['SRC'] = n\n",
        "    a['BKGD'] = b\n",
        "\n",
        "    ### TRUNCATE ALL DATASETS TO CLEAN UP RIGHT EDGES\n",
        "    if trim:\n",
        "        if verbose: print(\"  Truncating to equal lengths\")\n",
        "        a, td, ta = trim_data(a,segstart=segstart,verbose=verbose)\n",
        "    else:\n",
        "        a['NIRS'] = n-b\n",
        "\n",
        "    ### REMOVE RAW DATA IF REQUESTED\n",
        "    config['keepraw'] = keepraw\n",
        "    if not keepraw:\n",
        "        a.pop('SRC')\n",
        "        a.pop('BKGD')\n",
        "\n",
        "    ### CLIP ANY NEG/SMALL VALUES; DO THIS //BEFORE// UNWRAP GAINS\n",
        "    a['NIRS'] = np.where(a['NIRS']<10,10,a['NIRS'])\n",
        "\n",
        "    ### PUT HEADER INTO INTO CONFIG\n",
        "    config.update(h)\n",
        "    config['gainunwrapped'] = 0\n",
        "\n",
        "    return a, td, ta, events, config\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def nin2plotdata(fname,segstart=0,segend=-1,trim=1,unwrapgain=1,keepraw=1,\n",
        "                 force='forc',acceltype=200,GSR=[],GSRcalibwin=[],\n",
        "                 basiconly=False,SNRwindow=[0,20],BLs=[6,6],ODoffsetstep=0.3,CONCoffsetstep=10,geometry=None,SNRthresh=5,\n",
        "                 NINbaseline=None,notchfilt=[],filt_param=DEFAULTfilt_param,savePNG=False,verbose=True):\n",
        "\n",
        "\n",
        "    ### LOAD IN ALL DATA\n",
        "    print(\"Loading %s as NIN-M file\" %fname)\n",
        "    tmp, td, ta, events, config = load_nin(fname,segstart,segend,trim=1,keepraw=1,verbose=verbose)\n",
        "    ea,eb,ec,ed = events\n",
        "\n",
        "    print(\"BEFORE CONVERSION:\", list(tmp.keys()))\n",
        "\n",
        "    ### CONVERT AUXILIARY UNITS, IF REQUESTED\n",
        "    if acceltype==0:  # don't convert anything\n",
        "        a = {}\n",
        "        for k in tmp.keys():\n",
        "            a[k] = tmp[k]\n",
        "    else:\n",
        "        a,config = nin_convert(tmp,config,unwrapgain=unwrapgain,acceltype=acceltype,force='forc',\n",
        "                             notchfilt=notchfilt,filt_param=filt_param,verbose=verbose)\n",
        "\n",
        "    print(\"AFTER CONVERSION:\", list(a.keys()))\n",
        "\n",
        "    del tmp  # save some memory, this is big\n",
        "    raw = a['SRC']\n",
        "    bkgd = a['BKGD']\n",
        "    diff = raw-bkgd\n",
        "\n",
        "    ### COMPUTE \"GOOD\" MEASUREMENT LIST\n",
        "    ml = nin_ML(diff,config['BOARDgain'],GAINthresh=16,SNRwindow=SNRwindow,SNRthresh=SNRthresh,DISTthresh=75,verbose=False,geometry=geometry)\n",
        "\n",
        "    ### CONVERT TO OD\n",
        "    od = nin_makeOD(diff,baseline=NINbaseline)\n",
        "\n",
        "    ### CONVERT TO CONCENTRATIONS\n",
        "    if not basiconly:\n",
        "        hbhbo,hbhboml = nin_od2hbhbo(od, wavelengths=DEFAULTwavelengths, BLs=BLs)\n",
        "\n",
        "    ### PRUNE DATA TO KEEP ONLY GOOD MEASUREMENTS\n",
        "    if not basiconly:\n",
        "        pdiff = prune_data(diff,ml,bothwavelengths=False)\n",
        "        pod = prune_data(od,ml,bothwavelengths=False)\n",
        "        phbhbo = prune_hbdata(hbhbo,hbhboml)\n",
        "\n",
        "    ### RETURN DATA\n",
        "    if basiconly:\n",
        "        return {'a':a, 'td':td, 'ta':ta, 'events':events, 'config':config, 'ml':ml, 'od':od}\n",
        "    else:\n",
        "        return {'a':a, 'td':td, 'ta':ta, 'events':events, 'config':config, 'ml':ml, 'od':od,\n",
        "                'hbhbo':hbhbo, 'hbhboml':hbhboml, 'pdiff':pdiff, 'pod':pod, 'phbhbo':phbhbo}\n"
      ],
      "metadata": {
        "id": "m4rbzLbHDwta"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "from glob import glob\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from __future__ import absolute_import\n",
        "#import nintools_v34 as nt\n",
        "fname = sys.argv[1]\n",
        "\n",
        "import sys\n",
        "import numpy as np\n",
        "from pylab import *\n",
        "from six.moves import range\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "data_path = \"/content\"\n",
        "nin_path_list = glob(data_path+\"/*.nin\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "new_keys=[]\n",
        "keys=['key1','key2','key3','key4']\n",
        "for i in nin_path_list:\n",
        "  i=widgets.Checkbox(\n",
        "    value=False,\n",
        "    description=i,\n",
        "    disabled=False,\n",
        "    indent=False\n",
        "    )\n",
        "  display(i)\n",
        "  new_keys.append(i)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79,
          "referenced_widgets": [
            "4b75605c183d4465b490c230fb5bc240",
            "94686f89e7cc4d9c8e45042878be0b21",
            "d3b30e5cc8524294a12b81762d1683f8",
            "d61ec988ca6848a2ba5368754b2d0694",
            "2dfb2d5b195049149dd9b79eb9541d55",
            "c0b3cf2040184e63b551809eb5cd5205"
          ]
        },
        "id": "k5ma9WyIOP5O",
        "outputId": "81f6fa2c-b318-49c5-b791-0e24e4f535d1"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Checkbox(value=False, description='/content/2022-0318-115200-50228.nin', indent=False)"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b75605c183d4465b490c230fb5bc240"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Checkbox(value=False, description='/content/2022-0318-115200-50227.nin', indent=False)"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d61ec988ca6848a2ba5368754b2d0694"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_path = []\n",
        "\n",
        "for i in range(len(new_keys)):\n",
        "  if new_keys[i].value ==True:\n",
        "    new_path.append(new_keys[i].description)\n",
        "\n",
        "\n",
        "single_path = new_path[0]"
      ],
      "metadata": {
        "id": "1ZNts3a5OVL8"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "RYsJcl6IDex1"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\"\"\"\n",
        "SRC = TIME x 64 @25Hz\n",
        "BKGD = TIME x 64 @25Hz\n",
        "NIRS = SRC-BKGD, TIME x 64 @25Hz\n",
        "ACCE = TIME x 3 (x,y,z) @250Hz\n",
        "EstG = Time x 8  (ch0-7) @250Hz\n",
        "FORC = TIME x 1  @25 Hz\n",
        "GYRO = TIME x 3 (p,r,y) @250Hz\n",
        "RESP = TIME x 1  @25Hz\n",
        "TEMP = TIME x 1  @25Hz\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "# LOAD IN ALL DATA\n",
        "d = nin2plotdata(single_path)\n",
        "\n",
        "# ASSIGNMENTS TO MAKE REFERENCING EASIER\n",
        "td = d['td']\n",
        "ta = d['ta']\n",
        "a = d['a']\n",
        "\n",
        "acce = a['ACCE']\n",
        "estg = a['EstG']\n",
        "temp = a['TEMP']\n",
        "forc = a['FORC']\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3EBrevHmKqyU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}